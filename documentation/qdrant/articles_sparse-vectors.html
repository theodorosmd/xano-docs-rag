<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta charset=UTF-8><title>What is a Sparse Vector? How to Achieve Vector-based Hybrid Search - Qdrant</title>
<link rel=icon href=https://qdrant.tech/favicon/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=https://qdrant.tech/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://qdrant.tech/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://qdrant.tech/favicon/favicon-16x16.png><link rel=manifest href=https://qdrant.tech/favicon/site.webmanifest><link rel=mask-icon href=https://qdrant.tech/favicon/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#2b5797"><meta name=msapplication-config content="/favicon/browserconfig.xml"><meta name=theme-color content="#ffffff"><meta name=partition content="learn"><link href=https://qdrant.tech/css/search/search.min.09596ee2b3c94d0ac82a1c33199cabdb3e0210b1ee46aaf1515200e9e484d05dd9e27cc1e861c58cc2e582af162f63b8e180ff2a12f7a6592b7aeaa0a7125130.css rel=stylesheet integrity="sha512-CVlu4rPJTQrIKhwzGZyr2z4CELHuRqrxUVIA6eSE0F3Z4nzB6GHFjMLlgq8WL2O44YD/KhL3plkreuqgpxJRMA=="><link href=https://qdrant.tech/css/documentation.min.de204cdcfc410689a41c17bcdad0a34f2caaa50cc8505c820adaab481cef2d69a920b0a32e0d624701c29487e3271b694559d98c5047cbfaa5aa475f638011e5.css rel=stylesheet integrity="sha512-3iBM3PxBBomkHBe82tCjTyyqpQzIUFyCCtqrSBzvLWmpILCjLg1iRwHClIfjJxtpRVnZjFBHy/qlqkdfY4AR5Q=="><link href=https://qdrant.tech/css/main.min.c1e379ad4cf03647832f6a0f040754b0be3e79934db2c29f50b396327c1ec7ac45f778abadbd93f5a8bc431850d1b0d9c9eff34c0171cd4236e83c5e324c1a0e.css rel=stylesheet integrity crossorigin=anonymous><meta name=generator content="Hugo 0.141.0"><meta name=description content="Learn what sparse vectors are, how they work, and their importance in modern data processing. Explore methods like SPLADE for creating and leveraging sparse vectors efficiently."><meta name=keywords content="sparse vectors,SPLADE,hybrid search,vector search,qdrant"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@id":"https://qdrant.tech/articles/sparse-vectors/#article","@type":"Article","abstract":"Learn what sparse vectors are how they work and their importance in modern data processing Explore methods like SPLADE for creating and leveraging sparse vectors efficiently","author":{"@type":"Person","name":"Nirant Kasliwal"},"dateModified":"2023-12-09 13:00:00 +0300 +0300","datePublished":"2023-12-09 13:00:00 +0300 +0300","description":"Learn what sparse vectors are how they work and their importance in modern data processing Explore methods like SPLADE for creating and leveraging sparse vectors efficiently","headline":"What is a Sparse Vector? How to Achieve Vector-based Hybrid Search","image":["https://qdrant.tech/articles_data/sparse-vectors/social_preview.png"],"name":"What is a Sparse Vector? How to Achieve Vector-based Hybrid Search","url":"https://qdrant.tech/articles/sparse-vectors/","wordCount":"3461"},{"@id":"https://qdrant.tech/articles/sparse-vectors/#organization","@type":"Organization","address":{"@type":"PostalAddress","addressCountry":"DE","addressLocality":"Berlin","addressRegion":"Berlin","postalCode":"10115","streetAddress":"Chausseestraße 86"},"contactPoint":{"@type":"ContactPoint","contactType":"customer support","email":"info@qdrant.com","telephone":"+49 3040797694"},"description":"Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.","email":"info@qdrant.com","founders":[{"@type":"Person","name":"map[email:info@qdrant.tech name:Andrey Vasnetsov]"},{"@type":"Person","name":"Andre Zayarni"}],"foundingDate":"2021","keywords":["sparse vectors","SPLADE","hybrid search","vector search","Qdrant"],"legalName":"Qdrant Solutions GmbH","location":"Berlin, Germany","logo":"https://qdrant.tech/images/logo_with_text.png","name":"Qdrant","sameAs":["https://github.com/qdrant/qdrant","https://qdrant.to/discord","https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA","https://www.linkedin.com/company/qdrant/","https://twitter.com/qdrant_engine"],"url":"https://qdrant.tech"}]}</script><meta property="og:url" content="https://qdrant.tech/articles/sparse-vectors/"><meta property="og:type" content="website"><meta property="og:title" content="What is a Sparse Vector? How to Achieve Vector-based Hybrid Search - Qdrant"><meta name=twitter:card content="summary_large_image"><meta name=twitter:domain content="qdrant"><meta name=twitter:url content="https://qdrant.tech/articles/sparse-vectors/"><meta name=twitter:title content="What is a Sparse Vector? How to Achieve Vector-based Hybrid Search - Qdrant"><meta property="og:description" content="Learn what sparse vectors are, how they work, and their importance in modern data processing. Explore methods like SPLADE for creating and leveraging sparse vectors efficiently."><meta name=twitter:description content="Learn what sparse vectors are, how they work, and their importance in modern data processing. Explore methods like SPLADE for creating and leveraging sparse vectors efficiently."><meta name=image property="og:image" content="https://qdrant.tech/articles_data/sparse-vectors/social_preview.png"><meta name=image property="og:image:secure_url" content="https://qdrant.tech/articles_data/sparse-vectors/social_preview.png"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name=twitter:image:src content="https://qdrant.tech/articles_data/sparse-vectors/social_preview.png"><meta name=author content="Nirant Kasliwal"><link rel=canonical href=https://qdrant.tech/articles/sparse-vectors/><script type=text/javascript src=//js-eu1.hsforms.net/forms/embed/v2.js></script><script src=https://qdrant.tech/js/documentation.min.594fc9226f6fb87b8c3b0cafb9d5c0b0bcd95f47d292b929aab04315e0506706b2f376dc4fae9961dc3082138cb19d45b2a3370ee8e881bbf4b8c91dcb735c32.js></script></head><body><main><header class=docs-header><div class="main-menu z-5"><a href=https://qdrant.tech/><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div></a><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><div class="d-block d-xl-none"><button role=button class=theme-switch></button></div><button type=button class=main-menu__trigger><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M1 12H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 5H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 19H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=main-menu__links><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/>Qdrant</a></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/cloud-intro/>Cloud</a></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/build/>Build</a></li><li class=main-menu__item><a class=menu-linkactive href=https://qdrant.tech/articles/>Learn</a></li><li class=main-menu__item><a class=menu-link href=https://api.qdrant.tech/api-reference target=_blank>API Reference</a></li></ul><div class=main-menu__buttons><div class=main-menu__buttons-input><button class="qdr-search-input-btn q-input input_md input_light-bg" type=button name=search data-target=#searchModal>
Search</button></div><button role=button class=theme-switch></button>
<a data-metric-loc=nav href=https://cloud.qdrant.io/login class="menu-link mx-3" target=_blank>Log in</a>
<a data-metric-loc=nav href=https://cloud.qdrant.io/signup class="button button_contained button_sm" target=_blank>Start Free</a></div></div><div class=menu-mobile><div class=menu-mobile__header><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><div class="d-block d-xl-none"><button role=button class=theme-switch></button></div><button type=button class=menu-mobile__close><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><g id="Close"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M19.778 5.63606C20.1685 5.24554 20.1685 4.61237 19.778 4.22185 19.3874 3.83132 18.7543 3.83132 18.3637 4.22185L11.9998 10.5858 5.63586 4.22185c-.39052-.39053-1.02369-.39053-1.41421.0C3.83112 4.61237 3.83112 5.24554 4.22165 5.63606L10.5856 12l-6.364 6.364C3.83108 18.7545 3.83108 19.3877 4.2216 19.7782 4.61213 20.1687 5.24529 20.1687 5.63582 19.7782l6.36398-6.364 6.364 6.364C18.7543 20.1687 19.3875 20.1687 19.778 19.7782 20.1685 19.3877 20.1685 18.7545 19.778 18.364L13.414 12l6.364-6.36394z" fill="#e1e5f0"/></g></svg></button></div></div><div class=main-menu__buttons-input><button class="qdr-search-input-btn q-input input_md input_light-bg" type=button name=search data-target=#searchModal>
Search</button></div><ul class=menu-mobile__items><li class=menu-mobile__item data-path=menu-0><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Documentation"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M4.25 1c-1.10092.0-2.12247.23681-2.88689.64443C.620129 2.04063.0 2.67297.0 3.5v11c0 .2761.223858.5.5.5s.5-.2239.5-.5c0-.278.21937-.6456.83364-.9732C2.42647 13.2107 3.27992 13 4.25 13 5.22008 13 6.07353 13.2107 6.66636 13.5268c.61427.3276.83364.6952.83364.9732.0.2761.22386.5.5.5s.5-.2239.5-.5c0-.278.21937-.6456.833640000000001-.9732C9.92647 13.2107 10.7799 13 11.75 13S13.5735 13.2107 14.1664 13.5268C14.7806 13.8544 15 14.222 15 14.5c0 .2761.2239.5.5.5s.5-.2239.5-.5V3.5C16 2.67297 15.3799 2.04063 14.6369 1.64443 13.8725 1.23681 12.8509 1 11.75 1s-2.12247.23681-2.88689.64443C8.53799 1.8178 8.2364 2.03638 8 2.29671c-.2364-.26033-.53799-.47891-.86311-.65228C6.37247 1.23681 5.35092 1 4.25 1zM1.36311 12.6444C1.23778 12.7113 1.11595 12.7848 1 12.8649V3.5c0-.27797.21937-.64563.83364-.97318C2.42647 2.21069 3.27992 2 4.25 2c.97008.0 1.82353.21069 2.41636.52682C7.28063 2.85437 7.5 3.22203 7.5 3.5v9.3649C7.38405 12.7848 7.26222 12.7113 7.13689 12.6444 6.37247 12.2368 5.35092 12 4.25 12 3.14908 12 2.12753 12.2368 1.36311 12.6444zM8.5 12.8649C8.61595 12.7848 8.73778 12.7113 8.86311 12.6444 9.62753 12.2368 10.6491 12 11.75 12S13.8725 12.2368 14.6369 12.6444C14.7622 12.7113 14.8841 12.7848 15 12.8649V3.5C15 3.22203 14.7806 2.85437 14.1664 2.52682 13.5735 2.21069 12.7201 2 11.75 2s-1.82353.21069-2.41636.52682C8.71937 2.85437 8.5 3.22203 8.5 3.5v9.3649z"/></g></svg>
Qdrant</a></div></li><li class=menu-mobile__item data-path=menu-1><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/cloud-intro/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Cloud"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M7.5 2C4.57416 2 2.18128 4.28566 2.00983 7.16851.8403 7.57763.0 8.68965.0 10c0 1.6571 1.34286 3 3 3H13c1.6571.0 3-1.3429 3-3 0-1.65714-1.3429-3-3-3L12.9776 7.00009C12.7249 4.19714 10.3686 2 7.5 2zM3.00107 7.48137 3.00008 7.47308C3.01457 5.0006 5.02412 3 7.5 3c2.47599.0 4.4856 2.00079 4.4999 4.47342L11.9987 7.4836C11.9969 7.50027 11.995 7.52348 11.995 7.551 11.995 7.701 12.0623 7.84308 12.1785 7.93804 12.2946 8.03301 12.4472 8.07082 12.5942 8.04106 12.726 8.01438 12.8617 8 13 8c1.1049.0 2 .89514 2 2C15 11.1049 14.1049 12 13 12H3C1.89514 12 1 11.1049 1 10 1 9.03225 1.68901 8.22422 2.60364 8.04017 2.83708 7.9932 3.005 7.78812 3.005 7.55 3.005 7.52154 3.00291 7.49773 3.00107 7.48137z"/></g></svg>
Cloud</a></div></li><li class=menu-mobile__item data-path=menu-2><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/build/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Blog"><path id="Union" fill-rule="evenodd" clip-rule="evenodd" d="M0 1.5C0 1.22386.223858 1 .5 1h5c.27614.0.5.22386.5.5v5c0 .27614-.22386.5-.5.5H.5C.223858 7 0 6.77614.0 6.5v-5zM1 2V6H5V2H1zm7 .5c0-.27614.22386-.5.5-.5h7c.2761.0.5.22386.5.5s-.2239.5-.5.5h-7C8.22386 3 8 2.77614 8 2.5zM8.5 6c-.27614.0-.5.22386-.5.5s.22386.5.5.5h7c.2761.0.5-.22386.5-.5s-.2239-.5-.5-.5h-7zM0 10.5c0-.2761.223858-.5.5-.5h15c.2761.0.5.2239.5.5s-.2239.5-.5.5H.5c-.276142.0-.5-.2239-.5-.5zM.5 14c-.276142.0-.5.2239-.5.5s.223858.5.5.5h15c.2761.0.5-.2239.5-.5s-.2239-.5-.5-.5H.5z"/></g></svg>
Build</a></div></li><li class=menu-mobile__item data-path=menu-3><div class=menu-mobile__item-content><a class=active href=https://qdrant.tech/articles/><svg width="16" height="16" viewBox="0 0 16 16" fill="none" stroke="#e1e5f0"><g id="Group"><path id="Vector" d="M10.084 1.84094l4.059 4.059" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_2" d="M8.49188 2.72406c-1.22044-.53042-2.59304-.59475-3.85774-.1808-1.2647.41395-2.33363 1.27742-3.00426 2.4268l2.34 2.34" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_3" d="M13.2657 7.47302C13.8062 8.69691 13.8769 10.077 13.4645 11.3497c-.4125 1.2728-1.2792 2.3491-2.4348 3.0233l-2.35001-2.35" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_4" d="M6.81217 13.049l-3.861-3.861S6.24917.983 15.5002.5c-.523 9.211-8.68803 12.549-8.68803 12.549z" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_5" d="M3.59892 12.4008C3.34181 12.1441 2.99331 12 2.62995 12c-.36335.0-.71186.1441-.96897.4008-.46665.4664-.63131 1.941-.65931 2.2322C.997021 14.6793 1.0021 14.726 1.01659 14.7701 1.03108 14.8143 1.05465 14.8549 1.08579 14.8895 1.11693 14.924 1.15495 14.9516 1.19741 14.9705 1.23987 14.9895 1.28583 14.9994 1.33233 14.9995 1.34298 15.0002 1.35367 15.0002 1.36433 14.9995 1.65565 14.9715 3.1316 14.8063 3.59759 14.3405 3.85501 14.0834 3.99975 13.7346 4 13.3709 4.00025 13.0072 3.85599 12.6582 3.59892 12.4008z" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_6" d="M9 8c.55228.0 1-.44772 1-1S9.55228 6 9 6 8 6.44772 8 7s.44772 1 1 1z"/></g></svg>
Learn</a></div></li><li class=menu-mobile__item data-path=menu-4><div class=menu-mobile__item-content><a href=https://api.qdrant.tech/api-reference target=_blank><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Roadmap" clip-path="url(#clip0_7182_4311)"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M13.5 1c-.8284.0-1.5.67157-1.5 1.5S12.6716 4 13.5 4 15 3.32843 15 2.5 14.3284 1 13.5 1zM11 2.5C11 1.11929 12.1193.0 13.5.0S16 1.11929 16 2.5 14.8807 5 13.5 5 11 3.88071 11 2.5zM2.5 12c-.82843.0-1.5.6716-1.5 1.5S1.67157 15 2.5 15 4 14.3284 4 13.5 3.32843 12 2.5 12zM0 13.5C0 12.1193 1.11929 11 2.5 11S5 12.1193 5 13.5 3.88071 16 2.5 16 0 14.8807.0 13.5zM3.65901 1.65901C4.08097 1.23705 4.65326 1 5.25 1s1.16903.23705 1.59099.65901C7.26295 2.08097 7.5 2.65326 7.5 3.25v9.5c0 .862.34241 1.6886.9519 2.2981C9.0614 15.6576 9.88805 16 10.75 16c.862.0 1.6886-.3424 2.2981-.9519S14 13.612 14 12.75V6.5c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v6.25C13 13.3467 12.7629 13.919 12.341 14.341 11.919 14.7629 11.3467 15 10.75 15S9.58097 14.7629 9.15901 14.341C8.73705 13.919 8.5 13.3467 8.5 12.75V3.25C8.5 2.38805 8.15759 1.5614 7.5481.951903 6.9386.34241 6.11195.0 5.25.0S3.5614.34241 2.9519.951903C2.34241 1.5614 2 2.38805 2 3.25V9.5c0 .27614.22386.5.5.5s.5-.22386.5-.5V3.25c0-.59674.23705-1.16903.65901-1.59099z"/></g><defs><clipPath id="clip0_7182_4311"><rect width="16" height="16" fill="#fff"/></clipPath></defs></svg>
API Reference</a></div></li></ul><div class=docs-menu><div id=sidebar class=docs-menu__content><h3 class=docs-menu__links-title>Learn</h3><nav><div class=docs-menu__links-group><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/vector-search-manuals/>Vector Search Manuals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/qdrant-internals/>Qdrant Internals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/data-exploration/>Data Exploration</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/machine-learning/>Machine Learning</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/rag-and-genai/>RAG & GenAI</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/practicle-examples/>Practical Examples</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/ecosystem/>Ecosystem</a></div></div></nav></div></div></div></header><section class="docs documentation"><div class=documentation__container><div class="d-flex flex-column flex-xl-row"><div class=docs-menu><div id=sidebar class=docs-menu__content><h3 class=docs-menu__links-title>Learn</h3><nav><div class=docs-menu__links-group><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/vector-search-manuals/>Vector Search Manuals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/qdrant-internals/>Qdrant Internals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/data-exploration/>Data Exploration</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/machine-learning/>Machine Learning</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/rag-and-genai/>RAG & GenAI</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/practicle-examples/>Practical Examples</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/ecosystem/>Ecosystem</a></div></div></nav></div></div><div class=documentation__content><div class=documentation__content-wrapper><div class=documentation__article-wrapper><ul class=docs-breadcrumbs><li class=docs-breadcrumbs__crumb><a href=https://qdrant.tech/articles/>Articles</a></li><li class=docs-breadcrumbs__crumb-separator></li><li class=docs-breadcrumbs__crumb>What is a Sparse Vector? How to Achieve Vector-based Hybrid Search</li></ul><article class=documentation-article><div class=documentation-article__header><a href=https://qdrant.tech/articles/vector-search-manuals/ class=documentation-article__header-link><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path d="M14.6668 8.00004H1.3335m0 0L6.00016 12.6667M1.3335 8.00004 6.00016 3.33337" stroke="#8f98b3" stroke-width="1.33333" stroke-linecap="round" stroke-linejoin="round"/></svg>
Back to Vector Search Manuals</a><h1 class=documentation-article__header-title>What is a Sparse Vector? How to Achieve Vector-based Hybrid Search</h1><div class=documentation-article__header-about><p>Nirant Kasliwal</p><span>&#183;</span><p>December 09, 2023</p></div><picture class=documentation-article__header-preview><source srcset=https://qdrant.tech/articles_data/sparse-vectors/preview/title.webp type=image/webp><img alt="What is a Sparse Vector? How to Achieve Vector-based Hybrid Search" src=https://qdrant.tech/articles_data/sparse-vectors/preview/title.jpg></picture></div><p>Think of a library with a vast index card system. Each index card only has a few keywords marked out (sparse vector) of a large possible set for each book (document). This is what sparse vectors enable for text.</p><h2 id=what-are-sparse-and-dense-vectors>What are sparse and dense vectors?</h2><p>Sparse vectors are like the Marie Kondo of data—keeping only what sparks joy (or relevance, in this case).</p><p>Consider a simplified example of 2 documents, each with 200 words. A dense vector would have several hundred non-zero values, whereas a sparse vector could have, much fewer, say only 20 non-zero values.</p><p>In this example: We assume it selects only 2 words or tokens from each document. The rest of the values are zero. This is why it&rsquo;s called a sparse vector.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>dense</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.2</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.7</span><span class=p>,</span> <span class=o>...</span><span class=p>]</span>  <span class=c1># several hundred floats</span>
</span></span><span class=line><span class=cl><span class=n>sparse</span> <span class=o>=</span> <span class=p>[{</span><span class=mi>331</span><span class=p>:</span> <span class=mf>0.5</span><span class=p>},</span> <span class=p>{</span><span class=mi>14136</span><span class=p>:</span> <span class=mf>0.7</span><span class=p>}]</span>  <span class=c1># 20 key value pairs</span>
</span></span></code></pre></div><p>The numbers 331 and 14136 map to specific tokens in the vocabulary e.g. <code>['chocolate', 'icecream']</code>. The rest of the values are zero. This is why it&rsquo;s called a sparse vector.</p><p>The tokens aren&rsquo;t always words though, sometimes they can be sub-words: <code>['ch', 'ocolate']</code> too.</p><p>They&rsquo;re pivotal in information retrieval, especially in ranking and search systems. BM25, a standard ranking function used by search engines like <a href="https://www.elastic.co/blog/practical-bm25-part-2-the-bm25-algorithm-and-its-variables?utm_source=qdrant&amp;utm_medium=website&amp;utm_campaign=sparse-vectors&amp;utm_content=article&amp;utm_term=sparse-vectors" target=_blank rel="noopener nofollow">Elasticsearch</a>, exemplifies this. BM25 calculates the relevance of documents to a given search query.</p><p>BM25&rsquo;s capabilities are well-established, yet it has its limitations.</p><p>BM25 relies solely on the frequency of words in a document and does not attempt to comprehend the meaning or the contextual importance of the words. Additionally, it requires the computation of the entire corpus&rsquo;s statistics in advance, posing a challenge for large datasets.</p><p>Sparse vectors harness the power of neural networks to surmount these limitations while retaining the ability to query exact words and phrases.
They excel in handling large text data, making them crucial in modern data processing a and marking an advancement over traditional methods such as BM25.</p><h2 id=understanding-sparse-vectors>Understanding sparse vectors</h2><p>Sparse Vectors are a representation where each dimension corresponds to a word or subword, greatly aiding in interpreting document rankings. This clarity is why sparse vectors are essential in modern search and recommendation systems, complimenting the meaning-rich embedding or dense vectors.</p><p>Dense vectors from models like OpenAI Ada-002 or Sentence Transformers contain non-zero values for every element. In contrast, sparse vectors focus on relative word weights per document, with most values being zero. This results in a more efficient and interpretable system, especially in text-heavy applications like search.</p><p>Sparse Vectors shine in domains and scenarios where many rare keywords or specialized terms are present.
For example, in the medical domain, many rare terms are not present in the general vocabulary, so general-purpose dense vectors cannot capture the nuances of the domain.</p><div class=table-responsive><table class="table mb-5"><thead><tr><th>Feature</th><th>Sparse Vectors</th><th>Dense Vectors</th></tr></thead><tbody><tr><td><strong>Data Representation</strong></td><td>Majority of elements are zero</td><td>All elements are non-zero</td></tr><tr><td><strong>Computational Efficiency</strong></td><td>Generally higher, especially in operations involving zero elements</td><td>Lower, as operations are performed on all elements</td></tr><tr><td><strong>Information Density</strong></td><td>Less dense, focuses on key features</td><td>Highly dense, capturing nuanced relationships</td></tr><tr><td><strong>Example Applications</strong></td><td>Text search, Hybrid search</td><td><a href=https://qdrant.tech/articles/what-is-rag-in-ai/ target=_blank rel="noopener nofollow">RAG</a>, many general machine learning tasks</td></tr></tbody></table></div><p>Where do sparse vectors fail though? They&rsquo;re not great at capturing nuanced relationships between words. For example, they can&rsquo;t capture the relationship between &ldquo;king&rdquo; and &ldquo;queen&rdquo; as well as dense vectors.</p><h2 id=splade>SPLADE</h2><p>Let&rsquo;s check out <a href="https://europe.naverlabs.com/research/computer-science/splade-a-sparse-bi-encoder-bert-based-model-achieves-effective-and-efficient-full-text-document-ranking/?utm_source=qdrant&amp;utm_medium=website&amp;utm_campaign=sparse-vectors&amp;utm_content=article&amp;utm_term=sparse-vectors" target=_blank rel="noopener nofollow">SPLADE</a>, an excellent way to make sparse vectors. Let&rsquo;s look at some numbers first. Higher is better:</p><div class=table-responsive><table class="table mb-5"><thead><tr><th>Model</th><th>MRR@10 (MS MARCO Dev)</th><th>Type</th></tr></thead><tbody><tr><td>BM25</td><td>0.184</td><td>Sparse</td></tr><tr><td>TCT-ColBERT</td><td>0.359</td><td>Dense</td></tr><tr><td>doc2query-T5 <a href=https://github.com/castorini/docTTTTTquery target=_blank rel="noopener nofollow">link</a></td><td>0.277</td><td>Sparse</td></tr><tr><td>SPLADE</td><td>0.322</td><td>Sparse</td></tr><tr><td>SPLADE-max</td><td>0.340</td><td>Sparse</td></tr><tr><td>SPLADE-doc</td><td>0.322</td><td>Sparse</td></tr><tr><td>DistilSPLADE-max</td><td>0.368</td><td>Sparse</td></tr></tbody></table></div><p>All numbers are from <a href=https://arxiv.org/abs/2109.10086 target=_blank rel="noopener nofollow">SPLADEv2</a>. MRR is <a href=https://www.wikiwand.com/en/Mean_reciprocal_rank#References target=_blank rel="noopener nofollow">Mean Reciprocal Rank</a>, a standard metric for ranking. <a href="https://microsoft.github.io/MSMARCO-Passage-Ranking/?utm_source=qdrant&amp;utm_medium=website&amp;utm_campaign=sparse-vectors&amp;utm_content=article&amp;utm_term=sparse-vectors" target=_blank rel="noopener nofollow">MS MARCO</a> is a dataset for evaluating ranking and retrieval for passages.</p><p>SPLADE is quite flexible as a method, with regularization knobs that can be tuned to obtain <a href=https://github.com/naver/splade target=_blank rel="noopener nofollow">different models</a> as well:</p><blockquote><p>SPLADE is more a class of models rather than a model per se: depending on the regularization magnitude, we can obtain different models (from very sparse to models doing intense query/doc expansion) with different properties and performance.</p></blockquote><p>First, let&rsquo;s look at how to create a sparse vector. Then, we&rsquo;ll look at the concepts behind SPLADE.</p><h2 id=creating-a-sparse-vector>Creating a sparse vector</h2><p>We&rsquo;ll explore two different ways to create a sparse vector. The higher performance way to create a sparse vector from dedicated document and query encoders. We&rsquo;ll look at a simpler approach &ndash; here we will use the same model for both document and query. We will get a dictionary of token ids and their corresponding weights for a sample text - representing a document.</p><p>If you&rsquo;d like to follow along, here&rsquo;s a <a href=https://colab.research.google.com/gist/NirantK/ad658be3abefc09b17ce29f45255e14e/splade-single-encoder.ipynb target=_blank rel="noopener nofollow">Colab Notebook</a>, <a href=https://gist.github.com/NirantK/ad658be3abefc09b17ce29f45255e14e target=_blank rel="noopener nofollow">alternate link</a> with all the code.</p><h3 id=setting-up>Setting Up</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoModelForMaskedLM</span><span class=p>,</span> <span class=n>AutoTokenizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model_id</span> <span class=o>=</span> <span class=s2>&#34;naver/splade-cocondenser-ensembledistil&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForMaskedLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=s2>&#34;&#34;&#34;Arthur Robert Ashe Jr. (July 10, 1943 – February 6, 1993) was an American professional tennis player. He won three Grand Slam titles in singles and two in doubles.&#34;&#34;&#34;</span>
</span></span></code></pre></div><h3 id=computing-the-sparse-vector>Computing the sparse vector</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>compute_vector</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Computes a vector from logits and attention mask using ReLU, log, and max operations.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>tokens</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=p>(</span><span class=n>text</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=o>**</span><span class=n>tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logits</span><span class=p>,</span> <span class=n>attention_mask</span> <span class=o>=</span> <span class=n>output</span><span class=o>.</span><span class=n>logits</span><span class=p>,</span> <span class=n>tokens</span><span class=o>.</span><span class=n>attention_mask</span>
</span></span><span class=line><span class=cl>    <span class=n>relu_log</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=mi>1</span> <span class=o>+</span> <span class=n>torch</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>logits</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>weighted_log</span> <span class=o>=</span> <span class=n>relu_log</span> <span class=o>*</span> <span class=n>attention_mask</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>max_val</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>weighted_log</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>vec</span> <span class=o>=</span> <span class=n>max_val</span><span class=o>.</span><span class=n>squeeze</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>vec</span><span class=p>,</span> <span class=n>tokens</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>vec</span><span class=p>,</span> <span class=n>tokens</span> <span class=o>=</span> <span class=n>compute_vector</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>vec</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span></code></pre></div><p>You&rsquo;ll notice that there are 38 tokens in the text based on this tokenizer. This will be different from the number of tokens in the vector. In a TF-IDF, we&rsquo;d assign weights only to these tokens or words. In SPLADE, we assign weights to all the tokens in the vocabulary using this vector using our learned model.</p><h2 id=term-expansion-and-weights>Term expansion and weights</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>extract_and_map_sparse_vector</span><span class=p>(</span><span class=n>vector</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Extracts non-zero elements from a given vector and maps these elements to their human-readable tokens using a tokenizer. The function creates and returns a sorted dictionary where keys are the tokens corresponding to non-zero elements in the vector, and values are the weights of these elements, sorted in descending order of weights.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    This function is useful in NLP tasks where you need to understand the significance of different tokens based on a model&#39;s output vector. It first identifies non-zero values in the vector, maps them to tokens, and sorts them by weight for better interpretability.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>    vector (torch.Tensor): A PyTorch tensor from which to extract non-zero elements.
</span></span></span><span class=line><span class=cl><span class=s2>    tokenizer: The tokenizer used for tokenization in the model, providing the mapping from tokens to indices.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>    dict: A sorted dictionary mapping human-readable tokens to their corresponding non-zero weights.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Extract indices and values of non-zero elements in the vector</span>
</span></span><span class=line><span class=cl>    <span class=n>cols</span> <span class=o>=</span> <span class=n>vector</span><span class=o>.</span><span class=n>nonzero</span><span class=p>()</span><span class=o>.</span><span class=n>squeeze</span><span class=p>()</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>weights</span> <span class=o>=</span> <span class=n>vector</span><span class=p>[</span><span class=n>cols</span><span class=p>]</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Map indices to tokens and create a dictionary</span>
</span></span><span class=line><span class=cl>    <span class=n>idx2token</span> <span class=o>=</span> <span class=p>{</span><span class=n>idx</span><span class=p>:</span> <span class=n>token</span> <span class=k>for</span> <span class=n>token</span><span class=p>,</span> <span class=n>idx</span> <span class=ow>in</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>get_vocab</span><span class=p>()</span><span class=o>.</span><span class=n>items</span><span class=p>()}</span>
</span></span><span class=line><span class=cl>    <span class=n>token_weight_dict</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>idx2token</span><span class=p>[</span><span class=n>idx</span><span class=p>]:</span> <span class=nb>round</span><span class=p>(</span><span class=n>weight</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span> <span class=k>for</span> <span class=n>idx</span><span class=p>,</span> <span class=n>weight</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>cols</span><span class=p>,</span> <span class=n>weights</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Sort the dictionary by weights in descending order</span>
</span></span><span class=line><span class=cl>    <span class=n>sorted_token_weight_dict</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>k</span><span class=p>:</span> <span class=n>v</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=nb>sorted</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>token_weight_dict</span><span class=o>.</span><span class=n>items</span><span class=p>(),</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>item</span><span class=p>:</span> <span class=n>item</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=n>reverse</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>sorted_token_weight_dict</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Usage example</span>
</span></span><span class=line><span class=cl><span class=n>sorted_tokens</span> <span class=o>=</span> <span class=n>extract_and_map_sparse_vector</span><span class=p>(</span><span class=n>vec</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>sorted_tokens</span>
</span></span></code></pre></div><p>There will be 102 sorted tokens in total. This has expanded to include tokens that weren&rsquo;t in the original text. This is the term expansion we will talk about next.</p><p>Here are some terms that are added: &ldquo;Berlin&rdquo;, and &ldquo;founder&rdquo; - despite having no mention of Arthur&rsquo;s race (which leads to Owen&rsquo;s Berlin win) and his work as the founder of Arthur Ashe Institute for Urban Health. Here are the top few <code>sorted_tokens</code> with a weight of more than 1:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;ashe&#34;</span><span class=p>:</span> <span class=mf>2.95</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;arthur&#34;</span><span class=p>:</span> <span class=mf>2.61</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;tennis&#34;</span><span class=p>:</span> <span class=mf>2.22</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;robert&#34;</span><span class=p>:</span> <span class=mf>1.74</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;jr&#34;</span><span class=p>:</span> <span class=mf>1.55</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;he&#34;</span><span class=p>:</span> <span class=mf>1.39</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;founder&#34;</span><span class=p>:</span> <span class=mf>1.36</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;doubles&#34;</span><span class=p>:</span> <span class=mf>1.24</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;won&#34;</span><span class=p>:</span> <span class=mf>1.22</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;slam&#34;</span><span class=p>:</span> <span class=mf>1.22</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;died&#34;</span><span class=p>:</span> <span class=mf>1.19</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;singles&#34;</span><span class=p>:</span> <span class=mf>1.1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;was&#34;</span><span class=p>:</span> <span class=mf>1.07</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;player&#34;</span><span class=p>:</span> <span class=mf>1.06</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;titles&#34;</span><span class=p>:</span> <span class=mf>0.99</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=o>...</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>If you&rsquo;re interested in using the higher-performance approach, check out the following models:</p><ol><li><a href=https://huggingface.co/naver/efficient-splade-vi-bt-large-doc target=_blank rel="noopener nofollow">naver/efficient-splade-VI-BT-large-doc</a></li><li><a href=https://huggingface.co/naver/efficient-splade-vi-bt-large-doc target=_blank rel="noopener nofollow">naver/efficient-splade-VI-BT-large-query</a></li></ol><h2 id=why-splade-works-term-expansion>Why SPLADE works: term expansion</h2><p>Consider a query &ldquo;solar energy advantages&rdquo;. SPLADE might expand this to include terms like &ldquo;renewable,&rdquo; &ldquo;sustainable,&rdquo; and &ldquo;photovoltaic,&rdquo; which are contextually relevant but not explicitly mentioned. This process is called term expansion, and it&rsquo;s a key component of SPLADE.</p><p>SPLADE learns the query/document expansion to include other relevant terms. This is a crucial advantage over other sparse methods which include the exact word, but completely miss the contextually relevant ones.</p><p>This expansion has a direct relationship with what we can control when making a SPLADE model: Sparsity via Regularisation. The number of tokens (BERT wordpieces) we use to represent each document. If we use more tokens, we can represent more terms, but the vectors become denser. This number is typically between 20 to 200 per document. As a reference point, the dense BERT vector is 768 dimensions, OpenAI Embedding is 1536 dimensions, and the sparse vector is 30 dimensions.</p><p>For example, assume a 1M document corpus. Say, we use 100 sparse token ids + weights per document. Correspondingly, dense BERT vector would be 768M floats, the OpenAI Embedding would be 1.536B floats, and the sparse vector would be a maximum of 100M integers + 100M floats. This could mean a <strong>10x reduction in memory usage</strong>, which is a huge win for large-scale systems:</p><div class=table-responsive><table class="table mb-5"><thead><tr><th>Vector Type</th><th>Memory (GB)</th></tr></thead><tbody><tr><td>Dense BERT Vector</td><td>6.144</td></tr><tr><td>OpenAI Embedding</td><td>12.288</td></tr><tr><td>Sparse Vector</td><td>1.12</td></tr></tbody></table></div><h3 id=how-splade-works-leveraging-bert>How SPLADE works: leveraging BERT</h3><p>SPLADE leverages a transformer architecture to generate sparse representations of documents and queries, enabling efficient retrieval. Let&rsquo;s dive into the process.</p><p>The output logits from the transformer backbone are inputs upon which SPLADE builds. The transformer architecture can be something familiar like BERT. Rather than producing dense probability distributions, SPLADE utilizes these logits to construct sparse vectors—think of them as a distilled essence of tokens, where each dimension corresponds to a term from the vocabulary and its associated weight in the context of the given document or query.</p><p>This sparsity is critical; it mirrors the probability distributions from a typical <a href="http://jalammar.github.io/illustrated-bert/?utm_source=qdrant&amp;utm_medium=website&amp;utm_campaign=sparse-vectors&amp;utm_content=article&amp;utm_term=sparse-vectors" target=_blank rel="noopener nofollow">Masked Language Modeling</a> task but is tuned for retrieval effectiveness, emphasizing terms that are both:</p><ol><li>Contextually relevant: Terms that represent a document well should be given more weight.</li><li>Discriminative across documents: Terms that a document has, and other documents don&rsquo;t, should be given more weight.</li></ol><p>The token-level distributions that you&rsquo;d expect in a standard transformer model are now transformed into token-level importance scores in SPLADE. These scores reflect the significance of each term in the context of the document or query, guiding the model to allocate more weight to terms that are likely to be more meaningful for retrieval purposes.</p><p>The resulting sparse vectors are not only memory-efficient but also tailored for precise matching in the high-dimensional space of a search engine like Qdrant.</p><h3 id=interpreting-splade>Interpreting SPLADE</h3><p>A downside of dense vectors is that they are not interpretable, making it difficult to understand why a document is relevant to a query.</p><p>SPLADE importance estimation can provide insights into the &lsquo;why&rsquo; behind a document&rsquo;s relevance to a query. By shedding light on which tokens contribute most to the retrieval score, SPLADE offers some degree of interpretability alongside performance, a rare feat in the realm of neural IR systems. For engineers working on search, this transparency is invaluable.</p><h2 id=known-limitations-of-splade>Known limitations of SPLADE</h2><h3 id=pooling-strategy>Pooling strategy</h3><p>The switch to max pooling in SPLADE improved its performance on the MS MARCO and TREC datasets. However, this indicates a potential limitation of the baseline SPLADE pooling method, suggesting that SPLADE&rsquo;s performance is sensitive to the choice of pooling strategy​​.</p><h3 id=document-and-query-eecoder>Document and query Eecoder</h3><p>The SPLADE model variant that uses a document encoder with max pooling but no query encoder reaches the same performance level as the prior SPLADE model. This suggests a limitation in the necessity of a query encoder, potentially affecting the efficiency of the model​​.</p><h3 id=other-sparse-vector-methods>Other sparse vector methods</h3><p>SPLADE is not the only method to create sparse vectors.</p><p>Essentially, sparse vectors are a superset of TF-IDF and BM25, which are the most popular text retrieval methods.
In other words, you can create a sparse vector using the term frequency and inverse document frequency (TF-IDF) to reproduce the BM25 score exactly.</p><p>Additionally, attention weights from Sentence Transformers can be used to create sparse vectors.
This method preserves the ability to query exact words and phrases but avoids the computational overhead of query expansion used in SPLADE.</p><p>We will cover these methods in detail in a future article.</p><h2 id=leveraging-sparse-vectors-in-qdrant-for-hybrid-search>Leveraging sparse vectors in Qdrant for hybrid search</h2><p>Qdrant supports a separate index for Sparse Vectors.
This enables you to use the same collection for both dense and sparse vectors.
Each &ldquo;Point&rdquo; in Qdrant can have both dense and sparse vectors.</p><p>But let&rsquo;s first take a look at how you can work with sparse vectors in Qdrant.</p><h2 id=practical-implementation-in-python>Practical implementation in Python</h2><p>Let&rsquo;s dive into how Qdrant handles sparse vectors with an example. Here is what we will cover:</p><ol><li><p>Setting Up Qdrant Client: Initially, we establish a connection with Qdrant using the QdrantClient. This setup is crucial for subsequent operations.</p></li><li><p>Creating a Collection with Sparse Vector Support: In Qdrant, a collection is a container for your vectors. Here, we create a collection specifically designed to support sparse vectors. This is done using the create_collection method where we define the parameters for sparse vectors, such as setting the index configuration.</p></li><li><p>Inserting Sparse Vectors: Once the collection is set up, we can insert sparse vectors into it. This involves defining the sparse vector with its indices and values, and then upserting this point into the collection.</p></li><li><p>Querying with Sparse Vectors: To perform a search, we first prepare a query vector. This involves computing the vector from a query text and extracting its indices and values. We then use these details to construct a query against our collection.</p></li><li><p>Retrieving and Interpreting Results: The search operation returns results that include the id of the matching document, its score, and other relevant details. The score is a crucial aspect, reflecting the similarity between the query and the documents in the collection.</p></li></ol><h3 id=1-set-up>1. Set up</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Qdrant client setup</span>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>QdrantClient</span><span class=p>(</span><span class=s2>&#34;:memory:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define collection name</span>
</span></span><span class=line><span class=cl><span class=n>COLLECTION_NAME</span> <span class=o>=</span> <span class=s2>&#34;example_collection&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Insert sparse vector into Qdrant collection</span>
</span></span><span class=line><span class=cl><span class=n>point_id</span> <span class=o>=</span> <span class=mi>1</span>  <span class=c1># Assign a unique ID for the point</span>
</span></span></code></pre></div><h3 id=2-create-a-collection-with-sparse-vector-support>2. Create a collection with sparse vector support</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>client</span><span class=o>.</span><span class=n>create_collection</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>collection_name</span><span class=o>=</span><span class=n>COLLECTION_NAME</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>vectors_config</span><span class=o>=</span><span class=p>{},</span>
</span></span><span class=line><span class=cl>    <span class=n>sparse_vectors_config</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>models</span><span class=o>.</span><span class=n>SparseVectorParams</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>index</span><span class=o>=</span><span class=n>models</span><span class=o>.</span><span class=n>SparseIndexParams</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>on_disk</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><h3 id=3-insert-sparse-vectors>3. Insert sparse vectors</h3><p>Here, we see the process of inserting a sparse vector into the Qdrant collection. This step is key to building a dataset that can be quickly retrieved in the first stage of the retrieval process, utilizing the efficiency of sparse vectors. Since this is for demonstration purposes, we insert only one point with Sparse Vector and no dense vector.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>client</span><span class=o>.</span><span class=n>upsert</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>collection_name</span><span class=o>=</span><span class=n>COLLECTION_NAME</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>points</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=n>models</span><span class=o>.</span><span class=n>PointStruct</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=nb>id</span><span class=o>=</span><span class=n>point_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>payload</span><span class=o>=</span><span class=p>{},</span>  <span class=c1># Add any additional payload if necessary</span>
</span></span><span class=line><span class=cl>            <span class=n>vector</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>models</span><span class=o>.</span><span class=n>SparseVector</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=n>indices</span><span class=o>=</span><span class=n>indices</span><span class=o>.</span><span class=n>tolist</span><span class=p>(),</span> <span class=n>values</span><span class=o>=</span><span class=n>values</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p>By upserting points with sparse vectors, we prepare our dataset for rapid first-stage retrieval, laying the groundwork for subsequent detailed analysis using dense vectors. Notice that we use &ldquo;text&rdquo; to denote the name of the sparse vector.</p><p>Those familiar with the Qdrant API will notice that the extra care taken to be consistent with the existing named vectors API &ndash; this is to make it easier to use sparse vectors in existing codebases. As always, you&rsquo;re able to <strong>apply payload filters</strong>, shard keys, and other advanced features you&rsquo;ve come to expect from Qdrant. To make things easier for you, the indices and values don&rsquo;t have to be sorted before upsert. Qdrant will sort them when the index is persisted e.g. on disk.</p><h3 id=4-query-with-sparse-vectors>4. Query with sparse vectors</h3><p>We use the same process to prepare a query vector as well. This involves computing the vector from a query text and extracting its indices and values. We then use these details to construct a query against our collection.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Preparing a query vector</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>query_text</span> <span class=o>=</span> <span class=s2>&#34;Who was Arthur Ashe?&#34;</span>
</span></span><span class=line><span class=cl><span class=n>query_vec</span><span class=p>,</span> <span class=n>query_tokens</span> <span class=o>=</span> <span class=n>compute_vector</span><span class=p>(</span><span class=n>query_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>query_vec</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>query_indices</span> <span class=o>=</span> <span class=n>query_vec</span><span class=o>.</span><span class=n>nonzero</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>query_values</span> <span class=o>=</span> <span class=n>query_vec</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()[</span><span class=n>query_indices</span><span class=p>]</span>
</span></span></code></pre></div><p>In this example, we use the same model for both document and query. This is not a requirement, but it&rsquo;s a simpler approach.</p><h3 id=5-retrieve-and-interpret-results>5. Retrieve and interpret results</h3><p>After setting up the collection and inserting sparse vectors, the next critical step is retrieving and interpreting the results. This process involves executing a search query and then analyzing the returned results.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Searching for similar documents</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>search</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>collection_name</span><span class=o>=</span><span class=n>COLLECTION_NAME</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>query_vector</span><span class=o>=</span><span class=n>models</span><span class=o>.</span><span class=n>NamedSparseVector</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=s2>&#34;text&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>vector</span><span class=o>=</span><span class=n>models</span><span class=o>.</span><span class=n>SparseVector</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>indices</span><span class=o>=</span><span class=n>query_indices</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>values</span><span class=o>=</span><span class=n>query_values</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>with_vectors</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>result</span>
</span></span></code></pre></div><p>In the above code, we execute a search against our collection using the prepared sparse vector query. The <code>client.search</code> method takes the collection name and the query vector as inputs. The query vector is constructed using the <code>models.NamedSparseVector</code>, which includes the indices and values derived from the query text. This is a crucial step in efficiently retrieving relevant documents.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>ScoredPoint</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=nb>id</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>version</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>score</span><span class=o>=</span><span class=mf>3.4292831420898438</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>payload</span><span class=o>=</span><span class=p>{},</span>
</span></span><span class=line><span class=cl>    <span class=n>vector</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>SparseVector</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>indices</span><span class=o>=</span><span class=p>[</span><span class=mi>2001</span><span class=p>,</span> <span class=mi>2002</span><span class=p>,</span> <span class=mi>2010</span><span class=p>,</span> <span class=mi>2018</span><span class=p>,</span> <span class=mi>2032</span><span class=p>,</span> <span class=o>...</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>values</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>                <span class=mf>1.0660614967346191</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=mf>1.391068458557129</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=mf>0.8903818726539612</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=mf>0.2502821087837219</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=o>...</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p>The result, as shown above, is a <code>ScoredPoint</code> object containing the ID of the retrieved document, its version, a similarity score, and the sparse vector. The score is a key element as it quantifies the similarity between the query and the document, based on their respective vectors.</p><p>To understand how this scoring works, we use the familiar dot product method:</p><p>$$\text{Similarity}(\text{Query}, \text{Document}) = \sum_{i \in I} \text{Query}_i \times \text{Document}_i$$</p><p>This formula calculates the similarity score by multiplying corresponding elements of the query and document vectors and summing these products. This method is particularly effective with sparse vectors, where many elements are zero, leading to a computationally efficient process. The higher the score, the greater the similarity between the query and the document, making it a valuable metric for assessing the relevance of the retrieved documents.</p><h2 id=hybrid-search-combining-sparse-and-dense-vectors>Hybrid search: combining sparse and dense vectors</h2><p>By combining search results from both dense and sparse vectors, you can achieve a hybrid search that is both efficient and accurate.
Results from sparse vectors will guarantee, that all results with the required keywords are returned,
while dense vectors will cover the semantically similar results.</p><p>The mixture of dense and sparse results can be presented directly to the user, or used as a first stage of a two-stage retrieval process.</p><p>Let&rsquo;s see how you can make a hybrid search query in Qdrant.</p><p>First, you need to create a collection with both dense and sparse vectors:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>client</span><span class=o>.</span><span class=n>create_collection</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>collection_name</span><span class=o>=</span><span class=n>COLLECTION_NAME</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>vectors_config</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;text-dense&#34;</span><span class=p>:</span> <span class=n>models</span><span class=o>.</span><span class=n>VectorParams</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>size</span><span class=o>=</span><span class=mi>1536</span><span class=p>,</span>  <span class=c1># OpenAI Embeddings</span>
</span></span><span class=line><span class=cl>            <span class=n>distance</span><span class=o>=</span><span class=n>models</span><span class=o>.</span><span class=n>Distance</span><span class=o>.</span><span class=n>COSINE</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=n>sparse_vectors_config</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;text-sparse&#34;</span><span class=p>:</span> <span class=n>models</span><span class=o>.</span><span class=n>SparseVectorParams</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>index</span><span class=o>=</span><span class=n>models</span><span class=o>.</span><span class=n>SparseIndexParams</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>on_disk</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p>Then, assuming you have upserted both dense and sparse vectors, you can query them together:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>query_text</span> <span class=o>=</span> <span class=s2>&#34;Who was Arthur Ashe?&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Compute sparse and dense vectors</span>
</span></span><span class=line><span class=cl><span class=n>query_indices</span><span class=p>,</span> <span class=n>query_values</span> <span class=o>=</span> <span class=n>compute_sparse_vector</span><span class=p>(</span><span class=n>query_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>query_dense_vector</span> <span class=o>=</span> <span class=n>compute_dense_vector</span><span class=p>(</span><span class=n>query_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>client</span><span class=o>.</span><span class=n>search_batch</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>collection_name</span><span class=o>=</span><span class=n>COLLECTION_NAME</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>requests</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=n>models</span><span class=o>.</span><span class=n>SearchRequest</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>vector</span><span class=o>=</span><span class=n>models</span><span class=o>.</span><span class=n>NamedVector</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>name</span><span class=o>=</span><span class=s2>&#34;text-dense&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>vector</span><span class=o>=</span><span class=n>query_dense_vector</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>limit</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>models</span><span class=o>.</span><span class=n>SearchRequest</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>vector</span><span class=o>=</span><span class=n>models</span><span class=o>.</span><span class=n>NamedSparseVector</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>name</span><span class=o>=</span><span class=s2>&#34;text-sparse&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>vector</span><span class=o>=</span><span class=n>models</span><span class=o>.</span><span class=n>SparseVector</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=n>indices</span><span class=o>=</span><span class=n>query_indices</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>values</span><span class=o>=</span><span class=n>query_values</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>limit</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p>The result will be a pair of result lists, one for dense and one for sparse vectors.</p><p>Having those results, there are several ways to combine them:</p><h3 id=mixing-or-fusion>Mixing or fusion</h3><p>You can mix the results from both dense and sparse vectors, based purely on their relative scores. This is a simple and effective approach, but it doesn&rsquo;t take into account the semantic similarity between the results. Among the <a href=https://medium.com/plain-simple-software/distribution-based-score-fusion-dbsf-a-new-approach-to-vector-search-ranking-f87c37488b18 target=_blank rel="noopener nofollow">popular mixing methods</a> are:</p><pre><code>- Reciprocal Ranked Fusion (RRF)
- Relative Score Fusion (RSF)
- Distribution-Based Score Fusion (DBSF)
</code></pre><figure><img src=https://qdrant.tech/articles_data/sparse-vectors/mixture.png alt="Relative Score Fusion" width=80%><figcaption><p>Relative Score Fusion</p></figcaption></figure><p><a href=https://github.com/AmenRa/ranx target=_blank rel="noopener nofollow">Ranx</a> is a great library for mixing results from different sources.</p><h3 id=re-ranking>Re-ranking</h3><p>You can use obtained results as a first stage of a two-stage retrieval process. In the second stage, you can re-rank the results from the first stage using a more complex model, such as <a href=https://www.sbert.net/examples/applications/cross-encoder/README.html target=_blank rel="noopener nofollow">Cross-Encoders</a> or services like <a href=https://txt.cohere.com/rerank/ target=_blank rel="noopener nofollow">Cohere Rerank</a>.</p><p>And that&rsquo;s it! You&rsquo;ve successfully achieved hybrid search with Qdrant!</p><h2 id=additional-resources>Additional resources</h2><p>For those who want to dive deeper, here are the top papers on the topic most of which have code available:</p><ol><li>Problem Motivation: <a href="https://ar5iv.org/abs/1506.02004?utm_source=qdrant&amp;utm_medium=website&amp;utm_campaign=sparse-vectors&amp;utm_content=article&amp;utm_term=sparse-vectors" target=_blank rel="noopener nofollow">Sparse Overcomplete Word Vector Representations</a></li><li><a href="https://ar5iv.org/abs/2109.10086?utm_source=qdrant&amp;utm_medium=website&amp;utm_campaign=sparse-vectors&amp;utm_content=article&amp;utm_term=sparse-vectors" target=_blank rel="noopener nofollow">SPLADE v2: Sparse Lexical and Expansion Model for Information Retrieval</a></li><li><a href="https://ar5iv.org/abs/2107.05720?utm_source=qdrant&amp;utm_medium=website&amp;utm_campaign=sparse-vectors&amp;utm_content=article&amp;utm_term=sparse-vectors" target=_blank rel="noopener nofollow">SPLADE: Sparse Lexical and Expansion Model for First Stage Ranking</a></li><li>Late Interaction - <a href="https://ar5iv.org/abs/2112.01488?utm_source=qdrant&amp;utm_medium=website&amp;utm_campaign=sparse-vectors&amp;utm_content=article&amp;utm_term=sparse-vectors" target=_blank rel="noopener nofollow">ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction</a></li><li><a href="https://research.google/pubs/pub52289/?utm_source=qdrant&amp;utm_medium=website&amp;utm_campaign=sparse-vectors&amp;utm_content=article&amp;utm_term=sparse-vectors" target=_blank rel="noopener nofollow">SparseEmbed: Learning Sparse Lexical Representations with Contextual Embeddings for Retrieval</a></li></ol><p><strong>Why just read when you can try it out?</strong></p><p>We&rsquo;ve packed an easy-to-use Colab for you on how to make a Sparse Vector: <a href="https://colab.research.google.com/drive/1wa2Yr5BCOgV0MTOFFTude99BOXCLHXky?usp=sharing" target=_blank rel="noopener nofollow">Sparse Vectors Single Encoder Demo</a>. Run it, tinker with it, and start seeing the magic unfold in your projects. We can&rsquo;t wait to hear how you use it!</p><h2 id=conclusion>Conclusion</h2><p>Alright, folks, let&rsquo;s wrap it up. Better search isn&rsquo;t a &rsquo;nice-to-have,&rsquo; it&rsquo;s a game-changer, and Qdrant can get you there.</p><p>Got questions? Our <a href="https://qdrant.to/discord?utm_source=qdrant&amp;utm_medium=website&amp;utm_campaign=sparse-vectors&amp;utm_content=article&amp;utm_term=sparse-vectors" target=_blank rel="noopener nofollow">Discord community</a> is teeming with answers.</p><p>If you enjoyed reading this, why not sign up for our <a href="https://qdrant.tech/subscribe/?utm_source=qdrant&amp;utm_medium=website&amp;utm_campaign=sparse-vectors&amp;utm_content=article&amp;utm_term=sparse-vectors">newsletter</a> to stay ahead of the curve.</p><p>And, of course, a big thanks to you, our readers, for pushing us to make ranking better for everyone.</p></article><section class="docs-feedback d-print-none"><h5 class=docs-feedback__title>Was this page useful?</h5><div class=docs-feedback__buttons><button class="button button_outlined button_sm docs-feedback__button" id=feedback__answer_yes>
<img src=https://qdrant.tech/icons/outline/thumb-up.svg alt="Thumb up icon">
Yes
</button>
<button class="button button_outlined button_sm docs-feedback__button" id=feedback__answer_no>
<img src=https://qdrant.tech/icons/outline/thumb-down.svg alt="Thumb down icon">
No</button></div></section><section class="docs-feedback__responses d-none"><p class="docs-feedback__response docs-feedback__response_yes" id=feedback__response_yes>Thank you for your feedback! 🙏</p><p class="docs-feedback__response docs-feedback__response_no" id=feedback__response_no>We are sorry to hear that. 😔 You can <a class=text-brand-p href=https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/sparse-vectors.md target=_blank>edit</a> this page on GitHub, or <a class=text-brand-p href=https://github.com/qdrant/landing_page/issues/new/choose target=_blank>create</a> a GitHub issue.</p></section><script>const buttonsSection=document.querySelector(".docs-feedback"),responsesSection=document.querySelector(".docs-feedback__responses"),yesButton=document.querySelector("#feedback__answer_yes"),noButton=document.querySelector("#feedback__answer_no"),yesResponse=document.querySelector("#feedback__response_yes"),noResponse=document.querySelector("#feedback__response_no"),toggleResponses=()=>{buttonsSection.classList.add("d-none"),responsesSection.classList.remove("d-none")};yesButton.addEventListener("click",()=>{yesResponse.classList.add("feedback__response_visible"),toggleResponses()}),noButton.addEventListener("click",()=>{noResponse.classList.add("feedback__response_visible"),toggleResponses()})</script></div><div class=table-of-contents><p class=table-of-contents__head>On this page:</p><nav id=TableOfContents><ul><li><a href=#what-are-sparse-and-dense-vectors>What are sparse and dense vectors?</a></li><li><a href=#understanding-sparse-vectors>Understanding sparse vectors</a></li><li><a href=#splade>SPLADE</a></li><li><a href=#creating-a-sparse-vector>Creating a sparse vector</a><ul><li><a href=#setting-up>Setting Up</a></li><li><a href=#computing-the-sparse-vector>Computing the sparse vector</a></li></ul></li><li><a href=#term-expansion-and-weights>Term expansion and weights</a></li><li><a href=#why-splade-works-term-expansion>Why SPLADE works: term expansion</a><ul><li><a href=#how-splade-works-leveraging-bert>How SPLADE works: leveraging BERT</a></li><li><a href=#interpreting-splade>Interpreting SPLADE</a></li></ul></li><li><a href=#known-limitations-of-splade>Known limitations of SPLADE</a><ul><li><a href=#pooling-strategy>Pooling strategy</a></li><li><a href=#document-and-query-eecoder>Document and query Eecoder</a></li><li><a href=#other-sparse-vector-methods>Other sparse vector methods</a></li></ul></li><li><a href=#leveraging-sparse-vectors-in-qdrant-for-hybrid-search>Leveraging sparse vectors in Qdrant for hybrid search</a></li><li><a href=#practical-implementation-in-python>Practical implementation in Python</a><ul><li><a href=#1-set-up>1. Set up</a></li><li><a href=#2-create-a-collection-with-sparse-vector-support>2. Create a collection with sparse vector support</a></li><li><a href=#3-insert-sparse-vectors>3. Insert sparse vectors</a></li><li><a href=#4-query-with-sparse-vectors>4. Query with sparse vectors</a></li><li><a href=#5-retrieve-and-interpret-results>5. Retrieve and interpret results</a></li></ul></li><li><a href=#hybrid-search-combining-sparse-and-dense-vectors>Hybrid search: combining sparse and dense vectors</a><ul><li><a href=#mixing-or-fusion>Mixing or fusion</a></li><li><a href=#re-ranking>Re-ranking</a></li></ul></li><li><a href=#additional-resources>Additional resources</a></li><li><a href=#conclusion>Conclusion</a></li></ul></nav><ul class=table-of-contents__external-links><li class=table-of-contents__link><a href=https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/sparse-vectors.md target=_blank><svg width="16" height="17" viewBox="0 0 16 17" fill="none"><g clip-path="url(#clip0_6269_955)"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 .700012c-4.4.0-8 3.599998-8 7.999998C0 12.2333 2.26667 15.2333 5.46667 16.3 5.86667 16.3667 6 16.1 6 15.9S6 15.2333 6 14.5667C3.8 15.0333 3.33333 13.5 3.33333 13.5 3 12.5667 2.46667 12.3 2.46667 12.3 1.66667 11.8333 2.46667 11.8333 2.46667 11.8333 3.26667 11.9 3.66667 12.6333 3.66667 12.6333 4.4 13.8333 5.53333 13.5 6 13.3 6.06667 12.7667 6.26667 12.4333 6.53333 12.2333 4.73333 12.0333 2.86667 11.3667 2.86667 8.30001c0-.86666.33333-1.6.8-2.13333.0-.26667-.33334-1.06667.13333-2.13333.0.0.66667-.200000000000001 2.2.8.66667-.2 1.33333-.26667 2-.26667S9.33333 4.63335 10 4.83335c1.5333-1.06667 2.2-.8 2.2-.8C12.6667 5.16668 12.3333 5.96668 12.2667 6.16668 12.8 6.70001 13.0667 7.43335 13.0667 8.30001c0 3.06669-1.8667 3.73329-3.6667 3.93329C9.66667 12.5 9.93333 12.9667 9.93333 13.7c0 1.0667.0 1.9333.0 2.2C9.93333 16.1 10.0667 16.3667 10.4667 16.3c3.2-1.0667 5.4666-4.0667 5.4666-7.59999C16 4.30001 12.4.700012 8 .700012z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_6269_955"><rect width="16" height="16" fill="#fff" transform="translate(0 0.5)"/></clipPath></defs></svg>
Edit on Github</a></li><li class=table-of-contents__link><a href=https://github.com/qdrant/landing_page/issues/new/choose target=_blank><svg width="16" height="17" viewBox="0 0 16 17" fill="none"><g clip-path="url(#clip0_6269_1540)"><path d="M16 9.83331V8.49998H13.9347C13.79 7.33465 13.3947 6.24065 12.8 5.31065l1.476-1.478L13.3327 2.89065 11.9633 4.26198c-.24-.248-.496600000000001-.474-.772-.676C11.0967 3.25665 10.9507 2.95398 10.7673 2.67598l1.038-1.038L10.8627.695312 9.82867 1.72931C9.29867 1.37798 8.672 1.16665 8 1.16665c-.672.0-1.29867.21133-1.828.56266L5.138.695312l-.94267.942668 1.038 1.038c-.18333.27733-.32933.58-.424.90867-.27533.202-.532.42933-.77266.67733L2.66733 2.89065l-.94333.942L3.2 5.30998c-.59467.93-.99 2.02467-1.13467 3.19H0V9.83331H2.01467C2.07333 11.276 2.50533 12.6026 3.204 13.688l-1.48 1.478L2.666 16.1093l1.37-1.368C4.93733 15.67 6.07667 16.288 7.33333 16.452V6.49998H8.66667V16.452C9.92333 16.2873 11.0627 15.67 11.964 14.7413l1.37 1.368L14.276 15.166l-1.48-1.478C13.4947 12.602 13.9267 11.2753 13.9853 9.83331H16z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_6269_1540"><rect width="16" height="16" fill="#fff" transform="translate(0 0.5)"/></clipPath></defs></svg>
Create an issue</a></li></ul></div><footer class="docs-footer w-100 py-0 pt-0 pb-4 pb-xl-0"><div class=docs-footer__cta><h4>Ready to get started with Qdrant?</h4><a href=https://qdrant.to/cloud/ class="button button_outlined button_sm" target=_blank>Start Free</a></div><div class=docs-footer__bottom><div class=docs-footer__bottom-content><span>© 2025 Qdrant.</span><div class=footer__bottom-links><a href=https://qdrant.tech/legal/terms_and_conditions/>Terms</a>
<a href=https://qdrant.tech/legal/privacy-policy/>Privacy Policy</a>
<a href=https://qdrant.tech/legal/impressum/>Impressum</a></div></div></div></footer></div></div></div></div></section></main></body><script src=https://cdn.cookielaw.org/scripttemplates/otSDKStub.js type=text/javascript data-domain-script=01960152-5e40-782d-af01-f7f5768a214e></script><script async type=text/javascript>function OptanonWrapper(){const e=new CustomEvent("onetrust_loaded");document.dispatchEvent(e)}</script><script>!function(){const o="eQYi1nZE2zQSmnHuxjMRlDd2uLl65oHe";var n,s,t="analytics",e=window[t]=window[t]||[];if(!e.initialize)if(e.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{e.invoked=!0,e.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","debug","page","screen","once","off","on","addSourceMiddleware","addIntegrationMiddleware","setAnonymousId","addDestinationMiddleware","register"],e.factory=function(n){return function(){if(window[t].initialized)return window[t][n].apply(window[t],arguments);var o,s=Array.prototype.slice.call(arguments);return["track","screen","alias","group","page","identify"].indexOf(n)>-1&&(o=document.querySelector("link[rel='canonical']"),s.push({__t:"bpc",c:o&&o.getAttribute("href")||void 0,p:location.pathname,u:location.href,s:location.search,t:document.title,r:document.referrer})),s.unshift(n),e.push(s),e}};for(n=0;n<e.methods.length;n++)s=e.methods[n],e[s]=e.factory(s);e.load=function(n,s){var i,o=document.createElement("script");o.type="text/javascript",o.async=!0,o.setAttribute("data-global-segment-analytics-key",t),o.src="https://evs.analytics.qdrant.tech/5caWuitPgcGFN5Q7HMpTaj/vEkmzjuRSqeXGbhGAFTWex.min.js",i=document.getElementsByTagName("script")[0],i.parentNode.insertBefore(o,i),e._loadOptions=s},e._writeKey=o,e._cdn="https://evs.analytics.qdrant.tech",e.SNIPPET_VERSION="5.2.0",e.load(o)}}()</script><script src=https://qdrant.tech/js/google-setup.min.14728a3ae9bd931593645b6ddbfe801d400cd2970006e782cb67f3966654248ca962dbaf4cf371493a2d326861b3a691a99d6d8349c8b2752339ab91d3787069.js></script><script src=https://qdrant.tech/js/index.min.e37feda1952d752f5568e1ebc55e183629e4d361f4df09edeed70b4a4327d601161c4147bdbe4149b4a3cdc1ed43f1bf1a2f2340a421f1aa821103980dfe0bda.js></script><script src=https://qdrant.tech/js/search/search.min.e58e7ea98cb549ea9d3ed7e68876abe323cfb323432038820f38a71c40e309deed0fba615e2d3346825229a81e0a76bbadf6f8a816ddad3438abdabfef4ebc09.js type=module></script><script src=https://qdrant.tech/js/search/scroll.min.f4ed4453a3af0adb0d4f49333cbb7892ff5430483a567d0d2dfbd4655fb203d22f22f46aff3d9f38fa5fd96dde5f30227afd0ce1d9f838f5cd5295fc83856ec9.js></script><script src=https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js></script><script src=https://qdrant.tech/js/copy-code.min.95b03a45b2ab4b7a608ecfd4b5919c8572a5b2cd1463f52561cd10976abf3b74334f91324c0e620cb80afac46026a0b18cce6fb753d8495f74c6d478c8ca1d03.js></script><script src=https://qdrant.tech/js/lang-switcher.min.63da11cef09772078425b1ee56415b9c37842a9399f2ba2d2f5efbf72fb751686c410bd50e9bcd283c8231cb97c1973199d4923beef29d8b06e59d9983a6ba51.js></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src=https://qdrant.tech/js/vendor/anchor.min.0e138e17ebcf1c1147a7a3a81d9ac3c601622eedc479f1636470eb2552470f4e27c9a8efe6e8378995dedc1ab67029d8989536ea76f0857d45d1615ae772b8a1.js></script><script>document.addEventListener("keydown",function(e){if((e.metaKey||e.ctrlKey)&&e.key==="k"){e.preventDefault();let t=document.querySelector('[data-target="#searchModal"]');t&&t?.click()}})</script><script>window.addEventListener("message",e=>{if(e.data.type==="hsFormCallback"&&e.data.eventName==="onFormReady"){const t=document.querySelector(`form[data-form-id="${e.data.id}"]`);if(t){const e=t.querySelector('[name="last_form_fill_url"]');e&&(e.value=window.location.href);const n=t.querySelector('[name="referrer_url"]');n&&(n.value=document.referrer)}}})</script></html>