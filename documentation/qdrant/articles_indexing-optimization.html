<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta charset=UTF-8><title>Optimizing Memory for Bulk Uploads - Qdrant</title>
<link rel=icon href=https://qdrant.tech/favicon/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=https://qdrant.tech/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://qdrant.tech/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://qdrant.tech/favicon/favicon-16x16.png><link rel=manifest href=https://qdrant.tech/favicon/site.webmanifest><link rel=mask-icon href=https://qdrant.tech/favicon/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#2b5797"><meta name=msapplication-config content="/favicon/browserconfig.xml"><meta name=theme-color content="#ffffff"><meta name=partition content="learn"><link href=https://qdrant.tech/css/search/search.min.09596ee2b3c94d0ac82a1c33199cabdb3e0210b1ee46aaf1515200e9e484d05dd9e27cc1e861c58cc2e582af162f63b8e180ff2a12f7a6592b7aeaa0a7125130.css rel=stylesheet integrity="sha512-CVlu4rPJTQrIKhwzGZyr2z4CELHuRqrxUVIA6eSE0F3Z4nzB6GHFjMLlgq8WL2O44YD/KhL3plkreuqgpxJRMA=="><link href=https://qdrant.tech/css/documentation.min.de204cdcfc410689a41c17bcdad0a34f2caaa50cc8505c820adaab481cef2d69a920b0a32e0d624701c29487e3271b694559d98c5047cbfaa5aa475f638011e5.css rel=stylesheet integrity="sha512-3iBM3PxBBomkHBe82tCjTyyqpQzIUFyCCtqrSBzvLWmpILCjLg1iRwHClIfjJxtpRVnZjFBHy/qlqkdfY4AR5Q=="><link href=https://qdrant.tech/css/main.min.c1e379ad4cf03647832f6a0f040754b0be3e79934db2c29f50b396327c1ec7ac45f778abadbd93f5a8bc431850d1b0d9c9eff34c0171cd4236e83c5e324c1a0e.css rel=stylesheet integrity crossorigin=anonymous><meta name=generator content="Hugo 0.141.0"><meta name=description content="Efficient memory management is key when handling large-scale vector data. Learn how to optimize memory consumption during bulk uploads in Qdrant and keep your deployments performant under heavy load."><meta name=keywords content="vector search engine,neural network,matching,SaaS,approximate nearest neighbor search,image search,recommender system,vectors,knn algorithm,hnsw,vector search,embeddings,similarity,simaes networks,BERT,transformer,word2vec,fasttext,qdrant"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@id":"https://qdrant.tech/articles/indexing-optimization/#article","@type":"Article","abstract":"Efficient memory management is key when handling largescale vector data Learn how to optimize memory consumption during bulk uploads in Qdrant and keep your deployments performant under heavy load","author":{"@type":"Person","name":"Sabrina Aquino"},"dateModified":"2025-02-13 00:00:00 +0000 UTC","datePublished":"2025-02-13 00:00:00 +0000 UTC","description":"Efficient memory management is key when handling largescale vector data Learn how to optimize memory consumption during bulk uploads in Qdrant and keep your deployments performant under heavy load","headline":"Optimizing Memory for Bulk Uploads","image":["https://qdrant.tech/articles_data/indexing-optimization/social-preview.png"],"name":"Optimizing Memory for Bulk Uploads","url":"https://qdrant.tech/articles/indexing-optimization/","wordCount":"1509"},{"@id":"https://qdrant.tech/articles/indexing-optimization/#organization","@type":"Organization","address":{"@type":"PostalAddress","addressCountry":"DE","addressLocality":"Berlin","addressRegion":"Berlin","postalCode":"10115","streetAddress":"Chausseestra√üe 86"},"contactPoint":{"@type":"ContactPoint","contactType":"customer support","email":"info@qdrant.com","telephone":"+49 3040797694"},"description":"Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.","email":"info@qdrant.com","founders":[{"@type":"Person","name":"map[email:info@qdrant.tech name:Andrey Vasnetsov]"},{"@type":"Person","name":"Andre Zayarni"}],"foundingDate":"2021","keywords":["vector search engine","neural network","matching","SaaS","approximate nearest neighbor search","image search","recommender system","vectors","knn algorithm","hnsw","vector search","embeddings","similarity","simaes networks","BERT","transformer","word2vec","fasttext","Qdrant"],"legalName":"Qdrant Solutions GmbH","location":"Berlin, Germany","logo":"https://qdrant.tech/images/logo_with_text.png","name":"Qdrant","sameAs":["https://github.com/qdrant/qdrant","https://qdrant.to/discord","https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA","https://www.linkedin.com/company/qdrant/","https://twitter.com/qdrant_engine"],"url":"https://qdrant.tech"}]}</script><meta property="og:url" content="https://qdrant.tech/articles/indexing-optimization/"><meta property="og:type" content="website"><meta property="og:title" content="Optimizing Memory for Bulk Uploads - Qdrant"><meta name=twitter:card content="summary_large_image"><meta name=twitter:domain content="qdrant"><meta name=twitter:url content="https://qdrant.tech/articles/indexing-optimization/"><meta name=twitter:title content="Optimizing Memory for Bulk Uploads - Qdrant"><meta property="og:description" content="Efficient memory management is key when handling large-scale vector data. Learn how to optimize memory consumption during bulk uploads in Qdrant and keep your deployments performant under heavy load."><meta name=twitter:description content="Efficient memory management is key when handling large-scale vector data. Learn how to optimize memory consumption during bulk uploads in Qdrant and keep your deployments performant under heavy load."><meta name=image property="og:image" content="https://qdrant.tech/articles_data/indexing-optimization/social-preview.png"><meta name=image property="og:image:secure_url" content="https://qdrant.tech/articles_data/indexing-optimization/social-preview.png"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name=twitter:image:src content="https://qdrant.tech/articles_data/indexing-optimization/social-preview.png"><meta name=author content="Sabrina Aquino"><link rel=canonical href=https://qdrant.tech/articles/indexing-optimization/><script type=text/javascript src=//js-eu1.hsforms.net/forms/embed/v2.js></script><script src=https://qdrant.tech/js/documentation.min.594fc9226f6fb87b8c3b0cafb9d5c0b0bcd95f47d292b929aab04315e0506706b2f376dc4fae9961dc3082138cb19d45b2a3370ee8e881bbf4b8c91dcb735c32.js></script></head><body><main><header class=docs-header><div class="main-menu z-5"><a href=https://qdrant.tech/><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div></a><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><div class="d-block d-xl-none"><button role=button class=theme-switch></button></div><button type=button class=main-menu__trigger><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M1 12H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 5H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 19H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=main-menu__links><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/>Qdrant</a></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/cloud-intro/>Cloud</a></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/build/>Build</a></li><li class=main-menu__item><a class=menu-linkactive href=https://qdrant.tech/articles/>Learn</a></li><li class=main-menu__item><a class=menu-link href=https://api.qdrant.tech/api-reference target=_blank>API Reference</a></li></ul><div class=main-menu__buttons><div class=main-menu__buttons-input><button class="qdr-search-input-btn q-input input_md input_light-bg" type=button name=search data-target=#searchModal>
Search</button></div><button role=button class=theme-switch></button>
<a data-metric-loc=nav href=https://cloud.qdrant.io/login class="menu-link mx-3" target=_blank>Log in</a>
<a data-metric-loc=nav href=https://cloud.qdrant.io/signup class="button button_contained button_sm" target=_blank>Start Free</a></div></div><div class=menu-mobile><div class=menu-mobile__header><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><div class="d-block d-xl-none"><button role=button class=theme-switch></button></div><button type=button class=menu-mobile__close><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><g id="Close"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M19.778 5.63606C20.1685 5.24554 20.1685 4.61237 19.778 4.22185 19.3874 3.83132 18.7543 3.83132 18.3637 4.22185L11.9998 10.5858 5.63586 4.22185c-.39052-.39053-1.02369-.39053-1.41421.0C3.83112 4.61237 3.83112 5.24554 4.22165 5.63606L10.5856 12l-6.364 6.364C3.83108 18.7545 3.83108 19.3877 4.2216 19.7782 4.61213 20.1687 5.24529 20.1687 5.63582 19.7782l6.36398-6.364 6.364 6.364C18.7543 20.1687 19.3875 20.1687 19.778 19.7782 20.1685 19.3877 20.1685 18.7545 19.778 18.364L13.414 12l6.364-6.36394z" fill="#e1e5f0"/></g></svg></button></div></div><div class=main-menu__buttons-input><button class="qdr-search-input-btn q-input input_md input_light-bg" type=button name=search data-target=#searchModal>
Search</button></div><ul class=menu-mobile__items><li class=menu-mobile__item data-path=menu-0><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Documentation"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M4.25 1c-1.10092.0-2.12247.23681-2.88689.64443C.620129 2.04063.0 2.67297.0 3.5v11c0 .2761.223858.5.5.5s.5-.2239.5-.5c0-.278.21937-.6456.83364-.9732C2.42647 13.2107 3.27992 13 4.25 13 5.22008 13 6.07353 13.2107 6.66636 13.5268c.61427.3276.83364.6952.83364.9732.0.2761.22386.5.5.5s.5-.2239.5-.5c0-.278.21937-.6456.833640000000001-.9732C9.92647 13.2107 10.7799 13 11.75 13S13.5735 13.2107 14.1664 13.5268C14.7806 13.8544 15 14.222 15 14.5c0 .2761.2239.5.5.5s.5-.2239.5-.5V3.5C16 2.67297 15.3799 2.04063 14.6369 1.64443 13.8725 1.23681 12.8509 1 11.75 1s-2.12247.23681-2.88689.64443C8.53799 1.8178 8.2364 2.03638 8 2.29671c-.2364-.26033-.53799-.47891-.86311-.65228C6.37247 1.23681 5.35092 1 4.25 1zM1.36311 12.6444C1.23778 12.7113 1.11595 12.7848 1 12.8649V3.5c0-.27797.21937-.64563.83364-.97318C2.42647 2.21069 3.27992 2 4.25 2c.97008.0 1.82353.21069 2.41636.52682C7.28063 2.85437 7.5 3.22203 7.5 3.5v9.3649C7.38405 12.7848 7.26222 12.7113 7.13689 12.6444 6.37247 12.2368 5.35092 12 4.25 12 3.14908 12 2.12753 12.2368 1.36311 12.6444zM8.5 12.8649C8.61595 12.7848 8.73778 12.7113 8.86311 12.6444 9.62753 12.2368 10.6491 12 11.75 12S13.8725 12.2368 14.6369 12.6444C14.7622 12.7113 14.8841 12.7848 15 12.8649V3.5C15 3.22203 14.7806 2.85437 14.1664 2.52682 13.5735 2.21069 12.7201 2 11.75 2s-1.82353.21069-2.41636.52682C8.71937 2.85437 8.5 3.22203 8.5 3.5v9.3649z"/></g></svg>
Qdrant</a></div></li><li class=menu-mobile__item data-path=menu-1><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/cloud-intro/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Cloud"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M7.5 2C4.57416 2 2.18128 4.28566 2.00983 7.16851.8403 7.57763.0 8.68965.0 10c0 1.6571 1.34286 3 3 3H13c1.6571.0 3-1.3429 3-3 0-1.65714-1.3429-3-3-3L12.9776 7.00009C12.7249 4.19714 10.3686 2 7.5 2zM3.00107 7.48137 3.00008 7.47308C3.01457 5.0006 5.02412 3 7.5 3c2.47599.0 4.4856 2.00079 4.4999 4.47342L11.9987 7.4836C11.9969 7.50027 11.995 7.52348 11.995 7.551 11.995 7.701 12.0623 7.84308 12.1785 7.93804 12.2946 8.03301 12.4472 8.07082 12.5942 8.04106 12.726 8.01438 12.8617 8 13 8c1.1049.0 2 .89514 2 2C15 11.1049 14.1049 12 13 12H3C1.89514 12 1 11.1049 1 10 1 9.03225 1.68901 8.22422 2.60364 8.04017 2.83708 7.9932 3.005 7.78812 3.005 7.55 3.005 7.52154 3.00291 7.49773 3.00107 7.48137z"/></g></svg>
Cloud</a></div></li><li class=menu-mobile__item data-path=menu-2><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/build/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Blog"><path id="Union" fill-rule="evenodd" clip-rule="evenodd" d="M0 1.5C0 1.22386.223858 1 .5 1h5c.27614.0.5.22386.5.5v5c0 .27614-.22386.5-.5.5H.5C.223858 7 0 6.77614.0 6.5v-5zM1 2V6H5V2H1zm7 .5c0-.27614.22386-.5.5-.5h7c.2761.0.5.22386.5.5s-.2239.5-.5.5h-7C8.22386 3 8 2.77614 8 2.5zM8.5 6c-.27614.0-.5.22386-.5.5s.22386.5.5.5h7c.2761.0.5-.22386.5-.5s-.2239-.5-.5-.5h-7zM0 10.5c0-.2761.223858-.5.5-.5h15c.2761.0.5.2239.5.5s-.2239.5-.5.5H.5c-.276142.0-.5-.2239-.5-.5zM.5 14c-.276142.0-.5.2239-.5.5s.223858.5.5.5h15c.2761.0.5-.2239.5-.5s-.2239-.5-.5-.5H.5z"/></g></svg>
Build</a></div></li><li class=menu-mobile__item data-path=menu-3><div class=menu-mobile__item-content><a class=active href=https://qdrant.tech/articles/><svg width="16" height="16" viewBox="0 0 16 16" fill="none" stroke="#e1e5f0"><g id="Group"><path id="Vector" d="M10.084 1.84094l4.059 4.059" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_2" d="M8.49188 2.72406c-1.22044-.53042-2.59304-.59475-3.85774-.1808-1.2647.41395-2.33363 1.27742-3.00426 2.4268l2.34 2.34" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_3" d="M13.2657 7.47302C13.8062 8.69691 13.8769 10.077 13.4645 11.3497c-.4125 1.2728-1.2792 2.3491-2.4348 3.0233l-2.35001-2.35" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_4" d="M6.81217 13.049l-3.861-3.861S6.24917.983 15.5002.5c-.523 9.211-8.68803 12.549-8.68803 12.549z" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_5" d="M3.59892 12.4008C3.34181 12.1441 2.99331 12 2.62995 12c-.36335.0-.71186.1441-.96897.4008-.46665.4664-.63131 1.941-.65931 2.2322C.997021 14.6793 1.0021 14.726 1.01659 14.7701 1.03108 14.8143 1.05465 14.8549 1.08579 14.8895 1.11693 14.924 1.15495 14.9516 1.19741 14.9705 1.23987 14.9895 1.28583 14.9994 1.33233 14.9995 1.34298 15.0002 1.35367 15.0002 1.36433 14.9995 1.65565 14.9715 3.1316 14.8063 3.59759 14.3405 3.85501 14.0834 3.99975 13.7346 4 13.3709 4.00025 13.0072 3.85599 12.6582 3.59892 12.4008z" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_6" d="M9 8c.55228.0 1-.44772 1-1S9.55228 6 9 6 8 6.44772 8 7s.44772 1 1 1z"/></g></svg>
Learn</a></div></li><li class=menu-mobile__item data-path=menu-4><div class=menu-mobile__item-content><a href=https://api.qdrant.tech/api-reference target=_blank><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Roadmap" clip-path="url(#clip0_7182_4311)"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M13.5 1c-.8284.0-1.5.67157-1.5 1.5S12.6716 4 13.5 4 15 3.32843 15 2.5 14.3284 1 13.5 1zM11 2.5C11 1.11929 12.1193.0 13.5.0S16 1.11929 16 2.5 14.8807 5 13.5 5 11 3.88071 11 2.5zM2.5 12c-.82843.0-1.5.6716-1.5 1.5S1.67157 15 2.5 15 4 14.3284 4 13.5 3.32843 12 2.5 12zM0 13.5C0 12.1193 1.11929 11 2.5 11S5 12.1193 5 13.5 3.88071 16 2.5 16 0 14.8807.0 13.5zM3.65901 1.65901C4.08097 1.23705 4.65326 1 5.25 1s1.16903.23705 1.59099.65901C7.26295 2.08097 7.5 2.65326 7.5 3.25v9.5c0 .862.34241 1.6886.9519 2.2981C9.0614 15.6576 9.88805 16 10.75 16c.862.0 1.6886-.3424 2.2981-.9519S14 13.612 14 12.75V6.5c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v6.25C13 13.3467 12.7629 13.919 12.341 14.341 11.919 14.7629 11.3467 15 10.75 15S9.58097 14.7629 9.15901 14.341C8.73705 13.919 8.5 13.3467 8.5 12.75V3.25C8.5 2.38805 8.15759 1.5614 7.5481.951903 6.9386.34241 6.11195.0 5.25.0S3.5614.34241 2.9519.951903C2.34241 1.5614 2 2.38805 2 3.25V9.5c0 .27614.22386.5.5.5s.5-.22386.5-.5V3.25c0-.59674.23705-1.16903.65901-1.59099z"/></g><defs><clipPath id="clip0_7182_4311"><rect width="16" height="16" fill="#fff"/></clipPath></defs></svg>
API Reference</a></div></li></ul><div class=docs-menu><div id=sidebar class=docs-menu__content><h3 class=docs-menu__links-title>Learn</h3><nav><div class=docs-menu__links-group><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/vector-search-manuals/>Vector Search Manuals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/qdrant-internals/>Qdrant Internals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/data-exploration/>Data Exploration</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/machine-learning/>Machine Learning</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/rag-and-genai/>RAG & GenAI</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/practicle-examples/>Practical Examples</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/ecosystem/>Ecosystem</a></div></div></nav></div></div></div></header><section class="docs documentation"><div class=documentation__container><div class="d-flex flex-column flex-xl-row"><div class=docs-menu><div id=sidebar class=docs-menu__content><h3 class=docs-menu__links-title>Learn</h3><nav><div class=docs-menu__links-group><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/vector-search-manuals/>Vector Search Manuals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/qdrant-internals/>Qdrant Internals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/data-exploration/>Data Exploration</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/machine-learning/>Machine Learning</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/rag-and-genai/>RAG & GenAI</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/practicle-examples/>Practical Examples</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/ecosystem/>Ecosystem</a></div></div></nav></div></div><div class=documentation__content><div class=documentation__content-wrapper><div class=documentation__article-wrapper><ul class=docs-breadcrumbs><li class=docs-breadcrumbs__crumb><a href=https://qdrant.tech/articles/>Articles</a></li><li class=docs-breadcrumbs__crumb-separator></li><li class=docs-breadcrumbs__crumb>Optimizing Memory for Bulk Uploads</li></ul><article class=documentation-article><div class=documentation-article__header><a href=https://qdrant.tech/articles/vector-search-manuals/ class=documentation-article__header-link><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path d="M14.6668 8.00004H1.3335m0 0L6.00016 12.6667M1.3335 8.00004 6.00016 3.33337" stroke="#8f98b3" stroke-width="1.33333" stroke-linecap="round" stroke-linejoin="round"/></svg>
Back to Vector Search Manuals</a><h1 class=documentation-article__header-title>Optimizing Memory for Bulk Uploads</h1><div class=documentation-article__header-about><p>Sabrina Aquino</p><span>&#183;</span><p>February 13, 2025</p></div><picture class=documentation-article__header-preview><source srcset=https://qdrant.tech/articles_data/indexing-optimization/preview/title.webp type=image/webp><img alt="Optimizing Memory for Bulk Uploads" src=https://qdrant.tech/articles_data/indexing-optimization/preview/title.jpg></picture></div><h1 id=optimizing-memory-consumption-during-bulk-uploads>Optimizing Memory Consumption During Bulk Uploads</h1><p>Efficient memory management is a constant challenge when you‚Äôre dealing with <strong>large-scale vector data</strong>. In high-volume ingestion scenarios, even seemingly minor configuration choices can significantly impact stability and performance.</p><p>Let‚Äôs take a look at the best practices and recommendations to help you optimize memory usage during bulk uploads in Qdrant. We&rsquo;ll cover scenarios with both <strong>dense</strong> and <strong>sparse</strong> vectors, helping your deployments remain performant even under high load and avoiding out-of-memory errors.</p><h2 id=indexing-for-dense-vs-sparse-vectors>Indexing for dense vs. sparse vectors</h2><p><strong>Dense vectors</strong></p><p>Qdrant employs an <strong>HNSW-based index</strong> for fast similarity search on dense vectors. By default, HNSW is built or updated once the number of <strong>unindexed</strong> vectors in a segment exceeds a set <code>indexing_threshold</code>. Although it delivers excellent query speed, building or updating the HNSW graph can be <strong>resource-intensive</strong> if it occurs frequently or across many small segments.</p><p><strong>Sparse vectors</strong></p><p>Sparse vectors use an <strong>inverted index</strong>. This index is updated at the <strong>time of upsertion</strong>, meaning you cannot disable or postpone it for sparse vectors. In most cases, its overhead is smaller than that of building an HNSW graph, but you should still be aware that each upsert triggers a sparse index update.</p><aside role=status>Sparse vectors are always indexed on upsert, regardless of the threshold.</aside><h2 id=bulk-upload-configuration-for-dense-vectors>Bulk upload configuration for dense vectors</h2><p>When performing high-volume vector ingestion, you have <strong>two primary options</strong> for handling indexing overhead. You should choose one depending on your specific workload and memory constraints:</p><ul><li><strong>Disable HNSW indexing</strong></li></ul><p>To reduce memory and CPU pressure during bulk ingestion, you can <strong>disable HNSW indexing entirely</strong> by setting <code>"m": 0</code>.
For dense vectors, the <code>m</code> parameter defines how many edges each node in the HNSW graph can have.
This way, no dense vector index will be built, preventing unnecessary CPU usage during ingestion.</p><p><strong>Figure 1:</strong> A description of three key HNSW parameters.</p><img src=https://qdrant.tech/articles_data/indexing-optimization/hnsw-parameters.png width=600><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=err>PATCH</span> <span class=err>/collections/your_collection</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;hnsw_config&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;m&#34;</span><span class=p>:</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>After ingestion is complete</strong>, you can <strong>re-enable HNSW</strong> by setting <code>m</code> back to a production value (commonly 16 or 32).
Remember that search won&rsquo;t use HNSW until the index is built, so search performance may be slower during this period.</p><ul><li><strong>Disabling optimizations completely</strong></li></ul><p>The <code>indexing_threshold</code> tells Qdrant how many unindexed dense vectors can accumulate in a segment before building the HNSW graph. Setting <code>"indexing_threshold"=0</code> defers indexing entirely, keeping <strong>ingestion speed at maximum</strong>. However, this means uploaded vectors are not moved to disk while uploading, which can lead to <strong>high RAM usage</strong>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=err>PATCH</span> <span class=err>/collections/your_collection</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;optimizer_config&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;indexing_threshold&#34;</span><span class=p>:</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><aside role=status>Warning: If your dataset is large, this can lead to excessive memory usage. Ensure your system has sufficient RAM or consider using "m"=0 instead.</aside><p>After bulk ingestion, set <code>indexing_threshold</code> to a positive value to ensure vectors are indexed and searchable via HNSW. <strong>Vectors will not be searchable via HNSW until indexing is performed.</strong></p><p>Small thresholds (e.g., 100) mean more frequent indexing, which can still be costly if many segments exist. Larger thresholds (e.g., 10000) delay indexing to batch more vectors at once, potentially using more RAM at the moment of index build, but fewer builds overall.</p><p>Between these two approaches, we generally recommend disabling HNSW (<code>"m"=0</code>) during bulk ingestion to keep memory usage predictable. Using <code>indexing_threshold=0</code> can be an alternative, but only if your system has enough memory to accommodate the unindexed vectors in RAM.</p><hr><h2 id=on-disk-storage-in-qdrant>On-Disk storage in Qdrant</h2><p>By default, Qdrant keeps <strong>vectors</strong>, <strong>payload data</strong>, and <strong>indexes</strong> in memory to ensure low-latency queries. However, in large-scale or memory-constrained scenarios, you can configure some or all of them to be stored on-disk. This helps reduce RAM usage at the cost of potential increases in query latency, particularly for cold reads.</p><p><strong>When to use on-disk</strong>:</p><ul><li>You have <strong>very large</strong> or <strong>rarely used</strong> payload data or indexes, and freeing up RAM is worth potential I/O overhead.</li><li>Your dataset doesn‚Äôt fit comfortably in available memory.</li><li>You want to reduce memory pressure.</li><li>You can tolerate slower queries if it ensures the system remains stable under heavy loads.</li></ul><hr><h2 id=memmap-storage-and-segmentation>Memmap storage and segmentation</h2><p>Qdrant uses <strong>memory-mapped files</strong> (segments) to store data on-disk. Rather than loading all vectors into RAM, Qdrant maps each segment into its address space, paging data in and out on demand. This helps keep the active RAM footprint lower, because data can be paged out if memory pressure is high. But each segment still incurs overhead (metadata, page table entries, etc.).</p><p>During <strong>high-volume ingestion</strong>, you can accumulate dozens of small segments. Qdrant‚Äôs <strong>optimizer</strong> can later merge these into fewer, larger segments, reducing per-segment overhead and lowering total memory usage.</p><p>When you create a collection with <code>"on_disk": true</code>, Qdrant will store newly inserted vectors in memmap storage from the start. For example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=err>PATCH</span> <span class=err>/collections/your_collection</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;vectors&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;on_disk&#34;</span><span class=p>:</span> <span class=kc>true</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>This approach immediately places all incoming vectors on disk, which can be very efficient in case of bulk ingestion.</p><p>However, <strong>vector data and indexes are stored separately</strong>, so enabling <code>on_disk</code> for vectors does not automatically store their indexes on disk. To fully optimize memory usage, you may need to configure <strong>both vector storage and index storage</strong> independently.</p><p>For dense vectors, you can enable on-disk storage for both the <strong>vector data</strong> and the <strong>HNSW index</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=err>PATCH</span> <span class=err>/collections/your_collection</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;vectors&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;on_disk&#34;</span><span class=p>:</span> <span class=kc>true</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;hnsw_config&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;on_disk&#34;</span><span class=p>:</span> <span class=kc>true</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>For sparse vectors, you need to enable <code>on_disk</code> for both the vector data and the sparse index separately:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=err>PATCH</span> <span class=err>/collections/your_collection</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;sparse_vectors&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;text&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;on_disk&#34;</span><span class=p>:</span> <span class=kc>true</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;index&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=nt>&#34;on_disk&#34;</span><span class=p>:</span> <span class=kc>true</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><hr><h2 id=best-practices-for-high-volume-vector-ingestion><strong>Best practices for high-volume vector ingestion</strong></h2><p>Bulk ingestion can lead to high memory consumption and even out-of-memory (OOM) errors. <strong>If you‚Äôre experiencing out-of-memory errors with your current setup</strong>, scaling up temporarily (increasing available RAM) will provide a buffer while you adjust Qdrant‚Äôs configuration for more a efficient data ingestion.</p><p>The key here is to control indexing overhead. Let‚Äôs walk through the best practices for high-volume vector ingestion in a constrained-memory environment.</p><h3 id=1-store-vector-data-on-disk-immediately>1. Store vector data on disk immediately</h3><p>The most effective way to reduce memory usage is to store vector data on disk right from the start using <code>on_disk: true</code>. This prevents RAM from being overloaded with raw vectors before optimization kicks in.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=err>PATCH</span> <span class=err>/collections/your_collection</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;vectors&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;on_disk&#34;</span><span class=p>:</span> <span class=kc>true</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Previously, vector data had to be held in RAM until optimizers could move it to disk, which caused significant memory pressure. Now, by writing vectors to disk directly, memory overhead is significantly reduced, making bulk ingestion much more efficient.</p><h3 id=2-disable-hnsw-for-dense-vectors-m0>2. Disable HNSW for dense vectors (<code>m=0</code>)</h3><p>During an <strong>initial bulk load</strong>, you can <strong>disable</strong> dense indexing by setting <code>"m": 0.</code> This ensures Qdrant won‚Äôt build an HNSW graph for incoming vectors, avoiding unnecessary memory and CPU usage.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=err>PATCH</span> <span class=err>/collections/your_collection</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;hnsw_config&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;m&#34;</span><span class=p>:</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;optimizer_config&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;indexing_threshold&#34;</span><span class=p>:</span> <span class=mi>10000</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><aside role=status>If your collection already contains a large number of vectors, changing these parameters will trigger a full index reconstruction, potentially causing slight performance degradation.</aside><h3 id=3-let-the-optimizer-run-after-bulk-uploads>3. Let the optimizer run <strong>after</strong> bulk uploads</h3><p>Qdrant‚Äôs optimizers continuously restructure data to improve search efficiency. However, during a bulk upload, this can lead to excessive data movement and overhead as segments are constantly reorganized while new data is still arriving.</p><p>To avoid this, <strong>upload all data first</strong>, then allow the optimizer to process everything in one go. This minimizes redundant operations and ensures a more efficient segment structure.</p><h3 id=4-wait-for-indexation-to-clear-up-memory><strong>4. Wait for indexation to clear up memory</strong></h3><p>Before performing additional operations, <strong>allow Qdrant to finish any ongoing indexing</strong>. Large indexing jobs can keep memory usage high until they fully complete.</p><p>Monitor Qdrant logs or metrics to confirm when indexing finishes‚Äîonce that happens, memory consumption should drop as intermediate data structures are freed.</p><h3 id=5-re-enable-hnsw-post-ingestion>5. Re-enable HNSW post-ingestion</h3><p>After the ingestion phase is over and memory usage has stabilized, re-enable HNSW for dense vectors by setting <code>m</code> back to a production value (commonly <code>16</code> or <code>32</code>):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=err>PATCH</span> <span class=err>/collections/your_collection</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;hnsw_config&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;m&#34;</span><span class=p>:</span> <span class=mi>16</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><aside role=status>If you're planning to use quantization, it‚Äôs best to enable it before re-enabling indexing, to avoid running additional optimizations later. Ideally, you can set both indexing and quantization in the same update call for efficiency.</aside><h3 id=5-enable-quantization>5. Enable quantization</h3><p>If you had planned to store all dense vectors on disk, be aware that searches can slow down drastically due to frequent disk I/O while memory pressure is high. A more balanced approach is <strong>scalar quantization</strong>: compress vectors (e.g., to <code>int8</code>) so they fit in RAM without occupying as much space as full floating-point values.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=err>PATCH</span> <span class=err>/collections/your_collection</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;quantization_config&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;scalar&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;int8&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;always_ram&#34;</span><span class=p>:</span> <span class=kc>true</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Quantized vectors remain <strong>in-memory</strong> yet consume less space, preserving much of the performance advantage of RAM-based search. Learn more about <a href=https://qdrant.tech/articles/what-is-vector-quantization/ target=_blank rel="noopener nofollow">vector quantization</a>.</p><h3 id=conclusion>Conclusion</h3><p>High-volume vector ingestion can place significant memory demands on Qdrant, especially if dense vectors are indexed in real time. By following these tips, you can substantially reduce the risk of out-of-memory errors and maintain stable performance in a memory-limited environment.</p><p>As always, monitor your system‚Äôs behavior. Review logs, watch metrics, and keep an eye on memory usage. Each workload is different, so it‚Äôs wise to fine-tune Qdrant‚Äôs parameters according to your hardware and data scale.</p></article><section class="docs-feedback d-print-none"><h5 class=docs-feedback__title>Was this page useful?</h5><div class=docs-feedback__buttons><button class="button button_outlined button_sm docs-feedback__button" id=feedback__answer_yes>
<img src=https://qdrant.tech/icons/outline/thumb-up.svg alt="Thumb up icon">
Yes
</button>
<button class="button button_outlined button_sm docs-feedback__button" id=feedback__answer_no>
<img src=https://qdrant.tech/icons/outline/thumb-down.svg alt="Thumb down icon">
No</button></div></section><section class="docs-feedback__responses d-none"><p class="docs-feedback__response docs-feedback__response_yes" id=feedback__response_yes>Thank you for your feedback! üôè</p><p class="docs-feedback__response docs-feedback__response_no" id=feedback__response_no>We are sorry to hear that. üòî You can <a class=text-brand-p href=https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/indexing-optimization.md target=_blank>edit</a> this page on GitHub, or <a class=text-brand-p href=https://github.com/qdrant/landing_page/issues/new/choose target=_blank>create</a> a GitHub issue.</p></section><script>const buttonsSection=document.querySelector(".docs-feedback"),responsesSection=document.querySelector(".docs-feedback__responses"),yesButton=document.querySelector("#feedback__answer_yes"),noButton=document.querySelector("#feedback__answer_no"),yesResponse=document.querySelector("#feedback__response_yes"),noResponse=document.querySelector("#feedback__response_no"),toggleResponses=()=>{buttonsSection.classList.add("d-none"),responsesSection.classList.remove("d-none")};yesButton.addEventListener("click",()=>{yesResponse.classList.add("feedback__response_visible"),toggleResponses()}),noButton.addEventListener("click",()=>{noResponse.classList.add("feedback__response_visible"),toggleResponses()})</script></div><div class=table-of-contents><p class=table-of-contents__head>On this page:</p><nav id=TableOfContents><ul><li><a href=#indexing-for-dense-vs-sparse-vectors>Indexing for dense vs. sparse vectors</a></li><li><a href=#bulk-upload-configuration-for-dense-vectors>Bulk upload configuration for dense vectors</a></li><li><a href=#on-disk-storage-in-qdrant>On-Disk storage in Qdrant</a></li><li><a href=#memmap-storage-and-segmentation>Memmap storage and segmentation</a></li><li><a href=#best-practices-for-high-volume-vector-ingestion><strong>Best practices for high-volume vector ingestion</strong></a><ul><li><a href=#1-store-vector-data-on-disk-immediately>1. Store vector data on disk immediately</a></li><li><a href=#2-disable-hnsw-for-dense-vectors-m0>2. Disable HNSW for dense vectors (<code>m=0</code>)</a></li><li><a href=#3-let-the-optimizer-run-after-bulk-uploads>3. Let the optimizer run <strong>after</strong> bulk uploads</a></li><li><a href=#4-wait-for-indexation-to-clear-up-memory><strong>4. Wait for indexation to clear up memory</strong></a></li><li><a href=#5-re-enable-hnsw-post-ingestion>5. Re-enable HNSW post-ingestion</a></li><li><a href=#5-enable-quantization>5. Enable quantization</a></li><li><a href=#conclusion>Conclusion</a></li></ul></li></ul></nav><ul class=table-of-contents__external-links><li class=table-of-contents__link><a href=https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/indexing-optimization.md target=_blank><svg width="16" height="17" viewBox="0 0 16 17" fill="none"><g clip-path="url(#clip0_6269_955)"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 .700012c-4.4.0-8 3.599998-8 7.999998C0 12.2333 2.26667 15.2333 5.46667 16.3 5.86667 16.3667 6 16.1 6 15.9S6 15.2333 6 14.5667C3.8 15.0333 3.33333 13.5 3.33333 13.5 3 12.5667 2.46667 12.3 2.46667 12.3 1.66667 11.8333 2.46667 11.8333 2.46667 11.8333 3.26667 11.9 3.66667 12.6333 3.66667 12.6333 4.4 13.8333 5.53333 13.5 6 13.3 6.06667 12.7667 6.26667 12.4333 6.53333 12.2333 4.73333 12.0333 2.86667 11.3667 2.86667 8.30001c0-.86666.33333-1.6.8-2.13333.0-.26667-.33334-1.06667.13333-2.13333.0.0.66667-.200000000000001 2.2.8.66667-.2 1.33333-.26667 2-.26667S9.33333 4.63335 10 4.83335c1.5333-1.06667 2.2-.8 2.2-.8C12.6667 5.16668 12.3333 5.96668 12.2667 6.16668 12.8 6.70001 13.0667 7.43335 13.0667 8.30001c0 3.06669-1.8667 3.73329-3.6667 3.93329C9.66667 12.5 9.93333 12.9667 9.93333 13.7c0 1.0667.0 1.9333.0 2.2C9.93333 16.1 10.0667 16.3667 10.4667 16.3c3.2-1.0667 5.4666-4.0667 5.4666-7.59999C16 4.30001 12.4.700012 8 .700012z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_6269_955"><rect width="16" height="16" fill="#fff" transform="translate(0 0.5)"/></clipPath></defs></svg>
Edit on Github</a></li><li class=table-of-contents__link><a href=https://github.com/qdrant/landing_page/issues/new/choose target=_blank><svg width="16" height="17" viewBox="0 0 16 17" fill="none"><g clip-path="url(#clip0_6269_1540)"><path d="M16 9.83331V8.49998H13.9347C13.79 7.33465 13.3947 6.24065 12.8 5.31065l1.476-1.478L13.3327 2.89065 11.9633 4.26198c-.24-.248-.496600000000001-.474-.772-.676C11.0967 3.25665 10.9507 2.95398 10.7673 2.67598l1.038-1.038L10.8627.695312 9.82867 1.72931C9.29867 1.37798 8.672 1.16665 8 1.16665c-.672.0-1.29867.21133-1.828.56266L5.138.695312l-.94267.942668 1.038 1.038c-.18333.27733-.32933.58-.424.90867-.27533.202-.532.42933-.77266.67733L2.66733 2.89065l-.94333.942L3.2 5.30998c-.59467.93-.99 2.02467-1.13467 3.19H0V9.83331H2.01467C2.07333 11.276 2.50533 12.6026 3.204 13.688l-1.48 1.478L2.666 16.1093l1.37-1.368C4.93733 15.67 6.07667 16.288 7.33333 16.452V6.49998H8.66667V16.452C9.92333 16.2873 11.0627 15.67 11.964 14.7413l1.37 1.368L14.276 15.166l-1.48-1.478C13.4947 12.602 13.9267 11.2753 13.9853 9.83331H16z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_6269_1540"><rect width="16" height="16" fill="#fff" transform="translate(0 0.5)"/></clipPath></defs></svg>
Create an issue</a></li></ul></div><footer class="docs-footer w-100 py-0 pt-0 pb-4 pb-xl-0"><div class=docs-footer__cta><h4>Ready to get started with Qdrant?</h4><a href=https://qdrant.to/cloud/ class="button button_outlined button_sm" target=_blank>Start Free</a></div><div class=docs-footer__bottom><div class=docs-footer__bottom-content><span>¬© 2025 Qdrant.</span><div class=footer__bottom-links><a href=https://qdrant.tech/legal/terms_and_conditions/>Terms</a>
<a href=https://qdrant.tech/legal/privacy-policy/>Privacy Policy</a>
<a href=https://qdrant.tech/legal/impressum/>Impressum</a></div></div></div></footer></div></div></div></div></section></main></body><script src=https://cdn.cookielaw.org/scripttemplates/otSDKStub.js type=text/javascript data-domain-script=01960152-5e40-782d-af01-f7f5768a214e></script><script async type=text/javascript>function OptanonWrapper(){const e=new CustomEvent("onetrust_loaded");document.dispatchEvent(e)}</script><script>!function(){const o="eQYi1nZE2zQSmnHuxjMRlDd2uLl65oHe";var n,s,t="analytics",e=window[t]=window[t]||[];if(!e.initialize)if(e.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{e.invoked=!0,e.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","debug","page","screen","once","off","on","addSourceMiddleware","addIntegrationMiddleware","setAnonymousId","addDestinationMiddleware","register"],e.factory=function(n){return function(){if(window[t].initialized)return window[t][n].apply(window[t],arguments);var o,s=Array.prototype.slice.call(arguments);return["track","screen","alias","group","page","identify"].indexOf(n)>-1&&(o=document.querySelector("link[rel='canonical']"),s.push({__t:"bpc",c:o&&o.getAttribute("href")||void 0,p:location.pathname,u:location.href,s:location.search,t:document.title,r:document.referrer})),s.unshift(n),e.push(s),e}};for(n=0;n<e.methods.length;n++)s=e.methods[n],e[s]=e.factory(s);e.load=function(n,s){var i,o=document.createElement("script");o.type="text/javascript",o.async=!0,o.setAttribute("data-global-segment-analytics-key",t),o.src="https://evs.analytics.qdrant.tech/5caWuitPgcGFN5Q7HMpTaj/vEkmzjuRSqeXGbhGAFTWex.min.js",i=document.getElementsByTagName("script")[0],i.parentNode.insertBefore(o,i),e._loadOptions=s},e._writeKey=o,e._cdn="https://evs.analytics.qdrant.tech",e.SNIPPET_VERSION="5.2.0",e.load(o)}}()</script><script src=https://qdrant.tech/js/google-setup.min.14728a3ae9bd931593645b6ddbfe801d400cd2970006e782cb67f3966654248ca962dbaf4cf371493a2d326861b3a691a99d6d8349c8b2752339ab91d3787069.js></script><script src=https://qdrant.tech/js/index.min.e37feda1952d752f5568e1ebc55e183629e4d361f4df09edeed70b4a4327d601161c4147bdbe4149b4a3cdc1ed43f1bf1a2f2340a421f1aa821103980dfe0bda.js></script><script src=https://qdrant.tech/js/search/search.min.e58e7ea98cb549ea9d3ed7e68876abe323cfb323432038820f38a71c40e309deed0fba615e2d3346825229a81e0a76bbadf6f8a816ddad3438abdabfef4ebc09.js type=module></script><script src=https://qdrant.tech/js/search/scroll.min.f4ed4453a3af0adb0d4f49333cbb7892ff5430483a567d0d2dfbd4655fb203d22f22f46aff3d9f38fa5fd96dde5f30227afd0ce1d9f838f5cd5295fc83856ec9.js></script><script src=https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js></script><script src=https://qdrant.tech/js/copy-code.min.95b03a45b2ab4b7a608ecfd4b5919c8572a5b2cd1463f52561cd10976abf3b74334f91324c0e620cb80afac46026a0b18cce6fb753d8495f74c6d478c8ca1d03.js></script><script src=https://qdrant.tech/js/lang-switcher.min.63da11cef09772078425b1ee56415b9c37842a9399f2ba2d2f5efbf72fb751686c410bd50e9bcd283c8231cb97c1973199d4923beef29d8b06e59d9983a6ba51.js></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src=https://qdrant.tech/js/vendor/anchor.min.0e138e17ebcf1c1147a7a3a81d9ac3c601622eedc479f1636470eb2552470f4e27c9a8efe6e8378995dedc1ab67029d8989536ea76f0857d45d1615ae772b8a1.js></script><script>document.addEventListener("keydown",function(e){if((e.metaKey||e.ctrlKey)&&e.key==="k"){e.preventDefault();let t=document.querySelector('[data-target="#searchModal"]');t&&t?.click()}})</script><script>window.addEventListener("message",e=>{if(e.data.type==="hsFormCallback"&&e.data.eventName==="onFormReady"){const t=document.querySelector(`form[data-form-id="${e.data.id}"]`);if(t){const e=t.querySelector('[name="last_form_fill_url"]');e&&(e.value=window.location.href);const n=t.querySelector('[name="referrer_url"]');n&&(n.value=document.referrer)}}})</script></html>