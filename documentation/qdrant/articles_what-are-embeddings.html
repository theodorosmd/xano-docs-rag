<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta charset=UTF-8><title>What are Vector Embeddings? - Revolutionize Your Search Experience - Qdrant</title>
<link rel=icon href=https://qdrant.tech/favicon/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=https://qdrant.tech/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://qdrant.tech/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://qdrant.tech/favicon/favicon-16x16.png><link rel=manifest href=https://qdrant.tech/favicon/site.webmanifest><link rel=mask-icon href=https://qdrant.tech/favicon/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#2b5797"><meta name=msapplication-config content="/favicon/browserconfig.xml"><meta name=theme-color content="#ffffff"><meta name=partition content="learn"><link href=https://qdrant.tech/css/search/search.min.09596ee2b3c94d0ac82a1c33199cabdb3e0210b1ee46aaf1515200e9e484d05dd9e27cc1e861c58cc2e582af162f63b8e180ff2a12f7a6592b7aeaa0a7125130.css rel=stylesheet integrity="sha512-CVlu4rPJTQrIKhwzGZyr2z4CELHuRqrxUVIA6eSE0F3Z4nzB6GHFjMLlgq8WL2O44YD/KhL3plkreuqgpxJRMA=="><link href=https://qdrant.tech/css/documentation.min.de204cdcfc410689a41c17bcdad0a34f2caaa50cc8505c820adaab481cef2d69a920b0a32e0d624701c29487e3271b694559d98c5047cbfaa5aa475f638011e5.css rel=stylesheet integrity="sha512-3iBM3PxBBomkHBe82tCjTyyqpQzIUFyCCtqrSBzvLWmpILCjLg1iRwHClIfjJxtpRVnZjFBHy/qlqkdfY4AR5Q=="><link href=https://qdrant.tech/css/main.min.c1e379ad4cf03647832f6a0f040754b0be3e79934db2c29f50b396327c1ec7ac45f778abadbd93f5a8bc431850d1b0d9c9eff34c0171cd4236e83c5e324c1a0e.css rel=stylesheet integrity crossorigin=anonymous><meta name=generator content="Hugo 0.141.0"><meta name=description content="Discover the power of vector embeddings. Learn how to harness the potential of numerical machine learning representations to create a personalized Neural Search Service with FastEmbed."><meta name=keywords content="vector search engine,neural network,matching,SaaS,approximate nearest neighbor search,image search,recommender system,vectors,knn algorithm,hnsw,vector search,embeddings,similarity,simaes networks,BERT,transformer,word2vec,fasttext,qdrant"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@id":"https://qdrant.tech/articles/what-are-embeddings/#article","@type":"Article","abstract":"Discover the power of vector embeddings Learn how to harness the potential of numerical machine learning representations to create a personalized Neural Search Service with FastEmbed","author":{"@type":"Person","name":"Sabrina Aquino"},"dateModified":"2024-02-06 15:29:33 -0300 -0300","datePublished":"2024-02-06 15:29:33 -0300 -0300","description":"Discover the power of vector embeddings Learn how to harness the potential of numerical machine learning representations to create a personalized Neural Search Service with FastEmbed","headline":"What are Vector Embeddings? - Revolutionize Your Search Experience","image":["https://qdrant.tech/articles_data/what-are-embeddings/preview/social-preview.jpg"],"name":"What are Vector Embeddings? - Revolutionize Your Search Experience","url":"https://qdrant.tech/articles/what-are-embeddings/","wordCount":"1163"},{"@id":"https://qdrant.tech/articles/what-are-embeddings/#organization","@type":"Organization","address":{"@type":"PostalAddress","addressCountry":"DE","addressLocality":"Berlin","addressRegion":"Berlin","postalCode":"10115","streetAddress":"Chausseestra√üe 86"},"contactPoint":{"@type":"ContactPoint","contactType":"customer support","email":"info@qdrant.com","telephone":"+49 3040797694"},"description":"Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.","email":"info@qdrant.com","founders":[{"@type":"Person","name":"map[email:info@qdrant.tech name:Andrey Vasnetsov]"},{"@type":"Person","name":"Andre Zayarni"}],"foundingDate":"2021","keywords":["vector search engine","neural network","matching","SaaS","approximate nearest neighbor search","image search","recommender system","vectors","knn algorithm","hnsw","vector search","embeddings","similarity","simaes networks","BERT","transformer","word2vec","fasttext","Qdrant"],"legalName":"Qdrant Solutions GmbH","location":"Berlin, Germany","logo":"https://qdrant.tech/images/logo_with_text.png","name":"Qdrant","sameAs":["https://github.com/qdrant/qdrant","https://qdrant.to/discord","https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA","https://www.linkedin.com/company/qdrant/","https://twitter.com/qdrant_engine"],"url":"https://qdrant.tech"}]}</script><meta property="og:url" content="https://qdrant.tech/articles/what-are-embeddings/"><meta property="og:type" content="website"><meta property="og:title" content="What are Vector Embeddings? - Revolutionize Your Search Experience - Qdrant"><meta name=twitter:card content="summary_large_image"><meta name=twitter:domain content="qdrant"><meta name=twitter:url content="https://qdrant.tech/articles/what-are-embeddings/"><meta name=twitter:title content="What are Vector Embeddings? - Revolutionize Your Search Experience - Qdrant"><meta property="og:description" content="Discover the power of vector embeddings. Learn how to harness the potential of numerical machine learning representations to create a personalized Neural Search Service with FastEmbed."><meta name=twitter:description content="Discover the power of vector embeddings. Learn how to harness the potential of numerical machine learning representations to create a personalized Neural Search Service with FastEmbed."><meta name=image property="og:image" content="https://qdrant.tech/articles_data/what-are-embeddings/preview/social-preview.jpg"><meta name=image property="og:image:secure_url" content="https://qdrant.tech/articles_data/what-are-embeddings/preview/social-preview.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name=twitter:image:src content="https://qdrant.tech/articles_data/what-are-embeddings/preview/social-preview.jpg"><meta name=author content="Sabrina Aquino"><link rel=canonical href=https://qdrant.tech/articles/what-are-embeddings/><script type=text/javascript src=//js-eu1.hsforms.net/forms/embed/v2.js></script><script src=https://qdrant.tech/js/documentation.min.594fc9226f6fb87b8c3b0cafb9d5c0b0bcd95f47d292b929aab04315e0506706b2f376dc4fae9961dc3082138cb19d45b2a3370ee8e881bbf4b8c91dcb735c32.js></script></head><body><main><header class=docs-header><div class="main-menu z-5"><a href=https://qdrant.tech/><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div></a><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><div class="d-block d-xl-none"><button role=button class=theme-switch></button></div><button type=button class=main-menu__trigger><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M1 12H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 5H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 19H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=main-menu__links><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/>Qdrant</a></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/cloud-intro/>Cloud</a></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/build/>Build</a></li><li class=main-menu__item><a class=menu-linkactive href=https://qdrant.tech/articles/>Learn</a></li><li class=main-menu__item><a class=menu-link href=https://api.qdrant.tech/api-reference target=_blank>API Reference</a></li></ul><div class=main-menu__buttons><div class=main-menu__buttons-input><button class="qdr-search-input-btn q-input input_md input_light-bg" type=button name=search data-target=#searchModal>
Search</button></div><button role=button class=theme-switch></button>
<a data-metric-loc=nav href=https://cloud.qdrant.io/login class="menu-link mx-3" target=_blank>Log in</a>
<a data-metric-loc=nav href=https://cloud.qdrant.io/signup class="button button_contained button_sm" target=_blank>Start Free</a></div></div><div class=menu-mobile><div class=menu-mobile__header><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><div class="d-block d-xl-none"><button role=button class=theme-switch></button></div><button type=button class=menu-mobile__close><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><g id="Close"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M19.778 5.63606C20.1685 5.24554 20.1685 4.61237 19.778 4.22185 19.3874 3.83132 18.7543 3.83132 18.3637 4.22185L11.9998 10.5858 5.63586 4.22185c-.39052-.39053-1.02369-.39053-1.41421.0C3.83112 4.61237 3.83112 5.24554 4.22165 5.63606L10.5856 12l-6.364 6.364C3.83108 18.7545 3.83108 19.3877 4.2216 19.7782 4.61213 20.1687 5.24529 20.1687 5.63582 19.7782l6.36398-6.364 6.364 6.364C18.7543 20.1687 19.3875 20.1687 19.778 19.7782 20.1685 19.3877 20.1685 18.7545 19.778 18.364L13.414 12l6.364-6.36394z" fill="#e1e5f0"/></g></svg></button></div></div><div class=main-menu__buttons-input><button class="qdr-search-input-btn q-input input_md input_light-bg" type=button name=search data-target=#searchModal>
Search</button></div><ul class=menu-mobile__items><li class=menu-mobile__item data-path=menu-0><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Documentation"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M4.25 1c-1.10092.0-2.12247.23681-2.88689.64443C.620129 2.04063.0 2.67297.0 3.5v11c0 .2761.223858.5.5.5s.5-.2239.5-.5c0-.278.21937-.6456.83364-.9732C2.42647 13.2107 3.27992 13 4.25 13 5.22008 13 6.07353 13.2107 6.66636 13.5268c.61427.3276.83364.6952.83364.9732.0.2761.22386.5.5.5s.5-.2239.5-.5c0-.278.21937-.6456.833640000000001-.9732C9.92647 13.2107 10.7799 13 11.75 13S13.5735 13.2107 14.1664 13.5268C14.7806 13.8544 15 14.222 15 14.5c0 .2761.2239.5.5.5s.5-.2239.5-.5V3.5C16 2.67297 15.3799 2.04063 14.6369 1.64443 13.8725 1.23681 12.8509 1 11.75 1s-2.12247.23681-2.88689.64443C8.53799 1.8178 8.2364 2.03638 8 2.29671c-.2364-.26033-.53799-.47891-.86311-.65228C6.37247 1.23681 5.35092 1 4.25 1zM1.36311 12.6444C1.23778 12.7113 1.11595 12.7848 1 12.8649V3.5c0-.27797.21937-.64563.83364-.97318C2.42647 2.21069 3.27992 2 4.25 2c.97008.0 1.82353.21069 2.41636.52682C7.28063 2.85437 7.5 3.22203 7.5 3.5v9.3649C7.38405 12.7848 7.26222 12.7113 7.13689 12.6444 6.37247 12.2368 5.35092 12 4.25 12 3.14908 12 2.12753 12.2368 1.36311 12.6444zM8.5 12.8649C8.61595 12.7848 8.73778 12.7113 8.86311 12.6444 9.62753 12.2368 10.6491 12 11.75 12S13.8725 12.2368 14.6369 12.6444C14.7622 12.7113 14.8841 12.7848 15 12.8649V3.5C15 3.22203 14.7806 2.85437 14.1664 2.52682 13.5735 2.21069 12.7201 2 11.75 2s-1.82353.21069-2.41636.52682C8.71937 2.85437 8.5 3.22203 8.5 3.5v9.3649z"/></g></svg>
Qdrant</a></div></li><li class=menu-mobile__item data-path=menu-1><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/cloud-intro/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Cloud"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M7.5 2C4.57416 2 2.18128 4.28566 2.00983 7.16851.8403 7.57763.0 8.68965.0 10c0 1.6571 1.34286 3 3 3H13c1.6571.0 3-1.3429 3-3 0-1.65714-1.3429-3-3-3L12.9776 7.00009C12.7249 4.19714 10.3686 2 7.5 2zM3.00107 7.48137 3.00008 7.47308C3.01457 5.0006 5.02412 3 7.5 3c2.47599.0 4.4856 2.00079 4.4999 4.47342L11.9987 7.4836C11.9969 7.50027 11.995 7.52348 11.995 7.551 11.995 7.701 12.0623 7.84308 12.1785 7.93804 12.2946 8.03301 12.4472 8.07082 12.5942 8.04106 12.726 8.01438 12.8617 8 13 8c1.1049.0 2 .89514 2 2C15 11.1049 14.1049 12 13 12H3C1.89514 12 1 11.1049 1 10 1 9.03225 1.68901 8.22422 2.60364 8.04017 2.83708 7.9932 3.005 7.78812 3.005 7.55 3.005 7.52154 3.00291 7.49773 3.00107 7.48137z"/></g></svg>
Cloud</a></div></li><li class=menu-mobile__item data-path=menu-2><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/build/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Blog"><path id="Union" fill-rule="evenodd" clip-rule="evenodd" d="M0 1.5C0 1.22386.223858 1 .5 1h5c.27614.0.5.22386.5.5v5c0 .27614-.22386.5-.5.5H.5C.223858 7 0 6.77614.0 6.5v-5zM1 2V6H5V2H1zm7 .5c0-.27614.22386-.5.5-.5h7c.2761.0.5.22386.5.5s-.2239.5-.5.5h-7C8.22386 3 8 2.77614 8 2.5zM8.5 6c-.27614.0-.5.22386-.5.5s.22386.5.5.5h7c.2761.0.5-.22386.5-.5s-.2239-.5-.5-.5h-7zM0 10.5c0-.2761.223858-.5.5-.5h15c.2761.0.5.2239.5.5s-.2239.5-.5.5H.5c-.276142.0-.5-.2239-.5-.5zM.5 14c-.276142.0-.5.2239-.5.5s.223858.5.5.5h15c.2761.0.5-.2239.5-.5s-.2239-.5-.5-.5H.5z"/></g></svg>
Build</a></div></li><li class=menu-mobile__item data-path=menu-3><div class=menu-mobile__item-content><a class=active href=https://qdrant.tech/articles/><svg width="16" height="16" viewBox="0 0 16 16" fill="none" stroke="#e1e5f0"><g id="Group"><path id="Vector" d="M10.084 1.84094l4.059 4.059" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_2" d="M8.49188 2.72406c-1.22044-.53042-2.59304-.59475-3.85774-.1808-1.2647.41395-2.33363 1.27742-3.00426 2.4268l2.34 2.34" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_3" d="M13.2657 7.47302C13.8062 8.69691 13.8769 10.077 13.4645 11.3497c-.4125 1.2728-1.2792 2.3491-2.4348 3.0233l-2.35001-2.35" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_4" d="M6.81217 13.049l-3.861-3.861S6.24917.983 15.5002.5c-.523 9.211-8.68803 12.549-8.68803 12.549z" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_5" d="M3.59892 12.4008C3.34181 12.1441 2.99331 12 2.62995 12c-.36335.0-.71186.1441-.96897.4008-.46665.4664-.63131 1.941-.65931 2.2322C.997021 14.6793 1.0021 14.726 1.01659 14.7701 1.03108 14.8143 1.05465 14.8549 1.08579 14.8895 1.11693 14.924 1.15495 14.9516 1.19741 14.9705 1.23987 14.9895 1.28583 14.9994 1.33233 14.9995 1.34298 15.0002 1.35367 15.0002 1.36433 14.9995 1.65565 14.9715 3.1316 14.8063 3.59759 14.3405 3.85501 14.0834 3.99975 13.7346 4 13.3709 4.00025 13.0072 3.85599 12.6582 3.59892 12.4008z" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_6" d="M9 8c.55228.0 1-.44772 1-1S9.55228 6 9 6 8 6.44772 8 7s.44772 1 1 1z"/></g></svg>
Learn</a></div></li><li class=menu-mobile__item data-path=menu-4><div class=menu-mobile__item-content><a href=https://api.qdrant.tech/api-reference target=_blank><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Roadmap" clip-path="url(#clip0_7182_4311)"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M13.5 1c-.8284.0-1.5.67157-1.5 1.5S12.6716 4 13.5 4 15 3.32843 15 2.5 14.3284 1 13.5 1zM11 2.5C11 1.11929 12.1193.0 13.5.0S16 1.11929 16 2.5 14.8807 5 13.5 5 11 3.88071 11 2.5zM2.5 12c-.82843.0-1.5.6716-1.5 1.5S1.67157 15 2.5 15 4 14.3284 4 13.5 3.32843 12 2.5 12zM0 13.5C0 12.1193 1.11929 11 2.5 11S5 12.1193 5 13.5 3.88071 16 2.5 16 0 14.8807.0 13.5zM3.65901 1.65901C4.08097 1.23705 4.65326 1 5.25 1s1.16903.23705 1.59099.65901C7.26295 2.08097 7.5 2.65326 7.5 3.25v9.5c0 .862.34241 1.6886.9519 2.2981C9.0614 15.6576 9.88805 16 10.75 16c.862.0 1.6886-.3424 2.2981-.9519S14 13.612 14 12.75V6.5c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v6.25C13 13.3467 12.7629 13.919 12.341 14.341 11.919 14.7629 11.3467 15 10.75 15S9.58097 14.7629 9.15901 14.341C8.73705 13.919 8.5 13.3467 8.5 12.75V3.25C8.5 2.38805 8.15759 1.5614 7.5481.951903 6.9386.34241 6.11195.0 5.25.0S3.5614.34241 2.9519.951903C2.34241 1.5614 2 2.38805 2 3.25V9.5c0 .27614.22386.5.5.5s.5-.22386.5-.5V3.25c0-.59674.23705-1.16903.65901-1.59099z"/></g><defs><clipPath id="clip0_7182_4311"><rect width="16" height="16" fill="#fff"/></clipPath></defs></svg>
API Reference</a></div></li></ul><div class=docs-menu><div id=sidebar class=docs-menu__content><h3 class=docs-menu__links-title>Learn</h3><nav><div class=docs-menu__links-group><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/vector-search-manuals/>Vector Search Manuals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/qdrant-internals/>Qdrant Internals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/data-exploration/>Data Exploration</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/machine-learning/>Machine Learning</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/rag-and-genai/>RAG & GenAI</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/practicle-examples/>Practical Examples</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/ecosystem/>Ecosystem</a></div></div></nav></div></div></div></header><section class="docs documentation"><div class=documentation__container><div class="d-flex flex-column flex-xl-row"><div class=docs-menu><div id=sidebar class=docs-menu__content><h3 class=docs-menu__links-title>Learn</h3><nav><div class=docs-menu__links-group><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/vector-search-manuals/>Vector Search Manuals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/qdrant-internals/>Qdrant Internals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/data-exploration/>Data Exploration</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/machine-learning/>Machine Learning</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/rag-and-genai/>RAG & GenAI</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/practicle-examples/>Practical Examples</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/ecosystem/>Ecosystem</a></div></div></nav></div></div><div class=documentation__content><div class=documentation__content-wrapper><div class=documentation__article-wrapper><ul class=docs-breadcrumbs><li class=docs-breadcrumbs__crumb><a href=https://qdrant.tech/articles/>Articles</a></li><li class=docs-breadcrumbs__crumb-separator></li><li class=docs-breadcrumbs__crumb>What are Vector Embeddings? - Revolutionize Your Search Experience</li></ul><article class=documentation-article><div class=documentation-article__header><a href=https://qdrant.tech/articles/vector-search-manuals/ class=documentation-article__header-link><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path d="M14.6668 8.00004H1.3335m0 0L6.00016 12.6667M1.3335 8.00004 6.00016 3.33337" stroke="#8f98b3" stroke-width="1.33333" stroke-linecap="round" stroke-linejoin="round"/></svg>
Back to Vector Search Manuals</a><h1 class=documentation-article__header-title>What are Vector Embeddings? - Revolutionize Your Search Experience</h1><div class=documentation-article__header-about><p>Sabrina Aquino</p><span>&#183;</span><p>February 06, 2024</p></div><picture class=documentation-article__header-preview><source srcset=https://qdrant.tech/articles_data/what-are-embeddings/preview/title.webp type=image/webp><img alt="What are Vector Embeddings? - Revolutionize Your Search Experience" src=https://qdrant.tech/articles_data/what-are-embeddings/preview/title.jpg></picture></div><blockquote><p><strong>Embeddings</strong> are numerical machine learning representations of the semantic of the input data. They capture the meaning of complex, high-dimensional data, like text, images, or audio, into vectors. Enabling algorithms to process and analyze the data more efficiently.</p></blockquote><p>You know when you‚Äôre scrolling through your social media feeds and the content just feels incredibly tailored to you? There&rsquo;s the news you care about, followed by a perfect tutorial with your favorite tech stack, and then a meme that makes you laugh so hard you snort.</p><p>Or what about how YouTube recommends videos you ended up loving. It‚Äôs by creators you&rsquo;ve never even heard of and you didn‚Äôt even send YouTube a note about your ideal content lineup.</p><p>This is the magic of embeddings.</p><p>These are the result of <strong>deep learning models</strong> analyzing the data of your interactions online. From your likes, shares, comments, searches, the kind of content you linger on, and even the content you decide to skip. It also allows the algorithm to predict future content that you are likely to appreciate.</p><p>The same embeddings can be repurposed for search, ads, and other features, creating a highly personalized user experience.</p><p><img src=https://qdrant.tech/articles_data/what-are-embeddings/Embeddings-Use-Case.jpg alt="How embeddings are applied to perform recommendantions and other use cases"></p><p>They make <a href=https://www.sciencedirect.com/topics/computer-science/high-dimensional-data target=_blank rel="noopener nofollow">high-dimensional</a> data more manageable. This reduces storage requirements, improves computational efficiency, and makes sense of a ton of <strong>unstructured</strong> data.</p><h2 id=why-use-vector-embeddings>Why use vector embeddings?</h2><p>The <strong>nuances</strong> of natural language or the hidden <strong>meaning</strong> in large datasets of images, sounds, or user interactions are hard to fit into a table. Traditional relational databases can&rsquo;t efficiently query most types of data being currently used and produced, making the <strong>retrieval</strong> of this information very limited.</p><p>In the embeddings space, synonyms tend to appear in similar contexts and end up having similar embeddings. The space is a system smart enough to understand that &ldquo;pretty&rdquo; and &ldquo;attractive&rdquo; are playing for the same team. Without being explicitly told so.</p><p>That‚Äôs the magic.</p><p>At their core, vector embeddings are about semantics. They take the idea that &ldquo;a word is known by the company it keeps&rdquo; and apply it on a grand scale.</p><p><img src=https://qdrant.tech/articles_data/what-are-embeddings/Similar-Embeddings.jpg alt="Example of how synonyms are placed closer together in the embeddings space"></p><p>This capability is crucial for creating search systems, recommendation engines, retrieval augmented generation (RAG) and any application that benefits from a deep understanding of content.</p><h2 id=how-do-embeddings-work>How do embeddings work?</h2><p>Embeddings are created through neural networks. They capture complex relationships and semantics into <a href=https://www1.se.cuhk.edu.hk/~seem5680/lecture/semantics-with-dense-vectors-2018.pdf target=_blank rel="noopener nofollow">dense vectors</a> which are more suitable for machine learning and data processing applications. They can then project these vectors into a proper <strong>high-dimensional</strong> space, specifically, a <a href=https://qdrant.tech/articles/what-is-a-vector-database/>Vector Database</a>.</p><p><img src=https://qdrant.tech/articles_data/what-are-embeddings/How-Embeddings-Work.jpg alt="The process for turning raw data into embeddings and placing them into the vector space"></p><p>The meaning of a data point is implicitly defined by its <strong>position</strong> on the vector space. After the vectors are stored, we can use their spatial properties to perform <a href="https://en.wikipedia.org/wiki/Nearest_neighbor_search#:~:text=Nearest%20neighbor%20search%20%28NNS%29%2C,the%20larger%20the%20function%20values." target=_blank rel="noopener nofollow">nearest neighbor searches</a>. These searches retrieve semantically similar items based on how close they are in this space.</p><blockquote><p>The quality of the vector representations drives the performance. The embedding model that works best for you depends on your use case.</p></blockquote><h3 id=creating-vector-embeddings>Creating vector embeddings</h3><p>Embeddings translate the complexities of human language to a format that computers can understand. It uses neural networks to assign <strong>numerical values</strong> to the input data, in a way that similar data has similar values.</p><p><img src=https://qdrant.tech/articles_data/what-are-embeddings/How-Do-Embeddings-Work_.jpg alt="The process of using Neural Networks to create vector embeddings"></p><p>For example, if I want to make my computer understand the word &lsquo;right&rsquo;, I can assign a number like 1.3. So when my computer sees 1.3, it sees the word &lsquo;right‚Äô.</p><p>Now I want to make my computer understand the context of the word ‚Äòright‚Äô. I can use a two-dimensional vector, such as [1.3, 0.8], to represent &lsquo;right&rsquo;. The first number 1.3 still identifies the word &lsquo;right&rsquo;, but the second number 0.8 specifies the context.</p><p>We can introduce more dimensions to capture more nuances. For example, a third dimension could represent formality of the word, a fourth could indicate its emotional connotation (positive, neutral, negative), and so on.</p><p>The evolution of this concept led to the development of embedding models like <a href=https://en.wikipedia.org/wiki/Word2vec target=_blank rel="noopener nofollow">Word2Vec</a> and <a href=https://en.wikipedia.org/wiki/GloVe target=_blank rel="noopener nofollow">GloVe</a>. They learn to understand the context in which words appear to generate high-dimensional vectors for each word, capturing far more complex properties.</p><p><img src=https://qdrant.tech/articles_data/what-are-embeddings/Word2Vec-model.jpg alt="How Word2Vec model creates the embeddings for a word"></p><p>However, these models still have limitations. They generate a single vector per word, based on its usage across texts. This means all the nuances of the word &ldquo;right&rdquo; are blended into one vector representation. That is not enough information for computers to fully understand the context.</p><p>So, how do we help computers grasp the nuances of language in different contexts? In other words, how do we differentiate between:</p><ul><li>&ldquo;your answer is right&rdquo;</li><li>&ldquo;turn right at the corner&rdquo;</li><li>&ldquo;everyone has the right to freedom of speech&rdquo;</li></ul><p>Each of these sentences use the word &lsquo;right&rsquo;, with different meanings.</p><p>More advanced models like <a href=https://en.wikipedia.org/wiki/BERT_%28language_model%29 target=_blank rel="noopener nofollow">BERT</a> and <a href=https://en.wikipedia.org/wiki/Generative_pre-trained_transformer target=_blank rel="noopener nofollow">GPT</a> use deep learning models based on the <a href=https://arxiv.org/abs/1706.03762 target=_blank rel="noopener nofollow">transformer architecture</a>, which helps computers consider the full context of a word. These models pay attention to the entire context. The model understands the specific use of a word in its <strong>surroundings</strong>, and then creates different embeddings for each.</p><p><img src=https://qdrant.tech/articles_data/what-are-embeddings/BERT-model.jpg alt="How the BERT model creates the embeddings for a word"></p><p>But how does this process of understanding and interpreting work in practice? Think of the term: &ldquo;biophilic design&rdquo;, for example. To generate its embedding, the transformer architecture can use the following contexts:</p><ul><li>&ldquo;Biophilic design incorporates natural elements into architectural planning.&rdquo;</li><li>&ldquo;Offices with biophilic design elements report higher employee well-being.&rdquo;</li><li>&ldquo;&mldr;plant life, natural light, and water features are key aspects of biophilic design.&rdquo;</li></ul><p>And then it compares contexts to known architectural and design principles:</p><ul><li>&ldquo;Sustainable designs prioritize environmental harmony.&rdquo;</li><li>&ldquo;Ergonomic spaces enhance user comfort and health.&rdquo;</li></ul><p>The model creates a vector embedding for &ldquo;biophilic design&rdquo; that encapsulates the concept of integrating natural elements into man-made environments. Augmented with attributes that highlight the correlation between this integration and its positive impact on health, well-being, and environmental sustainability.</p><h3 id=integration-with-embedding-apis>Integration with embedding APIs</h3><p>Selecting the right embedding model for your use case is crucial to your application performance. Qdrant makes it easier by offering seamless integration with the best selection of embedding APIs, including <a href=https://qdrant.tech/documentation/embeddings/cohere/>Cohere</a>, <a href=https://qdrant.tech/documentation/embeddings/gemini/>Gemini</a>, <a href=https://qdrant.tech/documentation/embeddings/jina-embeddings/>Jina Embeddings</a>, <a href=https://qdrant.tech/documentation/embeddings/openai/>OpenAI</a>, <a href=https://qdrant.tech/documentation/embeddings/aleph-alpha/>Aleph Alpha</a>, <a href=https://github.com/qdrant/fastembed target=_blank rel="noopener nofollow">Fastembed</a>, and <a href=https://qdrant.tech/documentation/embeddings/bedrock/>AWS Bedrock</a>.</p><p>If you‚Äôre looking for NLP and rapid prototyping, including language translation, question-answering, and text generation, OpenAI is a great choice. Gemini is ideal for image search, duplicate detection, and clustering tasks.</p><p>Fastembed, which we‚Äôll use on the example below, is designed for efficiency and speed, great for applications needing low-latency responses, such as autocomplete and instant content recommendations.</p><p>We plan to go deeper into selecting the best model based on performance, cost, integration ease, and scalability in a future post.</p><h2 id=create-a-neural-search-service-with-fastmbed>Create a neural search service with Fastmbed</h2><p>Now that you‚Äôre familiar with the core concepts around vector embeddings, how about start building your own <a href=https://qdrant.tech/documentation/tutorials/neural-search/>Neural Search Service</a>?</p><p>Tutorial guides you through a practical application of how to use Qdrant for document management based on descriptions of companies from <a href=https://www.startups-list.com/ target=_blank rel="noopener nofollow">startups-list.com</a>. From embedding data, integrating it with Qdrant&rsquo;s vector database, constructing a search API, and finally deploying your solution with FastAPI.</p><p>Check out what the final version of this project looks like on the <a href=https://qdrant.to/semantic-search-demo target=_blank rel="noopener nofollow">live online demo</a>.</p><p>Let us know what you‚Äôre building with embeddings! Join our <a href=https://discord.gg/qdrant-907569970500743200 target=_blank rel="noopener nofollow">Discord</a> community and share your projects!</p></article><section class="docs-feedback d-print-none"><h5 class=docs-feedback__title>Was this page useful?</h5><div class=docs-feedback__buttons><button class="button button_outlined button_sm docs-feedback__button" id=feedback__answer_yes>
<img src=https://qdrant.tech/icons/outline/thumb-up.svg alt="Thumb up icon">
Yes
</button>
<button class="button button_outlined button_sm docs-feedback__button" id=feedback__answer_no>
<img src=https://qdrant.tech/icons/outline/thumb-down.svg alt="Thumb down icon">
No</button></div></section><section class="docs-feedback__responses d-none"><p class="docs-feedback__response docs-feedback__response_yes" id=feedback__response_yes>Thank you for your feedback! üôè</p><p class="docs-feedback__response docs-feedback__response_no" id=feedback__response_no>We are sorry to hear that. üòî You can <a class=text-brand-p href=https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/what-are-embeddings.md target=_blank>edit</a> this page on GitHub, or <a class=text-brand-p href=https://github.com/qdrant/landing_page/issues/new/choose target=_blank>create</a> a GitHub issue.</p></section><script>const buttonsSection=document.querySelector(".docs-feedback"),responsesSection=document.querySelector(".docs-feedback__responses"),yesButton=document.querySelector("#feedback__answer_yes"),noButton=document.querySelector("#feedback__answer_no"),yesResponse=document.querySelector("#feedback__response_yes"),noResponse=document.querySelector("#feedback__response_no"),toggleResponses=()=>{buttonsSection.classList.add("d-none"),responsesSection.classList.remove("d-none")};yesButton.addEventListener("click",()=>{yesResponse.classList.add("feedback__response_visible"),toggleResponses()}),noButton.addEventListener("click",()=>{noResponse.classList.add("feedback__response_visible"),toggleResponses()})</script></div><div class=table-of-contents><p class=table-of-contents__head>On this page:</p><nav id=TableOfContents><ul><li><a href=#why-use-vector-embeddings>Why use vector embeddings?</a></li><li><a href=#how-do-embeddings-work>How do embeddings work?</a><ul><li><a href=#creating-vector-embeddings>Creating vector embeddings</a></li><li><a href=#integration-with-embedding-apis>Integration with embedding APIs</a></li></ul></li><li><a href=#create-a-neural-search-service-with-fastmbed>Create a neural search service with Fastmbed</a></li></ul></nav><ul class=table-of-contents__external-links><li class=table-of-contents__link><a href=https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/what-are-embeddings.md target=_blank><svg width="16" height="17" viewBox="0 0 16 17" fill="none"><g clip-path="url(#clip0_6269_955)"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 .700012c-4.4.0-8 3.599998-8 7.999998C0 12.2333 2.26667 15.2333 5.46667 16.3 5.86667 16.3667 6 16.1 6 15.9S6 15.2333 6 14.5667C3.8 15.0333 3.33333 13.5 3.33333 13.5 3 12.5667 2.46667 12.3 2.46667 12.3 1.66667 11.8333 2.46667 11.8333 2.46667 11.8333 3.26667 11.9 3.66667 12.6333 3.66667 12.6333 4.4 13.8333 5.53333 13.5 6 13.3 6.06667 12.7667 6.26667 12.4333 6.53333 12.2333 4.73333 12.0333 2.86667 11.3667 2.86667 8.30001c0-.86666.33333-1.6.8-2.13333.0-.26667-.33334-1.06667.13333-2.13333.0.0.66667-.200000000000001 2.2.8.66667-.2 1.33333-.26667 2-.26667S9.33333 4.63335 10 4.83335c1.5333-1.06667 2.2-.8 2.2-.8C12.6667 5.16668 12.3333 5.96668 12.2667 6.16668 12.8 6.70001 13.0667 7.43335 13.0667 8.30001c0 3.06669-1.8667 3.73329-3.6667 3.93329C9.66667 12.5 9.93333 12.9667 9.93333 13.7c0 1.0667.0 1.9333.0 2.2C9.93333 16.1 10.0667 16.3667 10.4667 16.3c3.2-1.0667 5.4666-4.0667 5.4666-7.59999C16 4.30001 12.4.700012 8 .700012z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_6269_955"><rect width="16" height="16" fill="#fff" transform="translate(0 0.5)"/></clipPath></defs></svg>
Edit on Github</a></li><li class=table-of-contents__link><a href=https://github.com/qdrant/landing_page/issues/new/choose target=_blank><svg width="16" height="17" viewBox="0 0 16 17" fill="none"><g clip-path="url(#clip0_6269_1540)"><path d="M16 9.83331V8.49998H13.9347C13.79 7.33465 13.3947 6.24065 12.8 5.31065l1.476-1.478L13.3327 2.89065 11.9633 4.26198c-.24-.248-.496600000000001-.474-.772-.676C11.0967 3.25665 10.9507 2.95398 10.7673 2.67598l1.038-1.038L10.8627.695312 9.82867 1.72931C9.29867 1.37798 8.672 1.16665 8 1.16665c-.672.0-1.29867.21133-1.828.56266L5.138.695312l-.94267.942668 1.038 1.038c-.18333.27733-.32933.58-.424.90867-.27533.202-.532.42933-.77266.67733L2.66733 2.89065l-.94333.942L3.2 5.30998c-.59467.93-.99 2.02467-1.13467 3.19H0V9.83331H2.01467C2.07333 11.276 2.50533 12.6026 3.204 13.688l-1.48 1.478L2.666 16.1093l1.37-1.368C4.93733 15.67 6.07667 16.288 7.33333 16.452V6.49998H8.66667V16.452C9.92333 16.2873 11.0627 15.67 11.964 14.7413l1.37 1.368L14.276 15.166l-1.48-1.478C13.4947 12.602 13.9267 11.2753 13.9853 9.83331H16z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_6269_1540"><rect width="16" height="16" fill="#fff" transform="translate(0 0.5)"/></clipPath></defs></svg>
Create an issue</a></li></ul></div><footer class="docs-footer w-100 py-0 pt-0 pb-4 pb-xl-0"><div class=docs-footer__cta><h4>Ready to get started with Qdrant?</h4><a href=https://qdrant.to/cloud/ class="button button_outlined button_sm" target=_blank>Start Free</a></div><div class=docs-footer__bottom><div class=docs-footer__bottom-content><span>¬© 2025 Qdrant.</span><div class=footer__bottom-links><a href=https://qdrant.tech/legal/terms_and_conditions/>Terms</a>
<a href=https://qdrant.tech/legal/privacy-policy/>Privacy Policy</a>
<a href=https://qdrant.tech/legal/impressum/>Impressum</a></div></div></div></footer></div></div></div></div></section></main></body><script src=https://cdn.cookielaw.org/scripttemplates/otSDKStub.js type=text/javascript data-domain-script=01960152-5e40-782d-af01-f7f5768a214e></script><script async type=text/javascript>function OptanonWrapper(){const e=new CustomEvent("onetrust_loaded");document.dispatchEvent(e)}</script><script>!function(){const o="eQYi1nZE2zQSmnHuxjMRlDd2uLl65oHe";var n,s,t="analytics",e=window[t]=window[t]||[];if(!e.initialize)if(e.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{e.invoked=!0,e.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","debug","page","screen","once","off","on","addSourceMiddleware","addIntegrationMiddleware","setAnonymousId","addDestinationMiddleware","register"],e.factory=function(n){return function(){if(window[t].initialized)return window[t][n].apply(window[t],arguments);var o,s=Array.prototype.slice.call(arguments);return["track","screen","alias","group","page","identify"].indexOf(n)>-1&&(o=document.querySelector("link[rel='canonical']"),s.push({__t:"bpc",c:o&&o.getAttribute("href")||void 0,p:location.pathname,u:location.href,s:location.search,t:document.title,r:document.referrer})),s.unshift(n),e.push(s),e}};for(n=0;n<e.methods.length;n++)s=e.methods[n],e[s]=e.factory(s);e.load=function(n,s){var i,o=document.createElement("script");o.type="text/javascript",o.async=!0,o.setAttribute("data-global-segment-analytics-key",t),o.src="https://evs.analytics.qdrant.tech/5caWuitPgcGFN5Q7HMpTaj/vEkmzjuRSqeXGbhGAFTWex.min.js",i=document.getElementsByTagName("script")[0],i.parentNode.insertBefore(o,i),e._loadOptions=s},e._writeKey=o,e._cdn="https://evs.analytics.qdrant.tech",e.SNIPPET_VERSION="5.2.0",e.load(o)}}()</script><script src=https://qdrant.tech/js/google-setup.min.14728a3ae9bd931593645b6ddbfe801d400cd2970006e782cb67f3966654248ca962dbaf4cf371493a2d326861b3a691a99d6d8349c8b2752339ab91d3787069.js></script><script src=https://qdrant.tech/js/index.min.e37feda1952d752f5568e1ebc55e183629e4d361f4df09edeed70b4a4327d601161c4147bdbe4149b4a3cdc1ed43f1bf1a2f2340a421f1aa821103980dfe0bda.js></script><script src=https://qdrant.tech/js/search/search.min.e58e7ea98cb549ea9d3ed7e68876abe323cfb323432038820f38a71c40e309deed0fba615e2d3346825229a81e0a76bbadf6f8a816ddad3438abdabfef4ebc09.js type=module></script><script src=https://qdrant.tech/js/search/scroll.min.f4ed4453a3af0adb0d4f49333cbb7892ff5430483a567d0d2dfbd4655fb203d22f22f46aff3d9f38fa5fd96dde5f30227afd0ce1d9f838f5cd5295fc83856ec9.js></script><script src=https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js></script><script src=https://qdrant.tech/js/copy-code.min.95b03a45b2ab4b7a608ecfd4b5919c8572a5b2cd1463f52561cd10976abf3b74334f91324c0e620cb80afac46026a0b18cce6fb753d8495f74c6d478c8ca1d03.js></script><script src=https://qdrant.tech/js/lang-switcher.min.63da11cef09772078425b1ee56415b9c37842a9399f2ba2d2f5efbf72fb751686c410bd50e9bcd283c8231cb97c1973199d4923beef29d8b06e59d9983a6ba51.js></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src=https://qdrant.tech/js/vendor/anchor.min.0e138e17ebcf1c1147a7a3a81d9ac3c601622eedc479f1636470eb2552470f4e27c9a8efe6e8378995dedc1ab67029d8989536ea76f0857d45d1615ae772b8a1.js></script><script>document.addEventListener("keydown",function(e){if((e.metaKey||e.ctrlKey)&&e.key==="k"){e.preventDefault();let t=document.querySelector('[data-target="#searchModal"]');t&&t?.click()}})</script><script>window.addEventListener("message",e=>{if(e.data.type==="hsFormCallback"&&e.data.eventName==="onFormReady"){const t=document.querySelector(`form[data-form-id="${e.data.id}"]`);if(t){const e=t.querySelector('[name="last_form_fill_url"]');e&&(e.value=window.location.href);const n=t.querySelector('[name="referrer_url"]');n&&(n.value=document.referrer)}}})</script></html>