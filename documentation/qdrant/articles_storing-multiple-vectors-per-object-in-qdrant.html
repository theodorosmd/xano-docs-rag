<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta charset=UTF-8><title>Optimizing Semantic Search by Managing Multiple Vectors - Qdrant</title>
<link rel=icon href=https://qdrant.tech/favicon/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=https://qdrant.tech/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://qdrant.tech/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://qdrant.tech/favicon/favicon-16x16.png><link rel=manifest href=https://qdrant.tech/favicon/site.webmanifest><link rel=mask-icon href=https://qdrant.tech/favicon/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#2b5797"><meta name=msapplication-config content="/favicon/browserconfig.xml"><meta name=theme-color content="#ffffff"><meta name=partition content="learn"><link href=https://qdrant.tech/css/search/search.min.09596ee2b3c94d0ac82a1c33199cabdb3e0210b1ee46aaf1515200e9e484d05dd9e27cc1e861c58cc2e582af162f63b8e180ff2a12f7a6592b7aeaa0a7125130.css rel=stylesheet integrity="sha512-CVlu4rPJTQrIKhwzGZyr2z4CELHuRqrxUVIA6eSE0F3Z4nzB6GHFjMLlgq8WL2O44YD/KhL3plkreuqgpxJRMA=="><link href=https://qdrant.tech/css/documentation.min.de204cdcfc410689a41c17bcdad0a34f2caaa50cc8505c820adaab481cef2d69a920b0a32e0d624701c29487e3271b694559d98c5047cbfaa5aa475f638011e5.css rel=stylesheet integrity="sha512-3iBM3PxBBomkHBe82tCjTyyqpQzIUFyCCtqrSBzvLWmpILCjLg1iRwHClIfjJxtpRVnZjFBHy/qlqkdfY4AR5Q=="><link href=https://qdrant.tech/css/main.min.c1e379ad4cf03647832f6a0f040754b0be3e79934db2c29f50b396327c1ec7ac45f778abadbd93f5a8bc431850d1b0d9c9eff34c0171cd4236e83c5e324c1a0e.css rel=stylesheet integrity crossorigin=anonymous><meta name=generator content="Hugo 0.141.0"><meta name=description content="Discover the power of vector storage optimization and learn how to efficiently manage multiple vectors per object for enhanced semantic search capabilities."><meta name=keywords content="vector search engine,neural network,matching,SaaS,approximate nearest neighbor search,image search,recommender system,vectors,knn algorithm,hnsw,vector search,embeddings,similarity,simaes networks,BERT,transformer,word2vec,fasttext,qdrant"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@id":"https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/#article","@type":"Article","abstract":"Discover the power of vector storage optimization and learn how to efficiently manage multiple vectors per object for enhanced semantic search capabilities","author":{"@type":"Person","name":"Kacper ≈Åukawski"},"dateModified":"2022-10-05 00:00:00 -0800 -0800","datePublished":"2022-10-05 00:00:00 -0800 -0800","description":"Discover the power of vector storage optimization and learn how to efficiently manage multiple vectors per object for enhanced semantic search capabilities","headline":"Optimizing Semantic Search by Managing Multiple Vectors","image":["https://qdrant.tech/articles_data/storing-multiple-vectors-per-object-in-qdrant/preview/social_preview.jpg"],"name":"Optimizing Semantic Search by Managing Multiple Vectors","url":"https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/","wordCount":"1200"},{"@id":"https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/#organization","@type":"Organization","address":{"@type":"PostalAddress","addressCountry":"DE","addressLocality":"Berlin","addressRegion":"Berlin","postalCode":"10115","streetAddress":"Chausseestra√üe 86"},"contactPoint":{"@type":"ContactPoint","contactType":"customer support","email":"info@qdrant.com","telephone":"+49 3040797694"},"description":"Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.","email":"info@qdrant.com","founders":[{"@type":"Person","name":"map[email:info@qdrant.tech name:Andrey Vasnetsov]"},{"@type":"Person","name":"Andre Zayarni"}],"foundingDate":"2021","keywords":["vector search engine","neural network","matching","SaaS","approximate nearest neighbor search","image search","recommender system","vectors","knn algorithm","hnsw","vector search","embeddings","similarity","simaes networks","BERT","transformer","word2vec","fasttext","Qdrant"],"legalName":"Qdrant Solutions GmbH","location":"Berlin, Germany","logo":"https://qdrant.tech/images/logo_with_text.png","name":"Qdrant","sameAs":["https://github.com/qdrant/qdrant","https://qdrant.to/discord","https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA","https://www.linkedin.com/company/qdrant/","https://twitter.com/qdrant_engine"],"url":"https://qdrant.tech"}]}</script><meta property="og:url" content="https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/"><meta property="og:type" content="website"><meta property="og:title" content="Optimizing Semantic Search by Managing Multiple Vectors - Qdrant"><meta name=twitter:card content="summary_large_image"><meta name=twitter:domain content="qdrant"><meta name=twitter:url content="https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/"><meta name=twitter:title content="Optimizing Semantic Search by Managing Multiple Vectors - Qdrant"><meta property="og:description" content="Discover the power of vector storage optimization and learn how to efficiently manage multiple vectors per object for enhanced semantic search capabilities."><meta name=twitter:description content="Discover the power of vector storage optimization and learn how to efficiently manage multiple vectors per object for enhanced semantic search capabilities."><meta name=image property="og:image" content="https://qdrant.tech/articles_data/storing-multiple-vectors-per-object-in-qdrant/preview/social_preview.jpg"><meta name=image property="og:image:secure_url" content="https://qdrant.tech/articles_data/storing-multiple-vectors-per-object-in-qdrant/preview/social_preview.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name=twitter:image:src content="https://qdrant.tech/articles_data/storing-multiple-vectors-per-object-in-qdrant/preview/social_preview.jpg"><meta name=author content="Kacper ≈Åukawski"><link rel=canonical href=https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/><script type=text/javascript src=//js-eu1.hsforms.net/forms/embed/v2.js></script><script src=https://qdrant.tech/js/documentation.min.594fc9226f6fb87b8c3b0cafb9d5c0b0bcd95f47d292b929aab04315e0506706b2f376dc4fae9961dc3082138cb19d45b2a3370ee8e881bbf4b8c91dcb735c32.js></script></head><body><main><header class=docs-header><div class="main-menu z-5"><a href=https://qdrant.tech/><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div></a><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><div class="d-block d-xl-none"><button role=button class=theme-switch></button></div><button type=button class=main-menu__trigger><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M1 12H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 5H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 19H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=main-menu__links><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/>Qdrant</a></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/cloud-intro/>Cloud</a></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/build/>Build</a></li><li class=main-menu__item><a class=menu-linkactive href=https://qdrant.tech/articles/>Learn</a></li><li class=main-menu__item><a class=menu-link href=https://api.qdrant.tech/api-reference target=_blank>API Reference</a></li></ul><div class=main-menu__buttons><div class=main-menu__buttons-input><button class="qdr-search-input-btn q-input input_md input_light-bg" type=button name=search data-target=#searchModal>
Search</button></div><button role=button class=theme-switch></button>
<a data-metric-loc=nav href=https://cloud.qdrant.io/login class="menu-link mx-3" target=_blank>Log in</a>
<a data-metric-loc=nav href=https://cloud.qdrant.io/signup class="button button_contained button_sm" target=_blank>Start Free</a></div></div><div class=menu-mobile><div class=menu-mobile__header><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><div class="d-block d-xl-none"><button role=button class=theme-switch></button></div><button type=button class=menu-mobile__close><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><g id="Close"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M19.778 5.63606C20.1685 5.24554 20.1685 4.61237 19.778 4.22185 19.3874 3.83132 18.7543 3.83132 18.3637 4.22185L11.9998 10.5858 5.63586 4.22185c-.39052-.39053-1.02369-.39053-1.41421.0C3.83112 4.61237 3.83112 5.24554 4.22165 5.63606L10.5856 12l-6.364 6.364C3.83108 18.7545 3.83108 19.3877 4.2216 19.7782 4.61213 20.1687 5.24529 20.1687 5.63582 19.7782l6.36398-6.364 6.364 6.364C18.7543 20.1687 19.3875 20.1687 19.778 19.7782 20.1685 19.3877 20.1685 18.7545 19.778 18.364L13.414 12l6.364-6.36394z" fill="#e1e5f0"/></g></svg></button></div></div><div class=main-menu__buttons-input><button class="qdr-search-input-btn q-input input_md input_light-bg" type=button name=search data-target=#searchModal>
Search</button></div><ul class=menu-mobile__items><li class=menu-mobile__item data-path=menu-0><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Documentation"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M4.25 1c-1.10092.0-2.12247.23681-2.88689.64443C.620129 2.04063.0 2.67297.0 3.5v11c0 .2761.223858.5.5.5s.5-.2239.5-.5c0-.278.21937-.6456.83364-.9732C2.42647 13.2107 3.27992 13 4.25 13 5.22008 13 6.07353 13.2107 6.66636 13.5268c.61427.3276.83364.6952.83364.9732.0.2761.22386.5.5.5s.5-.2239.5-.5c0-.278.21937-.6456.833640000000001-.9732C9.92647 13.2107 10.7799 13 11.75 13S13.5735 13.2107 14.1664 13.5268C14.7806 13.8544 15 14.222 15 14.5c0 .2761.2239.5.5.5s.5-.2239.5-.5V3.5C16 2.67297 15.3799 2.04063 14.6369 1.64443 13.8725 1.23681 12.8509 1 11.75 1s-2.12247.23681-2.88689.64443C8.53799 1.8178 8.2364 2.03638 8 2.29671c-.2364-.26033-.53799-.47891-.86311-.65228C6.37247 1.23681 5.35092 1 4.25 1zM1.36311 12.6444C1.23778 12.7113 1.11595 12.7848 1 12.8649V3.5c0-.27797.21937-.64563.83364-.97318C2.42647 2.21069 3.27992 2 4.25 2c.97008.0 1.82353.21069 2.41636.52682C7.28063 2.85437 7.5 3.22203 7.5 3.5v9.3649C7.38405 12.7848 7.26222 12.7113 7.13689 12.6444 6.37247 12.2368 5.35092 12 4.25 12 3.14908 12 2.12753 12.2368 1.36311 12.6444zM8.5 12.8649C8.61595 12.7848 8.73778 12.7113 8.86311 12.6444 9.62753 12.2368 10.6491 12 11.75 12S13.8725 12.2368 14.6369 12.6444C14.7622 12.7113 14.8841 12.7848 15 12.8649V3.5C15 3.22203 14.7806 2.85437 14.1664 2.52682 13.5735 2.21069 12.7201 2 11.75 2s-1.82353.21069-2.41636.52682C8.71937 2.85437 8.5 3.22203 8.5 3.5v9.3649z"/></g></svg>
Qdrant</a></div></li><li class=menu-mobile__item data-path=menu-1><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/cloud-intro/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Cloud"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M7.5 2C4.57416 2 2.18128 4.28566 2.00983 7.16851.8403 7.57763.0 8.68965.0 10c0 1.6571 1.34286 3 3 3H13c1.6571.0 3-1.3429 3-3 0-1.65714-1.3429-3-3-3L12.9776 7.00009C12.7249 4.19714 10.3686 2 7.5 2zM3.00107 7.48137 3.00008 7.47308C3.01457 5.0006 5.02412 3 7.5 3c2.47599.0 4.4856 2.00079 4.4999 4.47342L11.9987 7.4836C11.9969 7.50027 11.995 7.52348 11.995 7.551 11.995 7.701 12.0623 7.84308 12.1785 7.93804 12.2946 8.03301 12.4472 8.07082 12.5942 8.04106 12.726 8.01438 12.8617 8 13 8c1.1049.0 2 .89514 2 2C15 11.1049 14.1049 12 13 12H3C1.89514 12 1 11.1049 1 10 1 9.03225 1.68901 8.22422 2.60364 8.04017 2.83708 7.9932 3.005 7.78812 3.005 7.55 3.005 7.52154 3.00291 7.49773 3.00107 7.48137z"/></g></svg>
Cloud</a></div></li><li class=menu-mobile__item data-path=menu-2><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/build/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Blog"><path id="Union" fill-rule="evenodd" clip-rule="evenodd" d="M0 1.5C0 1.22386.223858 1 .5 1h5c.27614.0.5.22386.5.5v5c0 .27614-.22386.5-.5.5H.5C.223858 7 0 6.77614.0 6.5v-5zM1 2V6H5V2H1zm7 .5c0-.27614.22386-.5.5-.5h7c.2761.0.5.22386.5.5s-.2239.5-.5.5h-7C8.22386 3 8 2.77614 8 2.5zM8.5 6c-.27614.0-.5.22386-.5.5s.22386.5.5.5h7c.2761.0.5-.22386.5-.5s-.2239-.5-.5-.5h-7zM0 10.5c0-.2761.223858-.5.5-.5h15c.2761.0.5.2239.5.5s-.2239.5-.5.5H.5c-.276142.0-.5-.2239-.5-.5zM.5 14c-.276142.0-.5.2239-.5.5s.223858.5.5.5h15c.2761.0.5-.2239.5-.5s-.2239-.5-.5-.5H.5z"/></g></svg>
Build</a></div></li><li class=menu-mobile__item data-path=menu-3><div class=menu-mobile__item-content><a class=active href=https://qdrant.tech/articles/><svg width="16" height="16" viewBox="0 0 16 16" fill="none" stroke="#e1e5f0"><g id="Group"><path id="Vector" d="M10.084 1.84094l4.059 4.059" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_2" d="M8.49188 2.72406c-1.22044-.53042-2.59304-.59475-3.85774-.1808-1.2647.41395-2.33363 1.27742-3.00426 2.4268l2.34 2.34" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_3" d="M13.2657 7.47302C13.8062 8.69691 13.8769 10.077 13.4645 11.3497c-.4125 1.2728-1.2792 2.3491-2.4348 3.0233l-2.35001-2.35" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_4" d="M6.81217 13.049l-3.861-3.861S6.24917.983 15.5002.5c-.523 9.211-8.68803 12.549-8.68803 12.549z" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_5" d="M3.59892 12.4008C3.34181 12.1441 2.99331 12 2.62995 12c-.36335.0-.71186.1441-.96897.4008-.46665.4664-.63131 1.941-.65931 2.2322C.997021 14.6793 1.0021 14.726 1.01659 14.7701 1.03108 14.8143 1.05465 14.8549 1.08579 14.8895 1.11693 14.924 1.15495 14.9516 1.19741 14.9705 1.23987 14.9895 1.28583 14.9994 1.33233 14.9995 1.34298 15.0002 1.35367 15.0002 1.36433 14.9995 1.65565 14.9715 3.1316 14.8063 3.59759 14.3405 3.85501 14.0834 3.99975 13.7346 4 13.3709 4.00025 13.0072 3.85599 12.6582 3.59892 12.4008z" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_6" d="M9 8c.55228.0 1-.44772 1-1S9.55228 6 9 6 8 6.44772 8 7s.44772 1 1 1z"/></g></svg>
Learn</a></div></li><li class=menu-mobile__item data-path=menu-4><div class=menu-mobile__item-content><a href=https://api.qdrant.tech/api-reference target=_blank><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Roadmap" clip-path="url(#clip0_7182_4311)"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M13.5 1c-.8284.0-1.5.67157-1.5 1.5S12.6716 4 13.5 4 15 3.32843 15 2.5 14.3284 1 13.5 1zM11 2.5C11 1.11929 12.1193.0 13.5.0S16 1.11929 16 2.5 14.8807 5 13.5 5 11 3.88071 11 2.5zM2.5 12c-.82843.0-1.5.6716-1.5 1.5S1.67157 15 2.5 15 4 14.3284 4 13.5 3.32843 12 2.5 12zM0 13.5C0 12.1193 1.11929 11 2.5 11S5 12.1193 5 13.5 3.88071 16 2.5 16 0 14.8807.0 13.5zM3.65901 1.65901C4.08097 1.23705 4.65326 1 5.25 1s1.16903.23705 1.59099.65901C7.26295 2.08097 7.5 2.65326 7.5 3.25v9.5c0 .862.34241 1.6886.9519 2.2981C9.0614 15.6576 9.88805 16 10.75 16c.862.0 1.6886-.3424 2.2981-.9519S14 13.612 14 12.75V6.5c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v6.25C13 13.3467 12.7629 13.919 12.341 14.341 11.919 14.7629 11.3467 15 10.75 15S9.58097 14.7629 9.15901 14.341C8.73705 13.919 8.5 13.3467 8.5 12.75V3.25C8.5 2.38805 8.15759 1.5614 7.5481.951903 6.9386.34241 6.11195.0 5.25.0S3.5614.34241 2.9519.951903C2.34241 1.5614 2 2.38805 2 3.25V9.5c0 .27614.22386.5.5.5s.5-.22386.5-.5V3.25c0-.59674.23705-1.16903.65901-1.59099z"/></g><defs><clipPath id="clip0_7182_4311"><rect width="16" height="16" fill="#fff"/></clipPath></defs></svg>
API Reference</a></div></li></ul><div class=docs-menu><div id=sidebar class=docs-menu__content><h3 class=docs-menu__links-title>Learn</h3><nav><div class=docs-menu__links-group><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/vector-search-manuals/>Vector Search Manuals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/qdrant-internals/>Qdrant Internals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/data-exploration/>Data Exploration</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/machine-learning/>Machine Learning</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/rag-and-genai/>RAG & GenAI</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/practicle-examples/>Practical Examples</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/ecosystem/>Ecosystem</a></div></div></nav></div></div></div></header><section class="docs documentation"><div class=documentation__container><div class="d-flex flex-column flex-xl-row"><div class=docs-menu><div id=sidebar class=docs-menu__content><h3 class=docs-menu__links-title>Learn</h3><nav><div class=docs-menu__links-group><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/vector-search-manuals/>Vector Search Manuals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/qdrant-internals/>Qdrant Internals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/data-exploration/>Data Exploration</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/machine-learning/>Machine Learning</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/rag-and-genai/>RAG & GenAI</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/practicle-examples/>Practical Examples</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/ecosystem/>Ecosystem</a></div></div></nav></div></div><div class=documentation__content><div class=documentation__content-wrapper><div class=documentation__article-wrapper><ul class=docs-breadcrumbs><li class=docs-breadcrumbs__crumb><a href=https://qdrant.tech/articles/>Articles</a></li><li class=docs-breadcrumbs__crumb-separator></li><li class=docs-breadcrumbs__crumb>Optimizing Semantic Search by Managing Multiple Vectors</li></ul><article class=documentation-article><div class=documentation-article__header><a href=https://qdrant.tech/articles/vector-search-manuals/ class=documentation-article__header-link><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path d="M14.6668 8.00004H1.3335m0 0L6.00016 12.6667M1.3335 8.00004 6.00016 3.33337" stroke="#8f98b3" stroke-width="1.33333" stroke-linecap="round" stroke-linejoin="round"/></svg>
Back to Vector Search Manuals</a><h1 class=documentation-article__header-title>Optimizing Semantic Search by Managing Multiple Vectors</h1><div class=documentation-article__header-about><p>Kacper ≈Åukawski</p><span>&#183;</span><p>October 05, 2022</p></div><picture class=documentation-article__header-preview><source srcset=https://qdrant.tech/articles_data/storing-multiple-vectors-per-object-in-qdrant/preview/title.webp type=image/webp><img alt="Optimizing Semantic Search by Managing Multiple Vectors" src=https://qdrant.tech/articles_data/storing-multiple-vectors-per-object-in-qdrant/preview/title.jpg></picture></div><h1 id=how-to-optimize-vector-storage-by-storing-multiple-vectors-per-object>How to Optimize Vector Storage by Storing Multiple Vectors Per Object</h1><p>In a real case scenario, a single object might be described in several different ways. If you run an e-commerce business, then your items will typically have a name, longer textual description and also a bunch of photos. While cooking, you may care about the list of ingredients, and description of the taste but also the recipe and the way your meal is going to look. Up till now, if you wanted to enable <a href=https://qdrant.tech/documentation/tutorials/search-beginners/ target=_blank rel="noopener nofollow">semantic search</a> with multiple vectors per object, Qdrant would require you to create separate collections for each vector type, even though they could share some other attributes in a payload. However, since Qdrant 0.10 you are able to store all those vectors together in the same collection and share a single copy of the payload!</p><p>Running the new version of Qdrant is as simple as it always was. By running the following command, you are able to set up a single instance that will also expose the HTTP API:</p><pre tabindex=0><code>docker run -p 6333:6333 qdrant/qdrant:v0.10.1
</code></pre><h2 id=creating-a-collection>Creating a collection</h2><p>Adding new functionalities typically requires making some changes to the interfaces, so no surprise we had to do it to enable the multiple vectors support. Currently, if you want to create a collection, you need to define the configuration of all the vectors you want to store for each object. Each vector type has its own name and the distance function used to measure how far the points are.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>qdrant_client</span> <span class=kn>import</span> <span class=n>QdrantClient</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>qdrant_client.http.models</span> <span class=kn>import</span> <span class=n>VectorParams</span><span class=p>,</span> <span class=n>Distance</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>QdrantClient</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>client</span><span class=o>.</span><span class=n>create_collection</span><span class=p>(</span>
</span></span><span class=line><span class=cl>   <span class=n>collection_name</span><span class=o>=</span><span class=s2>&#34;multiple_vectors&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=n>vectors_config</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>       <span class=s2>&#34;title&#34;</span><span class=p>:</span> <span class=n>VectorParams</span><span class=p>(</span>
</span></span><span class=line><span class=cl>           <span class=n>size</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>           <span class=n>distance</span><span class=o>=</span><span class=n>Distance</span><span class=o>.</span><span class=n>EUCLID</span><span class=p>,</span>
</span></span><span class=line><span class=cl>       <span class=p>),</span>
</span></span><span class=line><span class=cl>       <span class=s2>&#34;image&#34;</span><span class=p>:</span> <span class=n>VectorParams</span><span class=p>(</span>
</span></span><span class=line><span class=cl>           <span class=n>size</span><span class=o>=</span><span class=mi>786</span><span class=p>,</span>
</span></span><span class=line><span class=cl>           <span class=n>distance</span><span class=o>=</span><span class=n>Distance</span><span class=o>.</span><span class=n>COSINE</span><span class=p>,</span>
</span></span><span class=line><span class=cl>       <span class=p>),</span>
</span></span><span class=line><span class=cl>   <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p>In case you want to keep a single vector per collection, you can still do it without putting a name though.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>client</span><span class=o>.</span><span class=n>create_collection</span><span class=p>(</span>
</span></span><span class=line><span class=cl>   <span class=n>collection_name</span><span class=o>=</span><span class=s2>&#34;single_vector&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=n>vectors_config</span><span class=o>=</span><span class=n>VectorParams</span><span class=p>(</span>
</span></span><span class=line><span class=cl>       <span class=n>size</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>       <span class=n>distance</span><span class=o>=</span><span class=n>Distance</span><span class=o>.</span><span class=n>COSINE</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p>All the search-related operations have slightly changed their interfaces as well, so you can choose which vector to use in a specific request. However, it might be easier to see all the changes by following an end-to-end Qdrant usage on a real-world example.</p><h2 id=building-service-with-multiple-embeddings>Building service with multiple embeddings</h2><p>Quite a common approach to building search engines is to combine semantic textual capabilities with image search as well. For that purpose, we need a dataset containing both images and their textual descriptions. There are several datasets available with¬†<a href=https://huggingface.co/datasets/ChristophSchuhmann/MS_COCO_2017_URL_TEXT target=_blank rel="noopener nofollow">MS_COCO_2017_URL_TEXT</a>¬†being probably the simplest available. And because it‚Äôs available on HuggingFace, we can easily use it with their¬†<a href=https://huggingface.co/docs/datasets/index target=_blank rel="noopener nofollow">datasets</a>¬†library.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>load_dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=s2>&#34;ChristophSchuhmann/MS_COCO_2017_URL_TEXT&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>Right now, we have a dataset with a structure containing the image URL and its textual description in English. For simplicity, we can convert it to the DataFrame, as this structure might be quite convenient for future processing.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>dataset_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>dataset</span><span class=p>[</span><span class=s2>&#34;train&#34;</span><span class=p>])</span>
</span></span></code></pre></div><p>The dataset consists of two columns:¬†<em>TEXT</em>¬†and¬†<em>URL</em>. Thus, each data sample is described by two separate pieces of information and each of them has to be encoded with a different model.</p><h2 id=processing-the-data-with-pretrained-models>Processing the data with pretrained models</h2><p>Thanks to¬†<a href=https://github.com/koaning/embetter target=_blank rel="noopener nofollow">embetter</a>, we can reuse some existing pretrained models and use a convenient scikit-learn API, including pipelines. This library also provides some utilities to load the images, but only supports the local filesystem, so we need to create our own class that will download the file, given its URL.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>urllib.request</span> <span class=kn>import</span> <span class=n>urlretrieve</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>embetter.base</span> <span class=kn>import</span> <span class=n>EmbetterBase</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DownloadFile</span><span class=p>(</span><span class=n>EmbetterBase</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>   <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>out_dir</span><span class=p>:</span> <span class=n>Path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>       <span class=bp>self</span><span class=o>.</span><span class=n>out_dir</span> <span class=o>=</span> <span class=n>out_dir</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>   <span class=k>def</span> <span class=nf>transform</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>       <span class=n>output_paths</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>       <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>X</span><span class=p>:</span>
</span></span><span class=line><span class=cl>           <span class=n>output_file</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>out_dir</span> <span class=o>/</span> <span class=n>Path</span><span class=p>(</span><span class=n>x</span><span class=p>)</span><span class=o>.</span><span class=n>name</span>
</span></span><span class=line><span class=cl>           <span class=n>urlretrieve</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>output_file</span><span class=p>)</span>
</span></span><span class=line><span class=cl>           <span class=n>output_paths</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>output_file</span><span class=p>))</span>
</span></span><span class=line><span class=cl>       <span class=k>return</span> <span class=n>output_paths</span>
</span></span></code></pre></div><p>Now we‚Äôre ready to define the pipelines to process our images and texts using¬†<em>all-MiniLM-L6-v2</em>¬†and¬†<em>vit_base_patch16_224</em>¬†models respectively. First of all, let‚Äôs start with Qdrant configuration.</p><h2 id=creating-qdrant-collection>Creating Qdrant collection</h2><p>We‚Äôre going to put two vectors per object (one for image and another one for text), so we need to create a collection with a configuration allowing us to do so.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>qdrant_client</span> <span class=kn>import</span> <span class=n>QdrantClient</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>qdrant_client.http.models</span> <span class=kn>import</span> <span class=n>VectorParams</span><span class=p>,</span> <span class=n>Distance</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>QdrantClient</span><span class=p>(</span><span class=n>timeout</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>client</span><span class=o>.</span><span class=n>create_collection</span><span class=p>(</span>
</span></span><span class=line><span class=cl>   <span class=n>collection_name</span><span class=o>=</span><span class=s2>&#34;ms-coco-2017&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=n>vectors_config</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>       <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>VectorParams</span><span class=p>(</span>
</span></span><span class=line><span class=cl>           <span class=n>size</span><span class=o>=</span><span class=mi>384</span><span class=p>,</span>
</span></span><span class=line><span class=cl>           <span class=n>distance</span><span class=o>=</span><span class=n>Distance</span><span class=o>.</span><span class=n>EUCLID</span><span class=p>,</span>
</span></span><span class=line><span class=cl>       <span class=p>),</span>
</span></span><span class=line><span class=cl>       <span class=s2>&#34;image&#34;</span><span class=p>:</span> <span class=n>VectorParams</span><span class=p>(</span>
</span></span><span class=line><span class=cl>           <span class=n>size</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>           <span class=n>distance</span><span class=o>=</span><span class=n>Distance</span><span class=o>.</span><span class=n>COSINE</span><span class=p>,</span>
</span></span><span class=line><span class=cl>       <span class=p>),</span>
</span></span><span class=line><span class=cl>   <span class=p>},</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><h2 id=defining-the-pipelines>Defining the pipelines</h2><p>And since we have all the puzzles already in place, we can start the processing to convert raw data into the embeddings we need. The pretrained models come in handy.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.pipeline</span> <span class=kn>import</span> <span class=n>make_pipeline</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>embetter.grab</span> <span class=kn>import</span> <span class=n>ColumnGrabber</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>embetter.vision</span> <span class=kn>import</span> <span class=n>ImageLoader</span><span class=p>,</span> <span class=n>TimmEncoder</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>embetter.text</span> <span class=kn>import</span> <span class=n>SentenceEncoder</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>output_directory</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=s2>&#34;./images&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>image_pipeline</span> <span class=o>=</span> <span class=n>make_pipeline</span><span class=p>(</span>
</span></span><span class=line><span class=cl>   <span class=n>ColumnGrabber</span><span class=p>(</span><span class=s2>&#34;URL&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>   <span class=n>DownloadFile</span><span class=p>(</span><span class=n>output_directory</span><span class=p>),</span>
</span></span><span class=line><span class=cl>   <span class=n>ImageLoader</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>   <span class=n>TimmEncoder</span><span class=p>(</span><span class=s2>&#34;vit_base_patch16_224&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text_pipeline</span> <span class=o>=</span> <span class=n>make_pipeline</span><span class=p>(</span>
</span></span><span class=line><span class=cl>   <span class=n>ColumnGrabber</span><span class=p>(</span><span class=s2>&#34;TEXT&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>   <span class=n>SentenceEncoder</span><span class=p>(</span><span class=s2>&#34;all-MiniLM-L6-v2&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p>Thanks to the scikit-learn API, we can simply call each pipeline on the created DataFrame and put created vectors into Qdrant to enable fast vector search. For convenience, we‚Äôre going to put the vectors as other columns in our DataFrame.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>sample_df</span> <span class=o>=</span> <span class=n>dataset_df</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=n>n</span><span class=o>=</span><span class=mi>2000</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>643</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>image_vectors</span> <span class=o>=</span> <span class=n>image_pipeline</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>sample_df</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>text_vectors</span> <span class=o>=</span> <span class=n>text_pipeline</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>sample_df</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>sample_df</span><span class=p>[</span><span class=s2>&#34;image_vector&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>image_vectors</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>sample_df</span><span class=p>[</span><span class=s2>&#34;text_vector&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>text_vectors</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span>
</span></span></code></pre></div><p>The created vectors might be easily put into Qdrant. For the sake of simplicity, we‚Äôre going to skip it, but if you are interested in details, please check out the¬†<a href=https://gist.github.com/kacperlukawski/961aaa7946f55110abfcd37fbe869b8f target=_blank rel="noopener nofollow">Jupyter notebook</a>¬†going step by step.</p><h2 id=searching-with-multiple-vectors>Searching with multiple vectors</h2><p>If you decided to describe each object with several <a href=https://qdrant.tech/articles/neural-search-tutorial/ target=_blank rel="noopener nofollow">neural embeddings</a>, then at each search operation you need to provide the vector name along with the <a href=https://qdrant.tech/articles/what-are-embeddings/ target=_blank rel="noopener nofollow">vector embedding</a>, so the engine knows which one to use. The interface of the search operation is pretty straightforward and requires an instance of NamedVector.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>qdrant_client.http.models</span> <span class=kn>import</span> <span class=n>NamedVector</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text_results</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>search</span><span class=p>(</span>
</span></span><span class=line><span class=cl>   <span class=n>collection_name</span><span class=o>=</span><span class=s2>&#34;ms-coco-2017&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=n>query_vector</span><span class=o>=</span><span class=n>NamedVector</span><span class=p>(</span>
</span></span><span class=line><span class=cl>       <span class=n>name</span><span class=o>=</span><span class=s2>&#34;text&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>       <span class=n>vector</span><span class=o>=</span><span class=n>row</span><span class=p>[</span><span class=s2>&#34;text_vector&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>   <span class=p>),</span>
</span></span><span class=line><span class=cl>   <span class=n>limit</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=n>with_vectors</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=n>with_payload</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p>If we, on the other hand, decided to search using the image embedding, then we just provide the vector name we have chosen while creating the collection, so instead of ‚Äútext‚Äù, we would provide ‚Äúimage‚Äù, as this is how we configured it at the very beginning.</p><h2 id=the-results-image-vs-text-search>The results: image vs text search</h2><p>Since we have two different vectors describing each object, we can perform the search query using any of those. That shouldn‚Äôt be surprising then, that the results are different depending on the chosen embedding method. The images below present the results returned by Qdrant for the image/text on the left-hand side.</p><h3 id=image-search>Image search</h3><p>If we query the system using image embedding, then it returns the following results:</p><p><figure><img src=https://qdrant.tech/blog/from_cms/0_5nqlmjznjkvdrjhj.webp alt title="Image search results"><figcaption>Image search results</figcaption></figure></p><h3 id=text-search>Text search</h3><p>However, if we use textual description embedding, then the results are slightly different:</p><p><figure><img src=https://qdrant.tech/blog/from_cms/0_3sdgctswb99xtexl.webp alt title="Text search However, if we use textual description embedding, then the results are slightly different:"><figcaption>Text search However, if we use textual description embedding, then the results are slightly different:</figcaption></figure></p><p>It is not surprising that a method used for creating neural encoding plays an important role in the search process and its quality. If your data points might be described using several vectors, then the latest release of Qdrant gives you an opportunity to store them together and reuse the payloads, instead of creating several collections and querying them separately.</p><h3 id=summary>Summary:</h3><ul><li>Qdrant 0.10 introduces efficient vector storage optimization, allowing seamless management of multiple vectors per object within a single collection.</li><li>This update streamlines semantic search capabilities by eliminating the need for separate collections for each vector type, enhancing search accuracy and performance.</li><li>With Qdrant&rsquo;s new features, users can easily configure vector parameters, including size and distance functions, for each vector type, optimizing search results and user experience.</li></ul><p>If you‚Äôd like to check out some other examples, please check out our¬†<a href=https://gist.github.com/kacperlukawski/961aaa7946f55110abfcd37fbe869b8f target=_blank rel="noopener nofollow">full notebook</a>¬†presenting the search results and the whole pipeline implementation.</p></article><section class="docs-feedback d-print-none"><h5 class=docs-feedback__title>Was this page useful?</h5><div class=docs-feedback__buttons><button class="button button_outlined button_sm docs-feedback__button" id=feedback__answer_yes>
<img src=https://qdrant.tech/icons/outline/thumb-up.svg alt="Thumb up icon">
Yes
</button>
<button class="button button_outlined button_sm docs-feedback__button" id=feedback__answer_no>
<img src=https://qdrant.tech/icons/outline/thumb-down.svg alt="Thumb down icon">
No</button></div></section><section class="docs-feedback__responses d-none"><p class="docs-feedback__response docs-feedback__response_yes" id=feedback__response_yes>Thank you for your feedback! üôè</p><p class="docs-feedback__response docs-feedback__response_no" id=feedback__response_no>We are sorry to hear that. üòî You can <a class=text-brand-p href=https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/storing-multiple-vectors-per-object-in-qdrant.md target=_blank>edit</a> this page on GitHub, or <a class=text-brand-p href=https://github.com/qdrant/landing_page/issues/new/choose target=_blank>create</a> a GitHub issue.</p></section><script>const buttonsSection=document.querySelector(".docs-feedback"),responsesSection=document.querySelector(".docs-feedback__responses"),yesButton=document.querySelector("#feedback__answer_yes"),noButton=document.querySelector("#feedback__answer_no"),yesResponse=document.querySelector("#feedback__response_yes"),noResponse=document.querySelector("#feedback__response_no"),toggleResponses=()=>{buttonsSection.classList.add("d-none"),responsesSection.classList.remove("d-none")};yesButton.addEventListener("click",()=>{yesResponse.classList.add("feedback__response_visible"),toggleResponses()}),noButton.addEventListener("click",()=>{noResponse.classList.add("feedback__response_visible"),toggleResponses()})</script></div><div class=table-of-contents><p class=table-of-contents__head>On this page:</p><nav id=TableOfContents><ul><li><a href=#creating-a-collection>Creating a collection</a></li><li><a href=#building-service-with-multiple-embeddings>Building service with multiple embeddings</a></li><li><a href=#processing-the-data-with-pretrained-models>Processing the data with pretrained models</a></li><li><a href=#creating-qdrant-collection>Creating Qdrant collection</a></li><li><a href=#defining-the-pipelines>Defining the pipelines</a></li><li><a href=#searching-with-multiple-vectors>Searching with multiple vectors</a></li><li><a href=#the-results-image-vs-text-search>The results: image vs text search</a><ul><li><a href=#image-search>Image search</a></li><li><a href=#text-search>Text search</a></li><li><a href=#summary>Summary:</a></li></ul></li></ul></nav><ul class=table-of-contents__external-links><li class=table-of-contents__link><a href=https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/storing-multiple-vectors-per-object-in-qdrant.md target=_blank><svg width="16" height="17" viewBox="0 0 16 17" fill="none"><g clip-path="url(#clip0_6269_955)"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 .700012c-4.4.0-8 3.599998-8 7.999998C0 12.2333 2.26667 15.2333 5.46667 16.3 5.86667 16.3667 6 16.1 6 15.9S6 15.2333 6 14.5667C3.8 15.0333 3.33333 13.5 3.33333 13.5 3 12.5667 2.46667 12.3 2.46667 12.3 1.66667 11.8333 2.46667 11.8333 2.46667 11.8333 3.26667 11.9 3.66667 12.6333 3.66667 12.6333 4.4 13.8333 5.53333 13.5 6 13.3 6.06667 12.7667 6.26667 12.4333 6.53333 12.2333 4.73333 12.0333 2.86667 11.3667 2.86667 8.30001c0-.86666.33333-1.6.8-2.13333.0-.26667-.33334-1.06667.13333-2.13333.0.0.66667-.200000000000001 2.2.8.66667-.2 1.33333-.26667 2-.26667S9.33333 4.63335 10 4.83335c1.5333-1.06667 2.2-.8 2.2-.8C12.6667 5.16668 12.3333 5.96668 12.2667 6.16668 12.8 6.70001 13.0667 7.43335 13.0667 8.30001c0 3.06669-1.8667 3.73329-3.6667 3.93329C9.66667 12.5 9.93333 12.9667 9.93333 13.7c0 1.0667.0 1.9333.0 2.2C9.93333 16.1 10.0667 16.3667 10.4667 16.3c3.2-1.0667 5.4666-4.0667 5.4666-7.59999C16 4.30001 12.4.700012 8 .700012z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_6269_955"><rect width="16" height="16" fill="#fff" transform="translate(0 0.5)"/></clipPath></defs></svg>
Edit on Github</a></li><li class=table-of-contents__link><a href=https://github.com/qdrant/landing_page/issues/new/choose target=_blank><svg width="16" height="17" viewBox="0 0 16 17" fill="none"><g clip-path="url(#clip0_6269_1540)"><path d="M16 9.83331V8.49998H13.9347C13.79 7.33465 13.3947 6.24065 12.8 5.31065l1.476-1.478L13.3327 2.89065 11.9633 4.26198c-.24-.248-.496600000000001-.474-.772-.676C11.0967 3.25665 10.9507 2.95398 10.7673 2.67598l1.038-1.038L10.8627.695312 9.82867 1.72931C9.29867 1.37798 8.672 1.16665 8 1.16665c-.672.0-1.29867.21133-1.828.56266L5.138.695312l-.94267.942668 1.038 1.038c-.18333.27733-.32933.58-.424.90867-.27533.202-.532.42933-.77266.67733L2.66733 2.89065l-.94333.942L3.2 5.30998c-.59467.93-.99 2.02467-1.13467 3.19H0V9.83331H2.01467C2.07333 11.276 2.50533 12.6026 3.204 13.688l-1.48 1.478L2.666 16.1093l1.37-1.368C4.93733 15.67 6.07667 16.288 7.33333 16.452V6.49998H8.66667V16.452C9.92333 16.2873 11.0627 15.67 11.964 14.7413l1.37 1.368L14.276 15.166l-1.48-1.478C13.4947 12.602 13.9267 11.2753 13.9853 9.83331H16z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_6269_1540"><rect width="16" height="16" fill="#fff" transform="translate(0 0.5)"/></clipPath></defs></svg>
Create an issue</a></li></ul></div><footer class="docs-footer w-100 py-0 pt-0 pb-4 pb-xl-0"><div class=docs-footer__cta><h4>Ready to get started with Qdrant?</h4><a href=https://qdrant.to/cloud/ class="button button_outlined button_sm" target=_blank>Start Free</a></div><div class=docs-footer__bottom><div class=docs-footer__bottom-content><span>¬© 2025 Qdrant.</span><div class=footer__bottom-links><a href=https://qdrant.tech/legal/terms_and_conditions/>Terms</a>
<a href=https://qdrant.tech/legal/privacy-policy/>Privacy Policy</a>
<a href=https://qdrant.tech/legal/impressum/>Impressum</a></div></div></div></footer></div></div></div></div></section></main></body><script src=https://cdn.cookielaw.org/scripttemplates/otSDKStub.js type=text/javascript data-domain-script=01960152-5e40-782d-af01-f7f5768a214e></script><script async type=text/javascript>function OptanonWrapper(){const e=new CustomEvent("onetrust_loaded");document.dispatchEvent(e)}</script><script>!function(){const o="eQYi1nZE2zQSmnHuxjMRlDd2uLl65oHe";var n,s,t="analytics",e=window[t]=window[t]||[];if(!e.initialize)if(e.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{e.invoked=!0,e.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","debug","page","screen","once","off","on","addSourceMiddleware","addIntegrationMiddleware","setAnonymousId","addDestinationMiddleware","register"],e.factory=function(n){return function(){if(window[t].initialized)return window[t][n].apply(window[t],arguments);var o,s=Array.prototype.slice.call(arguments);return["track","screen","alias","group","page","identify"].indexOf(n)>-1&&(o=document.querySelector("link[rel='canonical']"),s.push({__t:"bpc",c:o&&o.getAttribute("href")||void 0,p:location.pathname,u:location.href,s:location.search,t:document.title,r:document.referrer})),s.unshift(n),e.push(s),e}};for(n=0;n<e.methods.length;n++)s=e.methods[n],e[s]=e.factory(s);e.load=function(n,s){var i,o=document.createElement("script");o.type="text/javascript",o.async=!0,o.setAttribute("data-global-segment-analytics-key",t),o.src="https://evs.analytics.qdrant.tech/5caWuitPgcGFN5Q7HMpTaj/vEkmzjuRSqeXGbhGAFTWex.min.js",i=document.getElementsByTagName("script")[0],i.parentNode.insertBefore(o,i),e._loadOptions=s},e._writeKey=o,e._cdn="https://evs.analytics.qdrant.tech",e.SNIPPET_VERSION="5.2.0",e.load(o)}}()</script><script src=https://qdrant.tech/js/google-setup.min.14728a3ae9bd931593645b6ddbfe801d400cd2970006e782cb67f3966654248ca962dbaf4cf371493a2d326861b3a691a99d6d8349c8b2752339ab91d3787069.js></script><script src=https://qdrant.tech/js/index.min.e37feda1952d752f5568e1ebc55e183629e4d361f4df09edeed70b4a4327d601161c4147bdbe4149b4a3cdc1ed43f1bf1a2f2340a421f1aa821103980dfe0bda.js></script><script src=https://qdrant.tech/js/search/search.min.e58e7ea98cb549ea9d3ed7e68876abe323cfb323432038820f38a71c40e309deed0fba615e2d3346825229a81e0a76bbadf6f8a816ddad3438abdabfef4ebc09.js type=module></script><script src=https://qdrant.tech/js/search/scroll.min.f4ed4453a3af0adb0d4f49333cbb7892ff5430483a567d0d2dfbd4655fb203d22f22f46aff3d9f38fa5fd96dde5f30227afd0ce1d9f838f5cd5295fc83856ec9.js></script><script src=https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js></script><script src=https://qdrant.tech/js/copy-code.min.95b03a45b2ab4b7a608ecfd4b5919c8572a5b2cd1463f52561cd10976abf3b74334f91324c0e620cb80afac46026a0b18cce6fb753d8495f74c6d478c8ca1d03.js></script><script src=https://qdrant.tech/js/lang-switcher.min.63da11cef09772078425b1ee56415b9c37842a9399f2ba2d2f5efbf72fb751686c410bd50e9bcd283c8231cb97c1973199d4923beef29d8b06e59d9983a6ba51.js></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src=https://qdrant.tech/js/vendor/anchor.min.0e138e17ebcf1c1147a7a3a81d9ac3c601622eedc479f1636470eb2552470f4e27c9a8efe6e8378995dedc1ab67029d8989536ea76f0857d45d1615ae772b8a1.js></script><script>document.addEventListener("keydown",function(e){if((e.metaKey||e.ctrlKey)&&e.key==="k"){e.preventDefault();let t=document.querySelector('[data-target="#searchModal"]');t&&t?.click()}})</script><script>window.addEventListener("message",e=>{if(e.data.type==="hsFormCallback"&&e.data.eventName==="onFormReady"){const t=document.querySelector(`form[data-form-id="${e.data.id}"]`);if(t){const e=t.querySelector('[name="last_form_fill_url"]');e&&(e.value=window.location.href);const n=t.querySelector('[name="referrer_url"]');n&&(n.value=document.referrer)}}})</script></html>