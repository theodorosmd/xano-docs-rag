<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta charset=UTF-8><title>Optimizing RAG Through an Evaluation-Based Methodology - Qdrant</title>
<link rel=icon href=https://qdrant.tech/favicon/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=https://qdrant.tech/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://qdrant.tech/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://qdrant.tech/favicon/favicon-16x16.png><link rel=manifest href=https://qdrant.tech/favicon/site.webmanifest><link rel=mask-icon href=https://qdrant.tech/favicon/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#2b5797"><meta name=msapplication-config content="/favicon/browserconfig.xml"><meta name=theme-color content="#ffffff"><meta name=partition content="learn"><link href=https://qdrant.tech/css/search/search.min.09596ee2b3c94d0ac82a1c33199cabdb3e0210b1ee46aaf1515200e9e484d05dd9e27cc1e861c58cc2e582af162f63b8e180ff2a12f7a6592b7aeaa0a7125130.css rel=stylesheet integrity="sha512-CVlu4rPJTQrIKhwzGZyr2z4CELHuRqrxUVIA6eSE0F3Z4nzB6GHFjMLlgq8WL2O44YD/KhL3plkreuqgpxJRMA=="><link href=https://qdrant.tech/css/documentation.min.de204cdcfc410689a41c17bcdad0a34f2caaa50cc8505c820adaab481cef2d69a920b0a32e0d624701c29487e3271b694559d98c5047cbfaa5aa475f638011e5.css rel=stylesheet integrity="sha512-3iBM3PxBBomkHBe82tCjTyyqpQzIUFyCCtqrSBzvLWmpILCjLg1iRwHClIfjJxtpRVnZjFBHy/qlqkdfY4AR5Q=="><link href=https://qdrant.tech/css/main.min.c1e379ad4cf03647832f6a0f040754b0be3e79934db2c29f50b396327c1ec7ac45f778abadbd93f5a8bc431850d1b0d9c9eff34c0171cd4236e83c5e324c1a0e.css rel=stylesheet integrity crossorigin=anonymous><meta name=generator content="Hugo 0.141.0"><meta name=description content="Learn how Qdrant-powered RAG applications can be tested and iteratively improved using LLM evaluation tools like Quotient."><meta name=keywords content="vector database,vector search,retrieval augmented generation,quotient,optimization,rag,qdrant"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@id":"https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#article","@type":"Article","abstract":"Learn how Qdrantpowered RAG applications can be tested and iteratively improved using LLM evaluation tools like Quotient","author":{"@type":"Person","name":"Atita Arora"},"dateModified":"2024-06-12 00:00:00 +0000 UTC","datePublished":"2024-06-12 00:00:00 +0000 UTC","description":"Learn how Qdrantpowered RAG applications can be tested and iteratively improved using LLM evaluation tools like Quotient","headline":"Optimizing RAG Through an Evaluation-Based Methodology","image":["https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/preview/social_preview.jpg"],"name":"Optimizing RAG Through an Evaluation-Based Methodology","url":"https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/","wordCount":"3115"},{"@id":"https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#organization","@type":"Organization","address":{"@type":"PostalAddress","addressCountry":"DE","addressLocality":"Berlin","addressRegion":"Berlin","postalCode":"10115","streetAddress":"ChausseestraÃŸe 86"},"contactPoint":{"@type":"ContactPoint","contactType":"customer support","email":"info@qdrant.com","telephone":"+49 3040797694"},"description":"Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.","email":"info@qdrant.com","founders":[{"@type":"Person","name":"map[email:info@qdrant.tech name:Andrey Vasnetsov]"},{"@type":"Person","name":"Andre Zayarni"}],"foundingDate":"2021","keywords":["vector database","vector search","retrieval augmented generation","quotient","optimization","rag","Qdrant"],"legalName":"Qdrant Solutions GmbH","location":"Berlin, Germany","logo":"https://qdrant.tech/images/logo_with_text.png","name":"Qdrant","sameAs":["https://github.com/qdrant/qdrant","https://qdrant.to/discord","https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA","https://www.linkedin.com/company/qdrant/","https://twitter.com/qdrant_engine"],"url":"https://qdrant.tech"}]}</script><meta property="og:url" content="https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/"><meta property="og:type" content="website"><meta property="og:title" content="Optimizing RAG Through an Evaluation-Based Methodology - Qdrant"><meta name=twitter:card content="summary_large_image"><meta name=twitter:domain content="qdrant"><meta name=twitter:url content="https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/"><meta name=twitter:title content="Optimizing RAG Through an Evaluation-Based Methodology - Qdrant"><meta property="og:description" content="Learn how Qdrant-powered RAG applications can be tested and iteratively improved using LLM evaluation tools like Quotient."><meta name=twitter:description content="Learn how Qdrant-powered RAG applications can be tested and iteratively improved using LLM evaluation tools like Quotient."><meta name=image property="og:image" content="https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/preview/social_preview.jpg"><meta name=image property="og:image:secure_url" content="https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/preview/social_preview.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name=twitter:image:src content="https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/preview/social_preview.jpg"><meta name=author content="Atita Arora"><link rel=canonical href=https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/><script type=text/javascript src=//js-eu1.hsforms.net/forms/embed/v2.js></script><script src=https://qdrant.tech/js/documentation.min.594fc9226f6fb87b8c3b0cafb9d5c0b0bcd95f47d292b929aab04315e0506706b2f376dc4fae9961dc3082138cb19d45b2a3370ee8e881bbf4b8c91dcb735c32.js></script></head><body><main><header class=docs-header><div class="main-menu z-5"><a href=https://qdrant.tech/><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div></a><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><div class="d-block d-xl-none"><button role=button class=theme-switch></button></div><button type=button class=main-menu__trigger><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M1 12H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 5H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 19H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=main-menu__links><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/>Qdrant</a></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/cloud-intro/>Cloud</a></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/build/>Build</a></li><li class=main-menu__item><a class=menu-linkactive href=https://qdrant.tech/articles/>Learn</a></li><li class=main-menu__item><a class=menu-link href=https://api.qdrant.tech/api-reference target=_blank>API Reference</a></li></ul><div class=main-menu__buttons><div class=main-menu__buttons-input><button class="qdr-search-input-btn q-input input_md input_light-bg" type=button name=search data-target=#searchModal>
Search</button></div><button role=button class=theme-switch></button>
<a data-metric-loc=nav href=https://cloud.qdrant.io/login class="menu-link mx-3" target=_blank>Log in</a>
<a data-metric-loc=nav href=https://cloud.qdrant.io/signup class="button button_contained button_sm" target=_blank>Start Free</a></div></div><div class=menu-mobile><div class=menu-mobile__header><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><div class="d-block d-xl-none"><button role=button class=theme-switch></button></div><button type=button class=menu-mobile__close><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><g id="Close"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M19.778 5.63606C20.1685 5.24554 20.1685 4.61237 19.778 4.22185 19.3874 3.83132 18.7543 3.83132 18.3637 4.22185L11.9998 10.5858 5.63586 4.22185c-.39052-.39053-1.02369-.39053-1.41421.0C3.83112 4.61237 3.83112 5.24554 4.22165 5.63606L10.5856 12l-6.364 6.364C3.83108 18.7545 3.83108 19.3877 4.2216 19.7782 4.61213 20.1687 5.24529 20.1687 5.63582 19.7782l6.36398-6.364 6.364 6.364C18.7543 20.1687 19.3875 20.1687 19.778 19.7782 20.1685 19.3877 20.1685 18.7545 19.778 18.364L13.414 12l6.364-6.36394z" fill="#e1e5f0"/></g></svg></button></div></div><div class=main-menu__buttons-input><button class="qdr-search-input-btn q-input input_md input_light-bg" type=button name=search data-target=#searchModal>
Search</button></div><ul class=menu-mobile__items><li class=menu-mobile__item data-path=menu-0><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Documentation"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M4.25 1c-1.10092.0-2.12247.23681-2.88689.64443C.620129 2.04063.0 2.67297.0 3.5v11c0 .2761.223858.5.5.5s.5-.2239.5-.5c0-.278.21937-.6456.83364-.9732C2.42647 13.2107 3.27992 13 4.25 13 5.22008 13 6.07353 13.2107 6.66636 13.5268c.61427.3276.83364.6952.83364.9732.0.2761.22386.5.5.5s.5-.2239.5-.5c0-.278.21937-.6456.833640000000001-.9732C9.92647 13.2107 10.7799 13 11.75 13S13.5735 13.2107 14.1664 13.5268C14.7806 13.8544 15 14.222 15 14.5c0 .2761.2239.5.5.5s.5-.2239.5-.5V3.5C16 2.67297 15.3799 2.04063 14.6369 1.64443 13.8725 1.23681 12.8509 1 11.75 1s-2.12247.23681-2.88689.64443C8.53799 1.8178 8.2364 2.03638 8 2.29671c-.2364-.26033-.53799-.47891-.86311-.65228C6.37247 1.23681 5.35092 1 4.25 1zM1.36311 12.6444C1.23778 12.7113 1.11595 12.7848 1 12.8649V3.5c0-.27797.21937-.64563.83364-.97318C2.42647 2.21069 3.27992 2 4.25 2c.97008.0 1.82353.21069 2.41636.52682C7.28063 2.85437 7.5 3.22203 7.5 3.5v9.3649C7.38405 12.7848 7.26222 12.7113 7.13689 12.6444 6.37247 12.2368 5.35092 12 4.25 12 3.14908 12 2.12753 12.2368 1.36311 12.6444zM8.5 12.8649C8.61595 12.7848 8.73778 12.7113 8.86311 12.6444 9.62753 12.2368 10.6491 12 11.75 12S13.8725 12.2368 14.6369 12.6444C14.7622 12.7113 14.8841 12.7848 15 12.8649V3.5C15 3.22203 14.7806 2.85437 14.1664 2.52682 13.5735 2.21069 12.7201 2 11.75 2s-1.82353.21069-2.41636.52682C8.71937 2.85437 8.5 3.22203 8.5 3.5v9.3649z"/></g></svg>
Qdrant</a></div></li><li class=menu-mobile__item data-path=menu-1><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/cloud-intro/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Cloud"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M7.5 2C4.57416 2 2.18128 4.28566 2.00983 7.16851.8403 7.57763.0 8.68965.0 10c0 1.6571 1.34286 3 3 3H13c1.6571.0 3-1.3429 3-3 0-1.65714-1.3429-3-3-3L12.9776 7.00009C12.7249 4.19714 10.3686 2 7.5 2zM3.00107 7.48137 3.00008 7.47308C3.01457 5.0006 5.02412 3 7.5 3c2.47599.0 4.4856 2.00079 4.4999 4.47342L11.9987 7.4836C11.9969 7.50027 11.995 7.52348 11.995 7.551 11.995 7.701 12.0623 7.84308 12.1785 7.93804 12.2946 8.03301 12.4472 8.07082 12.5942 8.04106 12.726 8.01438 12.8617 8 13 8c1.1049.0 2 .89514 2 2C15 11.1049 14.1049 12 13 12H3C1.89514 12 1 11.1049 1 10 1 9.03225 1.68901 8.22422 2.60364 8.04017 2.83708 7.9932 3.005 7.78812 3.005 7.55 3.005 7.52154 3.00291 7.49773 3.00107 7.48137z"/></g></svg>
Cloud</a></div></li><li class=menu-mobile__item data-path=menu-2><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/build/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Blog"><path id="Union" fill-rule="evenodd" clip-rule="evenodd" d="M0 1.5C0 1.22386.223858 1 .5 1h5c.27614.0.5.22386.5.5v5c0 .27614-.22386.5-.5.5H.5C.223858 7 0 6.77614.0 6.5v-5zM1 2V6H5V2H1zm7 .5c0-.27614.22386-.5.5-.5h7c.2761.0.5.22386.5.5s-.2239.5-.5.5h-7C8.22386 3 8 2.77614 8 2.5zM8.5 6c-.27614.0-.5.22386-.5.5s.22386.5.5.5h7c.2761.0.5-.22386.5-.5s-.2239-.5-.5-.5h-7zM0 10.5c0-.2761.223858-.5.5-.5h15c.2761.0.5.2239.5.5s-.2239.5-.5.5H.5c-.276142.0-.5-.2239-.5-.5zM.5 14c-.276142.0-.5.2239-.5.5s.223858.5.5.5h15c.2761.0.5-.2239.5-.5s-.2239-.5-.5-.5H.5z"/></g></svg>
Build</a></div></li><li class=menu-mobile__item data-path=menu-3><div class=menu-mobile__item-content><a class=active href=https://qdrant.tech/articles/><svg width="16" height="16" viewBox="0 0 16 16" fill="none" stroke="#e1e5f0"><g id="Group"><path id="Vector" d="M10.084 1.84094l4.059 4.059" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_2" d="M8.49188 2.72406c-1.22044-.53042-2.59304-.59475-3.85774-.1808-1.2647.41395-2.33363 1.27742-3.00426 2.4268l2.34 2.34" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_3" d="M13.2657 7.47302C13.8062 8.69691 13.8769 10.077 13.4645 11.3497c-.4125 1.2728-1.2792 2.3491-2.4348 3.0233l-2.35001-2.35" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_4" d="M6.81217 13.049l-3.861-3.861S6.24917.983 15.5002.5c-.523 9.211-8.68803 12.549-8.68803 12.549z" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_5" d="M3.59892 12.4008C3.34181 12.1441 2.99331 12 2.62995 12c-.36335.0-.71186.1441-.96897.4008-.46665.4664-.63131 1.941-.65931 2.2322C.997021 14.6793 1.0021 14.726 1.01659 14.7701 1.03108 14.8143 1.05465 14.8549 1.08579 14.8895 1.11693 14.924 1.15495 14.9516 1.19741 14.9705 1.23987 14.9895 1.28583 14.9994 1.33233 14.9995 1.34298 15.0002 1.35367 15.0002 1.36433 14.9995 1.65565 14.9715 3.1316 14.8063 3.59759 14.3405 3.85501 14.0834 3.99975 13.7346 4 13.3709 4.00025 13.0072 3.85599 12.6582 3.59892 12.4008z" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_6" d="M9 8c.55228.0 1-.44772 1-1S9.55228 6 9 6 8 6.44772 8 7s.44772 1 1 1z"/></g></svg>
Learn</a></div></li><li class=menu-mobile__item data-path=menu-4><div class=menu-mobile__item-content><a href=https://api.qdrant.tech/api-reference target=_blank><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Roadmap" clip-path="url(#clip0_7182_4311)"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M13.5 1c-.8284.0-1.5.67157-1.5 1.5S12.6716 4 13.5 4 15 3.32843 15 2.5 14.3284 1 13.5 1zM11 2.5C11 1.11929 12.1193.0 13.5.0S16 1.11929 16 2.5 14.8807 5 13.5 5 11 3.88071 11 2.5zM2.5 12c-.82843.0-1.5.6716-1.5 1.5S1.67157 15 2.5 15 4 14.3284 4 13.5 3.32843 12 2.5 12zM0 13.5C0 12.1193 1.11929 11 2.5 11S5 12.1193 5 13.5 3.88071 16 2.5 16 0 14.8807.0 13.5zM3.65901 1.65901C4.08097 1.23705 4.65326 1 5.25 1s1.16903.23705 1.59099.65901C7.26295 2.08097 7.5 2.65326 7.5 3.25v9.5c0 .862.34241 1.6886.9519 2.2981C9.0614 15.6576 9.88805 16 10.75 16c.862.0 1.6886-.3424 2.2981-.9519S14 13.612 14 12.75V6.5c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v6.25C13 13.3467 12.7629 13.919 12.341 14.341 11.919 14.7629 11.3467 15 10.75 15S9.58097 14.7629 9.15901 14.341C8.73705 13.919 8.5 13.3467 8.5 12.75V3.25C8.5 2.38805 8.15759 1.5614 7.5481.951903 6.9386.34241 6.11195.0 5.25.0S3.5614.34241 2.9519.951903C2.34241 1.5614 2 2.38805 2 3.25V9.5c0 .27614.22386.5.5.5s.5-.22386.5-.5V3.25c0-.59674.23705-1.16903.65901-1.59099z"/></g><defs><clipPath id="clip0_7182_4311"><rect width="16" height="16" fill="#fff"/></clipPath></defs></svg>
API Reference</a></div></li></ul><div class=docs-menu><div id=sidebar class=docs-menu__content><h3 class=docs-menu__links-title>Learn</h3><nav><div class=docs-menu__links-group><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/vector-search-manuals/>Vector Search Manuals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/qdrant-internals/>Qdrant Internals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/data-exploration/>Data Exploration</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/machine-learning/>Machine Learning</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/rag-and-genai/>RAG & GenAI</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/practicle-examples/>Practical Examples</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/ecosystem/>Ecosystem</a></div></div></nav></div></div></div></header><section class="docs documentation"><div class=documentation__container><div class="d-flex flex-column flex-xl-row"><div class=docs-menu><div id=sidebar class=docs-menu__content><h3 class=docs-menu__links-title>Learn</h3><nav><div class=docs-menu__links-group><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/vector-search-manuals/>Vector Search Manuals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/qdrant-internals/>Qdrant Internals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/data-exploration/>Data Exploration</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/machine-learning/>Machine Learning</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/rag-and-genai/>RAG & GenAI</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/practicle-examples/>Practical Examples</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/ecosystem/>Ecosystem</a></div></div></nav></div></div><div class=documentation__content><div class=documentation__content-wrapper><div class=documentation__article-wrapper><ul class=docs-breadcrumbs><li class=docs-breadcrumbs__crumb><a href=https://qdrant.tech/articles/>Articles</a></li><li class=docs-breadcrumbs__crumb-separator></li><li class=docs-breadcrumbs__crumb>Optimizing RAG Through an Evaluation-Based Methodology</li></ul><article class=documentation-article><div class=documentation-article__header><a href=https://qdrant.tech/articles/rag-and-genai/ class=documentation-article__header-link><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path d="M14.6668 8.00004H1.3335m0 0L6.00016 12.6667M1.3335 8.00004 6.00016 3.33337" stroke="#8f98b3" stroke-width="1.33333" stroke-linecap="round" stroke-linejoin="round"/></svg>
Back to RAG & GenAI</a><h1 class=documentation-article__header-title>Optimizing RAG Through an Evaluation-Based Methodology</h1><div class=documentation-article__header-about><p>Atita Arora</p><span>&#183;</span><p>June 12, 2024</p></div><picture class=documentation-article__header-preview><source srcset=https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/preview/title.webp type=image/webp><img alt="Optimizing RAG Through an Evaluation-Based Methodology" src=https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/preview/title.jpg></picture></div><p>In today&rsquo;s fast-paced, information-rich world, AI is revolutionizing knowledge management. The systematic process of capturing, distributing, and effectively using knowledge within an organization is one of the fields in which AI provides exceptional value today.</p><blockquote><p>The potential for AI-powered knowledge management increases when leveraging <a href=https://qdrant.tech/rag/rag-evaluation-guide/ target=_blank rel="noopener nofollow">Retrieval Augmented Generation (RAG)</a>, a methodology that enables LLMs to access a vast, diverse repository of factual information from knowledge stores, such as vector databases.</p></blockquote><p>This process enhances the accuracy, relevance, and reliability of generated text, thereby mitigating the risk of faulty, incorrect, or nonsensical results sometimes associated with traditional LLMs. This method not only ensures that the answers are contextually relevant but also up-to-date, reflecting the latest insights and data available.</p><p>While RAG enhances the accuracy, relevance, and reliability of traditional LLM solutions, <strong>an evaluation strategy can further help teams ensure their AI products meet these benchmarks of success.</strong></p><h2 id=relevant-tools-for-this-experiment>Relevant tools for this experiment</h2><p>In this article, weâ€™ll break down a RAG Optimization workflow experiment that demonstrates that evaluation is essential to build a successful RAG strategy. We will use Qdrant and Quotient for this experiment.</p><p><a href=https://qdrant.tech/ target=_blank rel="noopener nofollow">Qdrant</a> is a vector database and vector similarity search engine designed for efficient storage and retrieval of high-dimensional vectors. Because Qdrant offers efficient indexing and searching capabilities, it is ideal for implementing RAG solutions, where quickly and accurately retrieving relevant information from extremely large datasets is crucial. Qdrant also offers a wealth of additional features, such as quantization, multivector support and multi-tenancy.</p><p>Alongside Qdrant we will use Quotient, which provides a seamless way to evaluate your RAG implementation, accelerating and improving the experimentation process.</p><p><a href=https://www.quotientai.co/ target=_blank rel="noopener nofollow">Quotient</a> is a platform that provides tooling for AI developers to build <a href=https://qdrant.tech/rag/rag-evaluation-guide/ target=_blank rel="noopener nofollow">evaluation frameworks</a> and conduct experiments on their products. Evaluation is how teams surface the shortcomings of their applications and improve performance in key benchmarks such as faithfulness, and semantic similarity. Iteration is key to building innovative AI products that will deliver value to end users.</p><blockquote><p>ðŸ’¡ The <a href=https://github.com/qdrant/qdrant-rag-eval/tree/master/workshop-rag-eval-qdrant-quotient target=_blank rel="noopener nofollow">accompanying notebook</a> for this exercise can be found on GitHub for future reference.</p></blockquote><h2 id=summary-of-key-findings>Summary of key findings</h2><ol><li><strong>Irrelevance and Hallucinations</strong>: When the documents retrieved are irrelevant, evidenced by low scores in both Chunk Relevance and Context Relevance, the model is prone to generating inaccurate or fabricated information.</li><li><strong>Optimizing Document Retrieval</strong>: By retrieving a greater number of documents and reducing the chunk size, we observed improved outcomes in the model&rsquo;s performance.</li><li><strong>Adaptive Retrieval Needs</strong>: Certain queries may benefit from accessing more documents. Implementing a dynamic retrieval strategy that adjusts based on the query could enhance accuracy.</li><li><strong>Influence of Model and Prompt Variations</strong>: Alterations in language models or the prompts used can significantly impact the quality of the generated responses, suggesting that fine-tuning these elements could optimize performance.</li></ol><p>Let us walk you through how we arrived at these findings!</p><h2 id=building-a-rag-pipeline>Building a RAG pipeline</h2><p>To evaluate a RAG pipeline, we will have to build a RAG Pipeline first. In the interest of simplicity, we are building a Naive RAG in this article. There are certainly other versions of RAG :</p><p><img src=https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/shades_of_rag.png alt=shades_of_rag.png></p><p>The illustration below depicts how we can leverage a <a href=https://qdrant.tech/rag/rag-evaluation-guide/ target=_blank rel="noopener nofollow">RAG Evaluation framework</a> to assess the quality of RAG Application.</p><p><img src=https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/qdrant_and_quotient.png alt=qdrant_and_quotient.png></p><p>We are going to build a RAG application using Qdrantâ€™s Documentation and the premeditated <a href=https://huggingface.co/datasets/atitaarora/qdrant_doc target=_blank rel="noopener nofollow">hugging face dataset</a>.
We will then assess our RAG applicationâ€™s ability to answer questions about Qdrant.</p><p>To prepare our knowledge store we will use Qdrant, which can be leveraged in 3 different ways as below :</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>qdrant_client</span><span class=o>.</span><span class=n>QdrantClient</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;QDRANT_URL&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>api_key</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;QDRANT_API_KEY&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p>We will be using <a href=https://cloud.qdrant.io/login target=_blank rel="noopener nofollow">Qdrant Cloud</a> so it is a good idea to provide the <code>QDRANT_URL</code> and <code>QDRANT_API_KEY</code> as environment variables for easier access.</p><p>Moving on, we will need to define the collection name as :</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>COLLECTION_NAME</span> <span class=o>=</span> <span class=s2>&#34;qdrant-docs-quotient&#34;</span>
</span></span></code></pre></div><p>In this case , we may need to create different collections based on the experiments we conduct.</p><p>To help us provide seamless embedding creations throughout the experiment, we will use Qdrantâ€™s own embeddings library <a href=https://qdrant.github.io/fastembed/ target=_blank rel="noopener nofollow">Fastembed</a> which supports <a href=https://qdrant.github.io/fastembed/examples/Supported_Models/ target=_blank rel="noopener nofollow">many different models</a> including dense as well as sparse vector models.</p><p>Before implementing RAG, we need to prepare and index our data in Qdrant.</p><p>This involves converting textual data into vectors using a suitable encoder (e.g., sentence transformers), and storing these vectors in Qdrant for retrieval.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.text_splitter</span> <span class=kn>import</span> <span class=n>RecursiveCharacterTextSplitter</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.docstore.document</span> <span class=kn>import</span> <span class=n>Document</span> <span class=k>as</span> <span class=n>LangchainDocument</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## Load the dataset with qdrant documentation</span>
</span></span><span class=line><span class=cl><span class=n>dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=s2>&#34;atitaarora/qdrant_doc&#34;</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s2>&#34;train&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## Dataset to langchain document</span>
</span></span><span class=line><span class=cl><span class=n>langchain_docs</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=n>LangchainDocument</span><span class=p>(</span><span class=n>page_content</span><span class=o>=</span><span class=n>doc</span><span class=p>[</span><span class=s2>&#34;text&#34;</span><span class=p>],</span> <span class=n>metadata</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;source&#34;</span><span class=p>:</span> <span class=n>doc</span><span class=p>[</span><span class=s2>&#34;source&#34;</span><span class=p>]})</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>doc</span> <span class=ow>in</span> <span class=n>dataset</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>len</span><span class=p>(</span><span class=n>langchain_docs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#Outputs</span>
</span></span><span class=line><span class=cl><span class=c1>#240</span>
</span></span></code></pre></div><p>You can preview documents in the dataset as below :</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1>## Here&#39;s an example of what a document in our dataset looks like</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>dataset</span><span class=p>[</span><span class=mi>100</span><span class=p>][</span><span class=s1>&#39;text&#39;</span><span class=p>])</span>
</span></span></code></pre></div><h2 id=evaluation-dataset>Evaluation dataset</h2><p>To measure the quality of our RAG setup, we will need a representative evaluation dataset. This dataset should contain realistic questions and the expected answers.</p><p>Additionally, including the expected contexts for which your RAG pipeline is designed to retrieve information would be beneficial.</p><p>We will be using a <a href=https://huggingface.co/datasets/atitaarora/qdrant_doc_qna target=_blank rel="noopener nofollow">prebuilt evaluation dataset</a>.</p><p>If you are struggling to make an evaluation dataset for your use case , you can use your documents and some techniques described in this <a href=https://github.com/qdrant/qdrant-rag-eval/blob/master/synthetic_qna/notebook/Synthetic_question_generation.ipynb target=_blank rel="noopener nofollow">notebook</a></p><h3 id=building-the-rag-pipeline>Building the RAG pipeline</h3><p>We establish the data preprocessing parameters essential for the RAG pipeline and configure the Qdrant vector database according to the specified criteria.</p><p>Key parameters under consideration are:</p><ul><li><strong>Chunk size</strong></li><li><strong>Chunk overlap</strong></li><li><strong>Embedding model</strong></li><li><strong>Number of documents retrieved (retrieval window)</strong></li></ul><p>Following the ingestion of data in Qdrant, we proceed to retrieve pertinent documents corresponding to each query. These documents are then seamlessly integrated into our evaluation dataset, enriching the contextual information within the designated <strong><code>context</code></strong> column to fulfil the evaluation aspect.</p><p>Next we define methods to take care of logistics with respect to adding documents to Qdrant</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>uuid</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>qdrant_client</span> <span class=kn>import</span> <span class=n>models</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>add_documents</span><span class=p>(</span><span class=n>client</span><span class=p>,</span> <span class=n>collection_name</span><span class=p>,</span> <span class=n>chunk_size</span><span class=p>,</span> <span class=n>chunk_overlap</span><span class=p>,</span> <span class=n>embedding_model_name</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    This function adds documents to the desired Qdrant collection given the specified RAG parameters.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>## Processing each document with desired TEXT_SPLITTER_ALGO, CHUNK_SIZE, CHUNK_OVERLAP</span>
</span></span><span class=line><span class=cl>    <span class=n>text_splitter</span> <span class=o>=</span> <span class=n>RecursiveCharacterTextSplitter</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>chunk_size</span><span class=o>=</span><span class=n>chunk_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>chunk_overlap</span><span class=o>=</span><span class=n>chunk_overlap</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>add_start_index</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>separators</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;</span><span class=se>\n\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=s2>&#34;.&#34;</span><span class=p>,</span> <span class=s2>&#34; &#34;</span><span class=p>,</span> <span class=s2>&#34;&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>docs_processed</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>doc</span> <span class=ow>in</span> <span class=n>langchain_docs</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>docs_processed</span> <span class=o>+=</span> <span class=n>text_splitter</span><span class=o>.</span><span class=n>split_documents</span><span class=p>([</span><span class=n>doc</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>## Processing documents to be encoded by Fastembed</span>
</span></span><span class=line><span class=cl>    <span class=n>docs_contents</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>docs_metadatas</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>doc</span> <span class=ow>in</span> <span class=n>docs_processed</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>hasattr</span><span class=p>(</span><span class=n>doc</span><span class=p>,</span> <span class=s1>&#39;page_content&#39;</span><span class=p>)</span> <span class=ow>and</span> <span class=nb>hasattr</span><span class=p>(</span><span class=n>doc</span><span class=p>,</span> <span class=s1>&#39;metadata&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>docs_contents</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>doc</span><span class=o>.</span><span class=n>page_content</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>docs_metadatas</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>doc</span><span class=o>.</span><span class=n>metadata</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># Handle the case where attributes are missing</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Warning: Some documents do not have &#39;page_content&#39; or &#39;metadata&#39; attributes.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;processed: &#34;</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>docs_processed</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;content: &#34;</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>docs_contents</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;metadata: &#34;</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>docs_metadatas</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=ow>not</span> <span class=n>client</span><span class=o>.</span><span class=n>collection_exists</span><span class=p>(</span><span class=n>collection_name</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>client</span><span class=o>.</span><span class=n>create_collection</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>collection_name</span><span class=o>=</span><span class=n>collection_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>vectors_config</span><span class=o>=</span><span class=n>models</span><span class=o>.</span><span class=n>VectorParams</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=mi>384</span><span class=p>,</span> <span class=n>distance</span><span class=o>=</span><span class=n>models</span><span class=o>.</span><span class=n>Distance</span><span class=o>.</span><span class=n>COSINE</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>client</span><span class=o>.</span><span class=n>upsert</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>collection_name</span><span class=o>=</span><span class=n>collection_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>points</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=n>models</span><span class=o>.</span><span class=n>PointStruct</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=nb>id</span><span class=o>=</span><span class=n>uuid</span><span class=o>.</span><span class=n>uuid4</span><span class=p>()</span><span class=o>.</span><span class=n>hex</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>vector</span><span class=o>=</span><span class=n>models</span><span class=o>.</span><span class=n>Document</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=n>content</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=n>embedding_model_name</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>payload</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;metadata&#34;</span><span class=p>:</span> <span class=n>metadata</span><span class=p>,</span> <span class=s2>&#34;document&#34;</span><span class=p>:</span> <span class=n>content</span><span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>metadata</span><span class=p>,</span> <span class=n>content</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>docs_metadatas</span><span class=p>,</span> <span class=n>docs_contents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></div><p>and retrieving documents from Qdrant during our RAG Pipeline assessment.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_documents</span><span class=p>(</span><span class=n>collection_name</span><span class=p>,</span> <span class=n>query</span><span class=p>,</span> <span class=n>num_documents</span><span class=o>=</span><span class=mi>3</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    This function retrieves the desired number of documents from the Qdrant collection given a query.
</span></span></span><span class=line><span class=cl><span class=s2>    It returns a list of the retrieved documents.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>search_results</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>query_points</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>collection_name</span><span class=o>=</span><span class=n>collection_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>query</span><span class=o>=</span><span class=n>models</span><span class=o>.</span><span class=n>Document</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=n>query</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=n>embedding_model_name</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>limit</span><span class=o>=</span><span class=n>num_documents</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span><span class=o>.</span><span class=n>points</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=p>[</span><span class=n>r</span><span class=o>.</span><span class=n>payload</span><span class=p>[</span><span class=s2>&#34;document&#34;</span><span class=p>]</span> <span class=k>for</span> <span class=n>r</span> <span class=ow>in</span> <span class=n>search_results</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>results</span>
</span></span></code></pre></div><h3 id=setting-up-quotient>Setting up Quotient</h3><p>You will need an account log in, which you can get by requesting access on <a href=https://www.quotientai.co/ target=_blank rel="noopener nofollow">Quotient&rsquo;s website</a>. Once you have an account, you can create an API key by running the <code>quotient authenticate</code> CLI command.</p><aside>ðŸ’¡ Be sure to save your API key, since it will only be displayed once (Note: you will not have to repeat this step again until your API key expires).</aside><p><strong>Once you have your API key, make sure to set it as an environment variable called <code>QUOTIENT_API_KEY</code></strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Import QuotientAI client and connect to QuotientAI</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>quotientai.client</span> <span class=kn>import</span> <span class=n>QuotientClient</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>quotientai.utils</span> <span class=kn>import</span> <span class=n>show_job_progress</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># IMPORTANT: be sure to set your API key as an environment variable called QUOTIENT_API_KEY</span>
</span></span><span class=line><span class=cl><span class=c1># You will need this set before running the code below. You may also uncomment the following line and insert your API key:</span>
</span></span><span class=line><span class=cl><span class=c1># os.environ[&#39;QUOTIENT_API_KEY&#39;] = &#34;YOUR_API_KEY&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>quotient</span> <span class=o>=</span> <span class=n>QuotientClient</span><span class=p>()</span>
</span></span></code></pre></div><p><strong>QuotientAI</strong> provides a seamless way to integrate <em>RAG evaluation</em> into your applications. Here, we&rsquo;ll see how to use it to evaluate text generated from an LLM, based on retrieved knowledge from the Qdrant vector database.</p><p>After retrieving the top similar documents and populating the <code>context</code> column, we can submit the evaluation dataset to Quotient and execute an evaluation job. To run a job, all you need is your evaluation dataset and a <code>recipe</code>.</p><p><em><strong>A recipe is a combination of a prompt template and a specified LLM.</strong></em></p><p><strong>Quotient</strong> orchestrates the evaluation run and handles version control and asset management throughout the experimentation process.</p><p><em><strong>Prior to assessing our RAG solution, it&rsquo;s crucial to outline our optimization goals.</strong></em></p><p>In the context of <em>question-answering on Qdrant documentation</em>, our focus extends beyond merely providing helpful responses. Ensuring the absence of any <em>inaccurate or misleading information</em> is paramount.</p><p>In other words, <strong>we want to minimize hallucinations</strong> in the LLM outputs.</p><p>For our evaluation, we will be considering the following metrics, with a focus on <strong>Faithfulness</strong>:</p><ul><li><strong>Context Relevance</strong></li><li><strong>Chunk Relevance</strong></li><li><strong>Faithfulness</strong></li><li><strong>ROUGE-L</strong></li><li><strong>BERT Sentence Similarity</strong></li><li><strong>BERTScore</strong></li></ul><h3 id=evaluation-in-action>Evaluation in action</h3><p>The function below takes an evaluation dataset as input, which in this case contains questions and their corresponding answers. It retrieves relevant documents based on the questions in the dataset and populates the context field with this information from Qdrant. The prepared dataset is then submitted to QuotientAI for evaluation for the chosen metrics. After the evaluation is complete, the function displays aggregated statistics on the evaluation metrics followed by the summarized evaluation results.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>run_eval</span><span class=p>(</span><span class=n>eval_df</span><span class=p>,</span> <span class=n>collection_name</span><span class=p>,</span> <span class=n>recipe_id</span><span class=p>,</span> <span class=n>num_docs</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>path</span><span class=o>=</span><span class=s2>&#34;eval_dataset_qdrant_questions.csv&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    This function evaluates the performance of a complete RAG pipeline on a given evaluation dataset.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Given an evaluation dataset (containing questions and ground truth answers),
</span></span></span><span class=line><span class=cl><span class=s2>    this function retrieves relevant documents, populates the context field, and submits the dataset to QuotientAI for evaluation.
</span></span></span><span class=line><span class=cl><span class=s2>    Once the evaluation is complete, aggregated statistics on the evaluation metrics are displayed.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    The evaluation results are returned as a pandas dataframe.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Add context to each question by retrieving relevant documents</span>
</span></span><span class=line><span class=cl>    <span class=n>eval_df</span><span class=p>[</span><span class=s1>&#39;documents&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>eval_df</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>get_documents</span><span class=p>(</span><span class=n>collection_name</span><span class=o>=</span><span class=n>collection_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                                                <span class=n>query</span><span class=o>=</span><span class=n>x</span><span class=p>[</span><span class=s1>&#39;input_text&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                                                                <span class=n>num_documents</span><span class=o>=</span><span class=n>num_docs</span><span class=p>),</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>eval_df</span><span class=p>[</span><span class=s1>&#39;context&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>eval_df</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=s1>&#39;documents&#39;</span><span class=p>]),</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Now we&#39;ll save the eval_df to a CSV</span>
</span></span><span class=line><span class=cl>    <span class=n>eval_df</span><span class=o>.</span><span class=n>to_csv</span><span class=p>(</span><span class=n>path</span><span class=p>,</span> <span class=n>index</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Upload the eval dataset to QuotientAI</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span> <span class=o>=</span> <span class=n>quotient</span><span class=o>.</span><span class=n>create_dataset</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>file_path</span><span class=o>=</span><span class=n>path</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=s2>&#34;qdrant-questions-eval-v1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Create a new task for the dataset</span>
</span></span><span class=line><span class=cl>    <span class=n>task</span> <span class=o>=</span> <span class=n>quotient</span><span class=o>.</span><span class=n>create_task</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>dataset_id</span><span class=o>=</span><span class=n>dataset</span><span class=p>[</span><span class=s1>&#39;id&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=s1>&#39;qdrant-questions-qa-v1&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>task_type</span><span class=o>=</span><span class=s1>&#39;question_answering&#39;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Run a job to evaluate the model</span>
</span></span><span class=line><span class=cl>    <span class=n>job</span> <span class=o>=</span> <span class=n>quotient</span><span class=o>.</span><span class=n>create_job</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>task_id</span><span class=o>=</span><span class=n>task</span><span class=p>[</span><span class=s1>&#39;id&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>recipe_id</span><span class=o>=</span><span class=n>recipe_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>num_fewshot_examples</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>limit</span><span class=o>=</span><span class=mi>500</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>metric_ids</span><span class=o>=</span><span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>50</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Show the progress of the job</span>
</span></span><span class=line><span class=cl>    <span class=n>show_job_progress</span><span class=p>(</span><span class=n>quotient</span><span class=p>,</span> <span class=n>job</span><span class=p>[</span><span class=s1>&#39;id&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Once the job is complete, we can get our results</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span> <span class=o>=</span> <span class=n>quotient</span><span class=o>.</span><span class=n>get_eval_results</span><span class=p>(</span><span class=n>job_id</span><span class=o>=</span><span class=n>job</span><span class=p>[</span><span class=s1>&#39;id&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Add the results to a pandas dataframe to get statistics on performance</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>json_normalize</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=s2>&#34;results&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>df_stats</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=n>df</span><span class=o>.</span><span class=n>columns</span><span class=p>[</span><span class=n>df</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>str</span><span class=o>.</span><span class=n>contains</span><span class=p>(</span><span class=s2>&#34;metric|completion_time&#34;</span><span class=p>)]]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>df</span><span class=o>.</span><span class=n>columns</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>str</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s2>&#34;metric.&#34;</span><span class=p>,</span> <span class=s2>&#34;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>df_stats</span><span class=o>.</span><span class=n>columns</span> <span class=o>=</span> <span class=n>df_stats</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>str</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s2>&#34;metric.&#34;</span><span class=p>,</span> <span class=s2>&#34;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;completion_time_ms&#39;</span><span class=p>:</span><span class=s1>&#39;Completion Time (ms)&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;chunk_relevance&#39;</span><span class=p>:</span> <span class=s1>&#39;Chunk Relevance&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;selfcheckgpt_nli_relevance&#39;</span><span class=p>:</span><span class=s2>&#34;Context Relevance&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;selfcheckgpt_nli&#39;</span><span class=p>:</span><span class=s2>&#34;Faithfulness&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;rougeL_fmeasure&#39;</span><span class=p>:</span><span class=s2>&#34;ROUGE-L&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;bert_score_f1&#39;</span><span class=p>:</span><span class=s2>&#34;BERTScore&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;bert_sentence_similarity&#39;</span><span class=p>:</span> <span class=s2>&#34;BERT Sentence Similarity&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;completion_verbosity&#39;</span><span class=p>:</span><span class=s2>&#34;Completion Verbosity&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;verbosity_ratio&#39;</span><span class=p>:</span><span class=s2>&#34;Verbosity Ratio&#34;</span><span class=p>,}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>df</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>rename</span><span class=p>(</span><span class=n>columns</span><span class=o>=</span><span class=n>metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>df_stats</span> <span class=o>=</span> <span class=n>df_stats</span><span class=o>.</span><span class=n>rename</span><span class=p>(</span><span class=n>columns</span><span class=o>=</span><span class=n>metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>display</span><span class=p>(</span><span class=n>df_stats</span><span class=p>[</span><span class=n>metrics</span><span class=o>.</span><span class=n>values</span><span class=p>()]</span><span class=o>.</span><span class=n>describe</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>df</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>main_metrics</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;Context Relevance&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;Chunk Relevance&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;Faithfulness&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;ROUGE-L&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;BERT Sentence Similarity&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;BERTScore&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=p>]</span>
</span></span></code></pre></div><h2 id=experimentation>Experimentation</h2><p>Our approach is rooted in the belief that improvement thrives in an environment of exploration and discovery. By systematically testing and tweaking various components of the RAG pipeline, we aim to incrementally enhance its capabilities and performance.</p><p>In the following section, we dive into the details of our experimentation process, outlining the specific experiments conducted and the insights gained.</p><h3 id=experiment-1---baseline>Experiment 1 - Baseline</h3><p>Parameters</p><ul><li><strong>Embedding Model: <code>bge-small-en</code></strong></li><li><strong>Chunk size: <code>512</code></strong></li><li><strong>Chunk overlap: <code>64</code></strong></li><li><strong>Number of docs retrieved (Retireval Window): <code>3</code></strong></li><li><strong>LLM: <code>Mistral-7B-Instruct</code></strong></li></ul><p>Weâ€™ll process our documents based on configuration above and ingest them into Qdrant using <code>add_documents</code> method introduced earlier</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1>#experiment1 - base config</span>
</span></span><span class=line><span class=cl><span class=n>chunk_size</span> <span class=o>=</span> <span class=mi>512</span>
</span></span><span class=line><span class=cl><span class=n>chunk_overlap</span> <span class=o>=</span> <span class=mi>64</span>
</span></span><span class=line><span class=cl><span class=n>embedding_model_name</span> <span class=o>=</span> <span class=s2>&#34;BAAI/bge-small-en&#34;</span>
</span></span><span class=line><span class=cl><span class=n>num_docs</span> <span class=o>=</span> <span class=mi>3</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>COLLECTION_NAME</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;experiment_</span><span class=si>{</span><span class=n>chunk_size</span><span class=si>}</span><span class=s2>_</span><span class=si>{</span><span class=n>chunk_overlap</span><span class=si>}</span><span class=s2>_</span><span class=si>{</span><span class=n>embedding_model_name</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;/&#39;</span><span class=p>)[</span><span class=mi>1</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>add_documents</span><span class=p>(</span><span class=n>client</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>collection_name</span><span class=o>=</span><span class=n>COLLECTION_NAME</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>chunk_size</span><span class=o>=</span><span class=n>chunk_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>chunk_overlap</span><span class=o>=</span><span class=n>chunk_overlap</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>embedding_model_name</span><span class=o>=</span><span class=n>embedding_model_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>              
</span></span><span class=line><span class=cl><span class=c1>#Outputs</span>
</span></span><span class=line><span class=cl><span class=c1>#processed: 4504</span>
</span></span><span class=line><span class=cl><span class=c1>#content:   4504</span>
</span></span><span class=line><span class=cl><span class=c1>#metadata:  4504</span>
</span></span></code></pre></div><p>Notice the <code>COLLECTION_NAME</code> which helps us segregate and identify our collections based on the experiments conducted.</p><p>To proceed with the evaluation, letâ€™s create the <code>evaluation recipe</code> up next</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Create a recipe for the generator model and prompt template</span>
</span></span><span class=line><span class=cl><span class=n>recipe_mistral</span> <span class=o>=</span> <span class=n>quotient</span><span class=o>.</span><span class=n>create_recipe</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model_id</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>prompt_template_id</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>name</span><span class=o>=</span><span class=s1>&#39;mistral-7b-instruct-qa-with-rag&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>description</span><span class=o>=</span><span class=s1>&#39;Mistral-7b-instruct using a prompt template that includes context.&#39;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>recipe_mistral</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#Outputs recipe JSON with the used prompt template</span>
</span></span><span class=line><span class=cl><span class=c1>#&#39;prompt_template&#39;: {&#39;id&#39;: 1,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;name&#39;: &#39;Default Question Answering Template&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;variables&#39;: &#39;[&#34;input_text&#34;,&#34;context&#34;]&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;created_at&#39;: &#39;2023-12-21T22:01:54.632367&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;template_string&#39;: &#39;Question: {input_text}\\n\\nContext: {context}\\n\\nAnswer:&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;owner_profile_id&#39;: None}</span>
</span></span></code></pre></div><p>To get a list of your existing recipes, you can simply run:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>quotient</span><span class=o>.</span><span class=n>list_recipes</span><span class=p>()</span>
</span></span></code></pre></div><p>Notice the recipe template is a simplest prompt using <code>Question</code> from evaluation template <code>Context</code> from document chunks retrieved from Qdrant and <code>Answer</code> generated by the pipeline.</p><p>To kick off the evaluation</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Kick off an evaluation job</span>
</span></span><span class=line><span class=cl><span class=n>experiment_1</span> <span class=o>=</span> <span class=n>run_eval</span><span class=p>(</span><span class=n>eval_df</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>collection_name</span><span class=o>=</span><span class=n>COLLECTION_NAME</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>recipe_id</span><span class=o>=</span><span class=n>recipe_mistral</span><span class=p>[</span><span class=s1>&#39;id&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                        <span class=n>num_docs</span><span class=o>=</span><span class=n>num_docs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>path</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>COLLECTION_NAME</span><span class=si>}</span><span class=s2>_</span><span class=si>{</span><span class=n>num_docs</span><span class=si>}</span><span class=s2>_mistral.csv&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>This may take few minutes (depending on the size of evaluation dataset!)</p><p>We can look at the results from our first (baseline) experiment as below :</p><p><img src=https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/experiment1_eval.png alt=experiment1_eval.png></p><p>Notice that we have a pretty <strong>low average Chunk Relevance</strong> and <strong>very large standard deviations for both Chunk Relevance and Context Relevance</strong>.</p><p>Let&rsquo;s take a look at some of the lower performing datapoints with <strong>poor Faithfulness</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>with</span> <span class=n>pd</span><span class=o>.</span><span class=n>option_context</span><span class=p>(</span><span class=s1>&#39;display.max_colwidth&#39;</span><span class=p>,</span> <span class=mi>0</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>display</span><span class=p>(</span><span class=n>experiment_1</span><span class=p>[[</span><span class=s1>&#39;content.input_text&#39;</span><span class=p>,</span> <span class=s1>&#39;content.answer&#39;</span><span class=p>,</span><span class=s1>&#39;content.documents&#39;</span><span class=p>,</span><span class=s1>&#39;Chunk Relevance&#39;</span><span class=p>,</span><span class=s1>&#39;Context Relevance&#39;</span><span class=p>,</span><span class=s1>&#39;Faithfulness&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=p>]</span><span class=o>.</span><span class=n>sort_values</span><span class=p>(</span><span class=n>by</span><span class=o>=</span><span class=s1>&#39;Faithfulness&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>head</span><span class=p>(</span><span class=mi>2</span><span class=p>))</span>
</span></span></code></pre></div><p><img src=https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/experiment1_bad_examples.png alt=experiment1_bad_examples.png></p><p>In instances where the retrieved documents are <strong>irrelevant (where both Chunk Relevance and Context Relevance are low)</strong>, the model also shows <strong>tendencies to hallucinate</strong> and <strong>produce poor quality responses</strong>.</p><p>The quality of the retrieved text directly impacts the quality of the LLM-generated answer. Therefore, our focus will be on enhancing the RAG setup by <strong>adjusting the chunking parameters</strong>.</p><h3 id=experiment-2---adjusting-the-chunk-parameter>Experiment 2 - Adjusting the chunk parameter</h3><p>Keeping all other parameters constant, we changed the <code>chunk size</code> and <code>chunk overlap</code> to see if we can improve our results.</p><p>Parameters :</p><ul><li><strong>Embedding Model : <code>bge-small-en</code></strong></li><li><strong>Chunk size: <code>1024</code></strong></li><li><strong>Chunk overlap: <code>128</code></strong></li><li><strong>Number of docs retrieved (Retireval Window): <code>3</code></strong></li><li><strong>LLM: <code>Mistral-7B-Instruct</code></strong></li></ul><p>We will reprocess the data with the updated parameters above:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1>## for iteration 2 - lets modify chunk configuration</span>
</span></span><span class=line><span class=cl><span class=c1>## We will start with creating seperate collection to store vectors</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>chunk_size</span> <span class=o>=</span> <span class=mi>1024</span>
</span></span><span class=line><span class=cl><span class=n>chunk_overlap</span> <span class=o>=</span> <span class=mi>128</span>
</span></span><span class=line><span class=cl><span class=n>embedding_model_name</span> <span class=o>=</span> <span class=s2>&#34;BAAI/bge-small-en&#34;</span>
</span></span><span class=line><span class=cl><span class=n>num_docs</span> <span class=o>=</span> <span class=mi>3</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>COLLECTION_NAME</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;experiment_</span><span class=si>{</span><span class=n>chunk_size</span><span class=si>}</span><span class=s2>_</span><span class=si>{</span><span class=n>chunk_overlap</span><span class=si>}</span><span class=s2>_</span><span class=si>{</span><span class=n>embedding_model_name</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;/&#39;</span><span class=p>)[</span><span class=mi>1</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>add_documents</span><span class=p>(</span><span class=n>client</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>collection_name</span><span class=o>=</span><span class=n>COLLECTION_NAME</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>chunk_size</span><span class=o>=</span><span class=n>chunk_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>chunk_overlap</span><span class=o>=</span><span class=n>chunk_overlap</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>embedding_model_name</span><span class=o>=</span><span class=n>embedding_model_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>              
</span></span><span class=line><span class=cl><span class=c1>#Outputs</span>
</span></span><span class=line><span class=cl><span class=c1>#processed: 2152</span>
</span></span><span class=line><span class=cl><span class=c1>#content:   2152</span>
</span></span><span class=line><span class=cl><span class=c1>#metadata:  2152</span>
</span></span></code></pre></div><p>Followed by running evaluation :</p><p><img src=https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/experiment2_eval.png alt=experiment2_eval.png></p><p>and <strong>comparing it with the results from Experiment 1:</strong></p><p><img src=https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/graph_exp1_vs_exp2.png alt=graph_exp1_vs_exp2.png></p><p>We observed slight enhancements in our LLM completion metrics (including BERT Sentence Similarity, BERTScore, ROUGE-L, and Knowledge F1) with the increase in <em>chunk size</em>. However, it&rsquo;s noteworthy that there was a significant decrease in <em>Faithfulness</em>, which is the primary metric we are aiming to optimize.</p><p>Moreover, <em>Context Relevance</em> demonstrated an increase, indicating that the RAG pipeline retrieved more relevant information required to address the query. Nonetheless, there was a considerable drop in <em>Chunk Relevance</em>, implying that a smaller portion of the retrieved documents contained pertinent information for answering the question.</p><p><strong>The correlation between the rise in Context Relevance and the decline in Chunk Relevance suggests that retrieving more documents using the smaller chunk size might yield improved results.</strong></p><h3 id=experiment-3---increasing-the-number-of-documents-retrieved-retrieval-window>Experiment 3 - Increasing the number of documents retrieved (retrieval window)</h3><p>This time, we are using the same RAG setup as <code>Experiment 1</code>, but increasing the number of retrieved documents from <strong>3</strong> to <strong>5</strong>.</p><p>Parameters :</p><ul><li><strong>Embedding Model : <code>bge-small-en</code></strong></li><li><strong>Chunk size: <code>512</code></strong></li><li><strong>Chunk overlap: <code>64</code></strong></li><li><strong>Number of docs retrieved (Retrieval Window): <code>5</code></strong></li><li><strong>LLM: : <code>Mistral-7B-Instruct</code></strong></li></ul><p>We can use the collection from Experiment 1 and run evaluation with modified <code>num_docs</code> parameter as :</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1>#collection name from Experiment 1</span>
</span></span><span class=line><span class=cl><span class=n>COLLECTION_NAME</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;experiment_</span><span class=si>{</span><span class=n>chunk_size</span><span class=si>}</span><span class=s2>_</span><span class=si>{</span><span class=n>chunk_overlap</span><span class=si>}</span><span class=s2>_</span><span class=si>{</span><span class=n>embedding_model_name</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;/&#39;</span><span class=p>)[</span><span class=mi>1</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#running eval for experiment 3</span>
</span></span><span class=line><span class=cl><span class=n>experiment_3</span> <span class=o>=</span> <span class=n>run_eval</span><span class=p>(</span><span class=n>eval_df</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>collection_name</span><span class=o>=</span><span class=n>COLLECTION_NAME</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>recipe_id</span><span class=o>=</span><span class=n>recipe_mistral</span><span class=p>[</span><span class=s1>&#39;id&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                        <span class=n>num_docs</span><span class=o>=</span><span class=n>num_docs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>path</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>COLLECTION_NAME</span><span class=si>}</span><span class=s2>_</span><span class=si>{</span><span class=n>num_docs</span><span class=si>}</span><span class=s2>_mistral.csv&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>Observe the results as below :</p><p><img src=https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/experiment_3_eval.png alt=experiment_3_eval.png></p><p>Comparing the results with Experiment 1 and 2 :</p><p><img src=https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/graph_exp1_exp2_exp3.png alt=graph_exp1_exp2_exp3.png></p><p>As anticipated, employing the smaller chunk size while retrieving a larger number of documents resulted in achieving the highest levels of both <em>Context Relevance</em> and <em>Chunk Relevance.</em> Additionally, it yielded the <strong>best</strong> (albeit marginal) <em>Faithfulness</em> score, indicating a <em>reduced occurrence of inaccuracies or hallucinations</em>.</p><p>Looks like we have achieved a good hold on our chunking parameters but it is worth testing another embedding model to see if we can get better results.</p><h3 id=experiment-4---changing-the-embedding-model>Experiment 4 - Changing the embedding model</h3><p>Let us try using <strong>MiniLM</strong> for this experiment
****Parameters :</p><ul><li><strong>Embedding Model : <code>MiniLM-L6-v2</code></strong></li><li><strong>Chunk size: <code>512</code></strong></li><li><strong>Chunk overlap: <code>64</code></strong></li><li><strong>Number of docs retrieved (Retrieval Window): <code>5</code></strong></li><li><strong>LLM: : <code>Mistral-7B-Instruct</code></strong></li></ul><p>We will have to create another collection for this experiment :</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1>#experiment-4</span>
</span></span><span class=line><span class=cl><span class=n>chunk_size</span><span class=o>=</span><span class=mi>512</span>
</span></span><span class=line><span class=cl><span class=n>chunk_overlap</span><span class=o>=</span><span class=mi>64</span>
</span></span><span class=line><span class=cl><span class=n>embedding_model_name</span><span class=o>=</span><span class=s2>&#34;sentence-transformers/all-MiniLM-L6-v2&#34;</span>
</span></span><span class=line><span class=cl><span class=n>num_docs</span><span class=o>=</span><span class=mi>5</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>COLLECTION_NAME</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;experiment_</span><span class=si>{</span><span class=n>chunk_size</span><span class=si>}</span><span class=s2>_</span><span class=si>{</span><span class=n>chunk_overlap</span><span class=si>}</span><span class=s2>_</span><span class=si>{</span><span class=n>embedding_model_name</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;/&#39;</span><span class=p>)[</span><span class=mi>1</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>add_documents</span><span class=p>(</span><span class=n>client</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>collection_name</span><span class=o>=</span><span class=n>COLLECTION_NAME</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>chunk_size</span><span class=o>=</span><span class=n>chunk_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>chunk_overlap</span><span class=o>=</span><span class=n>chunk_overlap</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>embedding_model_name</span><span class=o>=</span><span class=n>embedding_model_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#Outputs</span>
</span></span><span class=line><span class=cl><span class=c1>#processed: 4504</span>
</span></span><span class=line><span class=cl><span class=c1>#content:   4504</span>
</span></span><span class=line><span class=cl><span class=c1>#metadata:  4504</span>
</span></span></code></pre></div><p>We will observe our evaluations as :</p><p><img src=https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/experiment4_eval.png alt=experiment4_eval.png></p><p>Comparing these with our previous experiments :</p><p><img src=https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/graph_exp1_exp2_exp3_exp4.png alt=graph_exp1_exp2_exp3_exp4.png></p><p>It appears that <code>bge-small</code> was more proficient in capturing the semantic nuances of the Qdrant Documentation.</p><p>Up to this point, our experimentation has focused solely on the <em>retrieval aspect</em> of our RAG pipeline. Now, let&rsquo;s explore altering the <em>generation aspect</em> or LLM while retaining the optimal parameters identified in Experiment 3.</p><h3 id=experiment-5---changing-the-llm>Experiment 5 - Changing the LLM</h3><p>Parameters :</p><ul><li><strong>Embedding Model : <code>bge-small-en</code></strong></li><li><strong>Chunk size: <code>512</code></strong></li><li><strong>Chunk overlap: <code>64</code></strong></li><li><strong>Number of docs retrieved (Retrieval Window): <code>5</code></strong></li><li><strong>LLM: : <code>GPT-3.5-turbo</code></strong></li></ul><p>For this we can repurpose our collection from Experiment 3 while the evaluations to use a new recipe with <strong>GPT-3.5-turbo</strong> model.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1>#collection name from Experiment 3</span>
</span></span><span class=line><span class=cl><span class=n>COLLECTION_NAME</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;experiment_</span><span class=si>{</span><span class=n>chunk_size</span><span class=si>}</span><span class=s2>_</span><span class=si>{</span><span class=n>chunk_overlap</span><span class=si>}</span><span class=s2>_</span><span class=si>{</span><span class=n>embedding_model_name</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;/&#39;</span><span class=p>)[</span><span class=mi>1</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># We have to create a recipe using the same prompt template and GPT-3.5-turbo</span>
</span></span><span class=line><span class=cl><span class=n>recipe_gpt</span> <span class=o>=</span> <span class=n>quotient</span><span class=o>.</span><span class=n>create_recipe</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model_id</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>prompt_template_id</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>name</span><span class=o>=</span><span class=s1>&#39;gpt3.5-qa-with-rag-recipe-v1&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>description</span><span class=o>=</span><span class=s1>&#39;GPT-3.5 using a prompt template that includes context.&#39;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>recipe_gpt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#Outputs</span>
</span></span><span class=line><span class=cl><span class=c1>#{&#39;id&#39;: 495,</span>
</span></span><span class=line><span class=cl><span class=c1># &#39;name&#39;: &#39;gpt3.5-qa-with-rag-recipe-v1&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1># &#39;description&#39;: &#39;GPT-3.5 using a prompt template that includes context.&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1># &#39;model_id&#39;: 5,</span>
</span></span><span class=line><span class=cl><span class=c1># &#39;prompt_template_id&#39;: 1,</span>
</span></span><span class=line><span class=cl><span class=c1># &#39;created_at&#39;: &#39;2024-05-03T12:14:58.779585&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1># &#39;owner_profile_id&#39;: 34,</span>
</span></span><span class=line><span class=cl><span class=c1># &#39;system_prompt_id&#39;: None,</span>
</span></span><span class=line><span class=cl><span class=c1># &#39;prompt_template&#39;: {&#39;id&#39;: 1,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;name&#39;: &#39;Default Question Answering Template&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;variables&#39;: &#39;[&#34;input_text&#34;,&#34;context&#34;]&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;created_at&#39;: &#39;2023-12-21T22:01:54.632367&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;template_string&#39;: &#39;Question: {input_text}\\n\\nContext: {context}\\n\\nAnswer:&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;owner_profile_id&#39;: None},</span>
</span></span><span class=line><span class=cl><span class=c1># &#39;model&#39;: {&#39;id&#39;: 5,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;name&#39;: &#39;gpt-3.5-turbo&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;endpoint&#39;: &#39;https://api.openai.com/v1/chat/completions&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;revision&#39;: &#39;placeholder&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;created_at&#39;: &#39;2024-02-06T17:01:21.408454&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;model_type&#39;: &#39;OpenAI&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;description&#39;: &#39;Returns a maximum of 4K output tokens.&#39;,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;owner_profile_id&#39;: None,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;external_model_config_id&#39;: None,</span>
</span></span><span class=line><span class=cl><span class=c1>#  &#39;instruction_template_cls&#39;: &#39;NoneType&#39;}}</span>
</span></span></code></pre></div><p>Running the evaluations as :</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>experiment_5</span> <span class=o>=</span> <span class=n>run_eval</span><span class=p>(</span><span class=n>eval_df</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>collection_name</span><span class=o>=</span><span class=n>COLLECTION_NAME</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>recipe_id</span><span class=o>=</span><span class=n>recipe_gpt</span><span class=p>[</span><span class=s1>&#39;id&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                        <span class=n>num_docs</span><span class=o>=</span><span class=n>num_docs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>path</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>COLLECTION_NAME</span><span class=si>}</span><span class=s2>_</span><span class=si>{</span><span class=n>num_docs</span><span class=si>}</span><span class=s2>_gpt.csv&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>We observe :</p><p><img src=https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/experiment5_eval.png alt=experiment5_eval.png></p><p>and comparing all the 5 experiments as below :</p><p><img src=https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/graph_exp1_exp2_exp3_exp4_exp5.png alt=graph_exp1_exp2_exp3_exp4_exp5.png></p><p><strong>GPT-3.5 surpassed Mistral-7B in all metrics</strong>! Notably, Experiment 5 exhibited the <strong>lowest occurrence of hallucination</strong>.</p><h2 id=conclusions>Conclusions</h2><p>Letâ€™s take a look at our results from all 5 experiments above</p><p><img src=https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/overall_eval_results.png alt=overall_eval_results.png></p><p>We still have a long way to go in improving the retrieval performance of RAG, as indicated by our generally poor results thus far. It might be beneficial to <strong>explore alternative embedding models</strong> or <strong>different retrieval strategies</strong> to address this issue.</p><p>The significant variations in <em>Context Relevance</em> suggest that <strong>certain questions may necessitate retrieving more documents than others</strong>. Therefore, investigating a <strong>dynamic retrieval strategy</strong> could be worthwhile.</p><p>Furthermore, there&rsquo;s ongoing <strong>exploration required on the generative aspect</strong> of RAG.
Modifying LLMs or prompts can substantially impact the overall quality of responses.</p><p>This iterative process demonstrates how, starting from scratch, continual evaluation and adjustments throughout experimentation can lead to the development of an enhanced RAG system.</p><h2 id=watch-this-workshop-on-youtube>Watch this workshop on YouTube</h2><blockquote><p>A workshop version of this article is <a href="https://www.youtube.com/watch?v=3MEMPZR1aZA" target=_blank rel="noopener nofollow">available on YouTube</a>. Follow along using our <a href=https://github.com/qdrant/qdrant-rag-eval/tree/master/workshop-rag-eval-qdrant-quotient target=_blank rel="noopener nofollow">GitHub notebook</a>.</p></blockquote><iframe width=560 height=315 src="https://www.youtube.com/embed/3MEMPZR1aZA?si=n38oTBMtH3LNCTzd" title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy=strict-origin-when-cross-origin allowfullscreen></iframe></article><section class="docs-feedback d-print-none"><h5 class=docs-feedback__title>Was this page useful?</h5><div class=docs-feedback__buttons><button class="button button_outlined button_sm docs-feedback__button" id=feedback__answer_yes>
<img src=https://qdrant.tech/icons/outline/thumb-up.svg alt="Thumb up icon">
Yes
</button>
<button class="button button_outlined button_sm docs-feedback__button" id=feedback__answer_no>
<img src=https://qdrant.tech/icons/outline/thumb-down.svg alt="Thumb down icon">
No</button></div></section><section class="docs-feedback__responses d-none"><p class="docs-feedback__response docs-feedback__response_yes" id=feedback__response_yes>Thank you for your feedback! ðŸ™</p><p class="docs-feedback__response docs-feedback__response_no" id=feedback__response_no>We are sorry to hear that. ðŸ˜” You can <a class=text-brand-p href=https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/rapid-rag-optimization-with-qdrant-and-quotient.md target=_blank>edit</a> this page on GitHub, or <a class=text-brand-p href=https://github.com/qdrant/landing_page/issues/new/choose target=_blank>create</a> a GitHub issue.</p></section><script>const buttonsSection=document.querySelector(".docs-feedback"),responsesSection=document.querySelector(".docs-feedback__responses"),yesButton=document.querySelector("#feedback__answer_yes"),noButton=document.querySelector("#feedback__answer_no"),yesResponse=document.querySelector("#feedback__response_yes"),noResponse=document.querySelector("#feedback__response_no"),toggleResponses=()=>{buttonsSection.classList.add("d-none"),responsesSection.classList.remove("d-none")};yesButton.addEventListener("click",()=>{yesResponse.classList.add("feedback__response_visible"),toggleResponses()}),noButton.addEventListener("click",()=>{noResponse.classList.add("feedback__response_visible"),toggleResponses()})</script></div><div class=table-of-contents><p class=table-of-contents__head>On this page:</p><nav id=TableOfContents><ul><li><a href=#relevant-tools-for-this-experiment>Relevant tools for this experiment</a></li><li><a href=#summary-of-key-findings>Summary of key findings</a></li><li><a href=#building-a-rag-pipeline>Building a RAG pipeline</a></li><li><a href=#evaluation-dataset>Evaluation dataset</a><ul><li><a href=#building-the-rag-pipeline>Building the RAG pipeline</a></li><li><a href=#setting-up-quotient>Setting up Quotient</a></li><li><a href=#evaluation-in-action>Evaluation in action</a></li></ul></li><li><a href=#experimentation>Experimentation</a><ul><li><a href=#experiment-1---baseline>Experiment 1 - Baseline</a></li><li><a href=#experiment-2---adjusting-the-chunk-parameter>Experiment 2 - Adjusting the chunk parameter</a></li><li><a href=#experiment-3---increasing-the-number-of-documents-retrieved-retrieval-window>Experiment 3 - Increasing the number of documents retrieved (retrieval window)</a></li><li><a href=#experiment-4---changing-the-embedding-model>Experiment 4 - Changing the embedding model</a></li><li><a href=#experiment-5---changing-the-llm>Experiment 5 - Changing the LLM</a></li></ul></li><li><a href=#conclusions>Conclusions</a></li><li><a href=#watch-this-workshop-on-youtube>Watch this workshop on YouTube</a></li></ul></nav><ul class=table-of-contents__external-links><li class=table-of-contents__link><a href=https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/rapid-rag-optimization-with-qdrant-and-quotient.md target=_blank><svg width="16" height="17" viewBox="0 0 16 17" fill="none"><g clip-path="url(#clip0_6269_955)"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 .700012c-4.4.0-8 3.599998-8 7.999998C0 12.2333 2.26667 15.2333 5.46667 16.3 5.86667 16.3667 6 16.1 6 15.9S6 15.2333 6 14.5667C3.8 15.0333 3.33333 13.5 3.33333 13.5 3 12.5667 2.46667 12.3 2.46667 12.3 1.66667 11.8333 2.46667 11.8333 2.46667 11.8333 3.26667 11.9 3.66667 12.6333 3.66667 12.6333 4.4 13.8333 5.53333 13.5 6 13.3 6.06667 12.7667 6.26667 12.4333 6.53333 12.2333 4.73333 12.0333 2.86667 11.3667 2.86667 8.30001c0-.86666.33333-1.6.8-2.13333.0-.26667-.33334-1.06667.13333-2.13333.0.0.66667-.200000000000001 2.2.8.66667-.2 1.33333-.26667 2-.26667S9.33333 4.63335 10 4.83335c1.5333-1.06667 2.2-.8 2.2-.8C12.6667 5.16668 12.3333 5.96668 12.2667 6.16668 12.8 6.70001 13.0667 7.43335 13.0667 8.30001c0 3.06669-1.8667 3.73329-3.6667 3.93329C9.66667 12.5 9.93333 12.9667 9.93333 13.7c0 1.0667.0 1.9333.0 2.2C9.93333 16.1 10.0667 16.3667 10.4667 16.3c3.2-1.0667 5.4666-4.0667 5.4666-7.59999C16 4.30001 12.4.700012 8 .700012z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_6269_955"><rect width="16" height="16" fill="#fff" transform="translate(0 0.5)"/></clipPath></defs></svg>
Edit on Github</a></li><li class=table-of-contents__link><a href=https://github.com/qdrant/landing_page/issues/new/choose target=_blank><svg width="16" height="17" viewBox="0 0 16 17" fill="none"><g clip-path="url(#clip0_6269_1540)"><path d="M16 9.83331V8.49998H13.9347C13.79 7.33465 13.3947 6.24065 12.8 5.31065l1.476-1.478L13.3327 2.89065 11.9633 4.26198c-.24-.248-.496600000000001-.474-.772-.676C11.0967 3.25665 10.9507 2.95398 10.7673 2.67598l1.038-1.038L10.8627.695312 9.82867 1.72931C9.29867 1.37798 8.672 1.16665 8 1.16665c-.672.0-1.29867.21133-1.828.56266L5.138.695312l-.94267.942668 1.038 1.038c-.18333.27733-.32933.58-.424.90867-.27533.202-.532.42933-.77266.67733L2.66733 2.89065l-.94333.942L3.2 5.30998c-.59467.93-.99 2.02467-1.13467 3.19H0V9.83331H2.01467C2.07333 11.276 2.50533 12.6026 3.204 13.688l-1.48 1.478L2.666 16.1093l1.37-1.368C4.93733 15.67 6.07667 16.288 7.33333 16.452V6.49998H8.66667V16.452C9.92333 16.2873 11.0627 15.67 11.964 14.7413l1.37 1.368L14.276 15.166l-1.48-1.478C13.4947 12.602 13.9267 11.2753 13.9853 9.83331H16z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_6269_1540"><rect width="16" height="16" fill="#fff" transform="translate(0 0.5)"/></clipPath></defs></svg>
Create an issue</a></li></ul></div><footer class="docs-footer w-100 py-0 pt-0 pb-4 pb-xl-0"><div class=docs-footer__cta><h4>Ready to get started with Qdrant?</h4><a href=https://qdrant.to/cloud/ class="button button_outlined button_sm" target=_blank>Start Free</a></div><div class=docs-footer__bottom><div class=docs-footer__bottom-content><span>Â© 2025 Qdrant.</span><div class=footer__bottom-links><a href=https://qdrant.tech/legal/terms_and_conditions/>Terms</a>
<a href=https://qdrant.tech/legal/privacy-policy/>Privacy Policy</a>
<a href=https://qdrant.tech/legal/impressum/>Impressum</a></div></div></div></footer></div></div></div></div></section></main></body><script src=https://cdn.cookielaw.org/scripttemplates/otSDKStub.js type=text/javascript data-domain-script=01960152-5e40-782d-af01-f7f5768a214e></script><script async type=text/javascript>function OptanonWrapper(){const e=new CustomEvent("onetrust_loaded");document.dispatchEvent(e)}</script><script>!function(){const o="eQYi1nZE2zQSmnHuxjMRlDd2uLl65oHe";var n,s,t="analytics",e=window[t]=window[t]||[];if(!e.initialize)if(e.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{e.invoked=!0,e.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","debug","page","screen","once","off","on","addSourceMiddleware","addIntegrationMiddleware","setAnonymousId","addDestinationMiddleware","register"],e.factory=function(n){return function(){if(window[t].initialized)return window[t][n].apply(window[t],arguments);var o,s=Array.prototype.slice.call(arguments);return["track","screen","alias","group","page","identify"].indexOf(n)>-1&&(o=document.querySelector("link[rel='canonical']"),s.push({__t:"bpc",c:o&&o.getAttribute("href")||void 0,p:location.pathname,u:location.href,s:location.search,t:document.title,r:document.referrer})),s.unshift(n),e.push(s),e}};for(n=0;n<e.methods.length;n++)s=e.methods[n],e[s]=e.factory(s);e.load=function(n,s){var i,o=document.createElement("script");o.type="text/javascript",o.async=!0,o.setAttribute("data-global-segment-analytics-key",t),o.src="https://evs.analytics.qdrant.tech/5caWuitPgcGFN5Q7HMpTaj/vEkmzjuRSqeXGbhGAFTWex.min.js",i=document.getElementsByTagName("script")[0],i.parentNode.insertBefore(o,i),e._loadOptions=s},e._writeKey=o,e._cdn="https://evs.analytics.qdrant.tech",e.SNIPPET_VERSION="5.2.0",e.load(o)}}()</script><script src=https://qdrant.tech/js/google-setup.min.14728a3ae9bd931593645b6ddbfe801d400cd2970006e782cb67f3966654248ca962dbaf4cf371493a2d326861b3a691a99d6d8349c8b2752339ab91d3787069.js></script><script src=https://qdrant.tech/js/index.min.e37feda1952d752f5568e1ebc55e183629e4d361f4df09edeed70b4a4327d601161c4147bdbe4149b4a3cdc1ed43f1bf1a2f2340a421f1aa821103980dfe0bda.js></script><script src=https://qdrant.tech/js/search/search.min.e58e7ea98cb549ea9d3ed7e68876abe323cfb323432038820f38a71c40e309deed0fba615e2d3346825229a81e0a76bbadf6f8a816ddad3438abdabfef4ebc09.js type=module></script><script src=https://qdrant.tech/js/search/scroll.min.f4ed4453a3af0adb0d4f49333cbb7892ff5430483a567d0d2dfbd4655fb203d22f22f46aff3d9f38fa5fd96dde5f30227afd0ce1d9f838f5cd5295fc83856ec9.js></script><script src=https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js></script><script src=https://qdrant.tech/js/copy-code.min.95b03a45b2ab4b7a608ecfd4b5919c8572a5b2cd1463f52561cd10976abf3b74334f91324c0e620cb80afac46026a0b18cce6fb753d8495f74c6d478c8ca1d03.js></script><script src=https://qdrant.tech/js/lang-switcher.min.63da11cef09772078425b1ee56415b9c37842a9399f2ba2d2f5efbf72fb751686c410bd50e9bcd283c8231cb97c1973199d4923beef29d8b06e59d9983a6ba51.js></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src=https://qdrant.tech/js/vendor/anchor.min.0e138e17ebcf1c1147a7a3a81d9ac3c601622eedc479f1636470eb2552470f4e27c9a8efe6e8378995dedc1ab67029d8989536ea76f0857d45d1615ae772b8a1.js></script><script>document.addEventListener("keydown",function(e){if((e.metaKey||e.ctrlKey)&&e.key==="k"){e.preventDefault();let t=document.querySelector('[data-target="#searchModal"]');t&&t?.click()}})</script><script>window.addEventListener("message",e=>{if(e.data.type==="hsFormCallback"&&e.data.eventName==="onFormReady"){const t=document.querySelector(`form[data-form-id="${e.data.id}"]`);if(t){const e=t.querySelector('[name="last_form_fill_url"]');e&&(e.value=window.location.href);const n=t.querySelector('[name="referrer_url"]');n&&(n.value=document.referrer)}}})</script></html>