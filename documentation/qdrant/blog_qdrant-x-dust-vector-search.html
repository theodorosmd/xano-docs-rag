<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta charset=UTF-8><title>Unlocking AI Potential: Insights from Stanislas Polu - Qdrant</title>
<link rel=icon href=https://qdrant.tech/favicon/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=https://qdrant.tech/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://qdrant.tech/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://qdrant.tech/favicon/favicon-16x16.png><link rel=manifest href=https://qdrant.tech/favicon/site.webmanifest><link rel=mask-icon href=https://qdrant.tech/favicon/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#2b5797"><meta name=msapplication-config content="/favicon/browserconfig.xml"><meta name=theme-color content="#ffffff"><link href=https://qdrant.tech/css/search/search.min.09596ee2b3c94d0ac82a1c33199cabdb3e0210b1ee46aaf1515200e9e484d05dd9e27cc1e861c58cc2e582af162f63b8e180ff2a12f7a6592b7aeaa0a7125130.css rel=stylesheet integrity="sha512-CVlu4rPJTQrIKhwzGZyr2z4CELHuRqrxUVIA6eSE0F3Z4nzB6GHFjMLlgq8WL2O44YD/KhL3plkreuqgpxJRMA=="><link href=https://qdrant.tech/css/main.min.c1e379ad4cf03647832f6a0f040754b0be3e79934db2c29f50b396327c1ec7ac45f778abadbd93f5a8bc431850d1b0d9c9eff34c0171cd4236e83c5e324c1a0e.css rel=stylesheet integrity crossorigin=anonymous><meta name=generator content="Hugo 0.141.0"><meta name=description content="Explore the dynamic discussion with Stanislas Polu on AI, ML, entrepreneurship, and product development. Gain valuable insights into AI's transformative power."><meta name=keywords content="vector search engine,neural network,matching,SaaS,approximate nearest neighbor search,image search,recommender system,vectors,knn algorithm,hnsw,vector search,embeddings,similarity,simaes networks,BERT,transformer,word2vec,fasttext,qdrant"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@id":"https://qdrant.tech/blog/qdrant-x-dust-vector-search/#article","@type":"Article","abstract":"Explore the dynamic discussion with Stanislas Polu on AI ML entrepreneurship and product development Gain valuable insights into AIs transformative power","author":{"@type":"Person","name":"Demetrios Brinkmann"},"dateModified":"2024-01-26 16:22:37.487 +0000 UTC","datePublished":"2024-01-26 16:22:37.487 +0000 UTC","description":"Explore the dynamic discussion with Stanislas Polu on AI ML entrepreneurship and product development Gain valuable insights into AIs transformative power","headline":"Unlocking AI Potential: Insights from Stanislas Polu","image":[""],"name":"Unlocking AI Potential: Insights from Stanislas Polu","url":"https://qdrant.tech/blog/qdrant-x-dust-vector-search/","wordCount":"6000"},{"@id":"https://qdrant.tech/blog/qdrant-x-dust-vector-search/#organization","@type":"Organization","address":{"@type":"PostalAddress","addressCountry":"DE","addressLocality":"Berlin","addressRegion":"Berlin","postalCode":"10115","streetAddress":"Chausseestra√üe 86"},"contactPoint":{"@type":"ContactPoint","contactType":"customer support","email":"info@qdrant.com","telephone":"+49 3040797694"},"description":"Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.","email":"info@qdrant.com","founders":[{"@type":"Person","name":"map[email:info@qdrant.tech name:Andrey Vasnetsov]"},{"@type":"Person","name":"Andre Zayarni"}],"foundingDate":"2021","keywords":["vector search engine","neural network","matching","SaaS","approximate nearest neighbor search","image search","recommender system","vectors","knn algorithm","hnsw","vector search","embeddings","similarity","simaes networks","BERT","transformer","word2vec","fasttext","Qdrant"],"legalName":"Qdrant Solutions GmbH","location":"Berlin, Germany","logo":"https://qdrant.tech/images/logo_with_text.png","name":"Qdrant","sameAs":["https://github.com/qdrant/qdrant","https://qdrant.to/discord","https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA","https://www.linkedin.com/company/qdrant/","https://twitter.com/qdrant_engine"],"url":"https://qdrant.tech"}]}</script><meta property="og:url" content="https://qdrant.tech/blog/qdrant-x-dust-vector-search/"><meta property="og:type" content="website"><meta property="og:title" content="Unlocking AI Potential: Insights from Stanislas Polu - Qdrant"><meta name=twitter:card content="summary_large_image"><meta name=twitter:domain content="qdrant"><meta name=twitter:url content="https://qdrant.tech/blog/qdrant-x-dust-vector-search/"><meta name=twitter:title content="Unlocking AI Potential: Insights from Stanislas Polu - Qdrant"><meta property="og:description" content="Explore the dynamic discussion with Stanislas Polu on AI, ML, entrepreneurship, and product development. Gain valuable insights into AI's transformative power."><meta name=twitter:description content="Explore the dynamic discussion with Stanislas Polu on AI, ML, entrepreneurship, and product development. Gain valuable insights into AI's transformative power."><meta name=image property="og:image" content="https://qdrant.tech/blog/qdrant-x-dust-vector-search/preview/social_preview.jpg"><meta name=image property="og:image:secure_url" content="https://qdrant.tech/blog/qdrant-x-dust-vector-search/preview/social_preview.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name=twitter:image:src content="https://qdrant.tech/blog/qdrant-x-dust-vector-search/preview/social_preview.jpg"><meta name=author content="Demetrios Brinkmann"><link rel=canonical href=https://qdrant.tech/blog/qdrant-x-dust-vector-search/><script type=text/javascript src=//js-eu1.hsforms.net/forms/embed/v2.js></script></head><body><main><header class=site-header><section class=top-banner data-start=1749013200 data-end=1750428000 style=display:none><div><span class=top-banner__icon><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><g clip-path="url(#clip0_770_2716)"><path d="M14.598 6.37199C14.486 6.14399 14.254 5.99999 14 5.99999H8.7447L9.3287.739993C9.36204.44266 9.1927.159993 8.91537.0479934 8.63737-.0653399 8.31937.0226601 8.13737.259327L1.4707 8.92599C1.31604 9.12733 1.2887 9.39933 1.40137 9.62733c.11267.22866.34467.37266.59867.37266H7.25537L6.67137 15.26c-.0333299999999994.2973.136.58.41333.692C7.16537 15.9847 7.25004 16 7.33337 16 7.53604 16 7.73337 15.9073 7.86204 15.74L14.5287 7.07333C14.6834 6.87199 14.71 6.59999 14.598 6.37199z" fill="#8547ff"/></g><defs><clipPath id="clip0_770_2716"><rect width="16" height="16" fill="#fff"/></clipPath></defs></svg> </span><span class=top-banner__text>Learn how TripAdvisor Drives 2-3x More Revenue with Qdrant-Powered AI at Enterprise Scale </span><a data-metric-loc=banner data-metric-label="Learn how TripAdvisor Drives 2-3x More Revenue with Qdrant-Powered AI at Enterprise Scale Read now" class="link link_light link_sm" href=https://qdrant.tech/blog/case-study-tripadvisor/>Read now</a></div></section><div class="main-menu z-2"><a href=https://qdrant.tech/><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div></a><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><button type=button class=main-menu__trigger><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M1 12H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 5H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 19H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=main-menu__links><li class=main-menu__item><span>Products</span><ul class=main-menu__submenu><li class=main-menu__submenu-item><a href=https://qdrant.tech/qdrant-vector-database/><img src=https://qdrant.tech/img/menu/qdrant-vector-database.svg draggable=false>
<span>Qdrant Vector Database</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/cloud/><img src=https://qdrant.tech/img/menu/qdrant-cloud.svg draggable=false>
<span>Qdrant Cloud</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/hybrid-cloud/><img src=https://qdrant.tech/img/menu/hybrid-cloud.svg draggable=false>
<span>Qdrant Hybrid Cloud</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/enterprise-solutions/><img src=https://qdrant.tech/img/menu/qdrant-enterprise-solutions.svg draggable=false>
<span>Qdrant Enterprise Solutions</span></a></li></ul></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/use-cases/>Use Cases</a><ul class=main-menu__submenu><li class=main-menu__section-link><a class="link link_neutral link_sm" href=https://qdrant.tech/use-cases/>Use Cases</a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/rag/><img src=https://qdrant.tech/img/menu/rag.svg draggable=false>
<span>RAG</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/recommendations/><img src=https://qdrant.tech/img/menu/recommendation-systems.svg draggable=false>
<span>Recommendation Systems</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/advanced-search/><img src=https://qdrant.tech/img/menu/advanced-search.svg draggable=false>
<span>Advanced Search</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/data-analysis-anomaly-detection/><img src=https://qdrant.tech/img/menu/data-analysis-anomaly-detection.svg draggable=false>
<span>Data Analysis & Anomaly Detection</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/ai-agents/><img src=https://qdrant.tech/img/menu/ai-agents.svg draggable=false>
<span>AI Agents</span></a></li></ul></li><li class=main-menu__item><span>Developers</span><ul class=main-menu__submenu><li class=main-menu__submenu-item><a href=https://qdrant.tech/documentation/><img src=https://qdrant.tech/img/menu/documentation.svg draggable=false>
<span>Documentation</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/community/><img src=https://qdrant.tech/img/menu/community.svg draggable=false>
<span>Community</span></a></li><li class=main-menu__submenu-item><a href=https://github.com/qdrant/qdrant target=_blank rel="noopener noreferrer nofollow"><img src=https://qdrant.tech/img/menu/github.svg draggable=false>
<span>GitHub</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.to/roadmap target=_blank rel="noopener noreferrer nofollow"><img src=https://qdrant.tech/img/menu/roadmap.svg draggable=false>
<span>Roadmap</span></a></li><li class=main-menu__submenu-item><a href=https://github.com/qdrant/qdrant/releases target=_blank rel="noopener noreferrer nofollow"><img src=https://qdrant.tech/img/menu/changelog.svg draggable=false>
<span>Change Log</span></a></li></ul></li><li class=main-menu__item><span>Resources</span><ul class=main-menu__submenu><li class=main-menu__submenu-item><a href=https://qdrant.tech/benchmarks/><img src=https://qdrant.tech/img/menu/benchmarks.svg draggable=false>
<span>Benchmarks</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/blog/><img src=https://qdrant.tech/img/menu/blog.svg draggable=false>
<span>Blog</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/articles/><img src=https://qdrant.tech/img/menu/articles.svg draggable=false>
<span>Articles</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/demo/><img src=https://qdrant.tech/img/menu/demos.svg draggable=false>
<span>Demos</span></a></li><li class=main-menu__submenu-item><a href=https://try.qdrant.tech/events target=_blank rel="noopener noreferrer nofollow"><img src=https://qdrant.tech/img/menu/partners.svg draggable=false>
<span>Events</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/qdrant-for-startups/><img src=https://qdrant.tech/img/menu/qdrant-for-startups.svg draggable=false>
<span>Startup Program</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/security/bug-bounty-program/><img src=https://qdrant.tech/img/menu/bug-bounty-program.svg draggable=false>
<span>Bug Bounty Program</span></a></li></ul></li><li class=main-menu__item><span>Company</span><ul class=main-menu__submenu><li class=main-menu__submenu-item><a href=https://qdrant.tech/about-us/><img src=https://qdrant.tech/img/menu/about-us.svg draggable=false>
<span>About us</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/customers/><img src=https://qdrant.tech/img/menu/customers.svg draggable=false>
<span>Customers</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/partners/><img src=https://qdrant.tech/img/menu/partners.svg draggable=false>
<span>Partners</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.join.com/ target=_blank rel="noopener noreferrer nofollow"><img src=https://qdrant.tech/img/menu/careers.svg draggable=false>
<span>Careers</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/contact-us/><img src=https://qdrant.tech/img/menu/contact-us.svg draggable=false>
<span>Contact us</span></a></li></ul></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/pricing/>Pricing</a></li></ul><div class=main-menu__buttons><a data-metric-loc=nav href=https://cloud.qdrant.io/login class="menu-link mx-3">Log in</a>
<a data-metric-loc=nav href=https://cloud.qdrant.io/signup class="button button_contained button_sm">Get Started</a></div></div><div class=menu-mobile><div class=menu-mobile__header><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div><button type=button class=menu-mobile__close><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M19.0713 4.92871 4.92915 19.0708" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M19.0713 19.0708 4.9292 4.92871" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__items><li class=menu-mobile__item data-path=menu-0><div class=menu-mobile__item-content>Products
<button type=button class=menu-mobile__expand><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M2 7 12 17 22 7" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__subitems><a href=https://qdrant.tech/qdrant-vector-database/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/qdrant-vector-database.svg)></span>Qdrant Vector Database</li></a><a href=https://qdrant.tech/cloud/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/qdrant-cloud.svg)></span>Qdrant Cloud</li></a><a href=https://qdrant.tech/hybrid-cloud/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/hybrid-cloud.svg)></span>Qdrant Hybrid Cloud</li></a><a href=https://qdrant.tech/enterprise-solutions/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/qdrant-enterprise-solutions.svg)></span>Qdrant Enterprise Solutions</li></a></ul></li><li class=menu-mobile__item data-path=menu-1><div class=menu-mobile__item-content>Use Cases
<button type=button class=menu-mobile__expand><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M2 7 12 17 22 7" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__subitems><li class=menu-mobile__section-link><a class="link link_neutral link_sm" href=https://qdrant.tech/use-cases/>Use Cases</a></li><a href=https://qdrant.tech/rag/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/rag.svg)></span>RAG</li></a><a href=https://qdrant.tech/recommendations/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/recommendation-systems.svg)></span>Recommendation Systems</li></a><a href=https://qdrant.tech/advanced-search/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/advanced-search.svg)></span>Advanced Search</li></a><a href=https://qdrant.tech/data-analysis-anomaly-detection/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/data-analysis-anomaly-detection.svg)></span>Data Analysis & Anomaly Detection</li></a><a href=https://qdrant.tech/ai-agents/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/ai-agents.svg)></span>AI Agents</li></a></ul></li><li class=menu-mobile__item data-path=menu-2><div class=menu-mobile__item-content>Developers
<button type=button class=menu-mobile__expand><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M2 7 12 17 22 7" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__subitems><a href=https://qdrant.tech/documentation/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/documentation.svg)></span>Documentation</li></a><a href=https://qdrant.tech/community/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/community.svg)></span>Community</li></a><a href=https://github.com/qdrant/qdrant><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/github.svg)></span>GitHub</li></a><a href=https://qdrant.to/roadmap><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/roadmap.svg)></span>Roadmap</li></a><a href=https://github.com/qdrant/qdrant/releases><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/changelog.svg)></span>Change Log</li></a></ul></li><li class=menu-mobile__item data-path=menu-3><div class=menu-mobile__item-content>Resources
<button type=button class=menu-mobile__expand><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M2 7 12 17 22 7" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__subitems><a href=https://qdrant.tech/benchmarks/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/benchmarks.svg)></span>Benchmarks</li></a><a href=https://qdrant.tech/blog/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/blog.svg)></span>Blog</li></a><a href=https://qdrant.tech/articles/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/articles.svg)></span>Articles</li></a><a href=https://qdrant.tech/demo/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/demos.svg)></span>Demos</li></a><a href=https://try.qdrant.tech/events><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/partners.svg)></span>Events</li></a><a href=https://qdrant.tech/qdrant-for-startups/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/qdrant-for-startups.svg)></span>Startup Program</li></a><a href=https://qdrant.tech/security/bug-bounty-program/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/bug-bounty-program.svg)></span>Bug Bounty Program</li></a></ul></li><li class=menu-mobile__item data-path=menu-4><div class=menu-mobile__item-content>Company
<button type=button class=menu-mobile__expand><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M2 7 12 17 22 7" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__subitems><a href=https://qdrant.tech/about-us/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/about-us.svg)></span>About us</li></a><a href=https://qdrant.tech/customers/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/customers.svg)></span>Customers</li></a><a href=https://qdrant.tech/partners/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/partners.svg)></span>Partners</li></a><a href=https://qdrant.join.com/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/careers.svg)></span>Careers</li></a><a href=https://qdrant.tech/contact-us/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/contact-us.svg)></span>Contact us</li></a></ul></li><li class=menu-mobile__item data-path=menu-5><div class=menu-mobile__item-content><a href=https://qdrant.tech/pricing/>Pricing</a></div></li></ul><div class=menu-mobile__controls><a data-metric-loc=mobile_nav href=https://cloud.qdrant.io/login class="button button_outlined button_lg menu-mobile__login">Log in</a>
<a data-metric-loc=mobile_nav href=https://cloud.qdrant.io/signup class="button button_contained button_lg">Get Started</a></div></div></header><progress id=progress class=progress-bar value=0 max=100>0</progress><section class="qdrant-post
qdrant-blog-post"><article id=article class=container><div class=qdrant-post__header><h1 class=qdrant-post__title>Unlocking AI Potential: Insights from Stanislas Polu</h1><div class=qdrant-post__about><p>Demetrios Brinkmann</p><span>&#183;</span><p>January 26, 2024</p></div><picture class=qdrant-post__preview><img src=https://qdrant.tech/blog/qdrant-x-dust-vector-search/preview/title.jpg alt="Unlocking AI Potential: Insights from Stanislas Polu" loading=lazy></picture></div><div class="row qdrant-post__breadcrumbs"><div class=col-12><ul class=breadcrumbs><li class=breadcrumbs__crumb><a href=https://qdrant.tech/>Home</a></li><li class=breadcrumbs__crumb>/</li><li class=breadcrumbs__crumb><a href=https://qdrant.tech/blog/>Blog</a></li><li class=breadcrumbs__crumb>/</li><li class=breadcrumbs__crumb>Unlocking AI Potential: Insights from Stanislas Polu</li></ul></div></div><div class=qdrant-post__body><div class=table-of-contents><p class=table-of-contents__head>On this page:</p><nav id=TableOfContents><ul><li><a href=#qdrant-x-dust-how-vector-search-helps-make-work-better-with-stanislas-polu>Qdrant x Dust: How Vector Search Helps Make Work Better with Stanislas Polu</a><ul><li><a href=#top-takeaways><strong>Top takeaways:</strong></a></li><li><a href=#show-notes>Show notes:</a></li><li><a href=#more-quotes-from-stan>More Quotes from Stan:</a></li><li><a href=#transcript>Transcript:</a></li></ul></li></ul></nav><ul class=table-of-contents__external-links><li class=table-of-contents__link><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fqdrant.tech%2Fblog%2Fqdrant-x-dust-vector-search%2F&amp;text=Unlocking%20AI%20Potential:%20Insights%20from%20Stanislas%20Polu" target=_blank rel="noopener noreferrer" title=x><svg width="33" height="33" viewBox="0 0 33 33" fill="none"><path d="M14.959 20.7369l-8.581 9.798H1.625l11.114-12.696 2.22 2.898z" fill="#161e33"/><path d="M17.5508 11.5229l7.857-8.98799h4.75L19.7508 14.4369l-2.2-2.914z" fill="#161e33"/><path d="M31.9877 30.5349h-9.559L1.01172 2.53491H10.8127L31.9877 30.5349zm-8.248-2.843h2.632L9.38272 5.22891h-2.824L23.7397 27.6919z" fill="#161e33"/></svg>
Share on X</a></li><li class=table-of-contents__link><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fqdrant.tech%2Fblog%2Fqdrant-x-dust-vector-search%2F" target=_blank rel="noopener noreferrer" title=LinkedIn><svg width="32" height="33" viewBox="0 0 32 33" fill="none"><g clip-path="url(#clip0_1811_16094)"><path d="M30.6667.4375H1.33333C.533333.4375.0.970833.0 1.77083V31.1042C0 31.9042.533333 32.4375 1.33333 32.4375H30.6667C31.4667 32.4375 32 31.9042 32 31.1042V1.77083C32 .970833 31.4667.4375 30.6667.4375zM9.46667 27.7708H4.8V12.4375H9.6V27.7708H9.46667zm-2.4-17.4666c-1.46667.0-2.8-1.20003-2.8-2.80003.0-1.46667 1.2-2.8 2.8-2.8 1.46666.0 2.8 1.2 2.8 2.8s-1.2 2.80003-2.8 2.80003zM27.3333 27.7708h-4.8V20.3042c0-1.7334.0-4-2.4-4-2.5333.0-2.8 1.8666-2.8 3.8666v7.6h-4.8V12.4375h4.5334v2.1333C17.7333 13.3708 19.2 12.1708 21.6 12.1708c4.8.0 5.7333 3.2 5.7333 7.3334v8.2666z" fill="#161e33"/></g><defs><clipPath id="clip0_1811_16094"><rect width="32" height="32" fill="#fff" transform="translate(0 0.4375)"/></clipPath></defs></svg>
Share on LinkedIn</a></li></ul></div><div class=qdrant-post__content><h1 id=qdrant-x-dust-how-vector-search-helps-make-work-better-with-stanislas-polu>Qdrant x Dust: How Vector Search Helps Make Work Better with Stanislas Polu</h1><blockquote><p><em>&ldquo;We ultimately chose Qdrant due to its open-source nature, strong performance, being written in Rust, comprehensive documentation, and the feeling of control.‚Äù</em><br>&ndash; Stanislas Polu</p></blockquote><p>Stanislas Polu is the Co-Founder and an Engineer at Dust. He had previously sold a company to Stripe and spent 5 years there, seeing them grow from 80 to 3000 people. Then pivoted to research at OpenAI on large language models and mathematical reasoning capabilities. He started Dust 6 months ago to make work work better with LLMs.</p><p><em><strong>Listen to the episode on¬†<a href="https://open.spotify.com/episode/2YgcSFjP7mKE0YpDGmSiq5?si=6BhlAMveSty4Yt7umPeHjA" target=_blank rel="noopener nofollow">Spotify</a>, Apple Podcast, Podcast addicts, Castbox. You can¬†also watch this episode on <a href=https://youtu.be/1vKoiFAdorE target=_blank rel="noopener nofollow">YouTube</a>.</strong></em></p><iframe width=560 height=315 src="https://www.youtube.com/embed/toIgkJuysQ4?si=uzlzQtOiSL5Kcpk5" title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
<iframe src=https://podcasters.spotify.com/pod/show/qdrant-vector-space-talk/embed/episodes/Qdrant-x-Dust-How-Vector-Search-Helps-Make-Work-Work-Better---Stan-Polu--Vector-Space-Talk-010-e2ep9u8/a-aasgqb8 height=102px width=400px frameborder=0 scrolling=no></iframe><h2 id=top-takeaways><strong>Top takeaways:</strong></h2><p>Curious about the interplay of SaaS platforms and AI in improving productivity? Stanislas Polu dives into the intricacies of enterprise data management, the selective use of SaaS tools, and the role of customized AI assistants in streamlining workflows, all while sharing insights from his experiences at Stripe, OpenAI, and his latest venture, Dust.</p><p>Here are 5 golden nuggets you&rsquo;ll unearth from tuning in:</p><ol><li><strong>The SaaS Universe</strong>: Stan will give you the lowdown on why jumping between different SaaS galaxies like Salesforce and Slack is crucial for your business data&rsquo;s gravitational pull.</li><li><strong>API Expansions</strong>: Learn how pushing the boundaries of APIs to include global payment methods can alter the orbit of your company&rsquo;s growth.</li><li><strong>A Bot for Every Star</strong>: Discover how creating targeted assistants over general ones can skyrocket team productivity across various use cases.</li><li><strong>Behind the Tech Telescope</strong>: Stan discusses the decision-making behind opting for Qdrant for their database cosmos, including what triggered their switch.</li><li><strong>Integrating AI Stardust</strong>: They&rsquo;re not just talking about Gen AI; they&rsquo;re actively guiding companies on how to leverage it effectively, placing practicality over flashiness.</li></ol><blockquote><p>Fun Fact: Stanislas Polu co-founded a company that was acquired by Stripe, providing him with the opportunity to work with Greg Brockman at Stripe.</p></blockquote><h2 id=show-notes>Show notes:</h2><p>00:00 Interview about an exciting career in AI technology.<br>06:20 Most workflows involve multiple SaaS applications.<br>09:16 Inquiring about history with Stripe and AI.<br>10:32 Stripe works on expanding worldwide payment methods.<br>14:10 Document insertion supports hierarchy for user experience.<br>18:29 Competing, yet friends in the same field.<br>21:45 Workspace solutions, marketplace, templates, and user feedback.<br>25:24 Avoid giving false hope; be accountable.<br>26:06 Model calls, external API calls, structured data.<br>30:19 Complex knobs, but powerful once understood. Excellent support.<br>33:01 Companies hire someone to support teams and find use cases.</p><h2 id=more-quotes-from-stan>More Quotes from Stan:</h2><p><em>&ldquo;You really want to narrow the data exactly where that information lies. And that&rsquo;s where we&rsquo;re really relying hard on Qdrant as well. So the kind of indexing capabilities on top of the vector search.&rdquo;</em><br>&ndash; Stanislas Polu</p><p><em>&ldquo;I think the benchmarking was really about quality of models, answers in the context of ritual augmented generation. So it&rsquo;s not as much as performance, but obviously, performance matters and that&rsquo;s why we love using Qdrant.‚Äù</em><br>&ndash; Stanislas Polu</p><p><em>&ldquo;The workspace assistant are like the admin vetted the assistant, and it&rsquo;s kind of pushed to everyone by default.‚Äù</em><br>&ndash; Stanislas Polu</p><h2 id=transcript>Transcript:</h2><p>Demetrios:
All right, so, my man, I think people are going to want to know all about you. This is a conversation that we have had planned for a while. I&rsquo;m excited to chat about what you have been up to. You&rsquo;ve had quite the run around when it comes to doing some really cool stuff. You spent a lot of time at Stripe in the early days and I imagine you were doing, doing lots of fun ML initiatives and then you started researching on llms at OpenAI. And recently you are doing the entrepreneurial thing and following the trend of starting a company and getting really cool stuff out the door with AI. I think we should just start with background on yourself. What did I miss in that quick introduction?</p><p>Stanislas Polu:
Okay, sounds good. Yeah, perfect. Now you didn&rsquo;t miss too much. Maybe the only point is that starting the current company, Dust, with Gabrielle, my co founder, with whom we started a Company together twelve years or maybe 14 years ago.</p><p>Stanislas Polu:
I&rsquo;m very bad with years that eventually got acquired to stripe. So that&rsquo;s how we joined Stripe, the both of us, pretty early. Stripe was 80 people when we joined, all the way to 2500 people and got to meet with and walk with Greg Brockman there. And that&rsquo;s how I found my way to OpenAI after stripe when I started interested in myself, in research at OpenAI, even if I&rsquo;m not a trained researcher.</p><p>Stanislas Polu:
I did research on fate, doing research.
On larger good models, reasoning capabilities, and in particular larger models mathematical reasoning capabilities.
And from there.
18 months ago, kind of decided to leave OpenAI with the motivation. That is pretty simple.
It&rsquo;s that basically the hypothesis is that.
It was pre chattivity, but basically those large language models, they&rsquo;re already extremely capable and yet they are completely under deployed compared to the potential they have. And so while research remains a very active subject and it&rsquo;s going to be.
A tailwind for the whole ecosystem, there&rsquo;s.</p><p>Stanislas Polu:
Probably a lot of to be done at the product layer, and most of the locks between us and deploying that technology in the world is probably sitting.
At the product layer as it is sitting at the research layer.
And so that&rsquo;s kind of the hypothesis behind dust, is we try to explore at the product layer what it means to interface between models and humans, try to make them happier and augment them.
With superpowers in their daily jobs.</p><p>Demetrios:
So you say product layer, can you go into what you mean by that a little bit more?</p><p>Stanislas Polu:
Well, basically we have a motto at dust, which is no gpu before PMF. And so the idea is that while it&rsquo;s extremely exciting to train models. It&rsquo;s extremely exciting to fine tune and align models. There is a ton to be done.
Above the model, not only to use.
Them as best as possible, but also to really find the interaction interfaces that make sense for humans to leverage that technology. And so we basically don&rsquo;t train any models ourselves today.
There&rsquo;s many reasons to that.
The first one is as an early startup. It&rsquo;s a fascinating subject and fascinating exercise. As an early startup, it&rsquo;s actually a very big investment to go into training.
Models because even if the costs are.
Not necessarily big in terms of compute.
It&rsquo;S still research and development and pretty.
Hard research and development. It&rsquo;s basically research. We understand pretraining pretty well. We don&rsquo;t understand fine tuning that well. We believe it&rsquo;s a better idea to.</p><p>Stanislas Polu:
Really try to explore the product layer.
The image I use generally is that training a model is very sexy and it&rsquo;s exciting, but really you&rsquo;re building a small rock that will get submerged by the waves of bigger models coming in the future. And iterating and positioning yourself at the interface between humans and those models at.
The product layer is more akin to.
Building a surfboard that you will be.
Able to use to surf those same waves.</p><p>Demetrios:
I like that because I am a big surfer and I have a lot.</p><p>Stanislas Polu:
Of fun doing it.</p><p>Demetrios:
Now tell me about are you going after verticals? Are you going after different areas in a market, a certain subset of the market?</p><p>Stanislas Polu:
How do you look at that? Yeah.
Basically the idea is to look at productivity within the enterprise. So we&rsquo;re first focusing on internal use.
By teams, internal teams of that technology.
We&rsquo;re not at all going after external use. So backing products that embed AI or having on projects maybe exposed through our users to actual end customers. So we really focused on the internal use case. So the first thing you want to.
Do is obviously if you&rsquo;re interested in.
Productivity within enterprise, you definitely want to have the enterprise data, right? Because otherwise there&rsquo;s a ton that can be done with Chat GPT as an example. But there is so much more that can be done when you have context.
On the data that comes from the company you&rsquo;re in.
That&rsquo;s pretty much kind of the use.
Case we&rsquo;re focusing on, and we&rsquo;re making.
A bet, which is a crazy bet to answer your question, that there&rsquo;s actually value in being quite horizontal for now. So that comes with a lot of risks because an horizontal product is hard.</p><p>Stanislas Polu:
To read and it&rsquo;s hard to figure.
Out how to use it. But at the same time, the reality is that when you are somebody working in a team, even if you spend.
A lot of time on one particular.
Application, let&rsquo;s say Salesforce for sales, or GitHub for engineers, or intercom for customer support, the reality of most of your workflows do involve many SaaS, meaning that you spend a lot of time in Salesforce, but you also spend a lot of time in slack and notion. Maybe, or we all spend as engineers a lot of time in GitHub, but we also use notion and slack a ton or Google Drive or whatnot. Jira.</p><p>Demetrios:
Good old Jira. Everybody loves spending time in Jira.</p><p>Stanislas Polu:
Yeah. And so basically, following our users where.
They are requires us to have access to those different SaaS, which requires us.
To be somewhat horizontal.
We had a bunch of signals that.
Kind of confirms that position, and yet.
We&rsquo;Re still very conscious that it&rsquo;s a risky position. As an example, when we are benchmarked against other solutions that are purely verticalized, there is many instances where we actually do a better job because we have.
Access to all the data that matters within the company.</p><p>Demetrios:
Now, there is something very difficult when you have access to all of the data, and that is the data leakage issue and the data access. Right. How are you trying to conquer that hard problem?</p><p>Stanislas Polu:
Yeah, so we&rsquo;re basically focusing to continue.
Answering your questions through that other question.
I think we&rsquo;re focusing on tech companies.
That are less than 1000 people. And if you think about most recent tech companies, less than 1000 people.
There&rsquo;s been a wave of openness within.</p><p>Stanislas Polu:
Companies in terms of data access, meaning that it&rsquo;s becoming rare to see people actually relying on complex ACL for the internal data. You basically generally have silos. You have the exec silo with remuneration and ladders and whatnot. And this one is definitely not the.
Kind of data we&rsquo;re touching.
And then for the rest, you generally have a lot of data that is.
Accessible by every employee within your company.
So that&rsquo;s not a perfect answer, but that&rsquo;s really kind of the approach we&rsquo;re taking today. We give a lot of control on.</p><p>Stanislas Polu:
Which data comes into dust, but once.
It&rsquo;S into dust, and that control is pretty granular, meaning that you can select.
Specific slack channels, or you can select.
Specific notion pages, or you can select specific Google Drive subfolders. But once you decide to put it in dust, every dust user has access to this. And so we&rsquo;re really taking the silo.
Vision of the granular ACL story.
Obviously, if we were to go higher enterprise, that would become a very big issue, because I think larger are the enterprise, the more they rely on complex ackles.</p><p>Demetrios:
And I have to ask about your history with stripe. Have you been focusing on specific financial pieces to this? First thing that comes to mind is what about all those e commerce companies that are living and breathing with stripe? Feels like they&rsquo;ve got all kinds of use cases that they could leverage AI for, whether it is their supply chain or just getting better numbers, or getting answers that they have across all this disparate data. Have you looked at that at all? Is that informing any of your decisions that you&rsquo;re making these days?</p><p>Stanislas Polu:
No, not quite. Not really. At stripe, when we joined, it was.
Very early, it was the quintessential curlb onechargers number 42.
42, 42. And that&rsquo;s pretty much what stripe was almost, I&rsquo;m exaggerating, but not too much. So what I&rsquo;ve been focusing at stripe.
Was really driven by my and our.
Perspective as european funders joining a quite.
Us centric company, which is, no, there.</p><p>Stanislas Polu:
Is not credit card all over the world. Yes, there is also payment methods. And so most of my time spent at stripe was spent on trying to expand the API to not a couple us payment methods, but a variety of worldwide payment methods. So that requires kind of a change of paradigm from an API design, and that&rsquo;s where I spent most of my cycles
What I want to try.</p><p>Demetrios:
Okay, the next question that I had is you talked about how benchmarking with the horizontal solution, surprisingly, has been more effective in certain use cases. I&rsquo;m guessing that&rsquo;s why you got a little bit of love for <a href=https://qdrant.tech/ target=_blank rel="noopener nofollow">Qdrant</a> and what we&rsquo;re doing here.</p><p>Stanislas Polu:
Yeah
I think the benchmarking was really about quality of models, answers in the context of <a href=https://qdrant.tech/articles/what-is-rag-in-ai/ target=_blank rel="noopener nofollow">retrieval augmented generation</a>.
So it&rsquo;s not as much as performance, but obviously performance matters, and that&rsquo;s why we love using Qdrants. But I think the main idea of.</p><p>Stanislas Polu:
What I mentioned is that it&rsquo;s interesting because today the retrieval is noisy, because the embedders are not perfect, which is an interesting point.
Sorry, I&rsquo;m double clicking, but I&rsquo;ll come back. The embedded are really not perfect. Are really not perfect. So that&rsquo;s interesting. When Qdrant release kind of optimization for <a href=https://qdrant.tech/documentation/concepts/storage/ target=_blank rel="noopener nofollow">storage of vectors</a>, they come with obviously warnings that you may have a loss.
Of precision because of the compression, et cetera, et cetera.
And that&rsquo;s funny, like in all kind of retrieval and mental generation world, it really doesn&rsquo;t matter. We take all the performance we can because the loss of precision coming from compression of those vectors at the vector DB level are completely negligible compared to.
The holon fuckness of the embedders in.</p><p>Stanislas Polu:
Terms of capability to correctly embed text, because they&rsquo;re extremely powerful, but they&rsquo;re far from being perfect. And so that&rsquo;s an interesting thing where you can really go as far as you want in terms of performance, because your error is dominated completely by the.
Quality of your embeddings.
Going back up.
I think what&rsquo;s interesting is that the.
Retrieval is noisy, mostly because of the embedders, and the models are not perfect.
And so the reality is that more.
Data in a rack context is not.
Necessarily better data because the retrievals become noisy.
The model kind of gets confused and it starts hallucinating stuff, et cetera. And so the right trade off is that you want to access to as.
Much data as possible, but you want
To give the ability to our users.
To select very narrowly the data required for a given task.</p><p>Stanislas Polu:
And so that&rsquo;s kind of what our product does, is the ability to create assistants that are specialized to a given task. And most of the specification of an assistant is obviously a prompt, but also.
Saying, oh, I&rsquo;m working on helping sales find interesting next leads.
And you really want to narrow the data exactly where that information lies. And that&rsquo;s where there, we&rsquo;re really relying.
Hard on Qdrants as well.
So the kind of indexing capabilities on.
Top of the <a href=https://qdrant.tech/ target=_blank rel="noopener nofollow">vector search</a>, where whenever.</p><p>Stanislas Polu:
We insert the documents, we kind of try to insert an array of parents that reproduces the hierarchy of whatever that document is coming from, which lets us create a very nice user experience where when you create an assistant, you can say, oh, I&rsquo;m going down two levels within notion, and I select that page and all of those children will come together. And that&rsquo;s just one string in our specification, because then rely on those parents that have been injected in Qdrant, and then the Qdrant search really works well with a simple query like this thing has to be in parents.</p><p>Stanislas Polu:
And you filter by that and it.</p><p>Demetrios:
Feels like there&rsquo;s two levels to the evaluation that you can be doing with rags. One is the stuff you&rsquo;re retrieving and evaluating the retrieval, and then the other is the output that you&rsquo;re giving to the end user. How are you attacking both of those evaluation questions?</p><p>Stanislas Polu:
Yeah, so the truth in whole transparency.
Is that we don&rsquo;t, we&rsquo;re just too early.</p><p>Demetrios:
Well, I&rsquo;m glad you&rsquo;re honest with us, Alicia.</p><p>Stanislas Polu:
This is great, we should, but the rate is that we have so many other product priorities that I think evaluating the quality of retrievals, evaluating the quality.
Of retrieval, augmented generation.
Good sense but good sense is hard to define, because good sense with three.
Years doing research in that domain is probably better sense.
Better good sense than good sense with no clue on the domain. But basically with good sense I think.
You can get very far and then.
You&rsquo;Ll be optimizing at the margin.
And the reality is that if you.
Get far enough with good sense, and that everything seems to work reasonably well, then your priority is not necessarily on pushing 5% performance, whatever is the metric.</p><p>Stanislas Polu:
But more like I have a million other products questions to solve.
That is the kind of ten people answer to your question. And as we grow, we&rsquo;ll probably make a priority, of course, of benchmarking that better. In terms of benchmarking that better. Extremely interesting question as well, because the.
Embedding benchmarks are what they are, and.
I think they are not necessarily always a good representation of the use case you&rsquo;ll have in your products. And so that&rsquo;s something you want to be cautious of. And.
It&rsquo;S quite hard to benchmark your use case.
The kind of solutions you have and the ones that seems more plausible, whether it&rsquo;s spending like full years on that.</p><p>Stanislas Polu:
Is probably to.
Evaluate the retrieval with another model, right?
It&rsquo;s like you take five different embedding models, you record a bunch of questions.
That comes from your product, you use your product data and you run those retrievals against those five different embedders, and.
Then you ask GPT four to raise.
That would be something that seems sensible and probably will get you another step forward and is not perfect, but it&rsquo;s.
Probably really strong enough to go quite far.</p><p>Stanislas Polu:
And then the second question is evaluating.
The end to end pipeline, which includes.
Both the retrieval and the generation.
And to be honest, again, it&rsquo;s a.
Known question today because GPT four is.
Just so much above all the models.</p><p>Stanislas Polu:
That there&rsquo;s no point evaluating them. If you accept using GPD four, just use GP four. If you want to use open source models, then the questions is more important. But if you are okay with using GPD four for many reasons, then there.
Is no questions at this stage.</p><p>Demetrios:
So my next question there, because sounds like you got a little bit of a french accent, you&rsquo;re somewhere in Europe. Are you in France?</p><p>Stanislas Polu:
Yes, we&rsquo;re based in France and billion team from Paris.</p><p>Demetrios:
So I was wondering if you were going to lean more towards the history of you working at OpenAI or the fraternity from your french group and go for your amiz in.</p><p>Stanislas Polu:
Mean, we are absolute BFF with Mistral. The fun story is that Guillaume Lamp is a friend, because we were working on exactly the same subjects while I was at OpenAI and he was at Meta. So we were basically frenemies. We&rsquo;re competing against the same metrics and same goals, but grew a friendship out of that. Our platform is quite model agnostic, so.
We support Mistral there.
Then we do decide to set the defaults for our users, and we obviously set the defaults to GP four today. I think it&rsquo;s the question of where.
Today there&rsquo;s no question, but when the.
Time comes where open source or non open source, it&rsquo;s not the question, but where Ozo models kind of start catching.
Up with GPT four, that&rsquo;s going to.</p><p>Stanislas Polu:
Be an interesting product question, and hopefully.
Mistral will get there.
I think that&rsquo;s definitely their goal, to be within reach of GPT four this year.
And so that&rsquo;s going to be extremely exciting. Yeah.</p><p>Demetrios:
So then you mentioned how you have a lot of other product considerations that you&rsquo;re looking at before you even think about evaluation. What are some of the other considerations?</p><p>Stanislas Polu:
Yeah, so as I mentioned a bit.
The main hypothesis is we&rsquo;re going to do company productivity or team productivity. We need the company data. That was kind of hypothesis number zero. It&rsquo;s not even an hypothesis, almost an axiom. And then our first product was a conversational assistance, like chat. GPT, that is general, and has access.
To everything, and realized that didn&rsquo;t work.
Quite well enough on a bunch of use cases, was kind of good on some use cases, but not great on many others.
And so that&rsquo;s where we made that.
First strong product, the hypothesis, which is. So we want to have many assistants.
Not one assistant, but many assistants, targeted to specific tasks.
And that&rsquo;s what we&rsquo;ve been exploring since the end of the summer. And that hypothesis has been very strongly confirmed with our users. And so an example of issue that.
We have is, obviously, you want to.
Activate your product, so you want to make sure that people are creating assistance. So one thing that is much more important than the quality of rag is.
The ability of users to create personal assistance.
Before, it was only workspace assistance, and so only the admin or the builder could build it. And now we&rsquo;ve basically, as an example, worked on having anybody can create the assistant. The assistant is scoped to themselves, they can publish it afterwards, et cetera. That&rsquo;s the kind of product questions that.
Are, to be honest, more important than rack rarity, at least for us.</p><p>Demetrios:
All right, real quick, publish it for a greater user base or publish it for the internal company to be able to.</p><p>Stanislas Polu:
Yeah, within the workspace.
Okay.</p><p>Demetrios:
It&rsquo;s not like, oh, I could publish this for.</p><p>Stanislas Polu:
We&rsquo;Re not going there yet. And there&rsquo;s plenty to do internally to each workspace.
Before going there, though it&rsquo;s an interesting case because that&rsquo;s basically another big problem, is you have an horizontal platform, you can create an assistance, you&rsquo;re not an.
Expert and you&rsquo;re like, okay, what should I do? And so that&rsquo;s the kind of white blank page issue.</p><p>Stanislas Polu:
And so there having templates, inspiration, you can sit that within workspace, but you also want to have solutions for the new workspace that gets created. And maybe a marketplace is a good idea. Or having templates, et cetera, are also product questions that are much more important than the rack performance. And finally, the users where dust works really well, one example is Alan in.
France, there are 600, and dust is.
Running there pretty healthily, and they&rsquo;ve created.
More than 200 assistants. And so another big product question is like, when you get traction within a company, people start getting flooded with assistance.
And so how do they discover them? How did they, and do they know which one to use, et cetera? So that&rsquo;s kind of the kind of.
Many examples of product questions that are very first order compared to other things.</p><p>Demetrios:
Because out of these 200 assistants, are you seeing a lot of people creating the same assistance?</p><p>Stanislas Polu:
That&rsquo;s a good question. So far it&rsquo;s been kind of driven by somebody internally that was responsible for trying to push gen AI within the company. And so I think there&rsquo;s not that.
Much redundancy, which is interesting, but I.
Think there&rsquo;s a long tail of stuff that are mostly explorations, but from our perspective, it&rsquo;s very hard to distinguish the two. Obviously, usage is a very strong signal.
But yeah, displaying assistance by usage, pushing.
The right assistance to the right user. This problem seems completely trivial compared to building an LLM, obviously. But still, when you add the product layer requires a ton of work, and as a startup, that&rsquo;s where a lot of our resources go, and I think.
It&rsquo;S the right thing to do.</p><p>Demetrios:
Yeah, I wonder if, and you probably have thought about this, but if it&rsquo;s almost like you can tag it with this product, or this assistant is in beta or alpha or this is in production, you can trust that this one is stable, that kind of thing.</p><p>Stanislas Polu:
Yeah.
So we have the concept of shared.
Assistant and the concept of workspace assistant. The workspace assistant are like the admin vetted the assistant, and it&rsquo;s kind of pushed to everyone by default. And then the published assistant is like, there&rsquo;s a gallery of assistant that you can visit, and there, the strongest signal is probably the usage metric.
Right?</p><p>Demetrios:
Yeah. So when you&rsquo;re talking about assistance, just so that I&rsquo;m clear, it&rsquo;s not autonomous agents, is it?</p><p>Stanislas Polu:
No.</p><p>Stanislas Polu:
Yeah. So it&rsquo;s a great question.
We are really focusing on the one.
Step, trying to solve very nicely the one step thing. I have one granular task to achieve.
And I can get accelerated on that.
Task and maybe save a few minutes or maybe save a few tens of minutes on one specific thing, because the identity version of that is obviously the future.
But the reality is that current models, even GB four, are not that great at kind of chaining decisions of tool use in a way that is sustainable.
Beyond the demo effect. So while we are very hopeful for the future, it&rsquo;s not our core focus, because I think there&rsquo;s a lot of risk that it creates more deception than anything else. But it&rsquo;s obviously something that we are.
Targeting in the future as models get better.</p><p>Demetrios:
Yeah. And you don&rsquo;t want to burn people by making them think something&rsquo;s possible. And then they go and check up on it and they leave it in the agent&rsquo;s hands, and then next thing they know they&rsquo;re getting fired because they don&rsquo;t actually do the work that they said they were going to do.</p><p>Stanislas Polu:
Yeah. One thing that we don&rsquo;t do today.
Is we have kind of different ways.
To bring data into the assistant before it creates generation. And we&rsquo;re expanding that. One of the domain use case is the one based on Qdrant, which is.
The kind of retrieval one.
We also have kind of a workflow system where you can create an app.
An LLM app, where you can make.</p><p>Stanislas Polu:
Multiple calls to a model, you can call external APIs and search. And another thing we&rsquo;re digging into our structured data use case, which this time doesn&rsquo;t use Qdrants, which the idea is that semantic search is great, but it&rsquo;s really atrociously bad for quantitative questions.
Basically, the typical use case is you.
Have a big CSV somewhere and it gets chunked and then you do retrieval.
And you get kind of disordered partial.
Chunks, all of that.
And on top of that, the moles.
Are really bad at counting stuff. And so you really get bullshit, you.</p><p>Demetrios:
Know better than anybody.</p><p>Stanislas Polu:
Yeah, exactly. Past life. And so garbage in, garbage out. Basically, we&rsquo;re looking into being able, whenever the data is structured, to actually store.</p><p>It in a structured way and as needed.
Just in time, generate an in memory SQL database so that the model can generate a SQL query to that data and get kind of a SQL.
Answer and as a consequence hopefully be able to answer quantitative questions better.
And finally, obviously the next step also is as we integrated with those platform notion, Google Drive, slack, et cetera, basically.
There&rsquo;S some actions that we can take there.
We&rsquo;re not going to take the actions, but I think it&rsquo;s interesting to have.
The model prepare an action, meaning that here is the email I prepared, send.
It or iterate with me on it, or here is the slack message I prepare, or here is the edit to the notion doc that I prepared.</p><p>Stanislas Polu:
This is still not agentic, it&rsquo;s closer.
To taking action, but we definitely want.
To keep the human in the loop.
But obviously some stuff that are on our roadmap.
And another thing that we don&rsquo;t support, which is one type of action would.
Be the first we will be working on is obviously code interpretation, which is I think is one of the things that all users ask because they use.
It on Chat GPT.
And so we&rsquo;ll be looking into that as well.</p><p>Demetrios:
What made you choose Qdrant?</p><p>Stanislas Polu:
So the decision was made, if I.
Remember correctly, something like February or March last year. And so the alternatives I looked into.
Were pine cone wavy eight, some click owls because Chroma was using click owls at the time. But Chroma was.
2000 lines of code.
At the time as well.
And so I was like, oh, Chroma, we&rsquo;re part of AI grant. And Chroma is as an example also part of AI grant. So I was like, oh well, let&rsquo;s look at Chroma.
And however, what I&rsquo;m describing is last.
Year, but they were very early. And so it was definitely not something.
That seemed like to make sense for us.
So at the end it was between pine cone wavev eight and Qdrant wave v eight.
You look at the doc, you&rsquo;re like, yeah, not possible.
And then finally it&rsquo;s Qdrant and Pinecone. And I think we really appreciated obviously the open source nature of Qdrants.From.
Playing with it, the very strong performance, the fact that it&rsquo;s written in rust, the sanity of the documentation, and basically the feeling that because it&rsquo;s an open source, we&rsquo;re using the osted Qdrant cloud solution. But it&rsquo;s not a question of paying.
Or not paying, it&rsquo;s more a question.
Of being able to feel like you have more control. And at the time, I think it was the moment where Pinecon had their massive fuck up, where they erased gazillion database from their users and so we&rsquo;ve been on Qdrants and I think it&rsquo;s.
Been a two step process, really.</p><p>Stanislas Polu:
It&rsquo;s very smooth to start, but also Qdrants at this stage comes with a.
Lot of knobs to turns.
And so as you start scaling, you at some point reach a point where.
You need to start tweaking the knobs.
Which I think is great because the knobs, there&rsquo;s a lot of knobs, so they are hard to understand, but once you understand them, you see the power of them. And the Qdrant team has been excellent there supporting us. And so I think we&rsquo;ve reached that first level of scale where you have.
To tweak the nodes, and we&rsquo;ve reached.
The second level of scale where we.
Have to have multiple nodes.
But so far it&rsquo;s been extremely smooth.
And I think we&rsquo;ve been able to.
Do with Qdrant some stuff that really are possible only because of the very good performance of the database.
As an example, we&rsquo;re not using your clustered setup. We have n number of independent nodes.
And as we scale, we kind of.
Reshuffle which users go on which nodes.
As we need, trying to keep our largest users and most paying users on.
Very well identified nodes. We have a kind of a garbage.
Node for all the free users, as an example, migrating even a very big collection from one node. One capability that we build is say, oh, I have that collection over there. It&rsquo;s pretty big.
I&rsquo;m going to initiate on another node.
I&rsquo;m going to set up shadow writing on both, and I&rsquo;m going to migrate live the data. And that has been incredibly easy to do with Qdrant because crawling is fast, writing is fucking fast. And so even a pretty large collection.
You can migrate it in a minute.</p><p>Stanislas Polu:
And so it becomes really within the realm of being able to administrate your cluster with that in mind, which I.
Think would have probably not been possible with the different systems.</p><p>Demetrios:
So it feels like when you are helping companies build out their assistants, are you going in there and giving them ideas on what they can do?</p><p>Stanislas Polu:
Yeah, we are at a stage where obviously we have to do that because.
I think the product basically starts to.
Have strong legs, but I think it&rsquo;s still very early and so there&rsquo;s still a lot to do on activation, as an example. And so we are in a mode today where we do what doesn&rsquo;t scale.
Basically, and we do spend some time.</p><p>Stanislas Polu:
With companies, obviously, because there&rsquo;s nowhere around that. But what we&rsquo;ve seen also is that the users where it works the best and being on dust or anything else.
That is relative to having people adopt gen AI.
Within the company are companies where they.
Actually allocate resources to the problem, meaning that the companies where it works best.
Are the companies where there&rsquo;s somebody. Their role is really to go around the company, find, use cases, support the teams, et cetera. And in the case of companies using dust, this is kind of type of interface that is perfect for us because we provide them full support and we help them build whatever they think is.
Valuable for their team.</p><p>Demetrios:
Are you also having to be the bearer of bad news and tell them like, yeah, I know you saw that demo on Twitter, but that is not actually possible or reliably possible?</p><p>Stanislas Polu:
Yeah, that&rsquo;s an interesting question. That&rsquo;s a good question. Not that much, because I think one of the big learning is that you take any company, even a pretty techy.
Company, pretty young company, and the reality.
Is that most of the people, they&rsquo;re not necessarily in the ecosystem, they just want shit done. And so they&rsquo;re really glad to have some shit being done by a computer. But they don&rsquo;t really necessarily say, oh, I want the latest shiniest thingy that.
I saw on Twitter. So we&rsquo;ve been safe from that so far.</p><p>Demetrios:
Excellent. Well, man, this has been incredible. I really appreciate you coming on here and doing this. Thanks so much. And if anyone wants to check out dust, I encourage that they do.</p><p>Stanislas Polu:
It&rsquo;s dust.</p><p>Demetrios:
It&rsquo;s a bit of an interesting website. What is it?</p><p>Stanislas Polu:
Dust TT.</p><p>Demetrios:
That&rsquo;s it. That&rsquo;s what I was missing, dust. There you go. So if anybody wants to look into it, I encourage them to. And thanks so much for coming on here.</p><p>Stanislas Polu:
Yeah.</p><p>Stanislas Polu:
And Qdrant is the shit.</p><p>Demetrios:
There we go. Awesome, dude. Well, this has been great.</p><p>Stanislas Polu:
Yeah, thanks, Vintu. Have a good one.</p></div></div></article></section><section class=get-started-blogs><div class=container><div class=get-started-blogs__content><div class=row><div class="get-started-blogs__text col-12 col-lg-7"><h3 class=get-started-blogs__title>Get Started with Qdrant Free</h3><a href=https://cloud.qdrant.io/signup class="button button_contained" target=_blank>Get Started</a></div><div class="get-started-blogs__image col-12 col-lg-5"><img src=https://qdrant.tech/img/rocket.svg alt></div></div><div class=get-started-blogs__overlay-top></div></div></div></section></main><footer class=footer><div class=footer__top><div class=container><div class="row justify-content-md-between"><div class="col-12 col-md-6"><a href=https://qdrant.tech/ title="Go to Home Page"><img class=footer__top-logo src=https://qdrant.tech/img/logo-white.png alt="Qdrant Logo"></a></div><div class="col-12 col-md-6 footer__top-social-media-platforms"><a class=footer__top-social-media-link href=https://github.com/qdrant/qdrant target=_blank rel="noopener noreferrer nofollow"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><g clip-path="url(#clip0_1841_958)"><path fill-rule="evenodd" clip-rule="evenodd" d="M12 .299805C5.35.299805.0 5.6498.0 12.2998c0 5.3 3.45 9.8 8.2 11.4C8.8 23.7998 9 23.4498 9 23.0998 9 22.7998 9 22.0498 9 21.0498c-3.35.75-4.05-1.6-4.05-1.6-.55-1.4-1.35-1.75-1.35-1.75-1.1-.75.1-.75.1-.75C4.9 17.0498 5.55 18.1998 5.55 18.1998c1.05 1.85 2.8 1.3 3.5 1C9.15 18.3998 9.45 17.8998 9.8 17.5998 7.15 17.2998 4.35 16.2498 4.35 11.6498c0-1.3.45-2.4 1.25-3.2C5.5 8.1498 5.05 6.9498 5.7 5.2498c0 0 1-.3 3.3 1.25C9.95 6.2498 11 6.0998 12 6.0998S14.05 6.2498 15 6.4998c2.3-1.55 3.3-1.25 3.3-1.25C18.95 6.8998 18.55 8.0998 18.4 8.4498c.75.85 1.25 1.9 1.25 3.2.0 4.6-2.8 5.6-5.5 5.9C14.6 17.8998 14.95 18.6498 14.95 19.7498c0 1.6.0 2.9.0 3.3C14.95 23.3498 15.15 23.7498 15.8 23.6498c4.75-1.55 8.2-6.05 8.2-11.35C24 5.6498 18.65.299805 12 .299805z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_1841_958"><rect width="24" height="24" fill="#fff"/></clipPath></defs></svg>
</a><a class=footer__top-social-media-link href=https://qdrant.to/linkedin target=_blank rel="noopener noreferrer nofollow"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><g clip-path="url(#clip0_1841_961)"><path d="M21.75.75H2.25c-.39782.0-.77936.158035-1.06066.43934C.908035 1.47064.75 1.85218.75 2.25v19.5C.75 22.1478.908035 22.5294 1.18934 22.8107 1.47064 23.092 1.85218 23.25 2.25 23.25h19.5C22.1478 23.25 22.5294 23.092 22.8107 22.8107 23.092 22.5294 23.25 22.1478 23.25 21.75V2.25C23.25 1.85218 23.092 1.47064 22.8107 1.18934 22.5294.908035 22.1478.75 21.75.75zM7.41525 19.9455H4.0305V9.1875H7.41525v10.758zM5.7225 7.71075C5.33338 7.70956 4.95333 7.59309 4.63036 7.37604 4.30739 7.15899 4.05599 6.8511 3.9079 6.49126 3.75981 6.13141 3.72167 5.73575 3.79831 5.35425 3.87495 4.97275 4.06293 4.62251 4.3385 4.34778 4.61408 4.07304 4.96488 3.88613 5.34662 3.81065 5.72835 3.73517 6.1239 3.77451 6.48329 3.92369 6.84268 4.07288 7.1498 4.32522 7.36587 4.64885c.21606.32363.33138.70402.33138 1.09315C7.69735 6.00107 7.6463 6.25762 7.54702 6.49691 7.44774 6.73621 7.30219 6.95355 7.11872 7.13646 6.93525 7.31938 6.71746 7.46426 6.47787 7.56282 6.23827 7.66137 5.98157 7.71164 5.7225 7.71075zM19.9657 19.9455H16.65V14.742c0-1.2652.0-2.8125-1.7625-2.8125s-1.9748 1.3365-1.9748 2.742V20.016H9.6V9.1875h3.102v1.4767H12.7725C13.0924 10.1111 13.5567 9.65537 14.1156 9.34571 14.6746 9.03606 15.3072 8.88415 15.9457 8.90625c3.3848.0 4.0193 2.24995 4.0193 5.13295L19.9657 19.9455z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_1841_961"><rect width="24" height="24" fill="#fff"/></clipPath></defs></svg>
</a><a class=footer__top-social-media-link href=https://qdrant.to/twitter target=_blank rel="noopener noreferrer nofollow"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M10.8423 15.1515 4.40655 22.5H.841797L9.1773 12.978l1.665 2.1735z" fill="#f0f3fa"/><path d="M12.7881 8.241 18.6808 1.5h3.5625l-7.8052 8.9265-1.65-2.1855z" fill="#f0f3fa"/><path d="M23.6158 22.5H16.4465L.383789 1.5H7.73454l15.88126 21zm-6.186-2.1322h1.974L6.66204 3.5205h-2.118L17.4298 20.3678z" fill="#f0f3fa"/></svg>
</a><a class=footer__top-social-media-link href=https://qdrant.to/discord target=_blank rel="noopener noreferrer nofollow"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M5 1C2.79086 1 1 2.79086 1 5V19c0 2.2091 1.79086 4 4 4H19c2.2091.0 4-1.7909 4-4V5c0-2.20914-1.7909-4-4-4H5zM16.3683 18.5964S15.8027 17.9208 15.3314 17.3238C16.4701 17.0557 17.4774 16.3935 18.1749 15.4543 17.6098 15.8317 17.0037 16.1438 16.3683 16.3846 15.6374 16.6966 14.873 16.9233 14.0903 17.0602 12.7448 17.3079 11.3649 17.3026 10.0213 17.0445 9.23256 16.8901 8.45954 16.664 7.71193 16.3689 7.08195 16.1284 6.48116 15.8174 5.92097 15.442 6.59328 16.3616 7.56575 17.0173 8.67025 17.2958 8.19895 17.8928 7.61767 18.5998 7.61767 18.5998 4.14571 18.4898 2.82605 16.2091 2.82605 16.2091 2.87704 13.0242 3.65058 9.89242 5.08832 7.05004 6.35356 6.05636 7.89607 5.47998 9.5029 5.40046l.1571.18853c-1.51174.37413-2.92245 1.0768-4.13179 2.05804.0.0.34562-.18853.926900000000001-.4556C7.58438 6.67595 8.78793 6.34193 10.0213 6.20168 10.1093 6.18348 10.1986 6.17297 10.2884 6.17026 11.3412 6.0331 12.4066 6.02255 13.4619 6.13884c1.6595.18933 3.2659.70144 4.7288 1.5075C17.0426 6.71186 15.7093 6.0318 14.2788 5.65114L14.4988 5.39978C16.1056 5.4793 17.6481 6.05568 18.9133 7.04935c1.4378 2.84239 2.2113 5.97415 2.2623 9.15905.0.0-1.3354 2.278-4.8073 2.388zM9.06284 11.2616C8.62563 11.2983 8.21817 11.498 7.9212 11.821 7.62423 12.1439 7.45941 12.5667 7.45941 13.0054c0 .438800000000001.16482.8615.46179 1.1845S8.62563 14.7125 9.06284 14.7493C9.50005 14.7125 9.90751 14.5129 10.2045 14.1899 10.5015 13.8669 10.6663 13.4442 10.6663 13.0054c0-.438699999999999-.1648-.8615-.4618-1.1844C9.90751 11.498 9.50005 11.2983 9.06284 11.2616zm5.73766.0C14.4493 11.2319 14.0974 11.3089 13.7907 11.4825c-.3066.1736-.553699999999999.4358-.7089.7522-.155199999999999.3164-.2112.6723-.1608 1.021C12.9714 13.6045 13.1259 13.93 13.3644 14.1894 13.6028 14.4489 13.9141 14.6304 14.2573 14.71 14.6006 14.7897 14.96 14.7639 15.2883 14.6359c.3284-.1279.6104-.352.8093-.642899999999999C16.2965 13.702 16.4029 13.3578 16.4029 13.0054 16.4124 12.7854 16.3783 12.5657 16.3026 12.3588 16.2269 12.152 16.1112 11.9622 15.962 11.8002 15.8128 11.6381 15.6331 11.5072 15.4332 11.4148 15.2333 11.3223 15.0171 11.2703 14.7971 11.2616H14.8005z" fill="#f0f3fa"/></svg>
</a><a class=footer__top-social-media-link href=https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA target=_blank rel="noopener noreferrer nofollow"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M23.775 7.1999S23.55 5.5499 22.8 4.7999C21.9 3.8249 20.85 3.8249 20.4 3.7499c-3.375-.225-8.4-.225-8.4-.225s-5.025.0-8.4.225C3.15 3.8249 2.1 3.8249 1.2 4.7999c-.75.75-.975 2.4-.975 2.4S0 9.1499.0 11.0999v1.8c0 1.95.225 3.9.225 3.9s.225 1.65.975 2.4C2.1 20.1749 3.3 20.0999 3.825 20.2499 5.775 20.3999 12 20.4749 12 20.4749S17.025 20.4749 20.4 20.2499C20.85 20.1749 21.9 20.1749 22.8 19.1999 23.55 18.4499 23.775 16.7999 23.775 16.7999S24 14.8499 24 12.8999v-1.8C24 9.1499 23.775 7.1999 23.775 7.1999zm-14.25 7.95v-6.75l6.45 3.375-6.45 3.375z" fill="#f0f3fa"/></svg></a></div></div></div></div><div class=footer__menu><div class=container><nav class=footer__menu-content><div class=footer__menu-section><p class=footer__menu-section-title>Products</p><ul class=footer__menu-items><li class=footer__menu-item><a href=https://qdrant.tech/qdrant-vector-database/>Qdrant Vector Database</a></li><li class=footer__menu-item><a href=https://qdrant.tech/cloud/>Qdrant Cloud</a></li><li class=footer__menu-item><a href=https://qdrant.tech/hybrid-cloud/>Qdrant Hybrid Cloud</a></li><li class=footer__menu-item><a href=https://qdrant.tech/enterprise-solutions/>Qdrant Enterprise Solutions</a></li><li class=footer__menu-item><a href=https://qdrant.tech/pricing/>Pricing</a></li></ul></div><div class=footer__menu-section><p class=footer__menu-section-title>Use Cases</p><ul class=footer__menu-items><li class=footer__menu-item><a href=https://qdrant.tech/advanced-search/>Advanced Search</a></li><li class=footer__menu-item><a href=https://qdrant.tech/recommendations/>Recommendation Systems</a></li><li class=footer__menu-item><a href=https://qdrant.tech/rag/>Retrieval Augmented Generation</a></li><li class=footer__menu-item><a href=https://qdrant.tech/data-analysis-anomaly-detection/>Data Analysis & Anomaly Detection</a></li><li class=footer__menu-item><a href=https://qdrant.tech/ai-agents/>AI Agents</a></li></ul></div><div class=footer__menu-section><p class=footer__menu-section-title>Developers</p><ul class=footer__menu-items><li class=footer__menu-item><a href=https://qdrant.tech/documentation/>Documentation</a></li><li class=footer__menu-item><a href=https://qdrant.tech/community/>Community</a></li><li class=footer__menu-item><a href=https://github.com/qdrant/qdrant target=_blank rel="noopener noreferrer nofollow">GitHub</a></li><li class=footer__menu-item><a href=https://qdrant.to/roadmap target=_blank rel="noopener noreferrer nofollow">Roadmap</a></li><li class=footer__menu-item><a href=https://github.com/qdrant/qdrant/releases target=_blank rel="noopener noreferrer nofollow">Change Log</a></li><li class=footer__menu-item><a href=https://status.qdrant.io/ target=_blank rel="noopener noreferrer nofollow">Status Page</a></li></ul></div><div class=footer__menu-section><p class=footer__menu-section-title>Resources</p><ul class=footer__menu-items><li class=footer__menu-item><a href=https://qdrant.tech/blog/>Blog</a></li><li class=footer__menu-item><a href=https://qdrant.tech/benchmarks/>Benchmarks</a></li><li class=footer__menu-item><a href=https://qdrant.tech/articles/>Articles</a></li><li class=footer__menu-item><a href=https://try.qdrant.tech/events target=_blank rel="noopener noreferrer nofollow">Events</a></li><li class=footer__menu-item><a href=https://qdrant.tech/qdrant-for-startups/>Startup Program</a></li><li class=footer__menu-item><a href=https://qdrant.tech/demo/>Demos</a></li><li class=footer__menu-item><a href=https://qdrant.tech/security/bug-bounty-program/>Bug Bounty</a></li></ul></div><div class=footer__menu-section><p class=footer__menu-section-title>Company</p><ul class=footer__menu-items><li class=footer__menu-item><a href=https://qdrant.tech/about-us/>About Us</a></li><li class=footer__menu-item><a href=https://qdrant.tech/customers/>Customers</a></li><li class=footer__menu-item><a href=https://qdrant.tech/partners/>Partners</a></li><li class=footer__menu-item><a href=https://qdrant.join.com/ target=_blank rel="noopener noreferrer nofollow">Careers</a></li><li class=footer__menu-item><a href=https://qdrant.tech/contact-us/>Contact Us</a></li></ul></div></nav></div></div><div class=footer__middle><div class=container><div class="align-items-center row"><div class="col-12 col-lg-5"><p class=footer__middle-title>Sign up for Qdrant updates</p><p class=footer__middle-subtitle>We'll occasionally send you best practices for using vector data and similarity search, as well as product news.</p></div><div class="footer__middle-newsletter col-12 col-lg-7"><div id=footer-subscribe-form><script>(function(){const t={region:"eu1",portalId:"139603372",formId:"049d96c6-ef65-4e41-ba69-a3335b9334cf",cssClass:"subscribe-form",submitButtonClass:"button button_contained button_lg",submitText:"Subscribe"},n="weh",s=function(){const e=document.createElement("input");return e.classList.add(n),e.type="text",e.name="my-work-email",e.style.display="none",e.placeholder="Email",e.ariaHidden="true",e},o=function(e){const t=s();e.appendChild(t);const n=e.querySelector('[type="submit"]');t.addEventListener("input",function(){t.value.length>0&&(n.disabled=!0)})},i=["Argentina","Belgium","Canada","Czech Republic","Cyprus","Denmark","Germany","Hungary","Latvia","Liechtenstein","Luxembourg","Netherlands","Norway","France","Finland","Croatia","Bulgaria","Belarus","Bosnia and Herzegovina","Austria","Estonia","Georgia","Greenland","Hong Kong","Israel","Italy","Maldives","Moldova","Monaco","Portugal","Russia","Serbia","Slovakia","Slovenia","Sweden","Switzerland","T√ºrkiye","Ukraine","Macedonia (FYROM)","United Kingdom"];function e(e){const a=e.querySelector('select[name="country"]'),n=e.querySelector(".legal-consent-container .hs-fieldtype-booleancheckbox"),r=e.querySelector(".legal-consent-container > div:nth-child(3)"),c=e.querySelector(".legal-consent-container > div:nth-child(2)");if(!a||!n)return;const s=a.value,l=i.includes(s),o=s&&l,t=n.querySelector('input[type="checkbox"]');n.style.display=o?"block":"none",r&&(r.style.display=o?"block":"none"),c&&(c.style.display=o?"none":"block"),s&&!l?t.checked||t.click():t.checked&&t.click()}try{hbspt.forms.create({...t,formInstanceId:"#footer-subscribe-form",pageId:"",target:"#footer-subscribe-form",onFormReady:function(t){if(!t){console.warn("Form not found.");return}o(t),e(t);const n=t.querySelector('select[name="country"]');n&&n.addEventListener("change",()=>e(t))}})}catch{document.getElementById("footer-subscribe-form").innerHTML='<p class="text-white">Here should be a form but looks like it was blocked on your side. Please, check your trackers blocking policy.</p>'}})()</script></div></div></div></div></div><div class=footer__bottom><div class=container><div class="row g-3"><div class="col-12 col-lg-6 footer__bottom-content"><span class=footer__bottom-copyright>¬© 2025 Qdrant.</span><div class=footer__bottom-bages><a href=http://qdrant.to/trust-center target=_blank><img src=https://qdrant.tech/img/soc2-badge.png alt=SOC2>
</a><a href=https://heydata.eu/ target=_blank><img src=https://qdrant.tech/img/gdpr-badge.png alt="heyData GDPR">
</a><a href=https://qdrant.tech/# target=_blank><img src=https://qdrant.tech/img/dark-gdpr-badge.png alt=GDPR>
</a><a href=https://qdrant.tech/# target=_blank><img src=https://qdrant.tech/img/hipaa-badge.png alt=HIPAA></a></div></div><div class="col-12 col-lg-6 footer__bottom-links"><a href=https://qdrant.tech/legal/terms_and_conditions/>Terms</a>
<a href=https://qdrant.tech/legal/privacy-policy/>Privacy Policy</a>
<a href=https://qdrant.tech/legal/impressum/>Impressum</a></div></div></div></div></footer><button class="d-none button button_outlined go-to-top-button" id=scrollToTopBtn title="Go to top">Up!</button>
</body><script src=https://cdn.cookielaw.org/scripttemplates/otSDKStub.js type=text/javascript data-domain-script=01960152-5e40-782d-af01-f7f5768a214e></script><script async type=text/javascript>function OptanonWrapper(){const e=new CustomEvent("onetrust_loaded");document.dispatchEvent(e)}</script><script>!function(){const o="eQYi1nZE2zQSmnHuxjMRlDd2uLl65oHe";var n,s,t="analytics",e=window[t]=window[t]||[];if(!e.initialize)if(e.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{e.invoked=!0,e.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","debug","page","screen","once","off","on","addSourceMiddleware","addIntegrationMiddleware","setAnonymousId","addDestinationMiddleware","register"],e.factory=function(n){return function(){if(window[t].initialized)return window[t][n].apply(window[t],arguments);var o,s=Array.prototype.slice.call(arguments);return["track","screen","alias","group","page","identify"].indexOf(n)>-1&&(o=document.querySelector("link[rel='canonical']"),s.push({__t:"bpc",c:o&&o.getAttribute("href")||void 0,p:location.pathname,u:location.href,s:location.search,t:document.title,r:document.referrer})),s.unshift(n),e.push(s),e}};for(n=0;n<e.methods.length;n++)s=e.methods[n],e[s]=e.factory(s);e.load=function(n,s){var i,o=document.createElement("script");o.type="text/javascript",o.async=!0,o.setAttribute("data-global-segment-analytics-key",t),o.src="https://evs.analytics.qdrant.tech/5caWuitPgcGFN5Q7HMpTaj/vEkmzjuRSqeXGbhGAFTWex.min.js",i=document.getElementsByTagName("script")[0],i.parentNode.insertBefore(o,i),e._loadOptions=s},e._writeKey=o,e._cdn="https://evs.analytics.qdrant.tech",e.SNIPPET_VERSION="5.2.0",e.load(o)}}()</script><script src=https://qdrant.tech/js/google-setup.min.14728a3ae9bd931593645b6ddbfe801d400cd2970006e782cb67f3966654248ca962dbaf4cf371493a2d326861b3a691a99d6d8349c8b2752339ab91d3787069.js></script><script src=https://qdrant.tech/js/index.min.e37feda1952d752f5568e1ebc55e183629e4d361f4df09edeed70b4a4327d601161c4147bdbe4149b4a3cdc1ed43f1bf1a2f2340a421f1aa821103980dfe0bda.js></script><script src=https://qdrant.tech/js/search/scroll.min.f4ed4453a3af0adb0d4f49333cbb7892ff5430483a567d0d2dfbd4655fb203d22f22f46aff3d9f38fa5fd96dde5f30227afd0ce1d9f838f5cd5295fc83856ec9.js></script><script src=https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js></script><script src=https://qdrant.tech/js/copy-code.min.95b03a45b2ab4b7a608ecfd4b5919c8572a5b2cd1463f52561cd10976abf3b74334f91324c0e620cb80afac46026a0b18cce6fb753d8495f74c6d478c8ca1d03.js></script><script src=https://qdrant.tech/js/lang-switcher.min.63da11cef09772078425b1ee56415b9c37842a9399f2ba2d2f5efbf72fb751686c410bd50e9bcd283c8231cb97c1973199d4923beef29d8b06e59d9983a6ba51.js></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src=https://qdrant.tech/js/vendor/anchor.min.0e138e17ebcf1c1147a7a3a81d9ac3c601622eedc479f1636470eb2552470f4e27c9a8efe6e8378995dedc1ab67029d8989536ea76f0857d45d1615ae772b8a1.js></script><script>document.addEventListener("keydown",function(e){if((e.metaKey||e.ctrlKey)&&e.key==="k"){e.preventDefault();let t=document.querySelector('[data-target="#searchModal"]');t&&t?.click()}})</script><script>document.addEventListener("scroll",()=>{const e=document.getElementById("article"),t=document.getElementById("progress"),n=e.scrollHeight-window.innerHeight,s=window.scrollY-e.offsetTop;t.value=Math.min(Math.max(s/n*100,0),100)})</script><script>window.addEventListener("message",e=>{if(e.data.type==="hsFormCallback"&&e.data.eventName==="onFormReady"){const t=document.querySelector(`form[data-form-id="${e.data.id}"]`);if(t){const e=t.querySelector('[name="last_form_fill_url"]');e&&(e.value=window.location.href);const n=t.querySelector('[name="referrer_url"]');n&&(n.value=document.referrer)}}})</script></html>