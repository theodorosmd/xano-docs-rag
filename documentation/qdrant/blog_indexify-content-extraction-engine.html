<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta charset=UTF-8><title>Indexify Unveiled - Diptanu Gon Choudhury | Vector Space Talks - Qdrant</title>
<link rel=icon href=https://qdrant.tech/favicon/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=https://qdrant.tech/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://qdrant.tech/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://qdrant.tech/favicon/favicon-16x16.png><link rel=manifest href=https://qdrant.tech/favicon/site.webmanifest><link rel=mask-icon href=https://qdrant.tech/favicon/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#2b5797"><meta name=msapplication-config content="/favicon/browserconfig.xml"><meta name=theme-color content="#ffffff"><link href=https://qdrant.tech/css/search/search.min.09596ee2b3c94d0ac82a1c33199cabdb3e0210b1ee46aaf1515200e9e484d05dd9e27cc1e861c58cc2e582af162f63b8e180ff2a12f7a6592b7aeaa0a7125130.css rel=stylesheet integrity="sha512-CVlu4rPJTQrIKhwzGZyr2z4CELHuRqrxUVIA6eSE0F3Z4nzB6GHFjMLlgq8WL2O44YD/KhL3plkreuqgpxJRMA=="><link href=https://qdrant.tech/css/main.min.c1e379ad4cf03647832f6a0f040754b0be3e79934db2c29f50b396327c1ec7ac45f778abadbd93f5a8bc431850d1b0d9c9eff34c0171cd4236e83c5e324c1a0e.css rel=stylesheet integrity crossorigin=anonymous><meta name=generator content="Hugo 0.141.0"><meta name=description content="Diptanu Gon Choudhury shares insights on re-imaging Spark and data infrastructure while discussing his work on Indexify to enhance AI-driven workflows and knowledge bases."><meta name=keywords content="vector search engine,neural network,matching,SaaS,approximate nearest neighbor search,image search,recommender system,vectors,knn algorithm,hnsw,vector search,embeddings,similarity,simaes networks,BERT,transformer,word2vec,fasttext,qdrant"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@id":"https://qdrant.tech/blog/indexify-content-extraction-engine/#article","@type":"Article","abstract":"Diptanu Gon Choudhury shares insights on reimaging Spark and data infrastructure while discussing his work on Indexify to enhance AIdriven workflows and knowledge bases","author":{"@type":"Person","name":"Demetrios Brinkmann"},"dateModified":"2024-01-26 16:40:55.469 +0000 UTC","datePublished":"2024-01-26 16:40:55.469 +0000 UTC","description":"Diptanu Gon Choudhury shares insights on reimaging Spark and data infrastructure while discussing his work on Indexify to enhance AIdriven workflows and knowledge bases","headline":"Indexify Unveiled - Diptanu Gon Choudhury | Vector Space Talks","image":[""],"name":"Indexify Unveiled - Diptanu Gon Choudhury | Vector Space Talks","url":"https://qdrant.tech/blog/indexify-content-extraction-engine/","wordCount":"5192"},{"@id":"https://qdrant.tech/blog/indexify-content-extraction-engine/#organization","@type":"Organization","address":{"@type":"PostalAddress","addressCountry":"DE","addressLocality":"Berlin","addressRegion":"Berlin","postalCode":"10115","streetAddress":"Chausseestraße 86"},"contactPoint":{"@type":"ContactPoint","contactType":"customer support","email":"info@qdrant.com","telephone":"+49 3040797694"},"description":"Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.","email":"info@qdrant.com","founders":[{"@type":"Person","name":"map[email:info@qdrant.tech name:Andrey Vasnetsov]"},{"@type":"Person","name":"Andre Zayarni"}],"foundingDate":"2021","keywords":["vector search engine","neural network","matching","SaaS","approximate nearest neighbor search","image search","recommender system","vectors","knn algorithm","hnsw","vector search","embeddings","similarity","simaes networks","BERT","transformer","word2vec","fasttext","Qdrant"],"legalName":"Qdrant Solutions GmbH","location":"Berlin, Germany","logo":"https://qdrant.tech/images/logo_with_text.png","name":"Qdrant","sameAs":["https://github.com/qdrant/qdrant","https://qdrant.to/discord","https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA","https://www.linkedin.com/company/qdrant/","https://twitter.com/qdrant_engine"],"url":"https://qdrant.tech"}]}</script><meta property="og:url" content="https://qdrant.tech/blog/indexify-content-extraction-engine/"><meta property="og:type" content="website"><meta property="og:title" content="Indexify Unveiled - Diptanu Gon Choudhury | Vector Space Talks - Qdrant"><meta name=twitter:card content="summary_large_image"><meta name=twitter:domain content="qdrant"><meta name=twitter:url content="https://qdrant.tech/blog/indexify-content-extraction-engine/"><meta name=twitter:title content="Indexify Unveiled - Diptanu Gon Choudhury | Vector Space Talks - Qdrant"><meta property="og:description" content="Diptanu Gon Choudhury shares insights on re-imaging Spark and data infrastructure while discussing his work on Indexify to enhance AI-driven workflows and knowledge bases."><meta name=twitter:description content="Diptanu Gon Choudhury shares insights on re-imaging Spark and data infrastructure while discussing his work on Indexify to enhance AI-driven workflows and knowledge bases."><meta name=image property="og:image" content="https://qdrant.tech/blog/indexify-content-extraction-engine/preview/social_preview.jpg"><meta name=image property="og:image:secure_url" content="https://qdrant.tech/blog/indexify-content-extraction-engine/preview/social_preview.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name=twitter:image:src content="https://qdrant.tech/blog/indexify-content-extraction-engine/preview/social_preview.jpg"><meta name=author content="Demetrios Brinkmann"><link rel=canonical href=https://qdrant.tech/blog/indexify-content-extraction-engine/><script type=text/javascript src=//js-eu1.hsforms.net/forms/embed/v2.js></script></head><body><main><header class=site-header><section class=top-banner data-start=1749013200 data-end=1750428000 style=display:none><div><span class=top-banner__icon><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><g clip-path="url(#clip0_770_2716)"><path d="M14.598 6.37199C14.486 6.14399 14.254 5.99999 14 5.99999H8.7447L9.3287.739993C9.36204.44266 9.1927.159993 8.91537.0479934 8.63737-.0653399 8.31937.0226601 8.13737.259327L1.4707 8.92599C1.31604 9.12733 1.2887 9.39933 1.40137 9.62733c.11267.22866.34467.37266.59867.37266H7.25537L6.67137 15.26c-.0333299999999994.2973.136.58.41333.692C7.16537 15.9847 7.25004 16 7.33337 16 7.53604 16 7.73337 15.9073 7.86204 15.74L14.5287 7.07333C14.6834 6.87199 14.71 6.59999 14.598 6.37199z" fill="#8547ff"/></g><defs><clipPath id="clip0_770_2716"><rect width="16" height="16" fill="#fff"/></clipPath></defs></svg> </span><span class=top-banner__text>Learn how TripAdvisor Drives 2-3x More Revenue with Qdrant-Powered AI at Enterprise Scale </span><a data-metric-loc=banner data-metric-label="Learn how TripAdvisor Drives 2-3x More Revenue with Qdrant-Powered AI at Enterprise Scale Read now" class="link link_light link_sm" href=https://qdrant.tech/blog/case-study-tripadvisor/>Read now</a></div></section><div class="main-menu z-2"><a href=https://qdrant.tech/><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div></a><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><button type=button class=main-menu__trigger><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M1 12H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 5H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 19H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=main-menu__links><li class=main-menu__item><span>Products</span><ul class=main-menu__submenu><li class=main-menu__submenu-item><a href=https://qdrant.tech/qdrant-vector-database/><img src=https://qdrant.tech/img/menu/qdrant-vector-database.svg draggable=false>
<span>Qdrant Vector Database</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/cloud/><img src=https://qdrant.tech/img/menu/qdrant-cloud.svg draggable=false>
<span>Qdrant Cloud</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/hybrid-cloud/><img src=https://qdrant.tech/img/menu/hybrid-cloud.svg draggable=false>
<span>Qdrant Hybrid Cloud</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/enterprise-solutions/><img src=https://qdrant.tech/img/menu/qdrant-enterprise-solutions.svg draggable=false>
<span>Qdrant Enterprise Solutions</span></a></li></ul></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/use-cases/>Use Cases</a><ul class=main-menu__submenu><li class=main-menu__section-link><a class="link link_neutral link_sm" href=https://qdrant.tech/use-cases/>Use Cases</a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/rag/><img src=https://qdrant.tech/img/menu/rag.svg draggable=false>
<span>RAG</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/recommendations/><img src=https://qdrant.tech/img/menu/recommendation-systems.svg draggable=false>
<span>Recommendation Systems</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/advanced-search/><img src=https://qdrant.tech/img/menu/advanced-search.svg draggable=false>
<span>Advanced Search</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/data-analysis-anomaly-detection/><img src=https://qdrant.tech/img/menu/data-analysis-anomaly-detection.svg draggable=false>
<span>Data Analysis & Anomaly Detection</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/ai-agents/><img src=https://qdrant.tech/img/menu/ai-agents.svg draggable=false>
<span>AI Agents</span></a></li></ul></li><li class=main-menu__item><span>Developers</span><ul class=main-menu__submenu><li class=main-menu__submenu-item><a href=https://qdrant.tech/documentation/><img src=https://qdrant.tech/img/menu/documentation.svg draggable=false>
<span>Documentation</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/community/><img src=https://qdrant.tech/img/menu/community.svg draggable=false>
<span>Community</span></a></li><li class=main-menu__submenu-item><a href=https://github.com/qdrant/qdrant target=_blank rel="noopener noreferrer nofollow"><img src=https://qdrant.tech/img/menu/github.svg draggable=false>
<span>GitHub</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.to/roadmap target=_blank rel="noopener noreferrer nofollow"><img src=https://qdrant.tech/img/menu/roadmap.svg draggable=false>
<span>Roadmap</span></a></li><li class=main-menu__submenu-item><a href=https://github.com/qdrant/qdrant/releases target=_blank rel="noopener noreferrer nofollow"><img src=https://qdrant.tech/img/menu/changelog.svg draggable=false>
<span>Change Log</span></a></li></ul></li><li class=main-menu__item><span>Resources</span><ul class=main-menu__submenu><li class=main-menu__submenu-item><a href=https://qdrant.tech/benchmarks/><img src=https://qdrant.tech/img/menu/benchmarks.svg draggable=false>
<span>Benchmarks</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/blog/><img src=https://qdrant.tech/img/menu/blog.svg draggable=false>
<span>Blog</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/articles/><img src=https://qdrant.tech/img/menu/articles.svg draggable=false>
<span>Articles</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/demo/><img src=https://qdrant.tech/img/menu/demos.svg draggable=false>
<span>Demos</span></a></li><li class=main-menu__submenu-item><a href=https://try.qdrant.tech/events target=_blank rel="noopener noreferrer nofollow"><img src=https://qdrant.tech/img/menu/partners.svg draggable=false>
<span>Events</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/qdrant-for-startups/><img src=https://qdrant.tech/img/menu/qdrant-for-startups.svg draggable=false>
<span>Startup Program</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/security/bug-bounty-program/><img src=https://qdrant.tech/img/menu/bug-bounty-program.svg draggable=false>
<span>Bug Bounty Program</span></a></li></ul></li><li class=main-menu__item><span>Company</span><ul class=main-menu__submenu><li class=main-menu__submenu-item><a href=https://qdrant.tech/about-us/><img src=https://qdrant.tech/img/menu/about-us.svg draggable=false>
<span>About us</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/customers/><img src=https://qdrant.tech/img/menu/customers.svg draggable=false>
<span>Customers</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/partners/><img src=https://qdrant.tech/img/menu/partners.svg draggable=false>
<span>Partners</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.join.com/ target=_blank rel="noopener noreferrer nofollow"><img src=https://qdrant.tech/img/menu/careers.svg draggable=false>
<span>Careers</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/contact-us/><img src=https://qdrant.tech/img/menu/contact-us.svg draggable=false>
<span>Contact us</span></a></li></ul></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/pricing/>Pricing</a></li></ul><div class=main-menu__buttons><a data-metric-loc=nav href=https://cloud.qdrant.io/login class="menu-link mx-3">Log in</a>
<a data-metric-loc=nav href=https://cloud.qdrant.io/signup class="button button_contained button_sm">Get Started</a></div></div><div class=menu-mobile><div class=menu-mobile__header><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div><button type=button class=menu-mobile__close><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M19.0713 4.92871 4.92915 19.0708" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M19.0713 19.0708 4.9292 4.92871" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__items><li class=menu-mobile__item data-path=menu-0><div class=menu-mobile__item-content>Products
<button type=button class=menu-mobile__expand><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M2 7 12 17 22 7" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__subitems><a href=https://qdrant.tech/qdrant-vector-database/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/qdrant-vector-database.svg)></span>Qdrant Vector Database</li></a><a href=https://qdrant.tech/cloud/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/qdrant-cloud.svg)></span>Qdrant Cloud</li></a><a href=https://qdrant.tech/hybrid-cloud/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/hybrid-cloud.svg)></span>Qdrant Hybrid Cloud</li></a><a href=https://qdrant.tech/enterprise-solutions/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/qdrant-enterprise-solutions.svg)></span>Qdrant Enterprise Solutions</li></a></ul></li><li class=menu-mobile__item data-path=menu-1><div class=menu-mobile__item-content>Use Cases
<button type=button class=menu-mobile__expand><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M2 7 12 17 22 7" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__subitems><li class=menu-mobile__section-link><a class="link link_neutral link_sm" href=https://qdrant.tech/use-cases/>Use Cases</a></li><a href=https://qdrant.tech/rag/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/rag.svg)></span>RAG</li></a><a href=https://qdrant.tech/recommendations/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/recommendation-systems.svg)></span>Recommendation Systems</li></a><a href=https://qdrant.tech/advanced-search/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/advanced-search.svg)></span>Advanced Search</li></a><a href=https://qdrant.tech/data-analysis-anomaly-detection/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/data-analysis-anomaly-detection.svg)></span>Data Analysis & Anomaly Detection</li></a><a href=https://qdrant.tech/ai-agents/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/ai-agents.svg)></span>AI Agents</li></a></ul></li><li class=menu-mobile__item data-path=menu-2><div class=menu-mobile__item-content>Developers
<button type=button class=menu-mobile__expand><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M2 7 12 17 22 7" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__subitems><a href=https://qdrant.tech/documentation/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/documentation.svg)></span>Documentation</li></a><a href=https://qdrant.tech/community/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/community.svg)></span>Community</li></a><a href=https://github.com/qdrant/qdrant><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/github.svg)></span>GitHub</li></a><a href=https://qdrant.to/roadmap><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/roadmap.svg)></span>Roadmap</li></a><a href=https://github.com/qdrant/qdrant/releases><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/changelog.svg)></span>Change Log</li></a></ul></li><li class=menu-mobile__item data-path=menu-3><div class=menu-mobile__item-content>Resources
<button type=button class=menu-mobile__expand><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M2 7 12 17 22 7" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__subitems><a href=https://qdrant.tech/benchmarks/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/benchmarks.svg)></span>Benchmarks</li></a><a href=https://qdrant.tech/blog/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/blog.svg)></span>Blog</li></a><a href=https://qdrant.tech/articles/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/articles.svg)></span>Articles</li></a><a href=https://qdrant.tech/demo/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/demos.svg)></span>Demos</li></a><a href=https://try.qdrant.tech/events><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/partners.svg)></span>Events</li></a><a href=https://qdrant.tech/qdrant-for-startups/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/qdrant-for-startups.svg)></span>Startup Program</li></a><a href=https://qdrant.tech/security/bug-bounty-program/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/bug-bounty-program.svg)></span>Bug Bounty Program</li></a></ul></li><li class=menu-mobile__item data-path=menu-4><div class=menu-mobile__item-content>Company
<button type=button class=menu-mobile__expand><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M2 7 12 17 22 7" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__subitems><a href=https://qdrant.tech/about-us/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/about-us.svg)></span>About us</li></a><a href=https://qdrant.tech/customers/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/customers.svg)></span>Customers</li></a><a href=https://qdrant.tech/partners/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/partners.svg)></span>Partners</li></a><a href=https://qdrant.join.com/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/careers.svg)></span>Careers</li></a><a href=https://qdrant.tech/contact-us/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/contact-us.svg)></span>Contact us</li></a></ul></li><li class=menu-mobile__item data-path=menu-5><div class=menu-mobile__item-content><a href=https://qdrant.tech/pricing/>Pricing</a></div></li></ul><div class=menu-mobile__controls><a data-metric-loc=mobile_nav href=https://cloud.qdrant.io/login class="button button_outlined button_lg menu-mobile__login">Log in</a>
<a data-metric-loc=mobile_nav href=https://cloud.qdrant.io/signup class="button button_contained button_lg">Get Started</a></div></div></header><progress id=progress class=progress-bar value=0 max=100>0</progress><section class="qdrant-post
qdrant-blog-post"><article id=article class=container><div class=qdrant-post__header><h1 class=qdrant-post__title>Indexify Unveiled - Diptanu Gon Choudhury | Vector Space Talks</h1><div class=qdrant-post__about><p>Demetrios Brinkmann</p><span>&#183;</span><p>January 26, 2024</p></div><picture class=qdrant-post__preview><img src=https://qdrant.tech/blog/indexify-content-extraction-engine/preview/title.jpg alt="Indexify Unveiled - Diptanu Gon Choudhury | Vector Space Talks" loading=lazy></picture></div><div class="row qdrant-post__breadcrumbs"><div class=col-12><ul class=breadcrumbs><li class=breadcrumbs__crumb><a href=https://qdrant.tech/>Home</a></li><li class=breadcrumbs__crumb>/</li><li class=breadcrumbs__crumb><a href=https://qdrant.tech/blog/>Blog</a></li><li class=breadcrumbs__crumb>/</li><li class=breadcrumbs__crumb>Indexify Unveiled - Diptanu Gon Choudhury | Vector Space Talks</li></ul></div></div><div class=qdrant-post__body><div class=table-of-contents><p class=table-of-contents__head>On this page:</p><nav id=TableOfContents><ul><li><ul><li><a href=#top-takeaways><strong>Top takeaways:</strong></a></li><li><a href=#show-notes>Show notes:</a></li><li><a href=#more-quotes-from-diptanu>More Quotes from Diptanu:</a></li><li><a href=#transcript>Transcript:</a></li></ul></li></ul></nav><ul class=table-of-contents__external-links><li class=table-of-contents__link><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fqdrant.tech%2Fblog%2Findexify-content-extraction-engine%2F&amp;text=Indexify%20Unveiled%20-%20Diptanu%20Gon%20Choudhury%20%7c%20Vector%20Space%20Talks" target=_blank rel="noopener noreferrer" title=x><svg width="33" height="33" viewBox="0 0 33 33" fill="none"><path d="M14.959 20.7369l-8.581 9.798H1.625l11.114-12.696 2.22 2.898z" fill="#161e33"/><path d="M17.5508 11.5229l7.857-8.98799h4.75L19.7508 14.4369l-2.2-2.914z" fill="#161e33"/><path d="M31.9877 30.5349h-9.559L1.01172 2.53491H10.8127L31.9877 30.5349zm-8.248-2.843h2.632L9.38272 5.22891h-2.824L23.7397 27.6919z" fill="#161e33"/></svg>
Share on X</a></li><li class=table-of-contents__link><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fqdrant.tech%2Fblog%2Findexify-content-extraction-engine%2F" target=_blank rel="noopener noreferrer" title=LinkedIn><svg width="32" height="33" viewBox="0 0 32 33" fill="none"><g clip-path="url(#clip0_1811_16094)"><path d="M30.6667.4375H1.33333C.533333.4375.0.970833.0 1.77083V31.1042C0 31.9042.533333 32.4375 1.33333 32.4375H30.6667C31.4667 32.4375 32 31.9042 32 31.1042V1.77083C32 .970833 31.4667.4375 30.6667.4375zM9.46667 27.7708H4.8V12.4375H9.6V27.7708H9.46667zm-2.4-17.4666c-1.46667.0-2.8-1.20003-2.8-2.80003.0-1.46667 1.2-2.8 2.8-2.8 1.46666.0 2.8 1.2 2.8 2.8s-1.2 2.80003-2.8 2.80003zM27.3333 27.7708h-4.8V20.3042c0-1.7334.0-4-2.4-4-2.5333.0-2.8 1.8666-2.8 3.8666v7.6h-4.8V12.4375h4.5334v2.1333C17.7333 13.3708 19.2 12.1708 21.6 12.1708c4.8.0 5.7333 3.2 5.7333 7.3334v8.2666z" fill="#161e33"/></g><defs><clipPath id="clip0_1811_16094"><rect width="32" height="32" fill="#fff" transform="translate(0 0.4375)"/></clipPath></defs></svg>
Share on LinkedIn</a></li></ul></div><div class=qdrant-post__content><blockquote><p><em>&ldquo;We have something like Qdrant, which is very geared towards doing Vector search. And so we understand the shape of the storage system now.”</em><br>— Diptanu Gon Choudhury</p></blockquote><p>Diptanu Gon Choudhury is the founder of Tensorlake. They are building Indexify - an open-source scalable structured extraction engine for unstructured data to build near-real-time knowledgebase for AI/agent-driven workflows and query engines. Before building Indexify, Diptanu created the Nomad cluster scheduler at Hashicorp, inventor of the Titan/Titus cluster scheduler at Netflix, led the FBLearner machine learning platform, and built the real-time speech inference engine at Facebook.</p><p><em><strong>Listen to the episode on <a href="https://open.spotify.com/episode/6MSwo7urQAWE7EOxO7WTns?si=_s53wC0wR9C4uF8ngGYQlg" target=_blank rel="noopener nofollow">Spotify</a>, Apple Podcast, Podcast addicts, Castbox. You can also watch this episode on <a href=https://youtu.be/RoOgTxHkViA target=_blank rel="noopener nofollow">YouTube</a>.</strong></em></p><iframe width=560 height=315 src="https://www.youtube.com/embed/RoOgTxHkViA?si=r0EjWlssjFDVrzo6" title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
<iframe src=https://podcasters.spotify.com/pod/show/qdrant-vector-space-talk/embed/episodes/Indexify-Unveiled-A-Scalable-and-Near-Real-time-Content-Extraction-Engine-for-Multimodal-Unstructured-Data---Diptanu-Gon-Choudhury--Vector-Space-Talk-009-e2el8qc/a-aas4nil height=102px width=400px frameborder=0 scrolling=no></iframe><h2 id=top-takeaways><strong>Top takeaways:</strong></h2><p>Discover how reimagined data infrastructures revolutionize AI-agent workflows as Diptanu delves into Indexify, transforming raw data into real-time knowledge bases, and shares expert insights on optimizing rag-based applications, all amidst the ever-evolving landscape of Spark.</p><p>Here&rsquo;s What You&rsquo;ll Discover:</p><ol><li><strong>Innovative Data Infrastructure</strong>: Diptanu dives deep into how Indexify is revolutionizing the enterprise world by providing a sharper focus on data infrastructure and a refined abstraction for generative AI this year.</li><li><strong>AI-Copilot for Call Centers</strong>: Learn how Indexify streamlines customer service with a real-time knowledge base, transforming how agents interact and resolve issues.</li><li><strong>Scaling Real-Time Indexing</strong>: discover the system’s powerful capability to index content as it happens, enabling multiple extractors to run simultaneously. It’s all about the right model and the computing capacity for on-the-fly content generation.</li><li><strong>Revamping Developer Experience</strong>: get a glimpse into the future as Diptanu chats with Demetrios about reimagining Spark to fit today&rsquo;s tech capabilities, vastly different from just two years ago!</li><li><strong>AI Agent Workflow Insights</strong>: Understand the crux of AI agent-driven workflows, where models dynamically react to data, making orchestrated decisions in live environments.</li></ol><blockquote><p>Fun Fact: The development of Indexify by Diptanu was spurred by the rising use of Large Language Models in applications and the subsequent need for better data infrastructure to support these technologies.</p></blockquote><h2 id=show-notes>Show notes:</h2><p>00:00 AI&rsquo;s impact on model production and workflows.<br>05:15 Building agents need indexes for continuous updates.<br>09:27 Early RaG and LLMs adopters neglect data infrastructure.<br>12:32 Design partner creating copilot for call centers.<br>17:00 Efficient indexing and generation using scalable models.<br>20:47 Spark is versatile, used for many cases.<br>24:45 Recent survey paper on RAG covers tips.<br>26:57 Evaluation of various aspects of data generation.<br>28:45 Balancing trust and cost in factual accuracy.</p><h2 id=more-quotes-from-diptanu>More Quotes from Diptanu:</h2><p><em>&ldquo;In 2017, when I started doing machine learning, it would take us six months to ship a good model in production. And here we are today, in January 2024, new models are coming out every week, and people are putting them in production.”</em><br>&ndash; Diptanu Gon Choudhury</p><p><em>&ldquo;Over a period of time, you want to extract new information out of existing data, because models are getting better continuously.”</em><br>&ndash; Diptanu Gon Choudhury</p><p><em>&ldquo;We are in the golden age of demos. Golden age of demos with LLMs. Almost anyone, I think with some programming knowledge can kind of like write a demo with an OpenAI API or with an embedding model and so on.”</em><br>&ndash; Diptanu Gon Choudhury</p><h2 id=transcript>Transcript:</h2><p>Demetrios:
We are live, baby. This is it. Welcome back to another vector space talks. I&rsquo;m here with my man Diptanu. He is the founder and creator of Tenterlake. They are building indexify, an open source, scalable, structured extraction engine for unstructured data to build near real time knowledge bases for AI agent driven workflows and query engines. And if it sounds like I just threw every buzzword in the book into that sentence, you can go ahead and say, bingo, we are here, and we&rsquo;re about to dissect what all that means in the next 30 minutes. So, dude, first of all, I got to just let everyone know who is here, that you are a bit of a hard hitter.</p><p>Demetrios:
You&rsquo;ve got some track record under some notches on your belt. We could say before you created Tensorlake, let&rsquo;s just let people know that you were at Hashicorp, you created the nomad cluster scheduler, and you were the inventor of Titus cluster scheduler at Netflix. You led the FB learner machine learning platform and built real time speech inference engine at Facebook. You may be one of the most decorated people we&rsquo;ve had on and that I have had the pleasure of talking to, and that&rsquo;s saying a lot. I&rsquo;ve talked to a lot of people in my day, so I want to dig in, man. First question I&rsquo;ve got for you, it&rsquo;s a big one. What the hell do you mean by AI agent driven workflows? Are you talking to autonomous agents? Are you talking, like the voice agents? What&rsquo;s that?</p><p>Diptanu Gon Choudhury:
Yeah, I was going to say that what a great last couple of years has been for AI. I mean, in context, learning has kind of, like, changed the way people do models and access models and use models in production, like at Facebook. In 2017, when I started doing machine learning, it would take us six months to ship a good model in production. And here we are today, in January 2024, new models are coming out every week, and people are putting them in production. It&rsquo;s a little bit of a Yolo where I feel like people have stopped measuring how well models are doing and just ship in production, but here we are. But I think underpinning all of this is kind of like this whole idea that models are capable of reasoning over data and non parametric knowledge to a certain extent. And what we are seeing now is workflows stop being completely heuristics driven, or as people say, like software 10 driven. And people are putting models in the picture where models are reacting to data that a workflow is seeing, and then people are using models behavior on the data and kind of like making the model decide what should the workflow do? And I think that&rsquo;s pretty much like, to me, what an agent is that an agent responds to information of the world and information which is external and kind of reacts to the information and kind of orchestrates some kind of business process or some kind of workflow, some kind of decision making in a workflow.</p><p>Diptanu Gon Choudhury:
That&rsquo;s what I mean by agents. And they can be like autonomous. They can be something that writes an email or writes a chat message or something like that. The spectrum is wide here.</p><p>Demetrios:
Excellent. So next question, logical question is, and I will second what you&rsquo;re saying. Like the advances that we&rsquo;ve seen in the last year, wow. And the times are a change in, we are trying to evaluate while in production. And I like the term, yeah, we just yoloed it, or as the young kids say now, or so I&rsquo;ve heard, because I&rsquo;m not one of them, but we just do it for the plot. So we are getting those models out there, we&rsquo;re seeing if they work. And I imagine you saw some funny quotes from the Chevrolet chat bot, that it was a chat bot on the Chevrolet support page, and it was asked if Teslas are better than Chevys. And it said, yeah, Teslas are better than Chevys.</p><p>Demetrios:
So yes, that&rsquo;s what we do these days. This is 2024, baby. We just put it out there and test and prod. Anyway, getting back on topic, let&rsquo;s talk about indexify, because there was a whole lot of jargon that I said of what you do, give me the straight shooting answer. Break it down for me like I was five. Yeah.</p><p>Diptanu Gon Choudhury:
So if you are building an agent today, which depends on augmented generation, like retrieval, augmented generation, and given that this is Qdrant&rsquo;s show, I&rsquo;m assuming people are very much familiar with Arag and augmented generation. So if people are building applications where the data is external or non parametric, and the model needs to see updated information all the time, because let&rsquo;s say, the documents under the hood that the application is using for its knowledge base is changing, or someone is building a chat application where new chat messages are coming all the time, and the agent or the model needs to know about what is happening, then you need like an index, or a set of indexes, which are continuously updated. And you also, over a period of time, you want to extract new information out of existing data, because models are getting better continuously. And the other thing is, AI, until now, or until a couple of years back, used to be very domain oriented or task oriented, where modality was the key behind models. Now we are entering into a world where information being encoded in any form, documents, videos or whatever, are important to these workflows that people are building or these agents that people are building. And so you need capability to ingest any kind of data and then build indexes out of them. And indexes, in my opinion, are not just embedding indexes, they could be indexes of semi structured data. So let&rsquo;s say you have an invoice.</p><p>Diptanu Gon Choudhury:
You want to maybe transform that invoice into semi structured data of where the invoice is coming from or what are the line items and so on. So in a nutshell, you need good data infrastructure to store these indexes and serve these indexes. And also you need a scalable compute engine so that whenever new data comes in, you&rsquo;re able to index them appropriately and update the indexes and so on. And also you need capability to experiment, to add new extractors into your platform, add new models into your platform, and so on. Indexify helps you with all that, right? So indexify, imagine indexify to be an online service with an API so that developers can upload any form of unstructured data, and then a bunch of extractors run in parallel on the cluster and extract information out of this unstructured data, and then update indexes on something like Qdrant or postgres for semi structured data continuously.</p><p>Demetrios:
Okay?</p><p>Diptanu Gon Choudhury:
And you basically get that in a single application, in a single binary, which is distributed on your cluster. You wouldn&rsquo;t have any external dependencies other than storage systems, essentially, to have a very scalable data infrastructure for your Rag applications or for your LLM agents.</p><p>Demetrios:
Excellent. So then talk to me about the inspiration for creating this. What was it that you saw that gave you that spark of, you know what? There needs to be something on the market that can handle this. Yeah.</p><p>Diptanu Gon Choudhury:
Earlier this year I was working with founder of a generative AI startup here. I was looking at what they were doing, I was helping them out, and I saw that. And then I looked around, I looked around at what is happening. Not earlier this year as in 2023. Somewhere in early 2023, I was looking at how developers are building applications with llms, and we are in the golden age of demos. Golden age of demos with llms. Almost anyone, I think with some programming knowledge can kind of like write a demo with an OpenAI API or with an embedding model and so on. And I mostly saw that the data infrastructure part of those demos or those applications were very basic people would do like one shot transformation of data, build indexes and then do stuff, build an application on top.</p><p>Diptanu Gon Choudhury:
And then I started talking to early adopters of RaG and llms in enterprises, and I started talking to them about how they&rsquo;re building their data pipelines and their data infrastructure for llms. And I feel like people were mostly excited about the application layer, right? A very less amount of thought was being put on the data infrastructure, and it was almost like built out of duct tape, right, of pipeline, like pipelines and workflows like RabbitMQ, like x, Y and z, very bespoke pipelines, which are good at one shot transformation of data. So you put in some documents on a queue, and then somehow the documents get embedded and put into something like Qdrant. But there was no thought about how do you re index? How do you add a new capability into your pipeline? Or how do you keep the whole system online, right? Keep the indexes online while reindexing and so on. And so classically, if you talk to a distributed systems engineer, they would be, you know, this is a mapreduce problem, right? So there are tools like Spark, there are tools like any skills ray, and they would classically solve these problems, right? And if you go to Facebook, we use Spark for something like this, or like presto, or we have a ton of big data infrastructure for handling things like this. And I thought that in 2023 we need a better abstraction for doing something like this. The world is moving to our server less, right? Developers understand functions. Developer thinks about computers as functions and functions which are distributed on the cluster and can transform content into something that llms can consume.</p><p>Diptanu Gon Choudhury:
And that was the inspiration I was thinking, what would it look like if we redid Spark or ray for generative AI in 2023? How can we make it so easy so that developers can write functions to extract content out of any form of unstructured data, right? You don&rsquo;t need to think about text, audio, video, or whatever. You write a function which can kind of handle a particular data type and then extract something out of it. And now how can we scale it? How can we give developers very transparently, like, all the abilities to manage indexes and serve indexes in production? And so that was the inspiration for it. I wanted to reimagine Mapreduce for generative AI.</p><p>Demetrios:
Wow. I like the vision you sent me over some ideas of different use cases that we can walk through, and I&rsquo;d love to go through that and put it into actual tangible things that you&rsquo;ve been seeing out there. And how you can plug it in to these different use cases. I think the first one that I wanted to look at was building a copilot for call center agents and what that actually looks like in practice. Yeah.</p><p>Diptanu Gon Choudhury:
So I took that example because that was super close to my heart in the sense that we have a design partner like who is doing this. And you&rsquo;ll see that in a call center, the information that comes in into a call center or the information that an agent in a human being in a call center works with is very rich. In a call center you have phone calls coming in, you have chat messages coming in, you have emails going on, and then there are also documents which are knowledge bases for human beings to answer questions or make decisions on. Right. And so they&rsquo;re working with a lot of data and then they&rsquo;re always pulling up a lot of information. And so one of our design partner is like building a copilot for call centers essentially. And what they&rsquo;re doing is they want the humans in a call center to answer questions really easily based on the context of a conversation or a call that is happening with one of their users, or pull up up to date information about the policies of the company and so on. And so the way they are using indexify is that they ingest all the content, like the raw content that is coming in video, not video, actually, like audio emails, chat messages into indexify.</p><p>Diptanu Gon Choudhury:
And then they have a bunch of extractors which handle different type of modalities, right? Some extractors extract information out of emails. Like they would do email classification, they would do embedding of emails, they would do like entity extraction from emails. And so they are creating many different types of indexes from emails. Same with speech. Right? Like data that is coming on through calls. They would transcribe them first using ASR extractor, and from there on the speech would be embedded and the whole pipeline for a text would be invoked into it, and then the speech would be searchable. If someone wants to find out what conversation has happened, they would be able to look up things. There is a summarizer extractor, which is like looking at a phone call and then summarizing what the customer had called and so on.</p><p>Diptanu Gon Choudhury:
So they are basically building a near real time knowledge base of one what is happening with the customer. And also they are pulling in information from their documents. So that&rsquo;s like one classic use case. Now the only dependency now they have is essentially like a blob storage system and serving infrastructure for indexes, like in this case, like Qdrant and postgres. And they have a bunch of extractors that they have written in house and some extractors that we have written, they&rsquo;re using them out of the box and they can scale the system to as much as they need. And it&rsquo;s kind of like giving them a high level abstraction of building indexes and using them in llms.</p><p>Demetrios:
So I really like this idea of how you have the unstructured and you have the semi structured and how those play together almost. And I think one thing that is very clear is how you&rsquo;ve got the transcripts, you&rsquo;ve got the embeddings that you&rsquo;re doing, but then you&rsquo;ve also got documents that are very structured and maybe it&rsquo;s from the last call and it&rsquo;s like in some kind of a database. And I imagine we could say whatever, salesforce, it&rsquo;s in a salesforce and you&rsquo;ve got it all there. And so there is some structure to that data. And now you want to be able to plug into all of that and you want to be able to, especially in this use case, the call center agents, human agents need to make decisions and they need to make decisions fast. Right. So the real time aspect really plays a part of that.</p><p>Diptanu Gon Choudhury:
Exactly.</p><p>Demetrios:
You can&rsquo;t have it be something that it&rsquo;ll get back to you in 30 seconds, or maybe 30 seconds is okay, but really the less time the better. And so traditionally when I think about using llms, I kind of take real time off the table. Have you had luck with making it more real time? Yeah.</p><p>Diptanu Gon Choudhury:
So there are two aspects of it. How quickly can your indexes be updated? As of last night, we can index all of Wikipedia under five minutes on AWS. We can run up to like 5000 extractors with indexify concurrently and parallel. I feel like we got the indexing part covered. Unless obviously you are using a model as behind an API where we don&rsquo;t have any control. But assuming you&rsquo;re using some kind of embedding model or some kind of extractor model, right, like a named entity extractor or an speech to text model that you control and you understand the I Ops, we can scale it out and our system can kind of handle the scale of getting it indexed really quickly. Now on the generation side, that&rsquo;s where it&rsquo;s a little bit more nuanced, right? Generation depends on how big the generation model is. If you&rsquo;re using GPD four, then obviously you would be playing with the latency budgets that OpenAI provides.</p><p>Diptanu Gon Choudhury:
If you&rsquo;re using some other form of models like mixture MoE or something which is very optimized and you have worked on making the model optimized, then obviously you can cut it down. So it depends on the end to end stack. It&rsquo;s not like a single piece of software. It&rsquo;s not like a monolithic piece of software. So it depends on a lot of different factors. But I can confidently claim that we have gotten the indexing side of real time aspects covered as long as the models people are using are reasonable and they have enough compute in their cluster.</p><p>Demetrios:
Yeah. Okay. Now talking again about the idea of rethinking the developer experience with this and almost reimagining what Spark would be if it were created today.</p><p>Diptanu Gon Choudhury:
Exactly.</p><p>Demetrios:
How do you think that there are manifestations in what you&rsquo;ve built that play off of things that could only happen because you created it today as opposed to even two years ago.</p><p>Diptanu Gon Choudhury:
Yeah. So I think, for example, take Spark, right? Spark was born out of big data, like the 2011 twelve era of big data. In fact, I was one of the committers on Apache Mesos, the cluster scheduler that Spark used for a long time. And then when I was at Hashicorp, we tried to contribute support for Nomad in Spark. What I&rsquo;m trying to say is that Spark is a task scheduler at the end of the day and it uses an underlying scheduler. So the teams that manage spark today or any other similar tools, they have like tens or 15 people, or they&rsquo;re using like a hosted solution, which is super complex to manage. Right. A spark cluster is not easy to manage.</p><p>Diptanu Gon Choudhury:
I&rsquo;m not saying it&rsquo;s a bad thing or whatever. Software written at any given point in time reflect the world in which it was born. And so obviously it&rsquo;s from that era of systems engineering and so on. And since then, systems engineering has progressed quite a lot. I feel like we have learned how to make software which is scalable, but yet simpler to understand and to operate and so on. And the other big thing in spark that I feel like is missing or any skills, Ray, is that they are not natively integrated into the data stack. Right. They don&rsquo;t have an opinion on what the data stack is.</p><p>Diptanu Gon Choudhury:
They&rsquo;re like excellent Mapreduce systems, and then the data stuff is layered on top. And to a certain extent that has allowed them to generalize to so many different use cases. People use spark for everything. At Facebook, I was using Spark for batch transcoding of speech, to text, for various use cases with a lot of issues under the hood. Right? So they are tied to the big data storage infrastructure. So when I am reimagining Spark, I almost can take the position that we are going to use blob storage for ingestion and writing raw data, and we will have low latency serving infrastructure in the form of something like postgres or something like clickhouse or something for serving like structured data or semi structured data. And then we have something like Qdrant, which is very geared towards doing vector search and so on. And so we understand the shape of the storage system now.</p><p>Diptanu Gon Choudhury:
We understand that developers want to integrate with them. So now we can control the compute layer such that the compute layer is optimized for doing the compute and producing data such that they can be written in those data stores, right? So we understand the I Ops, right? The I O, what is it called? The I O characteristics of the underlying storage system really well. And we understand that the use case is that people want to consume those data in llms, right? So we can make design decisions such that how we write into those, into the storage system, how we serve very specifically for llms, that I feel like a developer would be making those decisions themselves, like if they were using some other tool.</p><p>Demetrios:
Yeah, it does feel like optimizing for that and recognizing that spark is almost like a swiss army knife. As you mentioned, you can do a million things with it, but sometimes you don&rsquo;t want to do a million things. You just want to do one thing and you want it to be really easy to be able to do that one thing. I had a friend who worked at some enterprise and he was talking about how spark engineers have all the job security in the world, because a, like you said, you need a lot of them, and b, it&rsquo;s hard stuff being able to work on that and getting really deep and knowing it and the ins and outs of it. So I can feel where you&rsquo;re coming from on that one.</p><p>Diptanu Gon Choudhury:
Yeah, I mean, we basically integrated the compute engine with the storage so developers don&rsquo;t have to think about it. Plug in whatever storage you want. We support, obviously, like all the blob stores, and we support Qdrant and postgres right now, indexify in the future can even have other storage engines. And now all an application developer needs to do is deploy this on AWS or GCP or whatever, right? Have enough compute, point it to the storage systems, and then now build your application. You don&rsquo;t need to make any of the hard decisions or build a distributed systems by bringing together like five different tools and spend like five months building the data layer, focus on the application, build your agents.</p><p>Demetrios:
So there is something else. As we are winding down, I want to ask you one last thing, and if anyone has any questions, feel free to throw them in the chat. I am monitoring that also, but I am wondering about advice that you have for people that are building rag based applications, because I feel like you&rsquo;ve probably seen quite a few out there in the wild. And so what are some optimizations or some nice hacks that you&rsquo;ve seen that have worked really well? Yeah.</p><p>Diptanu Gon Choudhury:
So I think, first of all, there is a recent paper, like a rack survey paper. I really like it. Maybe you can have the link on the show notes if you have one. There was a recent survey paper, I really liked it, and it covers a lot of tips and tricks that people can use with Rag. But essentially, Rag is an information. Rag is like a two step process in its essence. One is the document selection process and the document reading process. Document selection is how do you retrieve the most important information out of million documents that might be there, and then the reading process is how do you jam them in the context of a model, and so that the model can kind of ground its generation based on the context.</p><p>Diptanu Gon Choudhury:
So I think the most tricky part here, and the part which has the most tips and tricks is the document selection part. And that is like a classic information retrieval problem. So I would suggest people doing a lot of experimentation around ranking algorithms, hitting different type of indexes, and refining the results by merging results from different indexes. One thing that always works for me is reducing the search space of the documents that I am selecting in a very systematic manner. So like using some kind of hybrid search where someone does the embedding lookup first, and then does the keyword lookup, or vice versa, or does lookups parallel and then merges results together? Those kind of things where the search space is narrowed down always works for me.</p><p>Demetrios:
So I think one of the Qdrant team members would love to know because I&rsquo;ve been talking to them quite frequently about this, the evaluating of retrieval. Have you found any tricks or tips around that and evaluating the quality of what is retrieved?</p><p>Diptanu Gon Choudhury:
So I haven&rsquo;t come across a golden one trick that fits every use case type thing like solution for evaluation. Evaluation is really hard. There are open source projects like ragas who are trying to solve it, and everyone is trying to solve various, various aspects of evaluating like rag exactly. Some of them try to evaluate how accurate the results are, some people are trying to evaluate how diverse the answers are, and so on. I think the most important thing that our design partners care about is factual accuracy and factual accuracy. One process that has worked really well is like having a critique model. So let the generation model generate some data and then have a critique model go and try to find citations and look up how accurate the data is, how accurate the generation is, and then feed that back into the system. One another thing like going back to the previous point is what tricks can someone use for doing rag really well? I feel like people don&rsquo;t fine tune embedding models that much.</p><p>Diptanu Gon Choudhury:
I think if people are using an embedding model, like sentence transformer or anything like off the shelf, they should look into fine tuning the embedding models on their data set that they are embedding. And I think a combination of fine tuning the embedding models and kind of like doing some factual accuracy checks lead to a long way in getting like rag working really well.</p><p>Demetrios:
Yeah, it&rsquo;s an interesting one. And I&rsquo;ll probably leave it here on the extra model that is basically checking factual accuracy. You&rsquo;ve always got these trade offs that you&rsquo;re playing with, right? And one of the trade offs is going to be, maybe you&rsquo;re making another LLM call, which could be more costly, but you&rsquo;re gaining trust or you&rsquo;re gaining confidence that what it&rsquo;s outputting is actually what it says it is. And it&rsquo;s actually factually correct, as you said. So it&rsquo;s like, what price can you put on trust? And we&rsquo;re going back to that whole thing that I saw on Chevy&rsquo;s website where they were saying that a Tesla is better. It&rsquo;s like that hopefully doesn&rsquo;t happen anymore as people deploy this stuff and they recognize that humans are cunning when it comes to playing around with chat bots. So this has been fascinating, man. I appreciate you coming on here and chatting me with it.</p><p>Demetrios:
I encourage everyone to go and either reach out to you on LinkedIn, I know you are on there, and we&rsquo;ll leave a link to your LinkedIn in the chat too. And if not, check out Tensorleg, check out indexify, and we will be in touch. Man, this was great.</p><p>Diptanu Gon Choudhury:
Yeah, same. It was really great chatting with you about this, Demetrius, and thanks for having me today.</p><p>Demetrios:
Cheers. I&rsquo;ll talk to you later.</p></div></div></article></section><section class=get-started-blogs><div class=container><div class=get-started-blogs__content><div class=row><div class="get-started-blogs__text col-12 col-lg-7"><h3 class=get-started-blogs__title>Get Started with Qdrant Free</h3><a href=https://cloud.qdrant.io/signup class="button button_contained" target=_blank>Get Started</a></div><div class="get-started-blogs__image col-12 col-lg-5"><img src=https://qdrant.tech/img/rocket.svg alt></div></div><div class=get-started-blogs__overlay-top></div></div></div></section></main><footer class=footer><div class=footer__top><div class=container><div class="row justify-content-md-between"><div class="col-12 col-md-6"><a href=https://qdrant.tech/ title="Go to Home Page"><img class=footer__top-logo src=https://qdrant.tech/img/logo-white.png alt="Qdrant Logo"></a></div><div class="col-12 col-md-6 footer__top-social-media-platforms"><a class=footer__top-social-media-link href=https://github.com/qdrant/qdrant target=_blank rel="noopener noreferrer nofollow"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><g clip-path="url(#clip0_1841_958)"><path fill-rule="evenodd" clip-rule="evenodd" d="M12 .299805C5.35.299805.0 5.6498.0 12.2998c0 5.3 3.45 9.8 8.2 11.4C8.8 23.7998 9 23.4498 9 23.0998 9 22.7998 9 22.0498 9 21.0498c-3.35.75-4.05-1.6-4.05-1.6-.55-1.4-1.35-1.75-1.35-1.75-1.1-.75.1-.75.1-.75C4.9 17.0498 5.55 18.1998 5.55 18.1998c1.05 1.85 2.8 1.3 3.5 1C9.15 18.3998 9.45 17.8998 9.8 17.5998 7.15 17.2998 4.35 16.2498 4.35 11.6498c0-1.3.45-2.4 1.25-3.2C5.5 8.1498 5.05 6.9498 5.7 5.2498c0 0 1-.3 3.3 1.25C9.95 6.2498 11 6.0998 12 6.0998S14.05 6.2498 15 6.4998c2.3-1.55 3.3-1.25 3.3-1.25C18.95 6.8998 18.55 8.0998 18.4 8.4498c.75.85 1.25 1.9 1.25 3.2.0 4.6-2.8 5.6-5.5 5.9C14.6 17.8998 14.95 18.6498 14.95 19.7498c0 1.6.0 2.9.0 3.3C14.95 23.3498 15.15 23.7498 15.8 23.6498c4.75-1.55 8.2-6.05 8.2-11.35C24 5.6498 18.65.299805 12 .299805z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_1841_958"><rect width="24" height="24" fill="#fff"/></clipPath></defs></svg>
</a><a class=footer__top-social-media-link href=https://qdrant.to/linkedin target=_blank rel="noopener noreferrer nofollow"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><g clip-path="url(#clip0_1841_961)"><path d="M21.75.75H2.25c-.39782.0-.77936.158035-1.06066.43934C.908035 1.47064.75 1.85218.75 2.25v19.5C.75 22.1478.908035 22.5294 1.18934 22.8107 1.47064 23.092 1.85218 23.25 2.25 23.25h19.5C22.1478 23.25 22.5294 23.092 22.8107 22.8107 23.092 22.5294 23.25 22.1478 23.25 21.75V2.25C23.25 1.85218 23.092 1.47064 22.8107 1.18934 22.5294.908035 22.1478.75 21.75.75zM7.41525 19.9455H4.0305V9.1875H7.41525v10.758zM5.7225 7.71075C5.33338 7.70956 4.95333 7.59309 4.63036 7.37604 4.30739 7.15899 4.05599 6.8511 3.9079 6.49126 3.75981 6.13141 3.72167 5.73575 3.79831 5.35425 3.87495 4.97275 4.06293 4.62251 4.3385 4.34778 4.61408 4.07304 4.96488 3.88613 5.34662 3.81065 5.72835 3.73517 6.1239 3.77451 6.48329 3.92369 6.84268 4.07288 7.1498 4.32522 7.36587 4.64885c.21606.32363.33138.70402.33138 1.09315C7.69735 6.00107 7.6463 6.25762 7.54702 6.49691 7.44774 6.73621 7.30219 6.95355 7.11872 7.13646 6.93525 7.31938 6.71746 7.46426 6.47787 7.56282 6.23827 7.66137 5.98157 7.71164 5.7225 7.71075zM19.9657 19.9455H16.65V14.742c0-1.2652.0-2.8125-1.7625-2.8125s-1.9748 1.3365-1.9748 2.742V20.016H9.6V9.1875h3.102v1.4767H12.7725C13.0924 10.1111 13.5567 9.65537 14.1156 9.34571 14.6746 9.03606 15.3072 8.88415 15.9457 8.90625c3.3848.0 4.0193 2.24995 4.0193 5.13295L19.9657 19.9455z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_1841_961"><rect width="24" height="24" fill="#fff"/></clipPath></defs></svg>
</a><a class=footer__top-social-media-link href=https://qdrant.to/twitter target=_blank rel="noopener noreferrer nofollow"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M10.8423 15.1515 4.40655 22.5H.841797L9.1773 12.978l1.665 2.1735z" fill="#f0f3fa"/><path d="M12.7881 8.241 18.6808 1.5h3.5625l-7.8052 8.9265-1.65-2.1855z" fill="#f0f3fa"/><path d="M23.6158 22.5H16.4465L.383789 1.5H7.73454l15.88126 21zm-6.186-2.1322h1.974L6.66204 3.5205h-2.118L17.4298 20.3678z" fill="#f0f3fa"/></svg>
</a><a class=footer__top-social-media-link href=https://qdrant.to/discord target=_blank rel="noopener noreferrer nofollow"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M5 1C2.79086 1 1 2.79086 1 5V19c0 2.2091 1.79086 4 4 4H19c2.2091.0 4-1.7909 4-4V5c0-2.20914-1.7909-4-4-4H5zM16.3683 18.5964S15.8027 17.9208 15.3314 17.3238C16.4701 17.0557 17.4774 16.3935 18.1749 15.4543 17.6098 15.8317 17.0037 16.1438 16.3683 16.3846 15.6374 16.6966 14.873 16.9233 14.0903 17.0602 12.7448 17.3079 11.3649 17.3026 10.0213 17.0445 9.23256 16.8901 8.45954 16.664 7.71193 16.3689 7.08195 16.1284 6.48116 15.8174 5.92097 15.442 6.59328 16.3616 7.56575 17.0173 8.67025 17.2958 8.19895 17.8928 7.61767 18.5998 7.61767 18.5998 4.14571 18.4898 2.82605 16.2091 2.82605 16.2091 2.87704 13.0242 3.65058 9.89242 5.08832 7.05004 6.35356 6.05636 7.89607 5.47998 9.5029 5.40046l.1571.18853c-1.51174.37413-2.92245 1.0768-4.13179 2.05804.0.0.34562-.18853.926900000000001-.4556C7.58438 6.67595 8.78793 6.34193 10.0213 6.20168 10.1093 6.18348 10.1986 6.17297 10.2884 6.17026 11.3412 6.0331 12.4066 6.02255 13.4619 6.13884c1.6595.18933 3.2659.70144 4.7288 1.5075C17.0426 6.71186 15.7093 6.0318 14.2788 5.65114L14.4988 5.39978C16.1056 5.4793 17.6481 6.05568 18.9133 7.04935c1.4378 2.84239 2.2113 5.97415 2.2623 9.15905.0.0-1.3354 2.278-4.8073 2.388zM9.06284 11.2616C8.62563 11.2983 8.21817 11.498 7.9212 11.821 7.62423 12.1439 7.45941 12.5667 7.45941 13.0054c0 .438800000000001.16482.8615.46179 1.1845S8.62563 14.7125 9.06284 14.7493C9.50005 14.7125 9.90751 14.5129 10.2045 14.1899 10.5015 13.8669 10.6663 13.4442 10.6663 13.0054c0-.438699999999999-.1648-.8615-.4618-1.1844C9.90751 11.498 9.50005 11.2983 9.06284 11.2616zm5.73766.0C14.4493 11.2319 14.0974 11.3089 13.7907 11.4825c-.3066.1736-.553699999999999.4358-.7089.7522-.155199999999999.3164-.2112.6723-.1608 1.021C12.9714 13.6045 13.1259 13.93 13.3644 14.1894 13.6028 14.4489 13.9141 14.6304 14.2573 14.71 14.6006 14.7897 14.96 14.7639 15.2883 14.6359c.3284-.1279.6104-.352.8093-.642899999999999C16.2965 13.702 16.4029 13.3578 16.4029 13.0054 16.4124 12.7854 16.3783 12.5657 16.3026 12.3588 16.2269 12.152 16.1112 11.9622 15.962 11.8002 15.8128 11.6381 15.6331 11.5072 15.4332 11.4148 15.2333 11.3223 15.0171 11.2703 14.7971 11.2616H14.8005z" fill="#f0f3fa"/></svg>
</a><a class=footer__top-social-media-link href=https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA target=_blank rel="noopener noreferrer nofollow"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M23.775 7.1999S23.55 5.5499 22.8 4.7999C21.9 3.8249 20.85 3.8249 20.4 3.7499c-3.375-.225-8.4-.225-8.4-.225s-5.025.0-8.4.225C3.15 3.8249 2.1 3.8249 1.2 4.7999c-.75.75-.975 2.4-.975 2.4S0 9.1499.0 11.0999v1.8c0 1.95.225 3.9.225 3.9s.225 1.65.975 2.4C2.1 20.1749 3.3 20.0999 3.825 20.2499 5.775 20.3999 12 20.4749 12 20.4749S17.025 20.4749 20.4 20.2499C20.85 20.1749 21.9 20.1749 22.8 19.1999 23.55 18.4499 23.775 16.7999 23.775 16.7999S24 14.8499 24 12.8999v-1.8C24 9.1499 23.775 7.1999 23.775 7.1999zm-14.25 7.95v-6.75l6.45 3.375-6.45 3.375z" fill="#f0f3fa"/></svg></a></div></div></div></div><div class=footer__menu><div class=container><nav class=footer__menu-content><div class=footer__menu-section><p class=footer__menu-section-title>Products</p><ul class=footer__menu-items><li class=footer__menu-item><a href=https://qdrant.tech/qdrant-vector-database/>Qdrant Vector Database</a></li><li class=footer__menu-item><a href=https://qdrant.tech/cloud/>Qdrant Cloud</a></li><li class=footer__menu-item><a href=https://qdrant.tech/hybrid-cloud/>Qdrant Hybrid Cloud</a></li><li class=footer__menu-item><a href=https://qdrant.tech/enterprise-solutions/>Qdrant Enterprise Solutions</a></li><li class=footer__menu-item><a href=https://qdrant.tech/pricing/>Pricing</a></li></ul></div><div class=footer__menu-section><p class=footer__menu-section-title>Use Cases</p><ul class=footer__menu-items><li class=footer__menu-item><a href=https://qdrant.tech/advanced-search/>Advanced Search</a></li><li class=footer__menu-item><a href=https://qdrant.tech/recommendations/>Recommendation Systems</a></li><li class=footer__menu-item><a href=https://qdrant.tech/rag/>Retrieval Augmented Generation</a></li><li class=footer__menu-item><a href=https://qdrant.tech/data-analysis-anomaly-detection/>Data Analysis & Anomaly Detection</a></li><li class=footer__menu-item><a href=https://qdrant.tech/ai-agents/>AI Agents</a></li></ul></div><div class=footer__menu-section><p class=footer__menu-section-title>Developers</p><ul class=footer__menu-items><li class=footer__menu-item><a href=https://qdrant.tech/documentation/>Documentation</a></li><li class=footer__menu-item><a href=https://qdrant.tech/community/>Community</a></li><li class=footer__menu-item><a href=https://github.com/qdrant/qdrant target=_blank rel="noopener noreferrer nofollow">GitHub</a></li><li class=footer__menu-item><a href=https://qdrant.to/roadmap target=_blank rel="noopener noreferrer nofollow">Roadmap</a></li><li class=footer__menu-item><a href=https://github.com/qdrant/qdrant/releases target=_blank rel="noopener noreferrer nofollow">Change Log</a></li><li class=footer__menu-item><a href=https://status.qdrant.io/ target=_blank rel="noopener noreferrer nofollow">Status Page</a></li></ul></div><div class=footer__menu-section><p class=footer__menu-section-title>Resources</p><ul class=footer__menu-items><li class=footer__menu-item><a href=https://qdrant.tech/blog/>Blog</a></li><li class=footer__menu-item><a href=https://qdrant.tech/benchmarks/>Benchmarks</a></li><li class=footer__menu-item><a href=https://qdrant.tech/articles/>Articles</a></li><li class=footer__menu-item><a href=https://try.qdrant.tech/events target=_blank rel="noopener noreferrer nofollow">Events</a></li><li class=footer__menu-item><a href=https://qdrant.tech/qdrant-for-startups/>Startup Program</a></li><li class=footer__menu-item><a href=https://qdrant.tech/demo/>Demos</a></li><li class=footer__menu-item><a href=https://qdrant.tech/security/bug-bounty-program/>Bug Bounty</a></li></ul></div><div class=footer__menu-section><p class=footer__menu-section-title>Company</p><ul class=footer__menu-items><li class=footer__menu-item><a href=https://qdrant.tech/about-us/>About Us</a></li><li class=footer__menu-item><a href=https://qdrant.tech/customers/>Customers</a></li><li class=footer__menu-item><a href=https://qdrant.tech/partners/>Partners</a></li><li class=footer__menu-item><a href=https://qdrant.join.com/ target=_blank rel="noopener noreferrer nofollow">Careers</a></li><li class=footer__menu-item><a href=https://qdrant.tech/contact-us/>Contact Us</a></li></ul></div></nav></div></div><div class=footer__middle><div class=container><div class="align-items-center row"><div class="col-12 col-lg-5"><p class=footer__middle-title>Sign up for Qdrant updates</p><p class=footer__middle-subtitle>We'll occasionally send you best practices for using vector data and similarity search, as well as product news.</p></div><div class="footer__middle-newsletter col-12 col-lg-7"><div id=footer-subscribe-form><script>(function(){const t={region:"eu1",portalId:"139603372",formId:"049d96c6-ef65-4e41-ba69-a3335b9334cf",cssClass:"subscribe-form",submitButtonClass:"button button_contained button_lg",submitText:"Subscribe"},n="weh",s=function(){const e=document.createElement("input");return e.classList.add(n),e.type="text",e.name="my-work-email",e.style.display="none",e.placeholder="Email",e.ariaHidden="true",e},o=function(e){const t=s();e.appendChild(t);const n=e.querySelector('[type="submit"]');t.addEventListener("input",function(){t.value.length>0&&(n.disabled=!0)})},i=["Argentina","Belgium","Canada","Czech Republic","Cyprus","Denmark","Germany","Hungary","Latvia","Liechtenstein","Luxembourg","Netherlands","Norway","France","Finland","Croatia","Bulgaria","Belarus","Bosnia and Herzegovina","Austria","Estonia","Georgia","Greenland","Hong Kong","Israel","Italy","Maldives","Moldova","Monaco","Portugal","Russia","Serbia","Slovakia","Slovenia","Sweden","Switzerland","Türkiye","Ukraine","Macedonia (FYROM)","United Kingdom"];function e(e){const a=e.querySelector('select[name="country"]'),n=e.querySelector(".legal-consent-container .hs-fieldtype-booleancheckbox"),r=e.querySelector(".legal-consent-container > div:nth-child(3)"),c=e.querySelector(".legal-consent-container > div:nth-child(2)");if(!a||!n)return;const s=a.value,l=i.includes(s),o=s&&l,t=n.querySelector('input[type="checkbox"]');n.style.display=o?"block":"none",r&&(r.style.display=o?"block":"none"),c&&(c.style.display=o?"none":"block"),s&&!l?t.checked||t.click():t.checked&&t.click()}try{hbspt.forms.create({...t,formInstanceId:"#footer-subscribe-form",pageId:"",target:"#footer-subscribe-form",onFormReady:function(t){if(!t){console.warn("Form not found.");return}o(t),e(t);const n=t.querySelector('select[name="country"]');n&&n.addEventListener("change",()=>e(t))}})}catch{document.getElementById("footer-subscribe-form").innerHTML='<p class="text-white">Here should be a form but looks like it was blocked on your side. Please, check your trackers blocking policy.</p>'}})()</script></div></div></div></div></div><div class=footer__bottom><div class=container><div class="row g-3"><div class="col-12 col-lg-6 footer__bottom-content"><span class=footer__bottom-copyright>© 2025 Qdrant.</span><div class=footer__bottom-bages><a href=http://qdrant.to/trust-center target=_blank><img src=https://qdrant.tech/img/soc2-badge.png alt=SOC2>
</a><a href=https://heydata.eu/ target=_blank><img src=https://qdrant.tech/img/gdpr-badge.png alt="heyData GDPR">
</a><a href=https://qdrant.tech/# target=_blank><img src=https://qdrant.tech/img/dark-gdpr-badge.png alt=GDPR>
</a><a href=https://qdrant.tech/# target=_blank><img src=https://qdrant.tech/img/hipaa-badge.png alt=HIPAA></a></div></div><div class="col-12 col-lg-6 footer__bottom-links"><a href=https://qdrant.tech/legal/terms_and_conditions/>Terms</a>
<a href=https://qdrant.tech/legal/privacy-policy/>Privacy Policy</a>
<a href=https://qdrant.tech/legal/impressum/>Impressum</a></div></div></div></div></footer><button class="d-none button button_outlined go-to-top-button" id=scrollToTopBtn title="Go to top">Up!</button>
</body><script src=https://cdn.cookielaw.org/scripttemplates/otSDKStub.js type=text/javascript data-domain-script=01960152-5e40-782d-af01-f7f5768a214e></script><script async type=text/javascript>function OptanonWrapper(){const e=new CustomEvent("onetrust_loaded");document.dispatchEvent(e)}</script><script>!function(){const o="eQYi1nZE2zQSmnHuxjMRlDd2uLl65oHe";var n,s,t="analytics",e=window[t]=window[t]||[];if(!e.initialize)if(e.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{e.invoked=!0,e.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","debug","page","screen","once","off","on","addSourceMiddleware","addIntegrationMiddleware","setAnonymousId","addDestinationMiddleware","register"],e.factory=function(n){return function(){if(window[t].initialized)return window[t][n].apply(window[t],arguments);var o,s=Array.prototype.slice.call(arguments);return["track","screen","alias","group","page","identify"].indexOf(n)>-1&&(o=document.querySelector("link[rel='canonical']"),s.push({__t:"bpc",c:o&&o.getAttribute("href")||void 0,p:location.pathname,u:location.href,s:location.search,t:document.title,r:document.referrer})),s.unshift(n),e.push(s),e}};for(n=0;n<e.methods.length;n++)s=e.methods[n],e[s]=e.factory(s);e.load=function(n,s){var i,o=document.createElement("script");o.type="text/javascript",o.async=!0,o.setAttribute("data-global-segment-analytics-key",t),o.src="https://evs.analytics.qdrant.tech/5caWuitPgcGFN5Q7HMpTaj/vEkmzjuRSqeXGbhGAFTWex.min.js",i=document.getElementsByTagName("script")[0],i.parentNode.insertBefore(o,i),e._loadOptions=s},e._writeKey=o,e._cdn="https://evs.analytics.qdrant.tech",e.SNIPPET_VERSION="5.2.0",e.load(o)}}()</script><script src=https://qdrant.tech/js/google-setup.min.14728a3ae9bd931593645b6ddbfe801d400cd2970006e782cb67f3966654248ca962dbaf4cf371493a2d326861b3a691a99d6d8349c8b2752339ab91d3787069.js></script><script src=https://qdrant.tech/js/index.min.e37feda1952d752f5568e1ebc55e183629e4d361f4df09edeed70b4a4327d601161c4147bdbe4149b4a3cdc1ed43f1bf1a2f2340a421f1aa821103980dfe0bda.js></script><script src=https://qdrant.tech/js/search/scroll.min.f4ed4453a3af0adb0d4f49333cbb7892ff5430483a567d0d2dfbd4655fb203d22f22f46aff3d9f38fa5fd96dde5f30227afd0ce1d9f838f5cd5295fc83856ec9.js></script><script src=https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js></script><script src=https://qdrant.tech/js/copy-code.min.95b03a45b2ab4b7a608ecfd4b5919c8572a5b2cd1463f52561cd10976abf3b74334f91324c0e620cb80afac46026a0b18cce6fb753d8495f74c6d478c8ca1d03.js></script><script src=https://qdrant.tech/js/lang-switcher.min.63da11cef09772078425b1ee56415b9c37842a9399f2ba2d2f5efbf72fb751686c410bd50e9bcd283c8231cb97c1973199d4923beef29d8b06e59d9983a6ba51.js></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src=https://qdrant.tech/js/vendor/anchor.min.0e138e17ebcf1c1147a7a3a81d9ac3c601622eedc479f1636470eb2552470f4e27c9a8efe6e8378995dedc1ab67029d8989536ea76f0857d45d1615ae772b8a1.js></script><script>document.addEventListener("keydown",function(e){if((e.metaKey||e.ctrlKey)&&e.key==="k"){e.preventDefault();let t=document.querySelector('[data-target="#searchModal"]');t&&t?.click()}})</script><script>document.addEventListener("scroll",()=>{const e=document.getElementById("article"),t=document.getElementById("progress"),n=e.scrollHeight-window.innerHeight,s=window.scrollY-e.offsetTop;t.value=Math.min(Math.max(s/n*100,0),100)})</script><script>window.addEventListener("message",e=>{if(e.data.type==="hsFormCallback"&&e.data.eventName==="onFormReady"){const t=document.querySelector(`form[data-form-id="${e.data.id}"]`);if(t){const e=t.querySelector('[name="last_form_fill_url"]');e&&(e.value=window.location.href);const n=t.querySelector('[name="referrer_url"]');n&&(n.value=document.referrer)}}})</script></html>