<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta charset=UTF-8><title>Reranking in Semantic Search - Qdrant</title>
<link rel=icon href=https://qdrant.tech/favicon/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=https://qdrant.tech/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://qdrant.tech/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://qdrant.tech/favicon/favicon-16x16.png><link rel=manifest href=https://qdrant.tech/favicon/site.webmanifest><link rel=mask-icon href=https://qdrant.tech/favicon/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#2b5797"><meta name=msapplication-config content="/favicon/browserconfig.xml"><meta name=theme-color content="#ffffff"><meta name=partition content="build"><link href=https://qdrant.tech/css/search/search.min.09596ee2b3c94d0ac82a1c33199cabdb3e0210b1ee46aaf1515200e9e484d05dd9e27cc1e861c58cc2e582af162f63b8e180ff2a12f7a6592b7aeaa0a7125130.css rel=stylesheet integrity="sha512-CVlu4rPJTQrIKhwzGZyr2z4CELHuRqrxUVIA6eSE0F3Z4nzB6GHFjMLlgq8WL2O44YD/KhL3plkreuqgpxJRMA=="><link href=https://qdrant.tech/css/documentation.min.de204cdcfc410689a41c17bcdad0a34f2caaa50cc8505c820adaab481cef2d69a920b0a32e0d624701c29487e3271b694559d98c5047cbfaa5aa475f638011e5.css rel=stylesheet integrity="sha512-3iBM3PxBBomkHBe82tCjTyyqpQzIUFyCCtqrSBzvLWmpILCjLg1iRwHClIfjJxtpRVnZjFBHy/qlqkdfY4AR5Q=="><meta name=generator content="Hugo 0.141.0"><meta name=description content="Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API."><meta name=keywords content="vector search engine,neural network,matching,SaaS,approximate nearest neighbor search,image search,recommender system,vectors,knn algorithm,hnsw,vector search,embeddings,similarity,simaes networks,BERT,transformer,word2vec,fasttext,qdrant"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@id":"https://qdrant.tech/documentation/search-precision/reranking-semantic-search/#article","@type":"Article","abstract":"Reranking in RAG with Qdrant Vector Database In RetrievalAugmented Generation RAG systems irrelevant or missing information can throw off your modelrsquos ability to produce accurate meaningful outputs One of the best ways to ensure yoursquore feeding your language model the most relevant contextrich documents is through reranking Its a gamechangerIn this guide well dive into using reranking to boost the relevance of search results in Qdrant Well start with an easy use case that leverages the Cohere Rerank model Then well take it up a notch by exploring ColBERT for a more advanced approach By the time youre done youll know how to implement hybrid search finetune reranking models and significantly improve your accuracy","author":{"@type":"Organization","name":"Qdrant","url":"https://qdrant.tech/"},"dateModified":"0001-01-01 00:00:00 +0000 UTC","datePublished":"0001-01-01 00:00:00 +0000 UTC","description":"","headline":"Reranking in Semantic Search","image":[""],"name":"Reranking in Semantic Search","url":"https://qdrant.tech/documentation/search-precision/reranking-semantic-search/","wordCount":"3319"},{"@id":"https://qdrant.tech/documentation/search-precision/reranking-semantic-search/#organization","@type":"Organization","address":{"@type":"PostalAddress","addressCountry":"DE","addressLocality":"Berlin","addressRegion":"Berlin","postalCode":"10115","streetAddress":"Chausseestra√üe 86"},"contactPoint":{"@type":"ContactPoint","contactType":"customer support","email":"info@qdrant.com","telephone":"+49 3040797694"},"description":"Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.","email":"info@qdrant.com","founders":[{"@type":"Person","name":"map[email:info@qdrant.tech name:Andrey Vasnetsov]"},{"@type":"Person","name":"Andre Zayarni"}],"foundingDate":"2021","keywords":["vector search engine","neural network","matching","SaaS","approximate nearest neighbor search","image search","recommender system","vectors","knn algorithm","hnsw","vector search","embeddings","similarity","simaes networks","BERT","transformer","word2vec","fasttext","Qdrant"],"legalName":"Qdrant Solutions GmbH","location":"Berlin, Germany","logo":"https://qdrant.tech/images/logo_with_text.png","name":"Qdrant","sameAs":["https://github.com/qdrant/qdrant","https://qdrant.to/discord","https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA","https://www.linkedin.com/company/qdrant/","https://twitter.com/qdrant_engine"],"url":"https://qdrant.tech"}]}</script><meta property="og:url" content="https://qdrant.tech/documentation/search-precision/reranking-semantic-search/"><meta property="og:type" content="website"><meta property="og:title" content="Reranking in Semantic Search - Qdrant"><meta name=twitter:card content="summary_large_image"><meta name=twitter:domain content="qdrant"><meta name=twitter:url content="https://qdrant.tech/documentation/search-precision/reranking-semantic-search/"><meta name=twitter:title content="Reranking in Semantic Search - Qdrant"><meta property="og:description" content="Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API."><meta name=twitter:description content="Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API."><meta name=image property="og:image" content="https://qdrant.tech/images/previews/social-preview-E.png"><meta name=image property="og:image:secure_url" content="https://qdrant.tech/images/previews/social-preview-E.png"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name=twitter:image:src content="https://qdrant.tech/images/previews/social-preview-E.png"><link rel=canonical href=https://qdrant.tech/documentation/search-precision/reranking-semantic-search/><script type=text/javascript src=//js-eu1.hsforms.net/forms/embed/v2.js></script><script src=https://qdrant.tech/js/documentation.min.594fc9226f6fb87b8c3b0cafb9d5c0b0bcd95f47d292b929aab04315e0506706b2f376dc4fae9961dc3082138cb19d45b2a3370ee8e881bbf4b8c91dcb735c32.js></script></head><body><main><header class=docs-header><div class="main-menu z-5"><a href=https://qdrant.tech/><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div></a><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><div class="d-block d-xl-none"><button role=button class=theme-switch></button></div><button type=button class=main-menu__trigger><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M1 12H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 5H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 19H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=main-menu__links><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/>Qdrant</a></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/cloud-intro/>Cloud</a></li><li class=main-menu__item><a class=menu-linkactive href=https://qdrant.tech/documentation/build/>Build</a></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/articles/>Learn</a></li><li class=main-menu__item><a class=menu-link href=https://api.qdrant.tech/api-reference target=_blank>API Reference</a></li></ul><div class=main-menu__buttons><div class=main-menu__buttons-input><button class="qdr-search-input-btn q-input input_md input_light-bg" type=button name=search data-target=#searchModal>
Search</button></div><button role=button class=theme-switch></button>
<a data-metric-loc=nav href=https://cloud.qdrant.io/login class="menu-link mx-3" target=_blank>Log in</a>
<a data-metric-loc=nav href=https://cloud.qdrant.io/signup class="button button_contained button_sm" target=_blank>Start Free</a></div></div><div class=menu-mobile><div class=menu-mobile__header><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><div class="d-block d-xl-none"><button role=button class=theme-switch></button></div><button type=button class=menu-mobile__close><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><g id="Close"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M19.778 5.63606C20.1685 5.24554 20.1685 4.61237 19.778 4.22185 19.3874 3.83132 18.7543 3.83132 18.3637 4.22185L11.9998 10.5858 5.63586 4.22185c-.39052-.39053-1.02369-.39053-1.41421.0C3.83112 4.61237 3.83112 5.24554 4.22165 5.63606L10.5856 12l-6.364 6.364C3.83108 18.7545 3.83108 19.3877 4.2216 19.7782 4.61213 20.1687 5.24529 20.1687 5.63582 19.7782l6.36398-6.364 6.364 6.364C18.7543 20.1687 19.3875 20.1687 19.778 19.7782 20.1685 19.3877 20.1685 18.7545 19.778 18.364L13.414 12l6.364-6.36394z" fill="#e1e5f0"/></g></svg></button></div></div><div class=main-menu__buttons-input><button class="qdr-search-input-btn q-input input_md input_light-bg" type=button name=search data-target=#searchModal>
Search</button></div><ul class=menu-mobile__items><li class=menu-mobile__item data-path=menu-0><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Documentation"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M4.25 1c-1.10092.0-2.12247.23681-2.88689.64443C.620129 2.04063.0 2.67297.0 3.5v11c0 .2761.223858.5.5.5s.5-.2239.5-.5c0-.278.21937-.6456.83364-.9732C2.42647 13.2107 3.27992 13 4.25 13 5.22008 13 6.07353 13.2107 6.66636 13.5268c.61427.3276.83364.6952.83364.9732.0.2761.22386.5.5.5s.5-.2239.5-.5c0-.278.21937-.6456.833640000000001-.9732C9.92647 13.2107 10.7799 13 11.75 13S13.5735 13.2107 14.1664 13.5268C14.7806 13.8544 15 14.222 15 14.5c0 .2761.2239.5.5.5s.5-.2239.5-.5V3.5C16 2.67297 15.3799 2.04063 14.6369 1.64443 13.8725 1.23681 12.8509 1 11.75 1s-2.12247.23681-2.88689.64443C8.53799 1.8178 8.2364 2.03638 8 2.29671c-.2364-.26033-.53799-.47891-.86311-.65228C6.37247 1.23681 5.35092 1 4.25 1zM1.36311 12.6444C1.23778 12.7113 1.11595 12.7848 1 12.8649V3.5c0-.27797.21937-.64563.83364-.97318C2.42647 2.21069 3.27992 2 4.25 2c.97008.0 1.82353.21069 2.41636.52682C7.28063 2.85437 7.5 3.22203 7.5 3.5v9.3649C7.38405 12.7848 7.26222 12.7113 7.13689 12.6444 6.37247 12.2368 5.35092 12 4.25 12 3.14908 12 2.12753 12.2368 1.36311 12.6444zM8.5 12.8649C8.61595 12.7848 8.73778 12.7113 8.86311 12.6444 9.62753 12.2368 10.6491 12 11.75 12S13.8725 12.2368 14.6369 12.6444C14.7622 12.7113 14.8841 12.7848 15 12.8649V3.5C15 3.22203 14.7806 2.85437 14.1664 2.52682 13.5735 2.21069 12.7201 2 11.75 2s-1.82353.21069-2.41636.52682C8.71937 2.85437 8.5 3.22203 8.5 3.5v9.3649z"/></g></svg>
Qdrant</a></div></li><li class=menu-mobile__item data-path=menu-1><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/cloud-intro/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Cloud"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M7.5 2C4.57416 2 2.18128 4.28566 2.00983 7.16851.8403 7.57763.0 8.68965.0 10c0 1.6571 1.34286 3 3 3H13c1.6571.0 3-1.3429 3-3 0-1.65714-1.3429-3-3-3L12.9776 7.00009C12.7249 4.19714 10.3686 2 7.5 2zM3.00107 7.48137 3.00008 7.47308C3.01457 5.0006 5.02412 3 7.5 3c2.47599.0 4.4856 2.00079 4.4999 4.47342L11.9987 7.4836C11.9969 7.50027 11.995 7.52348 11.995 7.551 11.995 7.701 12.0623 7.84308 12.1785 7.93804 12.2946 8.03301 12.4472 8.07082 12.5942 8.04106 12.726 8.01438 12.8617 8 13 8c1.1049.0 2 .89514 2 2C15 11.1049 14.1049 12 13 12H3C1.89514 12 1 11.1049 1 10 1 9.03225 1.68901 8.22422 2.60364 8.04017 2.83708 7.9932 3.005 7.78812 3.005 7.55 3.005 7.52154 3.00291 7.49773 3.00107 7.48137z"/></g></svg>
Cloud</a></div></li><li class=menu-mobile__item data-path=menu-2><div class=menu-mobile__item-content><a class=active href=https://qdrant.tech/documentation/build/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Blog"><path id="Union" fill-rule="evenodd" clip-rule="evenodd" d="M0 1.5C0 1.22386.223858 1 .5 1h5c.27614.0.5.22386.5.5v5c0 .27614-.22386.5-.5.5H.5C.223858 7 0 6.77614.0 6.5v-5zM1 2V6H5V2H1zm7 .5c0-.27614.22386-.5.5-.5h7c.2761.0.5.22386.5.5s-.2239.5-.5.5h-7C8.22386 3 8 2.77614 8 2.5zM8.5 6c-.27614.0-.5.22386-.5.5s.22386.5.5.5h7c.2761.0.5-.22386.5-.5s-.2239-.5-.5-.5h-7zM0 10.5c0-.2761.223858-.5.5-.5h15c.2761.0.5.2239.5.5s-.2239.5-.5.5H.5c-.276142.0-.5-.2239-.5-.5zM.5 14c-.276142.0-.5.2239-.5.5s.223858.5.5.5h15c.2761.0.5-.2239.5-.5s-.2239-.5-.5-.5H.5z"/></g></svg>
Build</a></div></li><li class=menu-mobile__item data-path=menu-3><div class=menu-mobile__item-content><a href=https://qdrant.tech/articles/><svg width="16" height="16" viewBox="0 0 16 16" fill="none" stroke="#e1e5f0"><g id="Group"><path id="Vector" d="M10.084 1.84094l4.059 4.059" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_2" d="M8.49188 2.72406c-1.22044-.53042-2.59304-.59475-3.85774-.1808-1.2647.41395-2.33363 1.27742-3.00426 2.4268l2.34 2.34" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_3" d="M13.2657 7.47302C13.8062 8.69691 13.8769 10.077 13.4645 11.3497c-.4125 1.2728-1.2792 2.3491-2.4348 3.0233l-2.35001-2.35" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_4" d="M6.81217 13.049l-3.861-3.861S6.24917.983 15.5002.5c-.523 9.211-8.68803 12.549-8.68803 12.549z" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_5" d="M3.59892 12.4008C3.34181 12.1441 2.99331 12 2.62995 12c-.36335.0-.71186.1441-.96897.4008-.46665.4664-.63131 1.941-.65931 2.2322C.997021 14.6793 1.0021 14.726 1.01659 14.7701 1.03108 14.8143 1.05465 14.8549 1.08579 14.8895 1.11693 14.924 1.15495 14.9516 1.19741 14.9705 1.23987 14.9895 1.28583 14.9994 1.33233 14.9995 1.34298 15.0002 1.35367 15.0002 1.36433 14.9995 1.65565 14.9715 3.1316 14.8063 3.59759 14.3405 3.85501 14.0834 3.99975 13.7346 4 13.3709 4.00025 13.0072 3.85599 12.6582 3.59892 12.4008z" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_6" d="M9 8c.55228.0 1-.44772 1-1S9.55228 6 9 6 8 6.44772 8 7s.44772 1 1 1z"/></g></svg>
Learn</a></div></li><li class=menu-mobile__item data-path=menu-4><div class=menu-mobile__item-content><a href=https://api.qdrant.tech/api-reference target=_blank><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Roadmap" clip-path="url(#clip0_7182_4311)"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M13.5 1c-.8284.0-1.5.67157-1.5 1.5S12.6716 4 13.5 4 15 3.32843 15 2.5 14.3284 1 13.5 1zM11 2.5C11 1.11929 12.1193.0 13.5.0S16 1.11929 16 2.5 14.8807 5 13.5 5 11 3.88071 11 2.5zM2.5 12c-.82843.0-1.5.6716-1.5 1.5S1.67157 15 2.5 15 4 14.3284 4 13.5 3.32843 12 2.5 12zM0 13.5C0 12.1193 1.11929 11 2.5 11S5 12.1193 5 13.5 3.88071 16 2.5 16 0 14.8807.0 13.5zM3.65901 1.65901C4.08097 1.23705 4.65326 1 5.25 1s1.16903.23705 1.59099.65901C7.26295 2.08097 7.5 2.65326 7.5 3.25v9.5c0 .862.34241 1.6886.9519 2.2981C9.0614 15.6576 9.88805 16 10.75 16c.862.0 1.6886-.3424 2.2981-.9519S14 13.612 14 12.75V6.5c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v6.25C13 13.3467 12.7629 13.919 12.341 14.341 11.919 14.7629 11.3467 15 10.75 15S9.58097 14.7629 9.15901 14.341C8.73705 13.919 8.5 13.3467 8.5 12.75V3.25C8.5 2.38805 8.15759 1.5614 7.5481.951903 6.9386.34241 6.11195.0 5.25.0S3.5614.34241 2.9519.951903C2.34241 1.5614 2 2.38805 2 3.25V9.5c0 .27614.22386.5.5.5s.5-.22386.5-.5V3.25c0-.59674.23705-1.16903.65901-1.59099z"/></g><defs><clipPath id="clip0_7182_4311"><rect width="16" height="16" fill="#fff"/></clipPath></defs></svg>
API Reference</a></div></li></ul><div class=docs-menu><div id=sidebar class=docs-menu__content><nav class=docs-menu__links><h3 class=docs-menu__links-title>Essentials</h3><div class=docs-menu__links-group><div class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/data-ingestion-beginners/>Data Ingestion for Beginners</a></div></div><div class=docs-menu__links-group><div class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/agentic-rag-crewai-zoom/>Simple Agentic RAG System</a></div></div><div class=docs-menu__links-group><div class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/agentic-rag-langgraph/>Agentic RAG With LangGraph</a></div></div><div class=docs-menu__links-group><div class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/agentic-rag-camelai-discord/>Agentic RAG Discord Bot with CAMEL-AI</a></div></div><div class=docs-menu__links-group><div class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/multimodal-search/>Multilingual & Multimodal RAG with LlamaIndex</a></div></div><div class=docs-menu__links-group><div class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/rag-deepseek/>5 Minute RAG with Qdrant and DeepSeek</a></div></div><h3 class=docs-menu__links-title>Integrations</h3><details class="docs-menu__links-group link-group"><summary class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/data-management/>Data Management</a></summary><nav><ul class=docs-menu__links-submenu><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/airbyte/>Airbyte</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/airflow/>Apache Airflow</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/nifi/>Apache NiFi</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/spark/>Apache Spark</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/cocoindex/>CocoIndex</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/cognee/>cognee</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/confluent/>Confluent Kafka</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/dlt/>DLT</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/fondant/>Fondant</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/fluvio/>InfinyOn Fluvio</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/mindsdb/>MindsDB</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/redpanda/>Redpanda Connect</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/unstructured/>Unstructured</a></li></ul></nav></details><details class="docs-menu__links-group link-group"><summary class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/embeddings/>Embeddings</a></summary><nav><ul class=docs-menu__links-submenu><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/aleph-alpha/>Aleph Alpha</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/bedrock/>AWS Bedrock</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/cohere/>Cohere</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/gemini/>Gemini</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/jina-embeddings/>Jina Embeddings</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/mistral/>Mistral</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/mixedbread/>MixedBread</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/mixpeek/>Mixpeek</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/nomic/>Nomic</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/nvidia/>Nvidia</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/ollama/>Ollama</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/openai/>OpenAI</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/premai/>Prem AI</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/snowflake/>Snowflake Models</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/twelvelabs/>Twelve Labs</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/upstage/>Upstage</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/voyage/>Voyage AI</a></li></ul></nav></details><details class="docs-menu__links-group link-group"><summary class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/frameworks/>Frameworks</a></summary><nav><ul class=docs-menu__links-submenu><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/autogen/>Autogen</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/lakechain/>AWS Lakechain</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/camel/>CamelAI</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/cheshire-cat/>Cheshire Cat</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/crewai/>CrewAI</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/dagster/>Dagster</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/deepeval/>DeepEval</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/docarray/>DocArray</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/dsrag/>dsRAG</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/dynamiq/>Dynamiq</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/feast/>Feast</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/fifty-one/>FiftyOne</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/genkit/>Firebase Genkit</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/haystack/>Haystack</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/honeyhive/>HoneyHive</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/langchain/>Langchain</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/langchain-go/>Langchain Go</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/langchain4j/>Langchain4J</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/langgraph/>LangGraph</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/llama-index/>LlamaIndex</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/mastra/>Mastra</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/mem0/>Mem0</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/nlweb/>Microsoft NLWeb</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/neo4j-graphrag/>Neo4j GraphRAG</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/openai-agents/>OpenAI Agents</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/pandas-ai/>Pandas-AI</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/canopy/>Pinecone Canopy</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/ragbits/>Ragbits</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/rig-rs/>Rig-rs</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/semantic-router/>Semantic-Router</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/smolagents/>SmolAgents</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/solon/>Solon</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/spring-ai/>Spring AI</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/dspy/>Stanford DSPy</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/superduper/>Superduper</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/sycamore/>Sycamore</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/testcontainers/>Testcontainers</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/txtai/>txtai</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/vanna-ai/>Vanna.AI</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/mirror-security/>VectaX - Mirror Security</a></li></ul></nav></details><details class="docs-menu__links-group link-group"><summary class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/observability/>Observability</a></summary><nav><ul class=docs-menu__links-submenu><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/observability/openllmetry/>OpenLLMetry</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/observability/openlit/>OpenLIT</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/observability/datadog/>Datadog</a></li></ul></nav></details><details class="docs-menu__links-group link-group"><summary class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/platforms/>Platforms</a></summary><nav><ul class=docs-menu__links-submenu><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/apify/>Apify</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/bubble/>Bubble</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/buildship/>BuildShip</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/docsgpt/>DocsGPT</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/rivet/>Ironclad Rivet</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/keboola/>Keboola</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/kotaemon/>Kotaemon</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/make/>Make.com</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/n8n/>N8N</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/pipedream/>Pipedream</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/portable/>Portable.io</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/powerapps/>Power Apps</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/privategpt/>PrivateGPT</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/mulesoft/>Salesforce Mulesoft</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/tooljet/>ToolJet</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/vectorize/>Vectorize.io</a></li></ul></nav></details><h3 class=docs-menu__links-title>Examples</h3><details class="docs-menu__links-group link-group active" open><summary class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/search-precision/reranking-semantic-search/>Search Enhancement</a></summary><nav><ul class=docs-menu__links-submenu><li class="docs-menu__links-submenu-item
active"><a href=https://qdrant.tech/documentation/search-precision/reranking-semantic-search/>Reranking in Semantic Search</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/>Automate filtering with LLMs</a></li></ul></nav></details><details class="docs-menu__links-group link-group"><summary class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/send-data/>Send Data to Qdrant</a></summary><nav><ul class=docs-menu__links-submenu><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/send-data/databricks/>Qdrant on Databricks</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/>Semantic Querying with Airflow and Astronomer</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/>How to Setup Seamless Data Streaming with Kafka and Qdrant</a></li></ul></nav></details><details class="docs-menu__links-group link-group"><summary class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/examples/>Build Prototypes</a></summary><nav><ul class=docs-menu__links-submenu><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/>GraphRAG with Qdrant and Neo4j</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/llama-index-multitenancy/>Multitenancy with LlamaIndex</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/>Private Chatbot for Interactive Learning</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/cohere-rag-connector/>Implement Cohere RAG connector</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/>Question-Answering System for AI Customer Support</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/>Chat With Product PDF Manuals Using Hybrid Search</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/>Region-Specific Contract Management System</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/>RAG System for Employee Onboarding</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/>Private RAG Information Extraction Engine</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/>Movie Recommendation System</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/>Blog-Reading Chatbot with GPT-4o</a></li></ul></nav></details><div class=docs-menu__links-group><div class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/datasets/>Practice Datasets</a></div></div></nav></div></div></div></header><section class="docs documentation"><div class=documentation__container><div class="d-flex flex-column flex-xl-row"><div class=docs-menu><div id=sidebar class=docs-menu__content><nav class=docs-menu__links><h3 class=docs-menu__links-title>Essentials</h3><div class=docs-menu__links-group><div class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/data-ingestion-beginners/>Data Ingestion for Beginners</a></div></div><div class=docs-menu__links-group><div class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/agentic-rag-crewai-zoom/>Simple Agentic RAG System</a></div></div><div class=docs-menu__links-group><div class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/agentic-rag-langgraph/>Agentic RAG With LangGraph</a></div></div><div class=docs-menu__links-group><div class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/agentic-rag-camelai-discord/>Agentic RAG Discord Bot with CAMEL-AI</a></div></div><div class=docs-menu__links-group><div class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/multimodal-search/>Multilingual & Multimodal RAG with LlamaIndex</a></div></div><div class=docs-menu__links-group><div class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/rag-deepseek/>5 Minute RAG with Qdrant and DeepSeek</a></div></div><h3 class=docs-menu__links-title>Integrations</h3><details class="docs-menu__links-group link-group"><summary class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/data-management/>Data Management</a></summary><nav><ul class=docs-menu__links-submenu><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/airbyte/>Airbyte</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/airflow/>Apache Airflow</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/nifi/>Apache NiFi</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/spark/>Apache Spark</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/cocoindex/>CocoIndex</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/cognee/>cognee</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/confluent/>Confluent Kafka</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/dlt/>DLT</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/fondant/>Fondant</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/fluvio/>InfinyOn Fluvio</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/mindsdb/>MindsDB</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/redpanda/>Redpanda Connect</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/data-management/unstructured/>Unstructured</a></li></ul></nav></details><details class="docs-menu__links-group link-group"><summary class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/embeddings/>Embeddings</a></summary><nav><ul class=docs-menu__links-submenu><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/aleph-alpha/>Aleph Alpha</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/bedrock/>AWS Bedrock</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/cohere/>Cohere</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/gemini/>Gemini</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/jina-embeddings/>Jina Embeddings</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/mistral/>Mistral</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/mixedbread/>MixedBread</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/mixpeek/>Mixpeek</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/nomic/>Nomic</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/nvidia/>Nvidia</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/ollama/>Ollama</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/openai/>OpenAI</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/premai/>Prem AI</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/snowflake/>Snowflake Models</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/twelvelabs/>Twelve Labs</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/upstage/>Upstage</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/embeddings/voyage/>Voyage AI</a></li></ul></nav></details><details class="docs-menu__links-group link-group"><summary class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/frameworks/>Frameworks</a></summary><nav><ul class=docs-menu__links-submenu><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/autogen/>Autogen</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/lakechain/>AWS Lakechain</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/camel/>CamelAI</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/cheshire-cat/>Cheshire Cat</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/crewai/>CrewAI</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/dagster/>Dagster</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/deepeval/>DeepEval</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/docarray/>DocArray</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/dsrag/>dsRAG</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/dynamiq/>Dynamiq</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/feast/>Feast</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/fifty-one/>FiftyOne</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/genkit/>Firebase Genkit</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/haystack/>Haystack</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/honeyhive/>HoneyHive</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/langchain/>Langchain</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/langchain-go/>Langchain Go</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/langchain4j/>Langchain4J</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/langgraph/>LangGraph</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/llama-index/>LlamaIndex</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/mastra/>Mastra</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/mem0/>Mem0</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/nlweb/>Microsoft NLWeb</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/neo4j-graphrag/>Neo4j GraphRAG</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/openai-agents/>OpenAI Agents</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/pandas-ai/>Pandas-AI</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/canopy/>Pinecone Canopy</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/ragbits/>Ragbits</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/rig-rs/>Rig-rs</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/semantic-router/>Semantic-Router</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/smolagents/>SmolAgents</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/solon/>Solon</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/spring-ai/>Spring AI</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/dspy/>Stanford DSPy</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/superduper/>Superduper</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/sycamore/>Sycamore</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/testcontainers/>Testcontainers</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/txtai/>txtai</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/vanna-ai/>Vanna.AI</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/frameworks/mirror-security/>VectaX - Mirror Security</a></li></ul></nav></details><details class="docs-menu__links-group link-group"><summary class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/observability/>Observability</a></summary><nav><ul class=docs-menu__links-submenu><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/observability/openllmetry/>OpenLLMetry</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/observability/openlit/>OpenLIT</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/observability/datadog/>Datadog</a></li></ul></nav></details><details class="docs-menu__links-group link-group"><summary class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/platforms/>Platforms</a></summary><nav><ul class=docs-menu__links-submenu><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/apify/>Apify</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/bubble/>Bubble</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/buildship/>BuildShip</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/docsgpt/>DocsGPT</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/rivet/>Ironclad Rivet</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/keboola/>Keboola</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/kotaemon/>Kotaemon</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/make/>Make.com</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/n8n/>N8N</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/pipedream/>Pipedream</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/portable/>Portable.io</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/powerapps/>Power Apps</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/privategpt/>PrivateGPT</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/mulesoft/>Salesforce Mulesoft</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/tooljet/>ToolJet</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/platforms/vectorize/>Vectorize.io</a></li></ul></nav></details><h3 class=docs-menu__links-title>Examples</h3><details class="docs-menu__links-group link-group active" open><summary class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/search-precision/reranking-semantic-search/>Search Enhancement</a></summary><nav><ul class=docs-menu__links-submenu><li class="docs-menu__links-submenu-item
active"><a href=https://qdrant.tech/documentation/search-precision/reranking-semantic-search/>Reranking in Semantic Search</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/>Automate filtering with LLMs</a></li></ul></nav></details><details class="docs-menu__links-group link-group"><summary class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/send-data/>Send Data to Qdrant</a></summary><nav><ul class=docs-menu__links-submenu><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/send-data/databricks/>Qdrant on Databricks</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/>Semantic Querying with Airflow and Astronomer</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/>How to Setup Seamless Data Streaming with Kafka and Qdrant</a></li></ul></nav></details><details class="docs-menu__links-group link-group"><summary class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/examples/>Build Prototypes</a></summary><nav><ul class=docs-menu__links-submenu><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/>GraphRAG with Qdrant and Neo4j</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/llama-index-multitenancy/>Multitenancy with LlamaIndex</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/>Private Chatbot for Interactive Learning</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/cohere-rag-connector/>Implement Cohere RAG connector</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/>Question-Answering System for AI Customer Support</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/>Chat With Product PDF Manuals Using Hybrid Search</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/>Region-Specific Contract Management System</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/>RAG System for Employee Onboarding</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/>Private RAG Information Extraction Engine</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/>Movie Recommendation System</a></li><li class=docs-menu__links-submenu-item><a href=https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/>Blog-Reading Chatbot with GPT-4o</a></li></ul></nav></details><div class=docs-menu__links-group><div class=docs-menu__links-group-heading><a href=https://qdrant.tech/documentation/datasets/>Practice Datasets</a></div></div></nav></div></div><div class=documentation__content><div class=documentation__content-wrapper><div class=documentation__article-wrapper><ul class=docs-breadcrumbs><li class=docs-breadcrumbs__crumb><a href=https://qdrant.tech/documentation/>Documentation</a></li><li class=docs-breadcrumbs__crumb-separator></li><li class=docs-breadcrumbs__crumb><a href=https://qdrant.tech/documentation/search-precision/>Search precision</a></li><li class=docs-breadcrumbs__crumb-separator></li><li class=docs-breadcrumbs__crumb>Reranking in Semantic Search</li></ul><article class=documentation-article><h1 id=reranking-in-rag-with-qdrant-vector-database>Reranking in RAG with Qdrant Vector Database</h1><p>In Retrieval-Augmented Generation (RAG) systems, irrelevant or missing information can throw off your model&rsquo;s ability to produce accurate, meaningful outputs. One of the best ways to ensure you&rsquo;re feeding your language model the most relevant, context-rich documents is through reranking. It‚Äôs a game-changer.</p><p>In this guide, we‚Äôll dive into using reranking to boost the relevance of search results in Qdrant. We‚Äôll start with an easy use case that leverages the Cohere Rerank model. Then, we‚Äôll take it up a notch by exploring ColBERT for a more advanced approach. By the time you‚Äôre done, you‚Äôll know how to implement <a href=https://qdrant.tech/articles/hybrid-search/ target=_blank rel="noopener nofollow">hybrid search</a>, fine-tune reranking models, and significantly improve your accuracy.</p><p>Ready? Let‚Äôs jump in.</p><h1 id=understanding-reranking>Understanding Reranking</h1><p>This section is broken down into key parts to help you easily grasp the background, mechanics, and significance of reranking.</p><h2 id=background>Background</h2><p>In search systems, two metrics‚Äîprecision and recall‚Äîare the backbone of success. But what do they mean? Precision tells us how many of the retrieved results are actually relevant, while recall measures how well we‚Äôve captured all the relevant results out there. Simply put:</p><p><img src=https://qdrant.tech/documentation/examples/reranking-semantic-search/image5.png alt=image5.png></p><p>Sparse vector searches usually give you high precision because they‚Äôre great at finding exact matches. But, here&rsquo;s the catch‚Äîyour recall can suffer when relevant documents don‚Äôt contain those exact keywords. On the flip side, dense vector searches are fantastic for recall since they grasp the broader, semantic meaning of your query. However, this can lead to lower precision, where you might see results that are only loosely related.</p><p>This is exactly where reranking comes to the rescue. It takes a wide net of documents (giving you high recall) and then refines them by reordering the top candidates based on their relevance scores‚Äîboosting precision without losing that broad understanding. Typically, we retain only the top K candidates after reordering to focus on the most relevant results.</p><h2 id=working>Working</h2><p>Picture this: You walk into a massive library and ask for a book on &ldquo;climate change.&rdquo; The librarian pulls out a dozen books for you‚Äîsome are scientific papers, others are personal essays, and one‚Äôs even a novel. Sure, they‚Äôre all relevant, but the first one you get handed is the novel. Not exactly what you were hoping for, right?</p><p>Now, imagine a smarter, more intuitive librarian who really gets what you‚Äôre after. This one knows exactly which books are most impactful, the most current, and perfectly aligned with what you need. That‚Äôs what reranking does for your search results‚Äîit doesn‚Äôt just grab any relevant document; it smartly reorders them so the best ones land at the top of your list. It‚Äôs like having a librarian who knows exactly what you‚Äôre looking for before you do!</p><p><img src=https://qdrant.tech/documentation/examples/reranking-semantic-search/image6.png alt=image6.png></p><p>An illustration of the rerank model prioritizing better results</p><p>To become that smart, intuitive librarian, your algorithm needs to learn how to understand both your queries and the documents it retrieves. It has to evaluate the relationship between them effectively, so it can give you exactly what you‚Äôre looking for.</p><p>The way reranker models operate varies based on their type, which will be discussed later, but in general, they calculate a relevance score for each document-query pair.Unlike embedding models, which squash everything into a single vector upfront, rerankers keep all the important details intact by using the full transformer output to calculate a similarity score. The result? Precision. But, there‚Äôs a trade-off‚Äîreranking can be slow. Processing millions of documents can take hours, which is why rerankers focus on refining results, not searching through the entire document collection.</p><p>Rerankers come in different types, each with its own strengths. Let‚Äôs break them down:</p><ol><li><strong>Cross Encoder Models</strong>: These boost reranking by using a classification system to evaluate pairs of data‚Äîlike sentences or documents. They spit out a similarity score from 0 to 1, showing how closely the document matches your query. The catch? Cross-encoders need both query and document, so they can‚Äôt handle standalone documents or queries by themselves.</li><li><strong>Multi-Vector Rerankers (e.g., ColBERT)</strong>: These models take a more efficient route. They encode your query and the documents separately and only compare them later, reducing the computational load. This means document representations can be precomputed, speeding up retrieval times</li><li><strong>Large Language Models (LLMs) as Rerankers</strong>: This is a newer, smarter way to rerank. LLMs, like GPT, are getting better by the day. With the right instructions, they can prioritize the most relevant documents for you, leveraging their massive understanding of language to deliver even more accurate results.</li></ol><p>Each of these rerankers has its own special way of making sure you get the best search results, fast and relevant to what you need.</p><h2 id=importance>Importance</h2><p>In the previous section, we explored the background and mechanics of reranking, but now let‚Äôs talk about the three big wins you get from using it:</p><ul><li><strong>Enhancing Search Accuracy:</strong> Reranking is all about making your search results sharper and more relevant. After the initial ranking, rerankers step in, reshuffling the results based on deeper analysis to ensure that the most crucial information is front and center. <a href=https://cohere.com/blog/rerank target=_blank rel="noopener nofollow">Research shows that rerankers</a> can pull off a serious boost‚Äîimproving the top results for about 72% of search queries. That‚Äôs a huge leap in precision.</li><li><strong>Reducing Information Overload:</strong> If you feel like you‚Äôre drowning in a sea of search results, rerankers can come to your rescue. They filter and fine-tune the flood of information so you get exactly what you need, without the overwhelm. It makes your search experience more focused and way less chaotic.</li><li><strong>Balancing Speed and Relevance:</strong> First stage retrieval and second stage reranking strike the perfect balance between speed and accuracy. Sure, the second stage may add a bit of latency due to their processing power, but the trade-off is worth it. You get highly relevant results, and in the end, that‚Äôs what matters most.</li></ul><p>Now that you know why reranking is such a game-changer, let‚Äôs dive into the practical side of things.</p><h1 id=implementing-vector-search-with-reranking>Implementing Vector Search with Reranking</h1><p>In this section, you‚Äôre going to see how to implement vector search with reranking using Cohere. But first, let‚Äôs break it down.</p><h2 id=overview>Overview</h2><p>A typical search system works in two main stages: Ingestion and Retrieval. Think of ingestion as the process where your data gets prepped and loaded into the system, and retrieval as the part where the magic happens‚Äîwhere your queries pull out the most relevant documents.</p><p>Check out the architectural diagram below to visualize how these stages work together.</p><p><img src=https://qdrant.tech/documentation/examples/reranking-semantic-search/image1.png alt=image1.png></p><p>The two essential stages of a search system: Ingestion and Retrieval Process</p><h3 id=ingestion-stage>Ingestion Stage</h3><ul><li><strong>Documents:</strong> This is where it all starts. The system takes in raw data or documents that need to be prepped for search‚Äîthis is your initial input.</li><li><strong>Embeddings:</strong> Next, these documents are transformed into sparse or dense <a href=https://qdrant.tech/documentation/embeddings/ target=_blank rel="noopener nofollow">embeddings</a>, which are basically vector representations. These vectors capture the deep, underlying meaning of the text, allowing your system to perform smart, efficient searches and comparisons based on semantic meaning</li><li><strong>Vector Database:</strong> Once your documents are converted into these embeddings, they get stored in a vector database‚Äîessentially the powerhouse behind fast, accurate similarity searches. Here, we‚Äôll see the capabilities of the Qdrant vector database.</li></ul><h3 id=retrieval-stage>Retrieval Stage</h3><ul><li><strong>User&rsquo;s Query:</strong> Now we enter the retrieval phase. The user submits a query, and it‚Äôs time to match that query against the stored documents.</li><li><strong>Embeddings:</strong> Just like with the documents, the user‚Äôs query is converted into a sparse or dense embedding. This enables the system to compare the query&rsquo;s meaning with the meanings of the stored documents.</li><li><strong>Vector Search:</strong> The system searches for the most relevant documents by comparing the query‚Äôs embedding to those in the vector database, and it pulls up the closest matches.</li><li><strong>Rerank:</strong> Once the initial results are in, the reranking process kicks in to ensure you get the best results on top. We‚Äôll be using <strong>Cohere‚Äôs</strong> rerank-english-v3.0 model, which excels at reordering English language documents to prioritize relevance. It can handle up to 4096 tokens, giving it plenty of context to work with. And if you‚Äôre dealing with multi-lingual data, don‚Äôt worry‚ÄîCohere‚Äôs got reranking models for other languages too.</li></ul><h2 id=implementation>Implementation</h2><p>Now it‚Äôs time to dive into the actual implementation.</p><h3 id=setup>Setup</h3><p>To follow along with this tutorial, you&rsquo;ll need a few key tools::</p><ul><li>Python Client for Qdrant</li><li>Cohere</li></ul><p>Let‚Äôs install everything you need in one go using the Python package manager::</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-jsx data-lang=jsx><span class=line><span class=cl><span class=nx>pip</span> <span class=nx>install</span> <span class=nx>qdrant</span><span class=o>-</span><span class=nx>client</span> <span class=nx>cohere</span>
</span></span></code></pre></div><hr><p>Now, let‚Äôs bring in all the necessary components in one tidy block:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-jsx data-lang=jsx><span class=line><span class=cl><span class=nx>from</span> <span class=nx>qdrant_client</span> <span class=kr>import</span> <span class=nx>QdrantClient</span>
</span></span><span class=line><span class=cl><span class=nx>from</span> <span class=nx>qdrant_client</span><span class=p>.</span><span class=nx>models</span> <span class=kr>import</span> <span class=nx>Distance</span><span class=p>,</span> <span class=nx>VectorParams</span><span class=p>,</span> <span class=nx>PointStruct</span>
</span></span><span class=line><span class=cl><span class=kr>import</span> <span class=nx>cohere</span>
</span></span></code></pre></div><hr><p>Qdrant is a powerful vector similarity search engine that gives you a production-ready service with an easy-to-use API for storing, searching, and managing data. You can interact with Qdrant through a local or cloud setup, but since we‚Äôre working in Colab, let‚Äôs go with the cloud setup.</p><h3 id=steps-to-set-up-qdrant-cloud><strong>Steps to Set Up Qdrant Cloud:</strong></h3><ol><li><strong>Sign Up</strong>: Head to Qdrant‚Äôs website and sign up for a cloud account using your email, Google, or GitHub credentials.</li><li><strong>Create Your First Cluster</strong>: Once you‚Äôre in, navigate to the Overview section and follow the onboarding steps under Create First Cluster.</li><li><strong>Get Your API Key</strong>: After creating your cluster, an API key will be generated. This key will let you interact with the cluster using the Python client.</li><li><strong>Check Your Cluster</strong>: Your new cluster will appear under the Clusters section. From here, you‚Äôre all set to start interacting with your data.</li></ol><p>Finally, under the Overview section, you‚Äôll see the following code snippet:</p><p><img src=https://qdrant.tech/documentation/examples/reranking-semantic-search/image7.png alt=image7.png></p><p>Qdrant Overview Section</p><p>Add your API keys. This will let your Python client connect to Qdrant and Cohere.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-jsx data-lang=jsx><span class=line><span class=cl><span class=nx>client</span> <span class=o>=</span> <span class=nx>QdrantClient</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=nx>url</span><span class=o>=</span><span class=s2>&#34;&lt;ADD-URL&gt;&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nx>api_key</span><span class=o>=</span><span class=s2>&#34;&lt;API-KEY&gt;&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nx>print</span><span class=p>(</span><span class=nx>client</span><span class=p>.</span><span class=nx>get_collections</span><span class=p>())</span>
</span></span></code></pre></div><hr><p>Next, we‚Äôll set up Cohere for reranking. Log in to your Cohere account, generate an API key, and add it like this::</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-jsx data-lang=jsx><span class=line><span class=cl><span class=nx>co</span> <span class=o>=</span> <span class=nx>cohere</span><span class=p>.</span><span class=nx>Client</span><span class=p>(</span><span class=s2>&#34;&lt;API-KEY&gt;&#34;</span><span class=p>)</span>
</span></span></code></pre></div><hr><h3 id=ingestion>Ingestion</h3><h3 id=there-are-three-key-parts-to-ingestion-creating-a-collection-converting-documents-to-embeddings-and-upserting-the-data-lets-break-it-down>There are three key parts to ingestion: Creating a Collection, Converting Documents to Embeddings, and Upserting the Data. Let‚Äôs break it down.</h3><h3 id=creating-a-collection>Creating a Collection</h3><p>A collection is basically a named group of points (vectors with data) that you can search through. All the vectors in a collection need to have the same size and be compared using one distance metric. Here‚Äôs how to create one:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-jsx data-lang=jsx><span class=line><span class=cl><span class=nx>client</span><span class=p>.</span><span class=nx>create_collection</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=nx>collection_name</span><span class=o>=</span><span class=s2>&#34;basic-search-rerank&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nx>vectors_config</span><span class=o>=</span><span class=nx>VectorParams</span><span class=p>(</span><span class=nx>size</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span> <span class=nx>distance</span><span class=o>=</span><span class=nx>Distance</span><span class=p>.</span><span class=nx>DOT</span><span class=p>),</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><hr><p>Here, the vector size is set to 1024 to match our dense embeddings, and we‚Äôre using dot product as the distance metric‚Äîperfect for capturing the similarity between vectors, especially when they‚Äôre normalized.</p><h3 id=documents-to-embeddings>Documents to Embeddings</h3><p>Let‚Äôs set up some example data. Here‚Äôs a query and a few documents for demonstration:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-jsx data-lang=jsx><span class=line><span class=cl><span class=nx>query</span> <span class=o>=</span> <span class=s2>&#34;What is the purpose of feature scaling in machine learning?&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nx>documents</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;In machine learning, feature scaling is the process of normalizing the range of independent variables or features. The goal is to ensure that all features contribute equally to the model, especially in algorithms like SVM or k-nearest neighbors where distance calculations matter.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Feature scaling is commonly used in data preprocessing to ensure that features are on the same scale. This is particularly important for gradient descent-based algorithms where features with larger scales could disproportionately impact the cost function.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;In data science, feature extraction is the process of transforming raw data into a set of engineered features that can be used in predictive models. Feature scaling is related but focuses on adjusting the values of these features.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Unsupervised learning algorithms, such as clustering methods, may benefit from feature scaling as it ensures that features with larger numerical ranges don&#39;t dominate the learning process.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;One common data preprocessing technique in data science is feature selection. Unlike feature scaling, feature selection aims to reduce the number of input variables used in a model to avoid overfitting.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Principal component analysis (PCA) is a dimensionality reduction technique used in data science to reduce the number of variables. PCA works best when data is scaled, as it relies on variance which can be skewed by features on different scales.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Min-max scaling is a common feature scaling technique that usually transforms features to a fixed range [0, 1]. This method is useful when the distribution of data is not Gaussian.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Standardization, or z-score normalization, is another technique that transforms features into a mean of 0 and a standard deviation of 1. This method is effective for data that follows a normal distribution.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Feature scaling is critical when using algorithms that rely on distances, such as k-means clustering, as unscaled features can lead to misleading results.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Scaling can improve the convergence speed of gradient descent algorithms by preventing issues with different feature scales affecting the cost function&#39;s landscape.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;In deep learning, feature scaling helps in stabilizing the learning process, allowing for better performance and faster convergence during training.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Robust scaling is another method that uses the median and the interquartile range to scale features, making it less sensitive to outliers.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;When working with time series data, feature scaling can help in standardizing the input data, improving model performance across different periods.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Normalization is often used in image processing to scale pixel values to a range that enhances model performance in computer vision tasks.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Feature scaling is significant when features have different units of measurement, such as height in centimeters and weight in kilograms.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;In recommendation systems, scaling features such as user ratings can improve the model&#39;s ability to find similar users or items.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Dimensionality reduction techniques, like t-SNE and UMAP, often require feature scaling to visualize high-dimensional data in lower dimensions effectively.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Outlier detection techniques can also benefit from feature scaling, as they can be influenced by unscaled features that have extreme values.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Data preprocessing steps, including feature scaling, can significantly impact the performance of machine learning models, making it a crucial part of the modeling pipeline.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;In ensemble methods, like random forests, feature scaling is not strictly necessary, but it can still enhance interpretability and comparison of feature importance.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Feature scaling should be applied consistently across training and test datasets to avoid data leakage and ensure reliable model evaluation.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;In natural language processing (NLP), scaling can be useful when working with numerical features derived from text data, such as word counts or term frequencies.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Log transformation is a technique that can be applied to skewed data to stabilize variance and make the data more suitable for scaling.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Data augmentation techniques in machine learning may also include scaling to ensure consistency across training datasets, especially in computer vision tasks.&#34;</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span></code></pre></div><hr><p>We‚Äôll generate embeddings for these documents using Cohere‚Äôs embed-english-v3.0 model, which produces 1024-dimensional vectors:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span><span class=o>=</span><span class=s2>&#34;embed-english-v3.0&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>doc_embeddings</span> <span class=o>=</span> <span class=n>co</span><span class=o>.</span><span class=n>embed</span><span class=p>(</span><span class=n>texts</span><span class=o>=</span><span class=n>documents</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                          <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                          <span class=n>input_type</span><span class=o>=</span><span class=s2>&#34;search_document&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                          <span class=n>embedding_types</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;float&#39;</span><span class=p>])</span>
</span></span></code></pre></div><hr><p>This code taps into the power of the Cohere API to generate embeddings for your list of documents. It uses the embed-english-v3.0 model, sets the input type to &ldquo;search_document,&rdquo; and asks for the embeddings in float format. The result? A set of dense embeddings, each one representing the deep semantic meaning of your documents. These embeddings will be stored in doc_embeddings, ready for action.</p><h3 id=upsert-data>Upsert Data</h3><p>We need to transform those dense embeddings into a format Qdrant can work with, and that‚Äôs where Points come in. Points are the building blocks of Qdrant‚Äîthey‚Äôre records made up of a vector (the embedding) and an optional payload (like your document text).</p><p>Here‚Äôs how we convert those embeddings into Points:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>points</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>idx</span><span class=p>,</span> <span class=p>(</span><span class=n>embedding</span><span class=p>,</span> <span class=n>doc</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=nb>zip</span><span class=p>(</span><span class=n>doc_embeddings</span><span class=o>.</span><span class=n>embeddings</span><span class=o>.</span><span class=n>float_</span><span class=p>,</span> <span class=n>documents</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>    <span class=n>point</span> <span class=o>=</span> <span class=n>PointStruct</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=nb>id</span><span class=o>=</span><span class=n>idx</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>vector</span><span class=o>=</span><span class=n>embedding</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>payload</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;document&#34;</span><span class=p>:</span> <span class=n>doc</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>points</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>point</span><span class=p>)</span>
</span></span></code></pre></div><hr><p>What‚Äôs happening here? We‚Äôre building a list of Points from the embeddings:</p><ul><li>First, we start with an empty list.</li><li>Then, we loop through both <strong>doc_embeddings</strong> and <strong>documents</strong> at the same time using enumerate() to grab the index (idx) along the way.</li><li>For each pair (an embedding and its corresponding document), we create a PointStruct. Each point gets:<ul><li>An id (from idx).</li><li>A vector (the embedding).</li><li>A payload (the actual document text).</li></ul></li><li>Each Point is added to our list.</li></ul><p>Once that‚Äôs done, it‚Äôs time to send these Points into your Qdrant collection with the upsert() function:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>operation_info</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>upsert</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>collection_name</span><span class=o>=</span><span class=s2>&#34;basic-search-rerank&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>points</span><span class=o>=</span><span class=n>points</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><hr><h3 id=now-your-embeddings-are-all-set-in-qdrant-ready-to-power-your-search>Now your embeddings are all set in Qdrant, ready to power your search.</h3><h3 id=retrieval>Retrieval</h3><p>The first few steps here mirror what we did during ingestion‚Äîjust like before, we need to convert the query into an embedding:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>query_embeddings</span> <span class=o>=</span> <span class=n>co</span><span class=o>.</span><span class=n>embed</span><span class=p>(</span><span class=n>texts</span><span class=o>=</span><span class=p>[</span><span class=n>query</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                          <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                          <span class=n>input_type</span><span class=o>=</span><span class=s2>&#34;search_query&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                          <span class=n>embedding_types</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;float&#39;</span><span class=p>])</span>
</span></span></code></pre></div><hr><p>After that, we&rsquo;ll move on to retrieve results using vector search and apply reranking on the results. This two-stage process is super efficient because we‚Äôre grabbing a small set of the most relevant documents first, which is much faster than reranking a huge dataset.</p><h3 id=vector-search>Vector Search</h3><p>This snippet grabs the top 10 most relevant points from your Qdrant collection using the query embedding.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>search_result</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>query_points</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>collection_name</span><span class=o>=</span><span class=s2>&#34;basic-search-rerank&#34;</span><span class=p>,</span> <span class=n>query</span><span class=o>=</span><span class=n>query_embeddings</span><span class=o>.</span><span class=n>embeddings</span><span class=o>.</span><span class=n>float_</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>limit</span><span class=o>=</span><span class=mi>10</span>
</span></span><span class=line><span class=cl><span class=p>)</span><span class=o>.</span><span class=n>points</span>
</span></span></code></pre></div><hr><p>Here‚Äôs how it works: we use the query_points method to search within the &ldquo;basic-search-rerank&rdquo; collection. It compares the query embedding (the first embedding in query_embeddings) against all the document embeddings, pulling up the 10 closest matches. The matching points get stored in search_result.</p><p>And here‚Äôs a sneak peek at what you‚Äôll get from the vector search:</p><div class=table-responsive><table class="table mb-5"><thead><tr><th><strong>ID</strong></th><th><strong>Document</strong></th><th><strong>Score</strong></th></tr></thead><tbody><tr><td>0</td><td>In machine learning, feature scaling is the process of normalizing the range of independent&mldr;</td><td>0.71</td></tr><tr><td>10</td><td>In deep learning, feature scaling helps stabilize the learning process, allowing for&mldr;</td><td>0.69</td></tr><tr><td>1</td><td>Feature scaling is commonly used in data preprocessing to ensure that features are on the&mldr;</td><td>0.68</td></tr><tr><td>23</td><td>Data augmentation techniques in machine learning may also include scaling to ensure&mldr;</td><td>0.64</td></tr><tr><td>3</td><td>Unsupervised learning algorithms, such as clustering methods, may benefit from feature&mldr;</td><td>0.64</td></tr><tr><td>12</td><td>When working with time series data, feature scaling can help standardize the input&mldr;</td><td>0.62</td></tr><tr><td>19</td><td>In ensemble methods, like random forests, feature scaling is not strictly necessary&mldr;</td><td>0.61</td></tr><tr><td>21</td><td>In natural language processing (NLP), scaling can be useful when working with numerical&mldr;</td><td>0.61</td></tr><tr><td>20</td><td>Feature scaling should be applied consistently across training and test datasets&mldr;</td><td>0.61</td></tr><tr><td>18</td><td>Data preprocessing steps, including feature scaling, can significantly impact the performance&mldr;</td><td>0.61</td></tr></tbody></table></div><p>From the looks of it, the data pulled up is highly relevant to your query. Now, with this solid base of results, it‚Äôs time to refine them further with reranking.</p><h3 id=rerank>Rerank</h3><p>This code takes the documents from the search results and reranks them based on your query, making sure you get the most relevant ones right at the top.</p><p>First, we pull out the documents from the search results. Then we use Cohere‚Äôs rerank model to refine these results:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>document_list</span> <span class=o>=</span> <span class=p>[</span><span class=n>point</span><span class=o>.</span><span class=n>payload</span><span class=p>[</span><span class=s1>&#39;document&#39;</span><span class=p>]</span> <span class=k>for</span> <span class=n>point</span> <span class=ow>in</span> <span class=n>search_result</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>rerank_results</span> <span class=o>=</span> <span class=n>co</span><span class=o>.</span><span class=n>rerank</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=s2>&#34;rerank-english-v3.0&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>query</span><span class=o>=</span><span class=n>query</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>documents</span><span class=o>=</span><span class=n>document_list</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>top_n</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><hr><p>What‚Äôs happening here? In the first line, we‚Äôre building a list of documents by grabbing the &lsquo;document&rsquo; field from each search result point. Then, we pass this list, along with the original query, to Cohere‚Äôs rerank method. Using the <strong>rerank-english-v3.0</strong> model, it reshuffles the documents and gives you back the top 5, ranked by their relevance to the query.</p><p>Here‚Äôs the reranked result table, with the new order and their relevance scores:</p><div class=table-responsive><table class="table mb-5"><thead><tr><th><strong>Index</strong></th><th><strong>Document</strong></th><th><strong>Relevance Score</strong></th></tr></thead><tbody><tr><td>0</td><td>In machine learning, feature scaling is the process of normalizing the range of independent variables or features.</td><td>0.99995166</td></tr><tr><td>1</td><td>Feature scaling is commonly used in data preprocessing to ensure that features are on the same scale.</td><td>0.99929035</td></tr><tr><td>10</td><td>In deep learning, feature scaling helps stabilize the learning process, allowing for better performance and faster convergence.</td><td>0.998675</td></tr><tr><td>23</td><td>Data augmentation techniques in machine learning may also include scaling to ensure consistency across training datasets.</td><td>0.998043</td></tr><tr><td>3</td><td>Unsupervised learning algorithms, such as clustering methods, may benefit from feature scaling.</td><td>0.9979967</td></tr></tbody></table></div><p>As you can see, the reranking did its job. Positions for documents 10 and 1 got swapped, showing that the reranker has fine-tuned the results to give you the most relevant content at the top.</p><h2 id=conclusion>Conclusion</h2><p>Reranking is a powerful way to boost the relevance and precision of search results in RAG systems. By combining Qdrant‚Äôs vector search capabilities with tools like Cohere‚Äôs Rerank model or ColBERT, you can refine search outputs, ensuring the most relevant information rises to the top.</p><p>This guide demonstrated how reranking enhances precision without sacrificing recall, delivering sharper, context-rich results. With these tools, you‚Äôre equipped to create search systems that provide meaningful and impactful user experiences. Start implementing reranking to take your applications to the next level!</p></article><section class="docs-feedback d-print-none"><h5 class=docs-feedback__title>Was this page useful?</h5><div class=docs-feedback__buttons><button class="button button_outlined button_sm docs-feedback__button" id=feedback__answer_yes>
<img src=https://qdrant.tech/icons/outline/thumb-up.svg alt="Thumb up icon">
Yes
</button>
<button class="button button_outlined button_sm docs-feedback__button" id=feedback__answer_no>
<img src=https://qdrant.tech/icons/outline/thumb-down.svg alt="Thumb down icon">
No</button></div></section><section class="docs-feedback__responses d-none"><p class="docs-feedback__response docs-feedback__response_yes" id=feedback__response_yes>Thank you for your feedback! üôè</p><p class="docs-feedback__response docs-feedback__response_no" id=feedback__response_no>We are sorry to hear that. üòî You can <a class=text-brand-p href=https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/search-precision/reranking-semantic-search.md target=_blank>edit</a> this page on GitHub, or <a class=text-brand-p href=https://github.com/qdrant/landing_page/issues/new/choose target=_blank>create</a> a GitHub issue.</p></section><script>const buttonsSection=document.querySelector(".docs-feedback"),responsesSection=document.querySelector(".docs-feedback__responses"),yesButton=document.querySelector("#feedback__answer_yes"),noButton=document.querySelector("#feedback__answer_no"),yesResponse=document.querySelector("#feedback__response_yes"),noResponse=document.querySelector("#feedback__response_no"),toggleResponses=()=>{buttonsSection.classList.add("d-none"),responsesSection.classList.remove("d-none")};yesButton.addEventListener("click",()=>{yesResponse.classList.add("feedback__response_visible"),toggleResponses()}),noButton.addEventListener("click",()=>{noResponse.classList.add("feedback__response_visible"),toggleResponses()})</script></div><div class=table-of-contents><p class=table-of-contents__head>On this page:</p><nav id=TableOfContents><ul><li><a href=#reranking-in-rag-with-qdrant-vector-database>Reranking in RAG with Qdrant Vector Database</a></li><li><a href=#understanding-reranking>Understanding Reranking</a><ul><li><a href=#background>Background</a></li><li><a href=#working>Working</a></li><li><a href=#importance>Importance</a></li></ul></li><li><a href=#implementing-vector-search-with-reranking>Implementing Vector Search with Reranking</a><ul><li><a href=#overview>Overview</a><ul><li><a href=#ingestion-stage>Ingestion Stage</a></li><li><a href=#retrieval-stage>Retrieval Stage</a></li></ul></li><li><a href=#implementation>Implementation</a><ul><li><a href=#setup>Setup</a></li><li><a href=#steps-to-set-up-qdrant-cloud><strong>Steps to Set Up Qdrant Cloud:</strong></a></li><li><a href=#ingestion>Ingestion</a></li><li><a href=#there-are-three-key-parts-to-ingestion-creating-a-collection-converting-documents-to-embeddings-and-upserting-the-data-lets-break-it-down>There are three key parts to ingestion: Creating a Collection, Converting Documents to Embeddings, and Upserting the Data. Let‚Äôs break it down.</a></li><li><a href=#creating-a-collection>Creating a Collection</a></li><li><a href=#documents-to-embeddings>Documents to Embeddings</a></li><li><a href=#upsert-data>Upsert Data</a></li><li><a href=#now-your-embeddings-are-all-set-in-qdrant-ready-to-power-your-search>Now your embeddings are all set in Qdrant, ready to power your search.</a></li><li><a href=#retrieval>Retrieval</a></li><li><a href=#vector-search>Vector Search</a></li><li><a href=#rerank>Rerank</a></li></ul></li><li><a href=#conclusion>Conclusion</a></li></ul></li></ul></nav><ul class=table-of-contents__external-links><li class=table-of-contents__link><a href=https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/search-precision/reranking-semantic-search.md target=_blank><svg width="16" height="17" viewBox="0 0 16 17" fill="none"><g clip-path="url(#clip0_6269_955)"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 .700012c-4.4.0-8 3.599998-8 7.999998C0 12.2333 2.26667 15.2333 5.46667 16.3 5.86667 16.3667 6 16.1 6 15.9S6 15.2333 6 14.5667C3.8 15.0333 3.33333 13.5 3.33333 13.5 3 12.5667 2.46667 12.3 2.46667 12.3 1.66667 11.8333 2.46667 11.8333 2.46667 11.8333 3.26667 11.9 3.66667 12.6333 3.66667 12.6333 4.4 13.8333 5.53333 13.5 6 13.3 6.06667 12.7667 6.26667 12.4333 6.53333 12.2333 4.73333 12.0333 2.86667 11.3667 2.86667 8.30001c0-.86666.33333-1.6.8-2.13333.0-.26667-.33334-1.06667.13333-2.13333.0.0.66667-.200000000000001 2.2.8.66667-.2 1.33333-.26667 2-.26667S9.33333 4.63335 10 4.83335c1.5333-1.06667 2.2-.8 2.2-.8C12.6667 5.16668 12.3333 5.96668 12.2667 6.16668 12.8 6.70001 13.0667 7.43335 13.0667 8.30001c0 3.06669-1.8667 3.73329-3.6667 3.93329C9.66667 12.5 9.93333 12.9667 9.93333 13.7c0 1.0667.0 1.9333.0 2.2C9.93333 16.1 10.0667 16.3667 10.4667 16.3c3.2-1.0667 5.4666-4.0667 5.4666-7.59999C16 4.30001 12.4.700012 8 .700012z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_6269_955"><rect width="16" height="16" fill="#fff" transform="translate(0 0.5)"/></clipPath></defs></svg>
Edit on Github</a></li><li class=table-of-contents__link><a href=https://github.com/qdrant/landing_page/issues/new/choose target=_blank><svg width="16" height="17" viewBox="0 0 16 17" fill="none"><g clip-path="url(#clip0_6269_1540)"><path d="M16 9.83331V8.49998H13.9347C13.79 7.33465 13.3947 6.24065 12.8 5.31065l1.476-1.478L13.3327 2.89065 11.9633 4.26198c-.24-.248-.496600000000001-.474-.772-.676C11.0967 3.25665 10.9507 2.95398 10.7673 2.67598l1.038-1.038L10.8627.695312 9.82867 1.72931C9.29867 1.37798 8.672 1.16665 8 1.16665c-.672.0-1.29867.21133-1.828.56266L5.138.695312l-.94267.942668 1.038 1.038c-.18333.27733-.32933.58-.424.90867-.27533.202-.532.42933-.77266.67733L2.66733 2.89065l-.94333.942L3.2 5.30998c-.59467.93-.99 2.02467-1.13467 3.19H0V9.83331H2.01467C2.07333 11.276 2.50533 12.6026 3.204 13.688l-1.48 1.478L2.666 16.1093l1.37-1.368C4.93733 15.67 6.07667 16.288 7.33333 16.452V6.49998H8.66667V16.452C9.92333 16.2873 11.0627 15.67 11.964 14.7413l1.37 1.368L14.276 15.166l-1.48-1.478C13.4947 12.602 13.9267 11.2753 13.9853 9.83331H16z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_6269_1540"><rect width="16" height="16" fill="#fff" transform="translate(0 0.5)"/></clipPath></defs></svg>
Create an issue</a></li></ul></div><footer class="docs-footer w-100 py-0 pt-0 pb-4 pb-xl-0"><div class=docs-footer__cta><h4>Ready to get started with Qdrant?</h4><a href=https://qdrant.to/cloud/ class="button button_outlined button_sm" target=_blank>Start Free</a></div><div class=docs-footer__bottom><div class=docs-footer__bottom-content><span>¬© 2025 Qdrant.</span><div class=footer__bottom-links><a href=https://qdrant.tech/legal/terms_and_conditions/>Terms</a>
<a href=https://qdrant.tech/legal/privacy-policy/>Privacy Policy</a>
<a href=https://qdrant.tech/legal/impressum/>Impressum</a></div></div></div></footer></div></div></div></div></section></main></body><script src=https://cdn.cookielaw.org/scripttemplates/otSDKStub.js type=text/javascript data-domain-script=01960152-5e40-782d-af01-f7f5768a214e></script><script async type=text/javascript>function OptanonWrapper(){const e=new CustomEvent("onetrust_loaded");document.dispatchEvent(e)}</script><script>!function(){const o="eQYi1nZE2zQSmnHuxjMRlDd2uLl65oHe";var n,s,t="analytics",e=window[t]=window[t]||[];if(!e.initialize)if(e.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{e.invoked=!0,e.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","debug","page","screen","once","off","on","addSourceMiddleware","addIntegrationMiddleware","setAnonymousId","addDestinationMiddleware","register"],e.factory=function(n){return function(){if(window[t].initialized)return window[t][n].apply(window[t],arguments);var o,s=Array.prototype.slice.call(arguments);return["track","screen","alias","group","page","identify"].indexOf(n)>-1&&(o=document.querySelector("link[rel='canonical']"),s.push({__t:"bpc",c:o&&o.getAttribute("href")||void 0,p:location.pathname,u:location.href,s:location.search,t:document.title,r:document.referrer})),s.unshift(n),e.push(s),e}};for(n=0;n<e.methods.length;n++)s=e.methods[n],e[s]=e.factory(s);e.load=function(n,s){var i,o=document.createElement("script");o.type="text/javascript",o.async=!0,o.setAttribute("data-global-segment-analytics-key",t),o.src="https://evs.analytics.qdrant.tech/5caWuitPgcGFN5Q7HMpTaj/vEkmzjuRSqeXGbhGAFTWex.min.js",i=document.getElementsByTagName("script")[0],i.parentNode.insertBefore(o,i),e._loadOptions=s},e._writeKey=o,e._cdn="https://evs.analytics.qdrant.tech",e.SNIPPET_VERSION="5.2.0",e.load(o)}}()</script><script src=https://qdrant.tech/js/google-setup.min.14728a3ae9bd931593645b6ddbfe801d400cd2970006e782cb67f3966654248ca962dbaf4cf371493a2d326861b3a691a99d6d8349c8b2752339ab91d3787069.js></script><script src=https://qdrant.tech/js/index.min.e37feda1952d752f5568e1ebc55e183629e4d361f4df09edeed70b4a4327d601161c4147bdbe4149b4a3cdc1ed43f1bf1a2f2340a421f1aa821103980dfe0bda.js></script><script src=https://qdrant.tech/js/search/search.min.e58e7ea98cb549ea9d3ed7e68876abe323cfb323432038820f38a71c40e309deed0fba615e2d3346825229a81e0a76bbadf6f8a816ddad3438abdabfef4ebc09.js type=module></script><script src=https://qdrant.tech/js/search/scroll.min.f4ed4453a3af0adb0d4f49333cbb7892ff5430483a567d0d2dfbd4655fb203d22f22f46aff3d9f38fa5fd96dde5f30227afd0ce1d9f838f5cd5295fc83856ec9.js></script><script src=https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js></script><script src=https://qdrant.tech/js/copy-code.min.95b03a45b2ab4b7a608ecfd4b5919c8572a5b2cd1463f52561cd10976abf3b74334f91324c0e620cb80afac46026a0b18cce6fb753d8495f74c6d478c8ca1d03.js></script><script src=https://qdrant.tech/js/lang-switcher.min.63da11cef09772078425b1ee56415b9c37842a9399f2ba2d2f5efbf72fb751686c410bd50e9bcd283c8231cb97c1973199d4923beef29d8b06e59d9983a6ba51.js></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src=https://qdrant.tech/js/vendor/anchor.min.0e138e17ebcf1c1147a7a3a81d9ac3c601622eedc479f1636470eb2552470f4e27c9a8efe6e8378995dedc1ab67029d8989536ea76f0857d45d1615ae772b8a1.js></script><script>document.addEventListener("keydown",function(e){if((e.metaKey||e.ctrlKey)&&e.key==="k"){e.preventDefault();let t=document.querySelector('[data-target="#searchModal"]');t&&t?.click()}})</script><script>window.addEventListener("message",e=>{if(e.data.type==="hsFormCallback"&&e.data.eventName==="onFormReady"){const t=document.querySelector(`form[data-form-id="${e.data.id}"]`);if(t){const e=t.querySelector('[name="last_form_fill_url"]');e&&(e.value=window.location.href);const n=t.querySelector('[name="referrer_url"]');n&&(n.value=document.referrer)}}})</script></html>