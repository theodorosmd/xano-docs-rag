<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta charset=UTF-8><title>Advancements and Challenges in RAG Systems - Syed Asad | Vector Space Talks - Qdrant</title>
<link rel=icon href=https://qdrant.tech/favicon/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=https://qdrant.tech/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://qdrant.tech/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://qdrant.tech/favicon/favicon-16x16.png><link rel=manifest href=https://qdrant.tech/favicon/site.webmanifest><link rel=mask-icon href=https://qdrant.tech/favicon/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#2b5797"><meta name=msapplication-config content="/favicon/browserconfig.xml"><meta name=theme-color content="#ffffff"><link href=https://qdrant.tech/css/search/search.min.09596ee2b3c94d0ac82a1c33199cabdb3e0210b1ee46aaf1515200e9e484d05dd9e27cc1e861c58cc2e582af162f63b8e180ff2a12f7a6592b7aeaa0a7125130.css rel=stylesheet integrity="sha512-CVlu4rPJTQrIKhwzGZyr2z4CELHuRqrxUVIA6eSE0F3Z4nzB6GHFjMLlgq8WL2O44YD/KhL3plkreuqgpxJRMA=="><link href=https://qdrant.tech/css/main.min.c1e379ad4cf03647832f6a0f040754b0be3e79934db2c29f50b396327c1ec7ac45f778abadbd93f5a8bc431850d1b0d9c9eff34c0171cd4236e83c5e324c1a0e.css rel=stylesheet integrity crossorigin=anonymous><meta name=generator content="Hugo 0.141.0"><meta name=description content="Syed Asad unfolds the challenges of developing multimodal RAG systems at Kiwi Tech, detailing the balance between accuracy and cost-efficiency, and exploring various tools and approaches like GPT 4 and Mixtral to enhance family tree apps and financial chatbots while navigating the hurdles of data privacy and infrastructure demands."><meta name=keywords content="vector search engine,neural network,matching,SaaS,approximate nearest neighbor search,image search,recommender system,vectors,knn algorithm,hnsw,vector search,embeddings,similarity,simaes networks,BERT,transformer,word2vec,fasttext,qdrant"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@id":"https://qdrant.tech/blog/rag-advancements-challenges/#article","@type":"Article","abstract":"Syed Asad unfolds the challenges of developing multimodal RAG systems at Kiwi Tech detailing the balance between accuracy and costefficiency and exploring various tools and approaches like GPT 4 and Mixtral to enhance family tree apps and financial chatbots while navigating the hurdles of data privacy and infrastructure demands","author":{"@type":"Person","name":"Demetrios Brinkmann"},"dateModified":"2024-04-11 22:25:00 +0000 UTC","datePublished":"2024-04-11 22:25:00 +0000 UTC","description":"Syed Asad unfolds the challenges of developing multimodal RAG systems at Kiwi Tech detailing the balance between accuracy and costefficiency and exploring various tools and approaches like GPT 4 and Mixtral to enhance family tree apps and financial chatbots while navigating the hurdles of data privacy and infrastructure demands","headline":"Advancements and Challenges in RAG Systems - Syed Asad | Vector Space Talks","image":[""],"name":"Advancements and Challenges in RAG Systems - Syed Asad | Vector Space Talks","url":"https://qdrant.tech/blog/rag-advancements-challenges/","wordCount":"6810"},{"@id":"https://qdrant.tech/blog/rag-advancements-challenges/#organization","@type":"Organization","address":{"@type":"PostalAddress","addressCountry":"DE","addressLocality":"Berlin","addressRegion":"Berlin","postalCode":"10115","streetAddress":"Chausseestraße 86"},"contactPoint":{"@type":"ContactPoint","contactType":"customer support","email":"info@qdrant.com","telephone":"+49 3040797694"},"description":"Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.","email":"info@qdrant.com","founders":[{"@type":"Person","name":"map[email:info@qdrant.tech name:Andrey Vasnetsov]"},{"@type":"Person","name":"Andre Zayarni"}],"foundingDate":"2021","keywords":["vector search engine","neural network","matching","SaaS","approximate nearest neighbor search","image search","recommender system","vectors","knn algorithm","hnsw","vector search","embeddings","similarity","simaes networks","BERT","transformer","word2vec","fasttext","Qdrant"],"legalName":"Qdrant Solutions GmbH","location":"Berlin, Germany","logo":"https://qdrant.tech/images/logo_with_text.png","name":"Qdrant","sameAs":["https://github.com/qdrant/qdrant","https://qdrant.to/discord","https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA","https://www.linkedin.com/company/qdrant/","https://twitter.com/qdrant_engine"],"url":"https://qdrant.tech"}]}</script><meta property="og:url" content="https://qdrant.tech/blog/rag-advancements-challenges/"><meta property="og:type" content="website"><meta property="og:title" content="Advancements and Challenges in RAG Systems - Syed Asad | Vector Space Talks - Qdrant"><meta name=twitter:card content="summary_large_image"><meta name=twitter:domain content="qdrant"><meta name=twitter:url content="https://qdrant.tech/blog/rag-advancements-challenges/"><meta name=twitter:title content="Advancements and Challenges in RAG Systems - Syed Asad | Vector Space Talks - Qdrant"><meta property="og:description" content="Syed Asad unfolds the challenges of developing multimodal RAG systems at Kiwi Tech, detailing the balance between accuracy and cost-efficiency, and exploring various tools and approaches like GPT 4 and Mixtral to enhance family tree apps and financial chatbots while navigating the hurdles of data privacy and infrastructure demands."><meta name=twitter:description content="Syed Asad unfolds the challenges of developing multimodal RAG systems at Kiwi Tech, detailing the balance between accuracy and cost-efficiency, and exploring various tools and approaches like GPT 4 and Mixtral to enhance family tree apps and financial chatbots while navigating the hurdles of data privacy and infrastructure demands."><meta name=image property="og:image" content="https://qdrant.tech/blog/rag-advancements-challenges/preview/social_preview.jpg"><meta name=image property="og:image:secure_url" content="https://qdrant.tech/blog/rag-advancements-challenges/preview/social_preview.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name=twitter:image:src content="https://qdrant.tech/blog/rag-advancements-challenges/preview/social_preview.jpg"><meta name=author content="Demetrios Brinkmann"><link rel=canonical href=https://qdrant.tech/blog/rag-advancements-challenges/><script type=text/javascript src=//js-eu1.hsforms.net/forms/embed/v2.js></script></head><body><main><header class=site-header><section class=top-banner data-start=1749013200 data-end=1750428000 style=display:none><div><span class=top-banner__icon><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><g clip-path="url(#clip0_770_2716)"><path d="M14.598 6.37199C14.486 6.14399 14.254 5.99999 14 5.99999H8.7447L9.3287.739993C9.36204.44266 9.1927.159993 8.91537.0479934 8.63737-.0653399 8.31937.0226601 8.13737.259327L1.4707 8.92599C1.31604 9.12733 1.2887 9.39933 1.40137 9.62733c.11267.22866.34467.37266.59867.37266H7.25537L6.67137 15.26c-.0333299999999994.2973.136.58.41333.692C7.16537 15.9847 7.25004 16 7.33337 16 7.53604 16 7.73337 15.9073 7.86204 15.74L14.5287 7.07333C14.6834 6.87199 14.71 6.59999 14.598 6.37199z" fill="#8547ff"/></g><defs><clipPath id="clip0_770_2716"><rect width="16" height="16" fill="#fff"/></clipPath></defs></svg> </span><span class=top-banner__text>Learn how TripAdvisor Drives 2-3x More Revenue with Qdrant-Powered AI at Enterprise Scale </span><a data-metric-loc=banner data-metric-label="Learn how TripAdvisor Drives 2-3x More Revenue with Qdrant-Powered AI at Enterprise Scale Read now" class="link link_light link_sm" href=https://qdrant.tech/blog/case-study-tripadvisor/>Read now</a></div></section><div class="main-menu z-2"><a href=https://qdrant.tech/><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div></a><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><button type=button class=main-menu__trigger><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M1 12H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 5H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 19H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=main-menu__links><li class=main-menu__item><span>Products</span><ul class=main-menu__submenu><li class=main-menu__submenu-item><a href=https://qdrant.tech/qdrant-vector-database/><img src=https://qdrant.tech/img/menu/qdrant-vector-database.svg draggable=false>
<span>Qdrant Vector Database</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/cloud/><img src=https://qdrant.tech/img/menu/qdrant-cloud.svg draggable=false>
<span>Qdrant Cloud</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/hybrid-cloud/><img src=https://qdrant.tech/img/menu/hybrid-cloud.svg draggable=false>
<span>Qdrant Hybrid Cloud</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/enterprise-solutions/><img src=https://qdrant.tech/img/menu/qdrant-enterprise-solutions.svg draggable=false>
<span>Qdrant Enterprise Solutions</span></a></li></ul></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/use-cases/>Use Cases</a><ul class=main-menu__submenu><li class=main-menu__section-link><a class="link link_neutral link_sm" href=https://qdrant.tech/use-cases/>Use Cases</a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/rag/><img src=https://qdrant.tech/img/menu/rag.svg draggable=false>
<span>RAG</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/recommendations/><img src=https://qdrant.tech/img/menu/recommendation-systems.svg draggable=false>
<span>Recommendation Systems</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/advanced-search/><img src=https://qdrant.tech/img/menu/advanced-search.svg draggable=false>
<span>Advanced Search</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/data-analysis-anomaly-detection/><img src=https://qdrant.tech/img/menu/data-analysis-anomaly-detection.svg draggable=false>
<span>Data Analysis & Anomaly Detection</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/ai-agents/><img src=https://qdrant.tech/img/menu/ai-agents.svg draggable=false>
<span>AI Agents</span></a></li></ul></li><li class=main-menu__item><span>Developers</span><ul class=main-menu__submenu><li class=main-menu__submenu-item><a href=https://qdrant.tech/documentation/><img src=https://qdrant.tech/img/menu/documentation.svg draggable=false>
<span>Documentation</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/community/><img src=https://qdrant.tech/img/menu/community.svg draggable=false>
<span>Community</span></a></li><li class=main-menu__submenu-item><a href=https://github.com/qdrant/qdrant target=_blank rel="noopener noreferrer nofollow"><img src=https://qdrant.tech/img/menu/github.svg draggable=false>
<span>GitHub</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.to/roadmap target=_blank rel="noopener noreferrer nofollow"><img src=https://qdrant.tech/img/menu/roadmap.svg draggable=false>
<span>Roadmap</span></a></li><li class=main-menu__submenu-item><a href=https://github.com/qdrant/qdrant/releases target=_blank rel="noopener noreferrer nofollow"><img src=https://qdrant.tech/img/menu/changelog.svg draggable=false>
<span>Change Log</span></a></li></ul></li><li class=main-menu__item><span>Resources</span><ul class=main-menu__submenu><li class=main-menu__submenu-item><a href=https://qdrant.tech/benchmarks/><img src=https://qdrant.tech/img/menu/benchmarks.svg draggable=false>
<span>Benchmarks</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/blog/><img src=https://qdrant.tech/img/menu/blog.svg draggable=false>
<span>Blog</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/articles/><img src=https://qdrant.tech/img/menu/articles.svg draggable=false>
<span>Articles</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/demo/><img src=https://qdrant.tech/img/menu/demos.svg draggable=false>
<span>Demos</span></a></li><li class=main-menu__submenu-item><a href=https://try.qdrant.tech/events target=_blank rel="noopener noreferrer nofollow"><img src=https://qdrant.tech/img/menu/partners.svg draggable=false>
<span>Events</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/qdrant-for-startups/><img src=https://qdrant.tech/img/menu/qdrant-for-startups.svg draggable=false>
<span>Startup Program</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/security/bug-bounty-program/><img src=https://qdrant.tech/img/menu/bug-bounty-program.svg draggable=false>
<span>Bug Bounty Program</span></a></li></ul></li><li class=main-menu__item><span>Company</span><ul class=main-menu__submenu><li class=main-menu__submenu-item><a href=https://qdrant.tech/about-us/><img src=https://qdrant.tech/img/menu/about-us.svg draggable=false>
<span>About us</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/customers/><img src=https://qdrant.tech/img/menu/customers.svg draggable=false>
<span>Customers</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/partners/><img src=https://qdrant.tech/img/menu/partners.svg draggable=false>
<span>Partners</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.join.com/ target=_blank rel="noopener noreferrer nofollow"><img src=https://qdrant.tech/img/menu/careers.svg draggable=false>
<span>Careers</span></a></li><li class=main-menu__submenu-item><a href=https://qdrant.tech/contact-us/><img src=https://qdrant.tech/img/menu/contact-us.svg draggable=false>
<span>Contact us</span></a></li></ul></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/pricing/>Pricing</a></li></ul><div class=main-menu__buttons><a data-metric-loc=nav href=https://cloud.qdrant.io/login class="menu-link mx-3">Log in</a>
<a data-metric-loc=nav href=https://cloud.qdrant.io/signup class="button button_contained button_sm">Get Started</a></div></div><div class=menu-mobile><div class=menu-mobile__header><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div><button type=button class=menu-mobile__close><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M19.0713 4.92871 4.92915 19.0708" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M19.0713 19.0708 4.9292 4.92871" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__items><li class=menu-mobile__item data-path=menu-0><div class=menu-mobile__item-content>Products
<button type=button class=menu-mobile__expand><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M2 7 12 17 22 7" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__subitems><a href=https://qdrant.tech/qdrant-vector-database/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/qdrant-vector-database.svg)></span>Qdrant Vector Database</li></a><a href=https://qdrant.tech/cloud/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/qdrant-cloud.svg)></span>Qdrant Cloud</li></a><a href=https://qdrant.tech/hybrid-cloud/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/hybrid-cloud.svg)></span>Qdrant Hybrid Cloud</li></a><a href=https://qdrant.tech/enterprise-solutions/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/qdrant-enterprise-solutions.svg)></span>Qdrant Enterprise Solutions</li></a></ul></li><li class=menu-mobile__item data-path=menu-1><div class=menu-mobile__item-content>Use Cases
<button type=button class=menu-mobile__expand><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M2 7 12 17 22 7" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__subitems><li class=menu-mobile__section-link><a class="link link_neutral link_sm" href=https://qdrant.tech/use-cases/>Use Cases</a></li><a href=https://qdrant.tech/rag/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/rag.svg)></span>RAG</li></a><a href=https://qdrant.tech/recommendations/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/recommendation-systems.svg)></span>Recommendation Systems</li></a><a href=https://qdrant.tech/advanced-search/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/advanced-search.svg)></span>Advanced Search</li></a><a href=https://qdrant.tech/data-analysis-anomaly-detection/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/data-analysis-anomaly-detection.svg)></span>Data Analysis & Anomaly Detection</li></a><a href=https://qdrant.tech/ai-agents/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/ai-agents.svg)></span>AI Agents</li></a></ul></li><li class=menu-mobile__item data-path=menu-2><div class=menu-mobile__item-content>Developers
<button type=button class=menu-mobile__expand><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M2 7 12 17 22 7" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__subitems><a href=https://qdrant.tech/documentation/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/documentation.svg)></span>Documentation</li></a><a href=https://qdrant.tech/community/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/community.svg)></span>Community</li></a><a href=https://github.com/qdrant/qdrant><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/github.svg)></span>GitHub</li></a><a href=https://qdrant.to/roadmap><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/roadmap.svg)></span>Roadmap</li></a><a href=https://github.com/qdrant/qdrant/releases><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/changelog.svg)></span>Change Log</li></a></ul></li><li class=menu-mobile__item data-path=menu-3><div class=menu-mobile__item-content>Resources
<button type=button class=menu-mobile__expand><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M2 7 12 17 22 7" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__subitems><a href=https://qdrant.tech/benchmarks/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/benchmarks.svg)></span>Benchmarks</li></a><a href=https://qdrant.tech/blog/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/blog.svg)></span>Blog</li></a><a href=https://qdrant.tech/articles/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/articles.svg)></span>Articles</li></a><a href=https://qdrant.tech/demo/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/demos.svg)></span>Demos</li></a><a href=https://try.qdrant.tech/events><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/partners.svg)></span>Events</li></a><a href=https://qdrant.tech/qdrant-for-startups/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/qdrant-for-startups.svg)></span>Startup Program</li></a><a href=https://qdrant.tech/security/bug-bounty-program/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/bug-bounty-program.svg)></span>Bug Bounty Program</li></a></ul></li><li class=menu-mobile__item data-path=menu-4><div class=menu-mobile__item-content>Company
<button type=button class=menu-mobile__expand><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M2 7 12 17 22 7" stroke="#161e33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=menu-mobile__subitems><a href=https://qdrant.tech/about-us/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/about-us.svg)></span>About us</li></a><a href=https://qdrant.tech/customers/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/customers.svg)></span>Customers</li></a><a href=https://qdrant.tech/partners/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/partners.svg)></span>Partners</li></a><a href=https://qdrant.join.com/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/careers.svg)></span>Careers</li></a><a href=https://qdrant.tech/contact-us/><li class=menu-mobile__subitem><span style=background-image:url(/img/menu/contact-us.svg)></span>Contact us</li></a></ul></li><li class=menu-mobile__item data-path=menu-5><div class=menu-mobile__item-content><a href=https://qdrant.tech/pricing/>Pricing</a></div></li></ul><div class=menu-mobile__controls><a data-metric-loc=mobile_nav href=https://cloud.qdrant.io/login class="button button_outlined button_lg menu-mobile__login">Log in</a>
<a data-metric-loc=mobile_nav href=https://cloud.qdrant.io/signup class="button button_contained button_lg">Get Started</a></div></div></header><progress id=progress class=progress-bar value=0 max=100>0</progress><section class="qdrant-post
qdrant-blog-post"><article id=article class=container><div class=qdrant-post__header><h1 class=qdrant-post__title>Advancements and Challenges in RAG Systems - Syed Asad | Vector Space Talks</h1><div class=qdrant-post__about><p>Demetrios Brinkmann</p><span>&#183;</span><p>April 11, 2024</p></div><picture class=qdrant-post__preview><img src=https://qdrant.tech/blog/rag-advancements-challenges/preview/title.jpg alt="Advancements and Challenges in RAG Systems - Syed Asad | Vector Space Talks" loading=lazy></picture></div><div class="row qdrant-post__breadcrumbs"><div class=col-12><ul class=breadcrumbs><li class=breadcrumbs__crumb><a href=https://qdrant.tech/>Home</a></li><li class=breadcrumbs__crumb>/</li><li class=breadcrumbs__crumb><a href=https://qdrant.tech/blog/>Blog</a></li><li class=breadcrumbs__crumb>/</li><li class=breadcrumbs__crumb>Advancements and Challenges in RAG Systems - Syed Asad | Vector Space Talks</li></ul></div></div><div class=qdrant-post__body><div class=table-of-contents><p class=table-of-contents__head>On this page:</p><nav id=TableOfContents><ul><li><ul><li><a href=#top-takeaways><strong>Top takeaways:</strong></a></li><li><a href=#show-notes>Show notes:</a></li><li><a href=#more-quotes-from-syed>More Quotes from Syed:</a></li><li><a href=#transcript>Transcript:</a></li></ul></li></ul></nav><ul class=table-of-contents__external-links><li class=table-of-contents__link><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fqdrant.tech%2Fblog%2Frag-advancements-challenges%2F&amp;text=Advancements%20and%20Challenges%20in%20RAG%20Systems%20-%20Syed%20Asad%20%7c%20Vector%20Space%20Talks" target=_blank rel="noopener noreferrer" title=x><svg width="33" height="33" viewBox="0 0 33 33" fill="none"><path d="M14.959 20.7369l-8.581 9.798H1.625l11.114-12.696 2.22 2.898z" fill="#161e33"/><path d="M17.5508 11.5229l7.857-8.98799h4.75L19.7508 14.4369l-2.2-2.914z" fill="#161e33"/><path d="M31.9877 30.5349h-9.559L1.01172 2.53491H10.8127L31.9877 30.5349zm-8.248-2.843h2.632L9.38272 5.22891h-2.824L23.7397 27.6919z" fill="#161e33"/></svg>
Share on X</a></li><li class=table-of-contents__link><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fqdrant.tech%2Fblog%2Frag-advancements-challenges%2F" target=_blank rel="noopener noreferrer" title=LinkedIn><svg width="32" height="33" viewBox="0 0 32 33" fill="none"><g clip-path="url(#clip0_1811_16094)"><path d="M30.6667.4375H1.33333C.533333.4375.0.970833.0 1.77083V31.1042C0 31.9042.533333 32.4375 1.33333 32.4375H30.6667C31.4667 32.4375 32 31.9042 32 31.1042V1.77083C32 .970833 31.4667.4375 30.6667.4375zM9.46667 27.7708H4.8V12.4375H9.6V27.7708H9.46667zm-2.4-17.4666c-1.46667.0-2.8-1.20003-2.8-2.80003.0-1.46667 1.2-2.8 2.8-2.8 1.46666.0 2.8 1.2 2.8 2.8s-1.2 2.80003-2.8 2.80003zM27.3333 27.7708h-4.8V20.3042c0-1.7334.0-4-2.4-4-2.5333.0-2.8 1.8666-2.8 3.8666v7.6h-4.8V12.4375h4.5334v2.1333C17.7333 13.3708 19.2 12.1708 21.6 12.1708c4.8.0 5.7333 3.2 5.7333 7.3334v8.2666z" fill="#161e33"/></g><defs><clipPath id="clip0_1811_16094"><rect width="32" height="32" fill="#fff" transform="translate(0 0.4375)"/></clipPath></defs></svg>
Share on LinkedIn</a></li></ul></div><div class=qdrant-post__content><blockquote><p><em>&ldquo;The problem with many of the vector databases is that they work fine, they are scalable. This is common. The problem is that they are not easy to use. So that is why I always use Qdrant.”</em><br>— Syed Asad</p></blockquote><p>Syed Asad is an accomplished AI/ML Professional, specializing in LLM Operations and RAGs. With a focus on Image Processing and Massive Scale Vector Search Operations, he brings a wealth of expertise to the field. His dedication to advancing artificial intelligence and machine learning technologies has been instrumental in driving innovation and solving complex challenges. Syed continues to push the boundaries of AI/ML applications, contributing significantly to the ever-evolving landscape of the industry.</p><p><em><strong>Listen to the episode on <a href="https://open.spotify.com/episode/4Gm4TQsO2PzOGBp5U6Cj2e?si=JrG0kHDpRTeb2gLi5zdi4Q" target=_blank rel="noopener nofollow">Spotify</a>, Apple Podcast, Podcast addicts, Castbox. You can also watch this episode on <a href="https://youtu.be/RVb6_CI7ysM?si=8Hm7XSWYTzK6SRj0" target=_blank rel="noopener nofollow">YouTube</a>.</strong></em></p><iframe width=560 height=315 src="https://www.youtube.com/embed/RVb6_CI7ysM?si=8Hm7XSWYTzK6SRj0" title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy=strict-origin-when-cross-origin allowfullscreen></iframe>
<iframe src=https://podcasters.spotify.com/pod/show/qdrant-vector-space-talk/embed/episodes/Advancements-and-Challenges-in-RAG-Systems---Syed-Asad--Vector-Space-Talks-021-e2i112h/a-ab4vnl8 height=102px width=400px frameborder=0 scrolling=no></iframe><h2 id=top-takeaways><strong>Top takeaways:</strong></h2><p>Prompt engineering is the new frontier in AI. Let’s find out about how critical its role is in controlling AI language models. In this episode, Demetrios and Syed gets to discuss about it.</p><p>Syed also explores the retrieval augmented generation systems and machine learning technology at Kiwi Tech. This episode showcases the challenges and advancements in AI applications across various industries.</p><p>Here are the highlights from this episode:</p><ol><li><strong>Digital Family Tree:</strong> Learn about the family tree app project that brings the past to life through video interactions with loved ones long gone.</li><li><strong>Multimodal Mayhem:</strong> Discover the complexities of creating AI systems that can understand diverse accents and overcome transcription tribulations – all while being cost-effective!</li><li><strong>The Perfect Match:</strong> Find out how semantic chunking is revolutionizing job matching in radiology and why getting the context right is non-negotiable.</li><li><strong>Quasar&rsquo;s Quantum Leap:</strong> Syed shares the inside scoop on Quasar, a financial chatbot, and the AI magic that makes it tick.</li><li><strong>The Privacy Paradox:</strong> Delve into the ever-present conflict between powerful AI outcomes and the essential quest to preserve data privacy.</li></ol><blockquote><p>Fun Fact: Syed Asad and his team at Kiwi Tech use a GPU-based approach with GPT 4 for their AI system named Quasar, addressing challenges like temperature control and mitigating hallucinatory responses.</p></blockquote><h2 id=show-notes>Show notes:</h2><p>00:00 Clients seek engaging multimedia apps over chatbots.<br>06:03 Challenges in multimodal rags: accent, transcription, cost.<br>08:18 AWS credits crucial, but costs skyrocket quickly.<br>10:59 Accurate procedures crucial, Qdrant excels in search.<br>14:46 Embraces AI for monitoring and research.<br>19:47 Seeking insights on ineffective marketing models and solutions.<br>23:40 GPT 4 useful, prompts need tracking tools<br>25:28 Discussing data localization and privacy, favoring Ollama.<br>29:21 Hallucination control and pricing are major concerns.<br>32:47 DeepEval, AI testing, LLM, potential, open source.<br>35:24 Filter for appropriate embedding model based on use case and size.</p><h2 id=more-quotes-from-syed>More Quotes from Syed:</h2><p><em>&ldquo;Qdrant has the ease of use. I have trained people in my team who specializes with Qdrant, and they were initially using Weaviate and Pinecone.”</em><br>— Syed Asad</p><p><em>&ldquo;What&rsquo;s happening nowadays is that the clients or the projects in which I am particularly working on are having more of multimedia or multimodal approach. They want their apps or their LLM apps to be more engaging rather than a mere chatbot.”</em><br>— Syed Asad</p><p><em>&ldquo;That is where the accuracy matters the most. And in this case, Qdrant has proved just commendable in giving excellent search results.”</em><br>— Syed Asad in Advancements in Medical Imaging Search</p><h2 id=transcript>Transcript:</h2><p>Demetrios:
What is up, good people? How y&rsquo;all doing? We are back for yet another vector space talks. I&rsquo;m super excited to be with you today because we&rsquo;re gonna be talking about rags and rag systems. And from the most basic naive rag all the way to the most advanced rag, we&rsquo;ve got it covered with our guest of honor, Asad. Where are you at, my man? There he is. What&rsquo;s going on, dude?</p><p>Syed Asad:
Yeah, everything is fine.</p><p>Demetrios:
Excellent, excellent. Well, I know we were talking before we went live, and you are currently in India. It is very late for you, so I appreciate you coming on here and doing this with us. You are also, for those who do not know, a senior engineer for AI and machine learning at Kiwi Tech. Can you break down what Kiwi tech is for us real fast?</p><p>Syed Asad:
Yeah, sure. Absolutely. So Kiwi tech is actually a software development, was actually a software development company focusing on software development, iOS and mobile apps. And right now we are in all focusing more on generative AI, machine learning and computer vision projects. So I am heading the AI part here. So. And we are having loads of projects here with, from basic to advanced rags, from naive to visual rags. So basically I&rsquo;m doing rag in and out from morning to evening.</p><p>Demetrios:
Yeah, you can&rsquo;t get away from it, huh? Man, that is great.</p><p>Syed Asad:
Everywhere there is rag. Even, even the machine learning part, which was previously done by me, is all now into rags engineered AI. Yeah. Machine learning is just at the background now.</p><p>Demetrios:
Yeah, yeah, yeah. It&rsquo;s funny, I understand the demand for it because people are trying to see where they can get value in their companies with the new generative AI advancements.</p><p>Syed Asad:
Yeah.</p><p>Demetrios:
So I want to talk a lot about advance rags, considering the audience that we have. I would love to hear about the visual rags also, because that sounds very exciting. Can we start with the visual rags and what exactly you are doing, what you&rsquo;re working on when it comes to that?</p><p>Syed Asad:
Yeah, absolutely. So initially when I started working, so you all might be aware with the concept of frozen rags, the normal and the basic rag, there is a text retrieval system. You just query your data and all those things. So what is happening nowadays is that the clients or the projects in which I am particularly working on are having more of multimedia or multimodal approach. So that is what is happening. So they want their apps or their LLM apps to be more engaging rather than a mere chatbot. Because. Because if we go on to the natural language or the normal english language, I mean, interacting by means of a video or interacting by means of a photo, like avatar, generation, anything like that.</p><p>Syed Asad:
So that has become more popular or, and is gaining more popularity. And if I talk about, specifically about visual rags. So the projects which I am working on is, say, for example, say, for example, there is a family tree type of app in which. In which you have an account right now. So, so you are recording day videos every day, right? Like whatever you are doing, for example, you are singing a song, you&rsquo;re walking in the park, you are eating anything like that, and you&rsquo;re recording those videos and just uploading them on that app. But what do you want? Like, your future generations can do some sort of query, like what, what was my grandfather like? What was my, my uncle like? Anything my friend like. And it was, it is not straight, restricted to a family. It can be friends also.</p><p>Syed Asad:
Anyway, so. And these are all us based projects, not indian based projects. Okay, so, so you, you go in query and it returns a video about your grandfather who has already died. He has not. You can see him speaking about that particular thing. So it becomes really engaging. So this is something which is called visual rag, which I am working right now on this.</p><p>Demetrios:
I love that use case. So basically it&rsquo;s, I get to be closer to my family that may or may not be here with us right now because the rag can pull writing that they had. It can pull video of other family members talking about it. It can pull videos of when my cousin was born, that type of stuff.</p><p>Syed Asad:
Anything, anything from cousin to family. You can add any numbers of members of your family. You can give access to any number of people who can have after you, after you&rsquo;re not there, like a sort of a nomination or a delegation live up thing. So that is, I mean, actually, it is a very big project, involves multiple transcription models, video transcription models. It also involves actually the databases, and I&rsquo;m using Qdrant, proud of it. So, in that, so. And Qdrant is working seamlessly in that. So, I mean, at the end there is a vector search, but at the background there is more of more of visual rag, and people want to communicate through videos and photos.</p><p>Syed Asad:
So that is coming into picture more.</p><p>Demetrios:
Well, talk to me about multimodal rag. And I know it&rsquo;s a bit of a hairy situation because if you&rsquo;re trying to do vector search with videos, it can be a little bit more complicated than just vector search with text. Right. So what are some of the unique challenges that you&rsquo;ve seen when it comes to multimodal rag?</p><p>Syed Asad:
The first challenge dealing with multimodal rags is actually the accent, because it can be varying accent. The problem with the transcription, one of the problems or the challenges which I have faced in this is that lack of proper transcription models, if you are, if you are able to get a proper transcription model, then if that, I want to deploy that model in the cloud, say for example, an AWS cloud. So that AWS cloud is costing heavy on the pockets. So managing infra is one of the part. I mean, I&rsquo;m talking in a, in a, in a highly scalable production environment. I&rsquo;m not talking about a research environment in which you can do anything on a collab notebook and just go with that. So whenever it comes to the client part or the delivery part, it becomes more critical. And even there, there were points then that we have to entirely overhaul the entire approach, which was working very fine when we were doing it on the dev environment, like the openais whisper.</p><p>Syed Asad:
We started with that OpenAI&rsquo;s whisper. It worked fine. The transcription was absolutely fantastic. But we couldn&rsquo;t go into the production.</p><p>Demetrios:
Part with that because it was too, the word error rate was too high, or because it was too slow. What made it not allow you to go into production?</p><p>Syed Asad:
It was, the word error rate was also high. It was very slow when it was being deployed on an AWS instance. And the thing is that the costing part, because usually these are startups, or mid startup, if I talk about the business point of view, not the tech point of view. So these companies usually offer these type of services for free, and on the basis of these services they try to raise funding. So they want something which is actually optimized, optimizing their cost as well. So what I personally feel, although AWS is massively scalable, but I don&rsquo;t prefer AWS at all until, unless there are various other options coming out, like salad. I had a call, I had some interactions with Titan machine learning also, but it was also fine. But salad is one of the best as of now.</p><p>Demetrios:
Yeah. Unless you get that free AWS credits from the startup program, it can get very expensive very quickly. And even if you do have the free AWS credits, it still gets very expensive very quickly. So I understand what you&rsquo;re saying is basically it was unusable because of the cost and the inability to figure out, it was more of a product problem if you could figure out how to properly monetize it. But then you had technical problems like word error rate being really high, the speed and latency was just unbearable. I can imagine. So unless somebody makes a query and they&rsquo;re ready to sit around for a few minutes and let that query come back to you, with a video or some documents, whatever it may be. Is that what I&rsquo;m understanding on this? And again, this is for the family tree use case that you&rsquo;re talking about.</p><p>Syed Asad:
Yes, family tree use case. So what was happening in that, in that case is a video is uploaded, it goes to the admin for an approval actually. So I mean you can, that is where we, they were restricting the costing part as far as the project was concerned. It&rsquo;s because you cannot upload any random videos and they will select that. Just some sort of moderation was also there, as in when the admin approves those videos, that videos goes on to the transcription pipeline. They are transcripted via an, say a video to text model like the open eyes whisper. So what was happening initially, all the, all the research was done with Openais, but at the end when deployment came, we have to go with deep Gram and AssemblyAI. That was the place where these models were excelling far better than OpenAI.</p><p>Syed Asad:
And I&rsquo;m a big advocate of open source models, so also I try to leverage those, but it was not pretty working in production environment.</p><p>Demetrios:
Fascinating. So you had that, that&rsquo;s one of your use cases, right? And that&rsquo;s very much the multimodal rag use case. Are all of your use cases multimodal or did you have, do you have other ones too?</p><p>Syed Asad:
No, all are not multimodal. There are few multimodal, there are few text based on naive rag also. So what, like for example, there is one use case coming which is sort of a job search which is happening. A job search for a radiology, radiology section. I mean a very specialized type of client it is. And they&rsquo;re doing some sort of job search matching the modalities and procedures. And it is sort of a temporary job. Like, like you have two shifts ready, two shifts begin, just some.</p><p>Syed Asad:
So, so that is, that is very critical when somebody is putting their procedures or what in. Like for example, they, they are specializing in x rays in, in some sort of medical procedures and that is matching with the, with the, with the, with the employers requirement. So that is where the accuracy matters the most. Accurate. And in this case, Qdrant has proved just commendable in giving excellent search results. The other way around is that in this case is there were some challenges related to the quality of results also because. So progressing from frozen rack to advanced rag like adopting methods like re ranking, semantic chunking. I have, I have started using semantic chunking.</p><p>Syed Asad:
So it has proved very beneficial as far as the quality of results is concerned.</p><p>Demetrios:
Well, talk to me more about. I&rsquo;m trying to understand this use case and why a rag is useful for the job matching. You have doctors who have specialties and they understand, all right, they&rsquo;re, maybe it&rsquo;s an orthopedic surgeon who is very good at a certain type of surgery, and then you have different jobs that come online. They need to be matched with those different jobs. And so where does the rag come into play? Because it seems like it could be solved with machine learning as opposed to AI.</p><p>Syed Asad:
Yeah, it could have been solved through machine learning, but the type of modalities that are, the type of, say, the type of jobs which they were posting are too much specialized. So it needed some sort of contextual matching also. So there comes the use case for the rag. In this place, the contextual matching was required. Initially, an approach for machine learning was on the table, but it was done with, it was not working.</p><p>Demetrios:
I get it, I get it. So now talk to me. This is really important that you said accuracy needs to be very high in this use case. How did you make sure that the accuracy was high? Besides the, I think you said chunking, looking at the chunks, looking at how you were doing that, what were some other methods you took to make sure that the accuracy was high?</p><p>Syed Asad:
I mean, as far as the accuracy is concerned. So what I did was that my focus was on the embedding model, actually when I started with what type of embed, choice of embedding model. So initially my team started with open source model available readily on hugging face, looking at some sort of leaderboard metrics, some sort of model specializing in medical, say, data, all those things. But even I was curious that the large language, the embedding models which were specializing in medical data, they were also not returning good results and they were mismatching. When, when there was a tabular format, I created a visualization in which the cosine similarity of various models were compared. So all were lagging behind until I went ahead with cohere. Cohere re rankers. They were the best in that case, although they are not trained on that.</p><p>Syed Asad:
And just an API call was required rather than loading that whole model onto the local.</p><p>Demetrios:
Interesting. All right. And so then were you doing certain types, so you had the cohere re ranker that gave you a big up. Were you doing any kind of monitoring of the output also, or evaluation of the output and if so, how?</p><p>Syed Asad:
Yes, for evaluation, for monitoring we readily use arrays AI, because I am a, I&rsquo;m a huge advocate of Llama index also because it has made everything so easier versus lang chain. I mean, if I talk about my personal preference, not regarding any bias, because I&rsquo;m not linked with anybody, I&rsquo;m not promoting it here, but they are having the best thing which I write, I like about Llama index and why I use it, is that anything which is coming into play as far as the new research is going on, like for example, a recent research paper was with the raft retrieval augmented fine tuning, which was released by the Microsoft, and it is right now available on archive. So barely few days after they just implemented it in the library, and you can readily start using it rather than creating your own structure. So, yeah, so it was. So one of my part is that I go through the research papers first, then coming on to a result. So a research based approach is required in actually selecting the models, because every day there is new advancement going on in rags and you cannot figure out what is, what would be fine for you, and you cannot do hit and trial the whole day.</p><p>Demetrios:
Yes, that is a great point. So then if we break down your tech stack, what does it look like? You&rsquo;re using Llama index, you&rsquo;re using arise for the monitoring, you&rsquo;re using Qdrant for your vector database. You have the, you have the coherent re ranker, you are using GPT 3.5.</p><p>Syed Asad:
No, it&rsquo;s GPT 4, not 3.5.</p><p>Demetrios:
You needed to go with GPT 4 because everything else wasn&rsquo;t good enough.</p><p>Syed Asad:
Yes, because one of the context length was one of the most things. But regarding our production, we have been readily using since the last one and a half months. I have been readily using Mixtril. I have been. I have been using because there&rsquo;s one more challenge coming onto the rack, because there&rsquo;s one more I&rsquo;ll give, I&rsquo;ll give you an example of one more use case. It is the I&rsquo;ll name the project also because I&rsquo;m allowed by my company. It is a big project by the name of Quasar markets. It is a us based company and they are actually creating a financial market type of check chatbot.</p><p>Syed Asad:
Q u a s a r, quasar. You can search it also, and they give you access to various public databases also, and some paid databases also. They have a membership plan. So we are entirely handling the front end backend. I&rsquo;m not handling the front end and the back end, I&rsquo;m handling the AI part in that. So one of the challenges is the inference, timing, the timing in which the users are getting queries when it is hitting the database. Say for example, there is a database publicly available database called Fred of us government. So when user can select in that app and go and select the Fred database and want to ask some questions regarding that.</p><p>Syed Asad:
So that is in this place there is no vectors, there are no vector databases. It is going without that. So we are following some keyword approach. We are extracting keywords, classifying the queries in simple or complex, then hitting it again to the database, sending it on the live API, getting results. So there are multiple hits going on. So what happened? This all multiple hits which were going on. They reduced the timing and I mean the user experience was being badly affected as the time for the retrieval has gone up and user and if you&rsquo;re going any query and inputting any query it is giving you results in say 1 minute. You wouldn&rsquo;t be waiting for 1 minute for a result.</p><p>Demetrios:
Not at all.</p><p>Syed Asad:
So this is one of the challenge for a GPU based approach. And in, in the background everything was working on GPT 4 even, not 3.5. I mean the costliest.</p><p>Demetrios:
Yeah.</p><p>Syed Asad:
So, so here I started with the LPU approach, the Grok. I mean it&rsquo;s magical.</p><p>Demetrios:
Yeah.</p><p>Syed Asad:
I have been implementing proc since the last many days and it has been magical. The chatbots are running blazingly fast but there are some shortcomings also. You cannot control the temperature if you have lesser control on hallucination. That is one of the challenges which I am facing. So that is why I am not able to deploy Grok into production right now. Because hallucination is one of the concern for the client. Also for anybody who is having, who wants to have a rag on their own data, say, or AI on their own data, they won&rsquo;t, they won&rsquo;t expect you, the LLM, to be creative. So that is one of the challenges.</p><p>Syed Asad:
So what I found that although many of the tools that are available in the market right now day in and day out, there are more researches. But most of the things which are coming up in our feeds or more, I mean they are coming as a sort of a marketing gimmick. They&rsquo;re not working actually on the ground.</p><p>Demetrios:
Tell me, tell me more about that. What other stuff have you tried that&rsquo;s not working? Because I feel that same way. I&rsquo;ve seen it and I also have seen what feels like some people, basically they release models for marketing purposes as opposed to actual valuable models going out there. So which ones? I mean Grok, knowing about Grok and where it excels and what some of the downfalls are is really useful. It feels like this idea of temperature being able to control the knob on the temperature and then trying to decrease the hallucinations is something that is fixable in the near future. So maybe it&rsquo;s like months that we&rsquo;ll have to deal with that type of thing for now. But I&rsquo;d love to hear what other things you&rsquo;ve tried that were not like you thought they were going to be when you were scrolling Twitter or LinkedIn.</p><p>Syed Asad:
Should I name them?</p><p>Demetrios:
Please. So we all know we don&rsquo;t have to spend our time on them.</p><p>Syed Asad:
I&rsquo;ll start with OpenAI. The clients don&rsquo;t like GPT 4 to be used in there just because the primary concern is the cost. Secondary concern is the data privacy. And the third is that, I mean, I&rsquo;m talking from the client&rsquo;s perspective, not the tech stack perspective.</p><p>Demetrios:
Yeah, yeah, yeah.</p><p>Syed Asad:
They consider OpenAI as a more of a marketing gimmick. Although GPT 4 gives good results. I&rsquo;m, I&rsquo;m aware of that, but the clients are not in favor. But the thing is that I do agree that GPT 4 is still the king of llms right now. So they have no option, no option to get the better, better results. But Mixtral is performing very good as far as the hallucinations are concerned. Just keeping the parameter temperature is equal to zero in a python code does not makes the hallucination go off. It is one of my key takeaways.</p><p>Syed Asad:
I have been bogging my head. Just. I&rsquo;ll give you an example, a chat bot. There is a, there&rsquo;s one of the use case in which is there&rsquo;s a big publishing company. I cannot name that company right now. And they want the entire system of books since the last 2025 years to be just converted into a rack pipeline. And the people got query. The.</p><p>Syed Asad:
The basic problem which I was having is handling a hello. When a user types hello. So when you type in hello, it.</p><p>Demetrios:
Gives you back a book.</p><p>Syed Asad:
It gives you back a book even. It is giving you back sometimes. Hello, I am this, this, this. And then again, some information. What you have written in the prompt, it is giving you everything there. I will answer according to this. I will answer according to this. So, so even if the temperature is zero inside the code, even so that, that included lots of prompt engineering.</p><p>Syed Asad:
So prompt engineering is what I feel is one of the most important trades which will be popular, which is becoming popular. And somebody is having specialization in prompt engineering. I mean, they can control the way how an LLM behaves because it behaves weirdly. Like in this use case, I was using croc and Mixtral. So to control Mixtral in such a way. It was heck lot of work, although it, we made it at the end, but it was heck lot of work in prompt engineering part.</p><p>Demetrios:
And this was, this was Mixtral large.</p><p>Syed Asad:
Mixtral, seven bits, eight by seven bits.</p><p>Demetrios:
Yeah. I mean, yeah, that&rsquo;s the trade off that you have to deal with. And it wasn&rsquo;t fine tuned at all.</p><p>Syed Asad:
No, it was not fine tuned because we were constructing a rack pipeline, not a fine tuned application, because right now, right now, even the customers are not interested in getting a fine tune model because it cost them and they are more interested in a contextual, like a rag contextual pipeline.</p><p>Demetrios:
Yeah, yeah. Makes sense. So basically, this is very useful to think about. I think we all understand and we&rsquo;ve all seen that GPT 4 does best if we can. We want to get off of it as soon as possible and see how we can, how far we can go down the line or how far we can go on the difficulty spectrum. Because as soon as you start getting off GPT 4, then you have to look at those kind of issues with like, okay, now it seems to be hallucinating a lot more. How do I figure this out? How can I prompt it? How can I tune my prompts? How can I have a lot of prompt templates or a prompt suite to make sure that things work? And so are you using any tools for keeping track of prompts? I know there&rsquo;s a ton out there.</p><p>Syed Asad:
We initially started with the parameter efficient fine tuning for prompts, but nothing is working 100% interesting. Nothing works 100% it is as far as the prompting is concerned. It goes on to a hit and trial at the end. Huge wastage of time in doing prompt engineering. Even if you are following the exact prompt template given on the hugging face given on the model card anywhere, it will, it will behave, it will act, but after some time.</p><p>Demetrios:
Yeah, yeah.</p><p>Syed Asad:
But mixed well. Is performing very good. Very, very good. Mixtral eight by seven bits. That&rsquo;s very good.</p><p>Demetrios:
Awesome.</p><p>Syed Asad:
The summarization part is very strong. It gives you responses at par with GPT 4.</p><p>Demetrios:
Nice. Okay. And you don&rsquo;t have to deal with any of those data concerns that your customers have.</p><p>Syed Asad:
Yeah, I&rsquo;m coming on to that only. So the next part was the data concern. So they, they want either now or in future the localization of llms. I have been doing it with readily, with Llama, CPP and Ollama. Right now. Ollama is very good. I mean, I&rsquo;m a huge, I&rsquo;m a huge fan of Ollama right now, and it is performing very good as far as the localization and data privacy is concerned because, because at the end what you are selling, it makes things, I mean, at the end it is sales. So even if the client is having data of the customers, they want to make their customers assure that the data is safe.</p><p>Syed Asad:
So that is with the localization only. So they want to gradually go into that place. So I want to bring here a few things. To summarize what I said, localization of llms is one of the concern right now is a big market. Second is quantization of models.</p><p>Demetrios:
Oh, interesting.</p><p>Syed Asad:
In quantization of models, whatever. So I perform scalar quantization and binary quantization, both using bits and bytes. I various other techniques also, but the bits and bytes was the best. Scalar quantization is performing better. Binary quantization, I mean the maximum compression or maximum lossy function is there, so it is not, it is, it is giving poor results. Scalar quantization is working very fine. It, it runs on CPU also. It gives you good results because whatever projects which we are having right now or even in the markets also, they are not having huge corpus of data right now, but they will eventually scale.</p><p>Syed Asad:
So they want something right now so that quantization works. So quantization is one of the concerns. People want to dodge aws, they don&rsquo;t want to go to AWS, but it is there. They don&rsquo;t have any other way. So that is why they want aws.</p><p>Demetrios:
And is that because of costs lock in?</p><p>Syed Asad:
Yeah, cost is the main part.</p><p>Demetrios:
Yeah. They understand that things can get out of hand real quick if you&rsquo;re using AWS and you start using different services. I think it&rsquo;s also worth noting that when you&rsquo;re using different services on AWS, it may be a very similar service. But if you&rsquo;re using sagemaker endpoints on AWS, it&rsquo;s like a lot more expensive than just an EKS endpoint.</p><p>Syed Asad:
Minimum cost for a startup, for just the GPU, bare minimum is minimum. $450. Minimum. It&rsquo;s $450 even without just on the testing phases or the development phases, even when it has not gone into production. So that gives a dent to the client also.</p><p>Demetrios:
Wow. Yeah. Yeah. So it&rsquo;s also, and this is even including trying to use like tranium or inferencia and all of that stuff. You know those services?</p><p>Syed Asad:
I know those services, but I&rsquo;ve not readily tried those services. I&rsquo;m right now in the process of trying salad also for inference, and they are very, very cheap right now.</p><p>Demetrios:
Nice. Okay. Yeah, cool. So if you could wave your magic wand and have something be different when it comes to your work, your day in, day out, especially because you&rsquo;ve been doing a lot of rags, a lot of different kinds of rags, a lot of different use cases with, with rags. Where do you think you would get the biggest uptick in your performance, your ability to just do what you need to do? How could rags be drastically changed? Is it something that you say, oh, the hallucinations. If we didn&rsquo;t have to deal with those, that would make my life so much easier. I didn&rsquo;t have to deal with prompts that would make my life infinitely easier. What are some things like where in five years do you want to see this field be?</p><p>Syed Asad:
Yeah, you figured it right. The hallucination part is one of the concerns, or biggest concerns with the client when it comes to the rag, because what we see on LinkedIn and what we see on places, it gives you a picture that it, it controls hallucination, and it gives you answer that. I don&rsquo;t know anything about this, as mentioned in the context, but it does not really happen when you come to the production. It gives you information like you are developing a rag for a publishing company, and it is giving you. Where is, how is New York like, it gives you information on that also, even if you have control and everything. So that is one of the things which needs to be toned down. As far as the rag is concerned, pricing is the biggest concern right now, because there are very few players in the market as far as the inference is concerned, and they are just dominating the market with their own rates. So this is one of the pain points.</p><p>Syed Asad:
And the. I&rsquo;ll also want to highlight the popular vector databases. There are many Pinecone weaviate, many things. So they are actually, the problem with many of the vector databases is that they work fine. They are scalable. This is common. The problem is that they are not easy to use. So that is why I always use Qdrant.</p><p>Syed Asad:
Not because Qdrant is sponsoring me, not because I am doing a job with Qdrant, but Qdrant is having the ease of use. And it, I have, I have trained people in my team who specialize with Qdrant, and they were initially using Weaviate and Pinecone. I mean, you can do also store vectors in those databases, but it is not especially the, especially the latest development with Pine, sorry, with Qdrant is the fast embed, which they just now released. And it made my work a lot easier by using the ONNX approach rather than a Pytorch based approach, because there was one of the projects in which we were deploying embedding model on an AWS server and it was running continuously. And minimum utilization of ram is 6gb. Even when it is not doing any sort of vector embedding so fast. Embed has so Qdrant is playing a huge role, I should acknowledge them. And one more thing which I would not like to use is LAN chain.</p><p>Syed Asad:
I have been using it. So. So I don&rsquo;t want to use that language because it is not, it did not serve any purpose for me, especially in the production. It serves purpose in the research phase. When you are releasing any notebook, say you have done this and does that. It is not. It does not works well in production, especially for me. Llama index works fine, works well.</p><p>Demetrios:
You haven&rsquo;t played around with anything else, have you? Like Haystack or.</p><p>Syed Asad:
Yeah, haystack. Haystack. I have been playing out around, but haystack is lacking functionalities. It is working well. I would say it is working well, but it lacks some functionalities. They need to add more things as compared to Llama index.</p><p>Demetrios:
And of course, the hottest one on the block right now is DSPY. Right? Have you messed around with that at all?</p><p>Syed Asad:
DSPy, actually DSPY. I have messed with DSPY. But the thing is that DSPY is right now, I have not experimented with that in the production thing, just in the research phase.</p><p>Demetrios:
Yeah.</p><p>Syed Asad:
So, and regarding the evaluation part, DeepEval, I heard you might have a DeepEval. So I&rsquo;ve been using that. It is because one of the, one of the challenges is the testing for the AI. Also, what responses are large language model is generating the traditional testers or the manual tester software? They don&rsquo;t know, actually. So there&rsquo;s one more vertical which is waiting to be developed, is the testing for AI. It has a huge potential. And DeepEval, the LLM based approach on testing is very, is working fine and is open source also.</p><p>Demetrios:
And that&rsquo;s the DeepEval I haven&rsquo;t heard.</p><p>Syed Asad:
Let me just tell you the exact spelling. It is. Sorry. It is DeepEval. D E E P. Deep eval. I can.</p><p>Demetrios:
Yeah. Okay. I know DeepEval. All right. Yeah, for sure. Okay. Hi. I for some reason was understanding D Eval.</p><p>Syed Asad:
Yeah, actually I was pronouncing it wrong.</p><p>Demetrios:
Nice. So these are some of your favorite, non favorite, and that&rsquo;s very good to know. It is awesome to hear about all of this. Is there anything else that you want to say before we jump off? Anything that you can, any wisdom you can impart on us for your rag systems and how you have learned the hard way? So tell us so we don&rsquo;t have to learn that way.</p><p>Syed Asad:
Just go. Don&rsquo;t go with the marketing. Don&rsquo;t go with the marketing. Do your own research. Hugging face is a good, I mean, just fantastic. The leaderboard, although everything does not work in the leaderboard, also say, for example, I don&rsquo;t, I don&rsquo;t know about today and tomorrow, today and yesterday, but there was a model from Salesforce, the embedding model from Salesforce. It is still topping charts, I think, in the, on the MTEB. MTEB leaderboard for the embedding models.</p><p>Syed Asad:
But you cannot use it in the production. It is way too huge to implement it. So what&rsquo;s the use? Mixed bread AI. The mixed bread AI, they are very light based, lightweight, and they, they are working fine. They&rsquo;re not even on the leaderboard. They were on the leaderboard, but they&rsquo;re right, they might not. When I saw they were ranking on around seven or eight on the leaderboard, MTEB leaderboard, but they were working fine. So even on the leaderboard thing, it does not works.</p><p>Demetrios:
And right now it feels a little bit like, especially when it comes to embedding models, you just kind of go to the leaderboard and you close your eyes and then you pick one of them. Have you figured out a way to better test these or do you just find one and then try and use it everywhere?</p><p>Syed Asad:
No, no, that is not the case. Actually what I do is that I need to find the first, the embedding model. Try to find the embedding model based on my use case. Like if it is an embedding model on a medical use case more. So I try to find that. But the second factor to filter that is, is the size of that embedding model. Because at the end, if I am doing the entire POC or an entire research with that embedding model, what? And it has happened to me that we did entire research with embedding models, large language models, and then we have to remove everything just on the production part and it just went in smoke. Everything.</p><p>Syed Asad:
So a lightweight embedding model, especially the one which, which has started working recently, is that the cohere embedding models, and they have given a facility to call those embedding models in a quantized format. So that is also working and fast. Embed is one of the things which is by Qdrant, these two things are working in the production. I&rsquo;m talking in the production for research. You can do anything.</p><p>Demetrios:
Brilliant, man. Well, this has been great. I really appreciate it. Asad, thank you for coming on here and for anybody else that would like to come on to the vector space talks, just let us know. In the meantime, don&rsquo;t get lost in vector space. We will see you all later. Have a great afternoon. Morning, evening, wherever you are.</p><p>Demetrios:
Asad, you taught me so much, bro. Thank you.</p></div></div></article></section><section class=get-started-blogs><div class=container><div class=get-started-blogs__content><div class=row><div class="get-started-blogs__text col-12 col-lg-7"><h3 class=get-started-blogs__title>Get Started with Qdrant Free</h3><a href=https://cloud.qdrant.io/signup class="button button_contained" target=_blank>Get Started</a></div><div class="get-started-blogs__image col-12 col-lg-5"><img src=https://qdrant.tech/img/rocket.svg alt></div></div><div class=get-started-blogs__overlay-top></div></div></div></section></main><footer class=footer><div class=footer__top><div class=container><div class="row justify-content-md-between"><div class="col-12 col-md-6"><a href=https://qdrant.tech/ title="Go to Home Page"><img class=footer__top-logo src=https://qdrant.tech/img/logo-white.png alt="Qdrant Logo"></a></div><div class="col-12 col-md-6 footer__top-social-media-platforms"><a class=footer__top-social-media-link href=https://github.com/qdrant/qdrant target=_blank rel="noopener noreferrer nofollow"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><g clip-path="url(#clip0_1841_958)"><path fill-rule="evenodd" clip-rule="evenodd" d="M12 .299805C5.35.299805.0 5.6498.0 12.2998c0 5.3 3.45 9.8 8.2 11.4C8.8 23.7998 9 23.4498 9 23.0998 9 22.7998 9 22.0498 9 21.0498c-3.35.75-4.05-1.6-4.05-1.6-.55-1.4-1.35-1.75-1.35-1.75-1.1-.75.1-.75.1-.75C4.9 17.0498 5.55 18.1998 5.55 18.1998c1.05 1.85 2.8 1.3 3.5 1C9.15 18.3998 9.45 17.8998 9.8 17.5998 7.15 17.2998 4.35 16.2498 4.35 11.6498c0-1.3.45-2.4 1.25-3.2C5.5 8.1498 5.05 6.9498 5.7 5.2498c0 0 1-.3 3.3 1.25C9.95 6.2498 11 6.0998 12 6.0998S14.05 6.2498 15 6.4998c2.3-1.55 3.3-1.25 3.3-1.25C18.95 6.8998 18.55 8.0998 18.4 8.4498c.75.85 1.25 1.9 1.25 3.2.0 4.6-2.8 5.6-5.5 5.9C14.6 17.8998 14.95 18.6498 14.95 19.7498c0 1.6.0 2.9.0 3.3C14.95 23.3498 15.15 23.7498 15.8 23.6498c4.75-1.55 8.2-6.05 8.2-11.35C24 5.6498 18.65.299805 12 .299805z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_1841_958"><rect width="24" height="24" fill="#fff"/></clipPath></defs></svg>
</a><a class=footer__top-social-media-link href=https://qdrant.to/linkedin target=_blank rel="noopener noreferrer nofollow"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><g clip-path="url(#clip0_1841_961)"><path d="M21.75.75H2.25c-.39782.0-.77936.158035-1.06066.43934C.908035 1.47064.75 1.85218.75 2.25v19.5C.75 22.1478.908035 22.5294 1.18934 22.8107 1.47064 23.092 1.85218 23.25 2.25 23.25h19.5C22.1478 23.25 22.5294 23.092 22.8107 22.8107 23.092 22.5294 23.25 22.1478 23.25 21.75V2.25C23.25 1.85218 23.092 1.47064 22.8107 1.18934 22.5294.908035 22.1478.75 21.75.75zM7.41525 19.9455H4.0305V9.1875H7.41525v10.758zM5.7225 7.71075C5.33338 7.70956 4.95333 7.59309 4.63036 7.37604 4.30739 7.15899 4.05599 6.8511 3.9079 6.49126 3.75981 6.13141 3.72167 5.73575 3.79831 5.35425 3.87495 4.97275 4.06293 4.62251 4.3385 4.34778 4.61408 4.07304 4.96488 3.88613 5.34662 3.81065 5.72835 3.73517 6.1239 3.77451 6.48329 3.92369 6.84268 4.07288 7.1498 4.32522 7.36587 4.64885c.21606.32363.33138.70402.33138 1.09315C7.69735 6.00107 7.6463 6.25762 7.54702 6.49691 7.44774 6.73621 7.30219 6.95355 7.11872 7.13646 6.93525 7.31938 6.71746 7.46426 6.47787 7.56282 6.23827 7.66137 5.98157 7.71164 5.7225 7.71075zM19.9657 19.9455H16.65V14.742c0-1.2652.0-2.8125-1.7625-2.8125s-1.9748 1.3365-1.9748 2.742V20.016H9.6V9.1875h3.102v1.4767H12.7725C13.0924 10.1111 13.5567 9.65537 14.1156 9.34571 14.6746 9.03606 15.3072 8.88415 15.9457 8.90625c3.3848.0 4.0193 2.24995 4.0193 5.13295L19.9657 19.9455z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_1841_961"><rect width="24" height="24" fill="#fff"/></clipPath></defs></svg>
</a><a class=footer__top-social-media-link href=https://qdrant.to/twitter target=_blank rel="noopener noreferrer nofollow"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M10.8423 15.1515 4.40655 22.5H.841797L9.1773 12.978l1.665 2.1735z" fill="#f0f3fa"/><path d="M12.7881 8.241 18.6808 1.5h3.5625l-7.8052 8.9265-1.65-2.1855z" fill="#f0f3fa"/><path d="M23.6158 22.5H16.4465L.383789 1.5H7.73454l15.88126 21zm-6.186-2.1322h1.974L6.66204 3.5205h-2.118L17.4298 20.3678z" fill="#f0f3fa"/></svg>
</a><a class=footer__top-social-media-link href=https://qdrant.to/discord target=_blank rel="noopener noreferrer nofollow"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M5 1C2.79086 1 1 2.79086 1 5V19c0 2.2091 1.79086 4 4 4H19c2.2091.0 4-1.7909 4-4V5c0-2.20914-1.7909-4-4-4H5zM16.3683 18.5964S15.8027 17.9208 15.3314 17.3238C16.4701 17.0557 17.4774 16.3935 18.1749 15.4543 17.6098 15.8317 17.0037 16.1438 16.3683 16.3846 15.6374 16.6966 14.873 16.9233 14.0903 17.0602 12.7448 17.3079 11.3649 17.3026 10.0213 17.0445 9.23256 16.8901 8.45954 16.664 7.71193 16.3689 7.08195 16.1284 6.48116 15.8174 5.92097 15.442 6.59328 16.3616 7.56575 17.0173 8.67025 17.2958 8.19895 17.8928 7.61767 18.5998 7.61767 18.5998 4.14571 18.4898 2.82605 16.2091 2.82605 16.2091 2.87704 13.0242 3.65058 9.89242 5.08832 7.05004 6.35356 6.05636 7.89607 5.47998 9.5029 5.40046l.1571.18853c-1.51174.37413-2.92245 1.0768-4.13179 2.05804.0.0.34562-.18853.926900000000001-.4556C7.58438 6.67595 8.78793 6.34193 10.0213 6.20168 10.1093 6.18348 10.1986 6.17297 10.2884 6.17026 11.3412 6.0331 12.4066 6.02255 13.4619 6.13884c1.6595.18933 3.2659.70144 4.7288 1.5075C17.0426 6.71186 15.7093 6.0318 14.2788 5.65114L14.4988 5.39978C16.1056 5.4793 17.6481 6.05568 18.9133 7.04935c1.4378 2.84239 2.2113 5.97415 2.2623 9.15905.0.0-1.3354 2.278-4.8073 2.388zM9.06284 11.2616C8.62563 11.2983 8.21817 11.498 7.9212 11.821 7.62423 12.1439 7.45941 12.5667 7.45941 13.0054c0 .438800000000001.16482.8615.46179 1.1845S8.62563 14.7125 9.06284 14.7493C9.50005 14.7125 9.90751 14.5129 10.2045 14.1899 10.5015 13.8669 10.6663 13.4442 10.6663 13.0054c0-.438699999999999-.1648-.8615-.4618-1.1844C9.90751 11.498 9.50005 11.2983 9.06284 11.2616zm5.73766.0C14.4493 11.2319 14.0974 11.3089 13.7907 11.4825c-.3066.1736-.553699999999999.4358-.7089.7522-.155199999999999.3164-.2112.6723-.1608 1.021C12.9714 13.6045 13.1259 13.93 13.3644 14.1894 13.6028 14.4489 13.9141 14.6304 14.2573 14.71 14.6006 14.7897 14.96 14.7639 15.2883 14.6359c.3284-.1279.6104-.352.8093-.642899999999999C16.2965 13.702 16.4029 13.3578 16.4029 13.0054 16.4124 12.7854 16.3783 12.5657 16.3026 12.3588 16.2269 12.152 16.1112 11.9622 15.962 11.8002 15.8128 11.6381 15.6331 11.5072 15.4332 11.4148 15.2333 11.3223 15.0171 11.2703 14.7971 11.2616H14.8005z" fill="#f0f3fa"/></svg>
</a><a class=footer__top-social-media-link href=https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA target=_blank rel="noopener noreferrer nofollow"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M23.775 7.1999S23.55 5.5499 22.8 4.7999C21.9 3.8249 20.85 3.8249 20.4 3.7499c-3.375-.225-8.4-.225-8.4-.225s-5.025.0-8.4.225C3.15 3.8249 2.1 3.8249 1.2 4.7999c-.75.75-.975 2.4-.975 2.4S0 9.1499.0 11.0999v1.8c0 1.95.225 3.9.225 3.9s.225 1.65.975 2.4C2.1 20.1749 3.3 20.0999 3.825 20.2499 5.775 20.3999 12 20.4749 12 20.4749S17.025 20.4749 20.4 20.2499C20.85 20.1749 21.9 20.1749 22.8 19.1999 23.55 18.4499 23.775 16.7999 23.775 16.7999S24 14.8499 24 12.8999v-1.8C24 9.1499 23.775 7.1999 23.775 7.1999zm-14.25 7.95v-6.75l6.45 3.375-6.45 3.375z" fill="#f0f3fa"/></svg></a></div></div></div></div><div class=footer__menu><div class=container><nav class=footer__menu-content><div class=footer__menu-section><p class=footer__menu-section-title>Products</p><ul class=footer__menu-items><li class=footer__menu-item><a href=https://qdrant.tech/qdrant-vector-database/>Qdrant Vector Database</a></li><li class=footer__menu-item><a href=https://qdrant.tech/cloud/>Qdrant Cloud</a></li><li class=footer__menu-item><a href=https://qdrant.tech/hybrid-cloud/>Qdrant Hybrid Cloud</a></li><li class=footer__menu-item><a href=https://qdrant.tech/enterprise-solutions/>Qdrant Enterprise Solutions</a></li><li class=footer__menu-item><a href=https://qdrant.tech/pricing/>Pricing</a></li></ul></div><div class=footer__menu-section><p class=footer__menu-section-title>Use Cases</p><ul class=footer__menu-items><li class=footer__menu-item><a href=https://qdrant.tech/advanced-search/>Advanced Search</a></li><li class=footer__menu-item><a href=https://qdrant.tech/recommendations/>Recommendation Systems</a></li><li class=footer__menu-item><a href=https://qdrant.tech/rag/>Retrieval Augmented Generation</a></li><li class=footer__menu-item><a href=https://qdrant.tech/data-analysis-anomaly-detection/>Data Analysis & Anomaly Detection</a></li><li class=footer__menu-item><a href=https://qdrant.tech/ai-agents/>AI Agents</a></li></ul></div><div class=footer__menu-section><p class=footer__menu-section-title>Developers</p><ul class=footer__menu-items><li class=footer__menu-item><a href=https://qdrant.tech/documentation/>Documentation</a></li><li class=footer__menu-item><a href=https://qdrant.tech/community/>Community</a></li><li class=footer__menu-item><a href=https://github.com/qdrant/qdrant target=_blank rel="noopener noreferrer nofollow">GitHub</a></li><li class=footer__menu-item><a href=https://qdrant.to/roadmap target=_blank rel="noopener noreferrer nofollow">Roadmap</a></li><li class=footer__menu-item><a href=https://github.com/qdrant/qdrant/releases target=_blank rel="noopener noreferrer nofollow">Change Log</a></li><li class=footer__menu-item><a href=https://status.qdrant.io/ target=_blank rel="noopener noreferrer nofollow">Status Page</a></li></ul></div><div class=footer__menu-section><p class=footer__menu-section-title>Resources</p><ul class=footer__menu-items><li class=footer__menu-item><a href=https://qdrant.tech/blog/>Blog</a></li><li class=footer__menu-item><a href=https://qdrant.tech/benchmarks/>Benchmarks</a></li><li class=footer__menu-item><a href=https://qdrant.tech/articles/>Articles</a></li><li class=footer__menu-item><a href=https://try.qdrant.tech/events target=_blank rel="noopener noreferrer nofollow">Events</a></li><li class=footer__menu-item><a href=https://qdrant.tech/qdrant-for-startups/>Startup Program</a></li><li class=footer__menu-item><a href=https://qdrant.tech/demo/>Demos</a></li><li class=footer__menu-item><a href=https://qdrant.tech/security/bug-bounty-program/>Bug Bounty</a></li></ul></div><div class=footer__menu-section><p class=footer__menu-section-title>Company</p><ul class=footer__menu-items><li class=footer__menu-item><a href=https://qdrant.tech/about-us/>About Us</a></li><li class=footer__menu-item><a href=https://qdrant.tech/customers/>Customers</a></li><li class=footer__menu-item><a href=https://qdrant.tech/partners/>Partners</a></li><li class=footer__menu-item><a href=https://qdrant.join.com/ target=_blank rel="noopener noreferrer nofollow">Careers</a></li><li class=footer__menu-item><a href=https://qdrant.tech/contact-us/>Contact Us</a></li></ul></div></nav></div></div><div class=footer__middle><div class=container><div class="align-items-center row"><div class="col-12 col-lg-5"><p class=footer__middle-title>Sign up for Qdrant updates</p><p class=footer__middle-subtitle>We'll occasionally send you best practices for using vector data and similarity search, as well as product news.</p></div><div class="footer__middle-newsletter col-12 col-lg-7"><div id=footer-subscribe-form><script>(function(){const t={region:"eu1",portalId:"139603372",formId:"049d96c6-ef65-4e41-ba69-a3335b9334cf",cssClass:"subscribe-form",submitButtonClass:"button button_contained button_lg",submitText:"Subscribe"},n="weh",s=function(){const e=document.createElement("input");return e.classList.add(n),e.type="text",e.name="my-work-email",e.style.display="none",e.placeholder="Email",e.ariaHidden="true",e},o=function(e){const t=s();e.appendChild(t);const n=e.querySelector('[type="submit"]');t.addEventListener("input",function(){t.value.length>0&&(n.disabled=!0)})},i=["Argentina","Belgium","Canada","Czech Republic","Cyprus","Denmark","Germany","Hungary","Latvia","Liechtenstein","Luxembourg","Netherlands","Norway","France","Finland","Croatia","Bulgaria","Belarus","Bosnia and Herzegovina","Austria","Estonia","Georgia","Greenland","Hong Kong","Israel","Italy","Maldives","Moldova","Monaco","Portugal","Russia","Serbia","Slovakia","Slovenia","Sweden","Switzerland","Türkiye","Ukraine","Macedonia (FYROM)","United Kingdom"];function e(e){const a=e.querySelector('select[name="country"]'),n=e.querySelector(".legal-consent-container .hs-fieldtype-booleancheckbox"),r=e.querySelector(".legal-consent-container > div:nth-child(3)"),c=e.querySelector(".legal-consent-container > div:nth-child(2)");if(!a||!n)return;const s=a.value,l=i.includes(s),o=s&&l,t=n.querySelector('input[type="checkbox"]');n.style.display=o?"block":"none",r&&(r.style.display=o?"block":"none"),c&&(c.style.display=o?"none":"block"),s&&!l?t.checked||t.click():t.checked&&t.click()}try{hbspt.forms.create({...t,formInstanceId:"#footer-subscribe-form",pageId:"",target:"#footer-subscribe-form",onFormReady:function(t){if(!t){console.warn("Form not found.");return}o(t),e(t);const n=t.querySelector('select[name="country"]');n&&n.addEventListener("change",()=>e(t))}})}catch{document.getElementById("footer-subscribe-form").innerHTML='<p class="text-white">Here should be a form but looks like it was blocked on your side. Please, check your trackers blocking policy.</p>'}})()</script></div></div></div></div></div><div class=footer__bottom><div class=container><div class="row g-3"><div class="col-12 col-lg-6 footer__bottom-content"><span class=footer__bottom-copyright>© 2025 Qdrant.</span><div class=footer__bottom-bages><a href=http://qdrant.to/trust-center target=_blank><img src=https://qdrant.tech/img/soc2-badge.png alt=SOC2>
</a><a href=https://heydata.eu/ target=_blank><img src=https://qdrant.tech/img/gdpr-badge.png alt="heyData GDPR">
</a><a href=https://qdrant.tech/# target=_blank><img src=https://qdrant.tech/img/dark-gdpr-badge.png alt=GDPR>
</a><a href=https://qdrant.tech/# target=_blank><img src=https://qdrant.tech/img/hipaa-badge.png alt=HIPAA></a></div></div><div class="col-12 col-lg-6 footer__bottom-links"><a href=https://qdrant.tech/legal/terms_and_conditions/>Terms</a>
<a href=https://qdrant.tech/legal/privacy-policy/>Privacy Policy</a>
<a href=https://qdrant.tech/legal/impressum/>Impressum</a></div></div></div></div></footer><button class="d-none button button_outlined go-to-top-button" id=scrollToTopBtn title="Go to top">Up!</button>
</body><script src=https://cdn.cookielaw.org/scripttemplates/otSDKStub.js type=text/javascript data-domain-script=01960152-5e40-782d-af01-f7f5768a214e></script><script async type=text/javascript>function OptanonWrapper(){const e=new CustomEvent("onetrust_loaded");document.dispatchEvent(e)}</script><script>!function(){const o="eQYi1nZE2zQSmnHuxjMRlDd2uLl65oHe";var n,s,t="analytics",e=window[t]=window[t]||[];if(!e.initialize)if(e.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{e.invoked=!0,e.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","debug","page","screen","once","off","on","addSourceMiddleware","addIntegrationMiddleware","setAnonymousId","addDestinationMiddleware","register"],e.factory=function(n){return function(){if(window[t].initialized)return window[t][n].apply(window[t],arguments);var o,s=Array.prototype.slice.call(arguments);return["track","screen","alias","group","page","identify"].indexOf(n)>-1&&(o=document.querySelector("link[rel='canonical']"),s.push({__t:"bpc",c:o&&o.getAttribute("href")||void 0,p:location.pathname,u:location.href,s:location.search,t:document.title,r:document.referrer})),s.unshift(n),e.push(s),e}};for(n=0;n<e.methods.length;n++)s=e.methods[n],e[s]=e.factory(s);e.load=function(n,s){var i,o=document.createElement("script");o.type="text/javascript",o.async=!0,o.setAttribute("data-global-segment-analytics-key",t),o.src="https://evs.analytics.qdrant.tech/5caWuitPgcGFN5Q7HMpTaj/vEkmzjuRSqeXGbhGAFTWex.min.js",i=document.getElementsByTagName("script")[0],i.parentNode.insertBefore(o,i),e._loadOptions=s},e._writeKey=o,e._cdn="https://evs.analytics.qdrant.tech",e.SNIPPET_VERSION="5.2.0",e.load(o)}}()</script><script src=https://qdrant.tech/js/google-setup.min.14728a3ae9bd931593645b6ddbfe801d400cd2970006e782cb67f3966654248ca962dbaf4cf371493a2d326861b3a691a99d6d8349c8b2752339ab91d3787069.js></script><script src=https://qdrant.tech/js/index.min.e37feda1952d752f5568e1ebc55e183629e4d361f4df09edeed70b4a4327d601161c4147bdbe4149b4a3cdc1ed43f1bf1a2f2340a421f1aa821103980dfe0bda.js></script><script src=https://qdrant.tech/js/search/scroll.min.f4ed4453a3af0adb0d4f49333cbb7892ff5430483a567d0d2dfbd4655fb203d22f22f46aff3d9f38fa5fd96dde5f30227afd0ce1d9f838f5cd5295fc83856ec9.js></script><script src=https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js></script><script src=https://qdrant.tech/js/copy-code.min.95b03a45b2ab4b7a608ecfd4b5919c8572a5b2cd1463f52561cd10976abf3b74334f91324c0e620cb80afac46026a0b18cce6fb753d8495f74c6d478c8ca1d03.js></script><script src=https://qdrant.tech/js/lang-switcher.min.63da11cef09772078425b1ee56415b9c37842a9399f2ba2d2f5efbf72fb751686c410bd50e9bcd283c8231cb97c1973199d4923beef29d8b06e59d9983a6ba51.js></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src=https://qdrant.tech/js/vendor/anchor.min.0e138e17ebcf1c1147a7a3a81d9ac3c601622eedc479f1636470eb2552470f4e27c9a8efe6e8378995dedc1ab67029d8989536ea76f0857d45d1615ae772b8a1.js></script><script>document.addEventListener("keydown",function(e){if((e.metaKey||e.ctrlKey)&&e.key==="k"){e.preventDefault();let t=document.querySelector('[data-target="#searchModal"]');t&&t?.click()}})</script><script>document.addEventListener("scroll",()=>{const e=document.getElementById("article"),t=document.getElementById("progress"),n=e.scrollHeight-window.innerHeight,s=window.scrollY-e.offsetTop;t.value=Math.min(Math.max(s/n*100,0),100)})</script><script>window.addEventListener("message",e=>{if(e.data.type==="hsFormCallback"&&e.data.eventName==="onFormReady"){const t=document.querySelector(`form[data-form-id="${e.data.id}"]`);if(t){const e=t.querySelector('[name="last_form_fill_url"]');e&&(e.value=window.location.href);const n=t.querySelector('[name="referrer_url"]');n&&(n.value=document.referrer)}}})</script></html>