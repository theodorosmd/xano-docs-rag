<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta charset=UTF-8><title>Fine Tuning Similar Cars Search - Qdrant</title>
<link rel=icon href=https://qdrant.tech/favicon/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=https://qdrant.tech/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://qdrant.tech/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://qdrant.tech/favicon/favicon-16x16.png><link rel=manifest href=https://qdrant.tech/favicon/site.webmanifest><link rel=mask-icon href=https://qdrant.tech/favicon/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#2b5797"><meta name=msapplication-config content="/favicon/browserconfig.xml"><meta name=theme-color content="#ffffff"><meta name=partition content="learn"><link href=https://qdrant.tech/css/search/search.min.09596ee2b3c94d0ac82a1c33199cabdb3e0210b1ee46aaf1515200e9e484d05dd9e27cc1e861c58cc2e582af162f63b8e180ff2a12f7a6592b7aeaa0a7125130.css rel=stylesheet integrity="sha512-CVlu4rPJTQrIKhwzGZyr2z4CELHuRqrxUVIA6eSE0F3Z4nzB6GHFjMLlgq8WL2O44YD/KhL3plkreuqgpxJRMA=="><link href=https://qdrant.tech/css/documentation.min.de204cdcfc410689a41c17bcdad0a34f2caaa50cc8505c820adaab481cef2d69a920b0a32e0d624701c29487e3271b694559d98c5047cbfaa5aa475f638011e5.css rel=stylesheet integrity="sha512-3iBM3PxBBomkHBe82tCjTyyqpQzIUFyCCtqrSBzvLWmpILCjLg1iRwHClIfjJxtpRVnZjFBHy/qlqkdfY4AR5Q=="><link href=https://qdrant.tech/css/main.min.c1e379ad4cf03647832f6a0f040754b0be3e79934db2c29f50b396327c1ec7ac45f778abadbd93f5a8bc431850d1b0d9c9eff34c0171cd4236e83c5e324c1a0e.css rel=stylesheet integrity crossorigin=anonymous><meta name=generator content="Hugo 0.141.0"><meta name=description content="Learn how to train a similarity model that can retrieve similar car images in novel categories."><meta name=keywords content="vector search engine,neural network,matching,SaaS,approximate nearest neighbor search,image search,recommender system,vectors,knn algorithm,hnsw,vector search,embeddings,similarity,simaes networks,BERT,transformer,word2vec,fasttext,qdrant"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@id":"https://qdrant.tech/articles/cars-recognition/#article","@type":"Article","abstract":"Learn how to train a similarity model that can retrieve similar car images in novel categories","author":{"@type":"Person","name":"Yusuf Sarıgöz"},"dateModified":"2022-06-28 13:00:00 +0300 +0300","datePublished":"2022-06-28 13:00:00 +0300 +0300","description":"Learn how to train a similarity model that can retrieve similar car images in novel categories","headline":"Fine Tuning Similar Cars Search","image":["https://qdrant.tech/articles_data/cars-recognition/preview/social_preview.jpg"],"name":"Fine Tuning Similar Cars Search","url":"https://qdrant.tech/articles/cars-recognition/","wordCount":"2486"},{"@id":"https://qdrant.tech/articles/cars-recognition/#organization","@type":"Organization","address":{"@type":"PostalAddress","addressCountry":"DE","addressLocality":"Berlin","addressRegion":"Berlin","postalCode":"10115","streetAddress":"Chausseestraße 86"},"contactPoint":{"@type":"ContactPoint","contactType":"customer support","email":"info@qdrant.com","telephone":"+49 3040797694"},"description":"Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.","email":"info@qdrant.com","founders":[{"@type":"Person","name":"map[email:info@qdrant.tech name:Andrey Vasnetsov]"},{"@type":"Person","name":"Andre Zayarni"}],"foundingDate":"2021","keywords":["vector search engine","neural network","matching","SaaS","approximate nearest neighbor search","image search","recommender system","vectors","knn algorithm","hnsw","vector search","embeddings","similarity","simaes networks","BERT","transformer","word2vec","fasttext","Qdrant"],"legalName":"Qdrant Solutions GmbH","location":"Berlin, Germany","logo":"https://qdrant.tech/images/logo_with_text.png","name":"Qdrant","sameAs":["https://github.com/qdrant/qdrant","https://qdrant.to/discord","https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA","https://www.linkedin.com/company/qdrant/","https://twitter.com/qdrant_engine"],"url":"https://qdrant.tech"}]}</script><meta property="og:url" content="https://qdrant.tech/articles/cars-recognition/"><meta property="og:type" content="website"><meta property="og:title" content="Fine Tuning Similar Cars Search - Qdrant"><meta name=twitter:card content="summary_large_image"><meta name=twitter:domain content="qdrant"><meta name=twitter:url content="https://qdrant.tech/articles/cars-recognition/"><meta name=twitter:title content="Fine Tuning Similar Cars Search - Qdrant"><meta property="og:description" content="Learn how to train a similarity model that can retrieve similar car images in novel categories."><meta name=twitter:description content="Learn how to train a similarity model that can retrieve similar car images in novel categories."><meta name=image property="og:image" content="https://qdrant.tech/articles_data/cars-recognition/preview/social_preview.jpg"><meta name=image property="og:image:secure_url" content="https://qdrant.tech/articles_data/cars-recognition/preview/social_preview.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name=twitter:image:src content="https://qdrant.tech/articles_data/cars-recognition/preview/social_preview.jpg"><meta name=author content="Yusuf Sarıgöz"><link rel=canonical href=https://qdrant.tech/articles/cars-recognition/><script type=text/javascript src=//js-eu1.hsforms.net/forms/embed/v2.js></script><script src=https://qdrant.tech/js/documentation.min.594fc9226f6fb87b8c3b0cafb9d5c0b0bcd95f47d292b929aab04315e0506706b2f376dc4fae9961dc3082138cb19d45b2a3370ee8e881bbf4b8c91dcb735c32.js></script></head><body><main><header class=docs-header><div class="main-menu z-5"><a href=https://qdrant.tech/><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div></a><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><div class="d-block d-xl-none"><button role=button class=theme-switch></button></div><button type=button class=main-menu__trigger><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M1 12H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 5H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 19H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=main-menu__links><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/>Qdrant</a></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/cloud-intro/>Cloud</a></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/build/>Build</a></li><li class=main-menu__item><a class=menu-linkactive href=https://qdrant.tech/articles/>Learn</a></li><li class=main-menu__item><a class=menu-link href=https://api.qdrant.tech/api-reference target=_blank>API Reference</a></li></ul><div class=main-menu__buttons><div class=main-menu__buttons-input><button class="qdr-search-input-btn q-input input_md input_light-bg" type=button name=search data-target=#searchModal>
Search</button></div><button role=button class=theme-switch></button>
<a data-metric-loc=nav href=https://cloud.qdrant.io/login class="menu-link mx-3" target=_blank>Log in</a>
<a data-metric-loc=nav href=https://cloud.qdrant.io/signup class="button button_contained button_sm" target=_blank>Start Free</a></div></div><div class=menu-mobile><div class=menu-mobile__header><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><div class="d-block d-xl-none"><button role=button class=theme-switch></button></div><button type=button class=menu-mobile__close><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><g id="Close"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M19.778 5.63606C20.1685 5.24554 20.1685 4.61237 19.778 4.22185 19.3874 3.83132 18.7543 3.83132 18.3637 4.22185L11.9998 10.5858 5.63586 4.22185c-.39052-.39053-1.02369-.39053-1.41421.0C3.83112 4.61237 3.83112 5.24554 4.22165 5.63606L10.5856 12l-6.364 6.364C3.83108 18.7545 3.83108 19.3877 4.2216 19.7782 4.61213 20.1687 5.24529 20.1687 5.63582 19.7782l6.36398-6.364 6.364 6.364C18.7543 20.1687 19.3875 20.1687 19.778 19.7782 20.1685 19.3877 20.1685 18.7545 19.778 18.364L13.414 12l6.364-6.36394z" fill="#e1e5f0"/></g></svg></button></div></div><div class=main-menu__buttons-input><button class="qdr-search-input-btn q-input input_md input_light-bg" type=button name=search data-target=#searchModal>
Search</button></div><ul class=menu-mobile__items><li class=menu-mobile__item data-path=menu-0><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Documentation"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M4.25 1c-1.10092.0-2.12247.23681-2.88689.64443C.620129 2.04063.0 2.67297.0 3.5v11c0 .2761.223858.5.5.5s.5-.2239.5-.5c0-.278.21937-.6456.83364-.9732C2.42647 13.2107 3.27992 13 4.25 13 5.22008 13 6.07353 13.2107 6.66636 13.5268c.61427.3276.83364.6952.83364.9732.0.2761.22386.5.5.5s.5-.2239.5-.5c0-.278.21937-.6456.833640000000001-.9732C9.92647 13.2107 10.7799 13 11.75 13S13.5735 13.2107 14.1664 13.5268C14.7806 13.8544 15 14.222 15 14.5c0 .2761.2239.5.5.5s.5-.2239.5-.5V3.5C16 2.67297 15.3799 2.04063 14.6369 1.64443 13.8725 1.23681 12.8509 1 11.75 1s-2.12247.23681-2.88689.64443C8.53799 1.8178 8.2364 2.03638 8 2.29671c-.2364-.26033-.53799-.47891-.86311-.65228C6.37247 1.23681 5.35092 1 4.25 1zM1.36311 12.6444C1.23778 12.7113 1.11595 12.7848 1 12.8649V3.5c0-.27797.21937-.64563.83364-.97318C2.42647 2.21069 3.27992 2 4.25 2c.97008.0 1.82353.21069 2.41636.52682C7.28063 2.85437 7.5 3.22203 7.5 3.5v9.3649C7.38405 12.7848 7.26222 12.7113 7.13689 12.6444 6.37247 12.2368 5.35092 12 4.25 12 3.14908 12 2.12753 12.2368 1.36311 12.6444zM8.5 12.8649C8.61595 12.7848 8.73778 12.7113 8.86311 12.6444 9.62753 12.2368 10.6491 12 11.75 12S13.8725 12.2368 14.6369 12.6444C14.7622 12.7113 14.8841 12.7848 15 12.8649V3.5C15 3.22203 14.7806 2.85437 14.1664 2.52682 13.5735 2.21069 12.7201 2 11.75 2s-1.82353.21069-2.41636.52682C8.71937 2.85437 8.5 3.22203 8.5 3.5v9.3649z"/></g></svg>
Qdrant</a></div></li><li class=menu-mobile__item data-path=menu-1><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/cloud-intro/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Cloud"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M7.5 2C4.57416 2 2.18128 4.28566 2.00983 7.16851.8403 7.57763.0 8.68965.0 10c0 1.6571 1.34286 3 3 3H13c1.6571.0 3-1.3429 3-3 0-1.65714-1.3429-3-3-3L12.9776 7.00009C12.7249 4.19714 10.3686 2 7.5 2zM3.00107 7.48137 3.00008 7.47308C3.01457 5.0006 5.02412 3 7.5 3c2.47599.0 4.4856 2.00079 4.4999 4.47342L11.9987 7.4836C11.9969 7.50027 11.995 7.52348 11.995 7.551 11.995 7.701 12.0623 7.84308 12.1785 7.93804 12.2946 8.03301 12.4472 8.07082 12.5942 8.04106 12.726 8.01438 12.8617 8 13 8c1.1049.0 2 .89514 2 2C15 11.1049 14.1049 12 13 12H3C1.89514 12 1 11.1049 1 10 1 9.03225 1.68901 8.22422 2.60364 8.04017 2.83708 7.9932 3.005 7.78812 3.005 7.55 3.005 7.52154 3.00291 7.49773 3.00107 7.48137z"/></g></svg>
Cloud</a></div></li><li class=menu-mobile__item data-path=menu-2><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/build/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Blog"><path id="Union" fill-rule="evenodd" clip-rule="evenodd" d="M0 1.5C0 1.22386.223858 1 .5 1h5c.27614.0.5.22386.5.5v5c0 .27614-.22386.5-.5.5H.5C.223858 7 0 6.77614.0 6.5v-5zM1 2V6H5V2H1zm7 .5c0-.27614.22386-.5.5-.5h7c.2761.0.5.22386.5.5s-.2239.5-.5.5h-7C8.22386 3 8 2.77614 8 2.5zM8.5 6c-.27614.0-.5.22386-.5.5s.22386.5.5.5h7c.2761.0.5-.22386.5-.5s-.2239-.5-.5-.5h-7zM0 10.5c0-.2761.223858-.5.5-.5h15c.2761.0.5.2239.5.5s-.2239.5-.5.5H.5c-.276142.0-.5-.2239-.5-.5zM.5 14c-.276142.0-.5.2239-.5.5s.223858.5.5.5h15c.2761.0.5-.2239.5-.5s-.2239-.5-.5-.5H.5z"/></g></svg>
Build</a></div></li><li class=menu-mobile__item data-path=menu-3><div class=menu-mobile__item-content><a class=active href=https://qdrant.tech/articles/><svg width="16" height="16" viewBox="0 0 16 16" fill="none" stroke="#e1e5f0"><g id="Group"><path id="Vector" d="M10.084 1.84094l4.059 4.059" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_2" d="M8.49188 2.72406c-1.22044-.53042-2.59304-.59475-3.85774-.1808-1.2647.41395-2.33363 1.27742-3.00426 2.4268l2.34 2.34" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_3" d="M13.2657 7.47302C13.8062 8.69691 13.8769 10.077 13.4645 11.3497c-.4125 1.2728-1.2792 2.3491-2.4348 3.0233l-2.35001-2.35" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_4" d="M6.81217 13.049l-3.861-3.861S6.24917.983 15.5002.5c-.523 9.211-8.68803 12.549-8.68803 12.549z" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_5" d="M3.59892 12.4008C3.34181 12.1441 2.99331 12 2.62995 12c-.36335.0-.71186.1441-.96897.4008-.46665.4664-.63131 1.941-.65931 2.2322C.997021 14.6793 1.0021 14.726 1.01659 14.7701 1.03108 14.8143 1.05465 14.8549 1.08579 14.8895 1.11693 14.924 1.15495 14.9516 1.19741 14.9705 1.23987 14.9895 1.28583 14.9994 1.33233 14.9995 1.34298 15.0002 1.35367 15.0002 1.36433 14.9995 1.65565 14.9715 3.1316 14.8063 3.59759 14.3405 3.85501 14.0834 3.99975 13.7346 4 13.3709 4.00025 13.0072 3.85599 12.6582 3.59892 12.4008z" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_6" d="M9 8c.55228.0 1-.44772 1-1S9.55228 6 9 6 8 6.44772 8 7s.44772 1 1 1z"/></g></svg>
Learn</a></div></li><li class=menu-mobile__item data-path=menu-4><div class=menu-mobile__item-content><a href=https://api.qdrant.tech/api-reference target=_blank><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Roadmap" clip-path="url(#clip0_7182_4311)"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M13.5 1c-.8284.0-1.5.67157-1.5 1.5S12.6716 4 13.5 4 15 3.32843 15 2.5 14.3284 1 13.5 1zM11 2.5C11 1.11929 12.1193.0 13.5.0S16 1.11929 16 2.5 14.8807 5 13.5 5 11 3.88071 11 2.5zM2.5 12c-.82843.0-1.5.6716-1.5 1.5S1.67157 15 2.5 15 4 14.3284 4 13.5 3.32843 12 2.5 12zM0 13.5C0 12.1193 1.11929 11 2.5 11S5 12.1193 5 13.5 3.88071 16 2.5 16 0 14.8807.0 13.5zM3.65901 1.65901C4.08097 1.23705 4.65326 1 5.25 1s1.16903.23705 1.59099.65901C7.26295 2.08097 7.5 2.65326 7.5 3.25v9.5c0 .862.34241 1.6886.9519 2.2981C9.0614 15.6576 9.88805 16 10.75 16c.862.0 1.6886-.3424 2.2981-.9519S14 13.612 14 12.75V6.5c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v6.25C13 13.3467 12.7629 13.919 12.341 14.341 11.919 14.7629 11.3467 15 10.75 15S9.58097 14.7629 9.15901 14.341C8.73705 13.919 8.5 13.3467 8.5 12.75V3.25C8.5 2.38805 8.15759 1.5614 7.5481.951903 6.9386.34241 6.11195.0 5.25.0S3.5614.34241 2.9519.951903C2.34241 1.5614 2 2.38805 2 3.25V9.5c0 .27614.22386.5.5.5s.5-.22386.5-.5V3.25c0-.59674.23705-1.16903.65901-1.59099z"/></g><defs><clipPath id="clip0_7182_4311"><rect width="16" height="16" fill="#fff"/></clipPath></defs></svg>
API Reference</a></div></li></ul><div class=docs-menu><div id=sidebar class=docs-menu__content><h3 class=docs-menu__links-title>Learn</h3><nav><div class=docs-menu__links-group><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/vector-search-manuals/>Vector Search Manuals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/qdrant-internals/>Qdrant Internals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/data-exploration/>Data Exploration</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/machine-learning/>Machine Learning</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/rag-and-genai/>RAG & GenAI</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/practicle-examples/>Practical Examples</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/ecosystem/>Ecosystem</a></div></div></nav></div></div></div></header><section class="docs documentation"><div class=documentation__container><div class="d-flex flex-column flex-xl-row"><div class=docs-menu><div id=sidebar class=docs-menu__content><h3 class=docs-menu__links-title>Learn</h3><nav><div class=docs-menu__links-group><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/vector-search-manuals/>Vector Search Manuals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/qdrant-internals/>Qdrant Internals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/data-exploration/>Data Exploration</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/machine-learning/>Machine Learning</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/rag-and-genai/>RAG & GenAI</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/practicle-examples/>Practical Examples</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/ecosystem/>Ecosystem</a></div></div></nav></div></div><div class=documentation__content><div class=documentation__content-wrapper><div class=documentation__article-wrapper><ul class=docs-breadcrumbs><li class=docs-breadcrumbs__crumb><a href=https://qdrant.tech/articles/>Articles</a></li><li class=docs-breadcrumbs__crumb-separator></li><li class=docs-breadcrumbs__crumb>Fine Tuning Similar Cars Search</li></ul><article class=documentation-article><div class=documentation-article__header><a href=https://qdrant.tech/articles/machine-learning/ class=documentation-article__header-link><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path d="M14.6668 8.00004H1.3335m0 0L6.00016 12.6667M1.3335 8.00004 6.00016 3.33337" stroke="#8f98b3" stroke-width="1.33333" stroke-linecap="round" stroke-linejoin="round"/></svg>
Back to Machine Learning</a><h1 class=documentation-article__header-title>Fine Tuning Similar Cars Search</h1><div class=documentation-article__header-about><p>Yusuf Sarıgöz</p><span>&#183;</span><p>June 28, 2022</p></div><picture class=documentation-article__header-preview><source srcset=https://qdrant.tech/articles_data/cars-recognition/preview/title.webp type=image/webp><img alt="Fine Tuning Similar Cars Search" src=https://qdrant.tech/articles_data/cars-recognition/preview/title.jpg></picture></div><p>Supervised classification is one of the most widely used training objectives in machine learning,
but not every task can be defined as such. For example,</p><ol><li>Your classes may change quickly —e.g., new classes may be added over time,</li><li>You may not have samples from every possible category,</li><li>It may be impossible to enumerate all the possible classes during the training time,</li><li>You may have an essentially different task, e.g., search or retrieval.</li></ol><p>All such problems may be efficiently solved with similarity learning.</p><p>N.B.: If you are new to the similarity learning concept, checkout the <a href=https://github.com/qdrant/awesome-metric-learning target=_blank rel="noopener nofollow">awesome-metric-learning</a> repo for great resources and use case examples.</p><p>However, similarity learning comes with its own difficulties such as:</p><ol><li>Need for larger batch sizes usually,</li><li>More sophisticated loss functions,</li><li>Changing architectures between training and inference.</li></ol><p>Quaterion is a fine tuning framework built to tackle such problems in similarity learning.
It uses <a href=https://www.pytorchlightning.ai/ target=_blank rel="noopener nofollow">PyTorch Lightning</a>
as a backend, which is advertized with the motto, &ldquo;spend more time on research, less on engineering.&rdquo;
This is also true for Quaterion, and it includes:</p><ol><li>Trainable and servable model classes,</li><li>Annotated built-in loss functions, and a wrapper over <a href=https://kevinmusgrave.github.io/pytorch-metric-learning/ target=_blank rel="noopener nofollow">pytorch-metric-learning</a> when you need even more,</li><li>Sample, dataset and data loader classes to make it easier to work with similarity learning data,</li><li>A caching mechanism for faster iterations and less memory footprint.</li></ol><h2 id=a-closer-look-at-quaterion>A closer look at Quaterion</h2><p>Let&rsquo;s break down some important modules:</p><ul><li><code>TrainableModel</code>: A subclass of <code>pl.LightNingModule</code> that has additional hook methods such as <code>configure_encoders</code>, <code>configure_head</code>, <code>configure_metrics</code> and others
to define objects needed for training and evaluation —see below to learn more on these.</li><li><code>SimilarityModel</code>: An inference-only export method to boost code transfer and lower dependencies during the inference time.
In fact, Quaterion is composed of two packages:<ol><li><code>quaterion_models</code>: package that you need for inference.</li><li><code>quaterion</code>: package that defines objects needed for training and also depends on <code>quaterion_models</code>.</li></ol></li><li><code>Encoder</code> and <code>EncoderHead</code>: Two objects that form a <code>SimilarityModel</code>.
In most of the cases, you may use a frozen pretrained encoder, e.g., ResNets from <code>torchvision</code>, or language modelling
models from <code>transformers</code>, with a trainable <code>EncoderHead</code> stacked on top of it.
<code>quaterion_models</code> offers several ready-to-use <code>EncoderHead</code> implementations,
but you may also create your own by subclassing a parent class or easily listing PyTorch modules in a <code>SequentialHead</code>.</li></ul><p>Quaterion has other objects such as distance functions, evaluation metrics, evaluators, convenient dataset and data loader classes, but these are mostly self-explanatory.
Thus, they will not be explained in detail in this article for brevity.
However, you can always go check out the <a href=https://quaterion.qdrant.tech target=_blank rel="noopener nofollow">documentation</a> to learn more about them.</p><p>The focus of this tutorial is a step-by-step solution to a similarity learning problem with Quaterion.
This will also help us better understand how the abovementioned objects fit together in a real project.
Let&rsquo;s start walking through some of the important parts of the code.</p><p>If you are looking for the complete source code instead, you can find it under the <a href=https://github.com/qdrant/quaterion/tree/master/examples/cars target=_blank rel="noopener nofollow">examples</a>
directory in the Quaterion repo.</p><h2 id=dataset>Dataset</h2><p>In this tutorial, we will use the <a href=https://pytorch.org/vision/main/generated/torchvision.datasets.StanfordCars.html target=_blank rel="noopener nofollow">Stanford Cars</a>
dataset.</p><figure><img src=https://storage.googleapis.com/quaterion/docs/class_montage.jpg alt="Stanford Cars Dataset"><figcaption><p>Stanford Cars Dataset</p></figcaption></figure><p>It has 16185 images of cars from 196 classes,
and it is split into training and testing subsets with almost a 50-50% split.
To make things even more interesting, however, we will first merge training and testing subsets,
then we will split it into two again in such a way that the half of the 196 classes will be put into the training set and the other half will be in the testing set.
This will let us test our model with samples from novel classes that it has never seen in the training phase,
which is what supervised classification cannot achieve but similarity learning can.</p><p>In the following code borrowed from <a href=https://github.com/qdrant/quaterion/blob/master/examples/cars/data.py target=_blank rel="noopener nofollow"><code>data.py</code></a>:</p><ul><li><code>get_datasets()</code> function performs the splitting task described above.</li><li><code>get_dataloaders()</code> function creates <code>GroupSimilarityDataLoader</code> instances from training and testing datasets.</li><li>Datasets are regular PyTorch datasets that emit <code>SimilarityGroupSample</code> instances.</li></ul><p>N.B.: Currently, Quaterion has two data types to represent samples in a dataset. To learn more about <code>SimilarityPairSample</code>, check out the <a href=https://quaterion.qdrant.tech/tutorials/nlp_tutorial.html target=_blank rel="noopener nofollow">NLP tutorial</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>tqdm</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>Dataset</span><span class=p>,</span> <span class=n>Subset</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchvision</span> <span class=kn>import</span> <span class=n>datasets</span><span class=p>,</span> <span class=n>transforms</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>Callable</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pytorch_lightning</span> <span class=kn>import</span> <span class=n>seed_everything</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>quaterion.dataset</span> <span class=kn>import</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>GroupSimilarityDataLoader</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>SimilarityGroupSample</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># set seed to deterministically sample train and test categories later on</span>
</span></span><span class=line><span class=cl><span class=n>seed_everything</span><span class=p>(</span><span class=n>seed</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># dataset will be downloaded to this directory under local directory</span>
</span></span><span class=line><span class=cl><span class=n>dataset_path</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=s2>&#34;.&#34;</span><span class=p>,</span> <span class=s2>&#34;torchvision&#34;</span><span class=p>,</span> <span class=s2>&#34;datasets&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_datasets</span><span class=p>(</span><span class=n>input_size</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Use Mean and std values for the ImageNet dataset as the base model was pretrained on it.</span>
</span></span><span class=line><span class=cl>    <span class=c1># taken from https://www.geeksforgeeks.org/how-to-normalize-images-in-pytorch/</span>
</span></span><span class=line><span class=cl>    <span class=n>mean</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.485</span><span class=p>,</span> <span class=mf>0.456</span><span class=p>,</span> <span class=mf>0.406</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.229</span><span class=p>,</span> <span class=mf>0.224</span><span class=p>,</span> <span class=mf>0.225</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># create train and test transforms</span>
</span></span><span class=line><span class=cl>    <span class=n>transform</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=n>transforms</span><span class=o>.</span><span class=n>Resize</span><span class=p>((</span><span class=n>input_size</span><span class=p>,</span> <span class=n>input_size</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>transforms</span><span class=o>.</span><span class=n>Normalize</span><span class=p>(</span><span class=n>mean</span><span class=p>,</span> <span class=n>std</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># we need to merge train and test splits into a full dataset first,</span>
</span></span><span class=line><span class=cl>    <span class=c1># and then we will split it to two subsets again with each one composed of distinct labels.</span>
</span></span><span class=line><span class=cl>    <span class=n>full_dataset</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>StanfordCars</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>root</span><span class=o>=</span><span class=n>dataset_path</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s2>&#34;train&#34;</span><span class=p>,</span> <span class=n>download</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span> <span class=o>+</span> <span class=n>datasets</span><span class=o>.</span><span class=n>StanfordCars</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=n>dataset_path</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s2>&#34;test&#34;</span><span class=p>,</span> <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># full_dataset contains examples from 196 categories labeled with an integer from 0 to 195</span>
</span></span><span class=line><span class=cl>    <span class=c1># randomly sample half of it to be used for training</span>
</span></span><span class=line><span class=cl>    <span class=n>train_categories</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>a</span><span class=o>=</span><span class=mi>196</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>196</span> <span class=o>//</span> <span class=mi>2</span><span class=p>,</span> <span class=n>replace</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># get a list of labels for all samples in the dataset</span>
</span></span><span class=line><span class=cl>    <span class=n>labels_list</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>label</span> <span class=k>for</span> <span class=n>_</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>tqdm</span><span class=o>.</span><span class=n>tqdm</span><span class=p>(</span><span class=n>full_dataset</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># get a mask for indices where label is included in train_categories</span>
</span></span><span class=line><span class=cl>    <span class=n>labels_mask</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>isin</span><span class=p>(</span><span class=n>labels_list</span><span class=p>,</span> <span class=n>train_categories</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># get a list of indices to be used as train samples</span>
</span></span><span class=line><span class=cl>    <span class=n>train_indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argwhere</span><span class=p>(</span><span class=n>labels_mask</span><span class=p>)</span><span class=o>.</span><span class=n>squeeze</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># others will be used as test samples</span>
</span></span><span class=line><span class=cl>    <span class=n>test_indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argwhere</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>logical_not</span><span class=p>(</span><span class=n>labels_mask</span><span class=p>))</span><span class=o>.</span><span class=n>squeeze</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># now that we have distinct indices for train and test sets, we can use `Subset` to create new datasets</span>
</span></span><span class=line><span class=cl>    <span class=c1># from `full_dataset`, which contain only the samples at given indices.</span>
</span></span><span class=line><span class=cl>    <span class=c1># finally, we apply transformations created above.</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataset</span> <span class=o>=</span> <span class=n>CarsDataset</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>Subset</span><span class=p>(</span><span class=n>full_dataset</span><span class=p>,</span> <span class=n>train_indices</span><span class=p>),</span> <span class=n>transform</span><span class=o>=</span><span class=n>transform</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>test_dataset</span> <span class=o>=</span> <span class=n>CarsDataset</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>Subset</span><span class=p>(</span><span class=n>full_dataset</span><span class=p>,</span> <span class=n>test_indices</span><span class=p>),</span> <span class=n>transform</span><span class=o>=</span><span class=n>transform</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>train_dataset</span><span class=p>,</span> <span class=n>test_dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_dataloaders</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>input_size</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>shuffle</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataset</span><span class=p>,</span> <span class=n>test_dataset</span> <span class=o>=</span> <span class=n>get_datasets</span><span class=p>(</span><span class=n>input_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>train_dataloader</span> <span class=o>=</span> <span class=n>GroupSimilarityDataLoader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>train_dataset</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=n>shuffle</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>test_dataloader</span> <span class=o>=</span> <span class=n>GroupSimilarityDataLoader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>test_dataset</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>train_dataloader</span><span class=p>,</span> <span class=n>test_dataloader</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>CarsDataset</span><span class=p>(</span><span class=n>Dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>dataset</span><span class=p>:</span> <span class=n>Dataset</span><span class=p>,</span> <span class=n>transform</span><span class=p>:</span> <span class=n>Callable</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_dataset</span> <span class=o>=</span> <span class=n>dataset</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_transform</span> <span class=o>=</span> <span class=n>transform</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__len__</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>int</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__getitem__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>index</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>SimilarityGroupSample</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>image</span><span class=p>,</span> <span class=n>label</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_dataset</span><span class=p>[</span><span class=n>index</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>image</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_transform</span><span class=p>(</span><span class=n>image</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>SimilarityGroupSample</span><span class=p>(</span><span class=n>obj</span><span class=o>=</span><span class=n>image</span><span class=p>,</span> <span class=n>group</span><span class=o>=</span><span class=n>label</span><span class=p>)</span>
</span></span></code></pre></div><h2 id=trainable-model>Trainable Model</h2><p>Now it&rsquo;s time to review one of the most exciting building blocks of Quaterion: <a href=https://quaterion.qdrant.tech/quaterion.train.trainable_model.html#module-quaterion.train.trainable_model target=_blank rel="noopener nofollow">TrainableModel</a>.
It is the base class for models you would like to configure for training,
and it provides several hook methods starting with <code>configure_</code> to set up every aspect of the training phase
just like <a href=https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.core.LightningModule.html target=_blank rel="noopener nofollow"><code>pl.LightningModule</code></a>, its own base class.
It is central to fine tuning with Quaterion, so we will break down this essential code in <a href=https://github.com/qdrant/quaterion/blob/master/examples/cars/models.py target=_blank rel="noopener nofollow"><code>models.py</code></a>
and review each method separately. Let&rsquo;s begin with the imports:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torchvision</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>quaterion_models.encoders</span> <span class=kn>import</span> <span class=n>Encoder</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>quaterion_models.heads</span> <span class=kn>import</span> <span class=n>EncoderHead</span><span class=p>,</span> <span class=n>SkipConnectionHead</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch</span> <span class=kn>import</span> <span class=n>nn</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>Dict</span><span class=p>,</span> <span class=n>Union</span><span class=p>,</span> <span class=n>Optional</span><span class=p>,</span> <span class=n>List</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>quaterion</span> <span class=kn>import</span> <span class=n>TrainableModel</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>quaterion.eval.attached_metric</span> <span class=kn>import</span> <span class=n>AttachedMetric</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>quaterion.eval.group</span> <span class=kn>import</span> <span class=n>RetrievalRPrecision</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>quaterion.loss</span> <span class=kn>import</span> <span class=n>SimilarityLoss</span><span class=p>,</span> <span class=n>TripletLoss</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>quaterion.train.cache</span> <span class=kn>import</span> <span class=n>CacheConfig</span><span class=p>,</span> <span class=n>CacheType</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>.encoders</span> <span class=kn>import</span> <span class=n>CarsEncoder</span>
</span></span></code></pre></div><p>In the following code snippet, we subclass <code>TrainableModel</code>.
You may use <code>__init__()</code> to store some attributes to be used in various <code>configure_*</code> methods later on.
The more interesting part is, however, in the <a href=https://quaterion.qdrant.tech/quaterion.train.trainable_model.html#quaterion.train.trainable_model.TrainableModel.configure_encoders target=_blank rel="noopener nofollow"><code>configure_encoders()</code></a> method.
We need to return an instance of <a href=https://quaterion-models.qdrant.tech/quaterion_models.encoders.encoder.html#quaterion_models.encoders.encoder.Encoder target=_blank rel="noopener nofollow"><code>Encoder</code></a> (or a dictionary with <code>Encoder</code> instances as values) from this method.
In our case, it is an instance of <code>CarsEncoders</code>, which we will review soon.
Notice now how it is created with a pretrained ResNet152 model whose classification layer is replaced by an identity function.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Model</span><span class=p>(</span><span class=n>TrainableModel</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>lr</span><span class=p>:</span> <span class=nb>float</span><span class=p>,</span> <span class=n>mining</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_lr</span> <span class=o>=</span> <span class=n>lr</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_mining</span> <span class=o>=</span> <span class=n>mining</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>configure_encoders</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Union</span><span class=p>[</span><span class=n>Encoder</span><span class=p>,</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Encoder</span><span class=p>]]:</span>
</span></span><span class=line><span class=cl>        <span class=n>pre_trained_encoder</span> <span class=o>=</span> <span class=n>torchvision</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>resnet152</span><span class=p>(</span><span class=n>pretrained</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>pre_trained_encoder</span><span class=o>.</span><span class=n>fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Identity</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>CarsEncoder</span><span class=p>(</span><span class=n>pre_trained_encoder</span><span class=p>)</span>
</span></span></code></pre></div><p>In Quaterion, a <a href=https://quaterion-models.qdrant.tech/quaterion_models.model.html#quaterion_models.model.SimilarityModel target=_blank rel="noopener nofollow"><code>SimilarityModel</code></a> is composed of one or more <code>Encoder</code>s
and an <a href=https://quaterion-models.qdrant.tech/quaterion_models.heads.encoder_head.html#quaterion_models.heads.encoder_head.EncoderHead target=_blank rel="noopener nofollow"><code>EncoderHead</code></a>.
<code>quaterion_models</code> has <a href=https://quaterion-models.qdrant.tech/quaterion_models.heads.html#module-quaterion_models.heads target=_blank rel="noopener nofollow">several <code>EncoderHead</code> implementations</a>
with a unified API such as a configurable dropout value.
You may use one of them or create your own subclass of <code>EncoderHead</code>.
In either case, you need to return an instance of it from <a href=https://quaterion.qdrant.tech/quaterion.train.trainable_model.html#quaterion.train.trainable_model.TrainableModel.configure_head target=_blank rel="noopener nofollow"><code>configure_head</code></a>
In this example, we will use a <code>SkipConnectionHead</code>, which is lightweight and more resistant to overfitting.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>configure_head</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_embedding_size</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>EncoderHead</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>SkipConnectionHead</span><span class=p>(</span><span class=n>input_embedding_size</span><span class=p>,</span> <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
</span></span></code></pre></div><p>Quaterion has implementations of <a href=https://quaterion.qdrant.tech/quaterion.loss.html target=_blank rel="noopener nofollow">some popular loss functions</a> for similarity learning, all of which subclass either <a href=https://quaterion.qdrant.tech/quaterion.loss.group_loss.html#quaterion.loss.group_loss.GroupLoss target=_blank rel="noopener nofollow"><code>GroupLoss</code></a>
or <a href=https://quaterion.qdrant.tech/quaterion.loss.pairwise_loss.html#quaterion.loss.pairwise_loss.PairwiseLoss target=_blank rel="noopener nofollow"><code>PairwiseLoss</code></a>.
In this example, we will use <a href=https://quaterion.qdrant.tech/quaterion.loss.triplet_loss.html#quaterion.loss.triplet_loss.TripletLoss target=_blank rel="noopener nofollow"><code>TripletLoss</code></a>,
which is a subclass of <code>GroupLoss</code>. In general, subclasses of <code>GroupLoss</code> are used with
datasets in which samples are assigned with some group (or label). In our example label is a make of the car.
Those datasets should emit <code>SimilarityGroupSample</code>.
Other alternatives are implementations of <code>PairwiseLoss</code>, which consume <code>SimilarityPairSample</code> - pair of objects for which similarity is specified individually.
To see an example of the latter, you may need to check out the <a href=https://quaterion.qdrant.tech/tutorials/nlp_tutorial.html target=_blank rel="noopener nofollow">NLP Tutorial</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>configure_loss</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>SimilarityLoss</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>TripletLoss</span><span class=p>(</span><span class=n>mining</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>_mining</span><span class=p>,</span> <span class=n>margin</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
</span></span></code></pre></div><p><code>configure_optimizers()</code> may be familiar to PyTorch Lightning users,
but there is a novel <code>self.model</code> used inside that method.
It is an instance of <code>SimilarityModel</code> and is automatically created by Quaterion from the return values of <code>configure_encoders()</code> and <code>configure_head()</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>configure_optimizers</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=bp>self</span><span class=o>.</span><span class=n>_lr</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>optimizer</span>
</span></span></code></pre></div><p>Caching in Quaterion is used for avoiding calculation of outputs of a frozen pretrained <code>Encoder</code> in every epoch.
When it is configured, outputs will be computed once and cached in the preferred device for direct usage later on.
It provides both a considerable speedup and less memory footprint.
However, it is quite a bit versatile and has several knobs to tune.
To get the most out of its potential, it&rsquo;s recommended that you check out the <a href=https://quaterion.qdrant.tech/tutorials/cache_tutorial.html target=_blank rel="noopener nofollow">cache tutorial</a>.
For the sake of making this article self-contained, you need to return a <a href=https://quaterion.qdrant.tech/quaterion.train.cache.cache_config.html#quaterion.train.cache.cache_config.CacheConfig target=_blank rel="noopener nofollow"><code>CacheConfig</code></a>
instance from <a href=https://quaterion.qdrant.tech/quaterion.train.trainable_model.html#quaterion.train.trainable_model.TrainableModel.configure_caches target=_blank rel="noopener nofollow"><code>configure_caches()</code></a>
to specify cache-related preferences such as:</p><ul><li><a href=https://quaterion.qdrant.tech/quaterion.train.cache.cache_config.html#quaterion.train.cache.cache_config.CacheType target=_blank rel="noopener nofollow"><code>CacheType</code></a>, i.e., whether to store caches on CPU or GPU,</li><li><code>save_dir</code>, i.e., where to persist caches for subsequent runs,</li><li><code>batch_size</code>, i.e., batch size to be used only when creating caches - the batch size to be used during the actual training might be different.</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>configure_caches</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Optional</span><span class=p>[</span><span class=n>CacheConfig</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>CacheConfig</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>cache_type</span><span class=o>=</span><span class=n>CacheType</span><span class=o>.</span><span class=n>AUTO</span><span class=p>,</span> <span class=n>save_dir</span><span class=o>=</span><span class=s2>&#34;./cache_dir&#34;</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span></code></pre></div><p>We have just configured the training-related settings of a <code>TrainableModel</code>.
However, evaluation is an integral part of experimentation in machine learning,
and you may configure evaluation metrics by returning one or more <a href=https://quaterion.qdrant.tech/quaterion.eval.attached_metric.html#quaterion.eval.attached_metric.AttachedMetric target=_blank rel="noopener nofollow"><code>AttachedMetric</code></a>
instances from <code>configure_metrics()</code>. Quaterion has several built-in <a href=https://quaterion.qdrant.tech/quaterion.eval.group.html target=_blank rel="noopener nofollow">group</a>
and <a href=https://quaterion.qdrant.tech/quaterion.eval.pair.html target=_blank rel="noopener nofollow">pairwise</a>
evaluation metrics.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>configure_metrics</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Union</span><span class=p>[</span><span class=n>AttachedMetric</span><span class=p>,</span> <span class=n>List</span><span class=p>[</span><span class=n>AttachedMetric</span><span class=p>]]:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>AttachedMetric</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;rrp&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>metric</span><span class=o>=</span><span class=n>RetrievalRPrecision</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>prog_bar</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>on_epoch</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>on_step</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span></code></pre></div><h2 id=encoder>Encoder</h2><p>As previously stated, a <code>SimilarityModel</code> is composed of one or more <code>Encoder</code>s and an <code>EncoderHead</code>.
Even if we freeze pretrained <code>Encoder</code> instances,
<code>EncoderHead</code> is still trainable and has enough parameters to adapt to the new task at hand.
It is recommended that you set the <code>trainable</code> property to <code>False</code> whenever possible,
as it lets you benefit from the caching mechanism described above.
Another important property is <code>embedding_size</code>, which will be passed to <code>TrainableModel.configure_head()</code> as <code>input_embedding_size</code>
to let you properly initialize the head layer.
Let&rsquo;s see how an <code>Encoder</code> is implemented in the following code borrowed from <a href=https://github.com/qdrant/quaterion/blob/master/examples/cars/encoders.py target=_blank rel="noopener nofollow"><code>encoders.py</code></a>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>quaterion_models.encoders</span> <span class=kn>import</span> <span class=n>Encoder</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>CarsEncoder</span><span class=p>(</span><span class=n>Encoder</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>encoder_model</span><span class=p>:</span> <span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_encoder</span> <span class=o>=</span> <span class=n>encoder_model</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_embedding_size</span> <span class=o>=</span> <span class=mi>2048</span>  <span class=c1># last dimension from the ResNet model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@property</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>trainable</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>bool</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@property</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>embedding_size</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>int</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_embedding_size</span>
</span></span></code></pre></div><p>An <code>Encoder</code> is a regular <code>torch.nn.Module</code> subclass,
and we need to implement the forward pass logic in the <code>forward</code> method.
Depending on how you create your submodules, this method may be more complex;
however, we simply pass the input through a pretrained ResNet152 backbone in this example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>images</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>embeddings</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_encoder</span><span class=o>.</span><span class=n>forward</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>embeddings</span>
</span></span></code></pre></div><p>An important step of machine learning development is proper saving and loading of models.
Quaterion lets you save your <code>SimilarityModel</code> with <a href=https://quaterion.qdrant.tech/quaterion.train.trainable_model.html#quaterion.train.trainable_model.TrainableModel.save_servable target=_blank rel="noopener nofollow"><code>TrainableModel.save_servable()</code></a>
and restore it with <a href=https://quaterion-models.qdrant.tech/quaterion_models.model.html#quaterion_models.model.SimilarityModel.load target=_blank rel="noopener nofollow"><code>SimilarityModel.load()</code></a>.
To be able to use these two methods, you need to implement <code>save()</code> and <code>load()</code> methods in your <code>Encoder</code>.
Additionally, it is also important that you define your subclass of <code>Encoder</code> outside the <code>__main__</code> namespace,
i.e., in a separate file from your main entry point.
It may not be restored properly otherwise.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>save</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>output_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=n>output_path</span><span class=p>,</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_encoder</span><span class=p>,</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>output_path</span><span class=p>,</span> <span class=s2>&#34;encoder.pth&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@classmethod</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>load</span><span class=p>(</span><span class=bp>cls</span><span class=p>,</span> <span class=n>input_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>encoder_model</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>input_path</span><span class=p>,</span> <span class=s2>&#34;encoder.pth&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>CarsEncoder</span><span class=p>(</span><span class=n>encoder_model</span><span class=p>)</span>
</span></span></code></pre></div><h2 id=training>Training</h2><p>With all essential objects implemented, it is easy to bring them all together and run a training loop with the <a href=https://quaterion.qdrant.tech/quaterion.main.html#quaterion.main.Quaterion.fit target=_blank rel="noopener nofollow"><code>Quaterion.fit()</code></a>
method. It expects:</p><ul><li>A <code>TrainableModel</code>,</li><li>A <a href=https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html target=_blank rel="noopener nofollow"><code>pl.Trainer</code></a>,</li><li>A <a href=https://quaterion.qdrant.tech/quaterion.dataset.similarity_data_loader.html#quaterion.dataset.similarity_data_loader.SimilarityDataLoader target=_blank rel="noopener nofollow"><code>SimilarityDataLoader</code></a> for training data,</li><li>And optionally, another <code>SimilarityDataLoader</code> for evaluation data.</li></ul><p>We need to import a few objects to prepare all of these:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pytorch_lightning</span> <span class=k>as</span> <span class=nn>pl</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pytorch_lightning.callbacks</span> <span class=kn>import</span> <span class=n>EarlyStopping</span><span class=p>,</span> <span class=n>ModelSummary</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>quaterion</span> <span class=kn>import</span> <span class=n>Quaterion</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>.data</span> <span class=kn>import</span> <span class=n>get_dataloaders</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>.models</span> <span class=kn>import</span> <span class=n>Model</span>
</span></span></code></pre></div><p>The <code>train()</code> function in the following code snippet expects several hyperparameter values as arguments.
They can be defined in a <code>config.py</code> or passed from the command line.
However, that part of the code is omitted for brevity.
Instead let&rsquo;s focus on how all the building blocks are initialized and passed to <code>Quaterion.fit()</code>,
which is responsible for running the whole loop.
When the training loop is complete, you can simply call <code>TrainableModel.save_servable()</code>
to save the current state of the <code>SimilarityModel</code> instance:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>train</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>lr</span><span class=p>:</span> <span class=nb>float</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>mining</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>epochs</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>input_size</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>shuffle</span><span class=p>:</span> <span class=nb>bool</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>save_dir</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>Model</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>lr</span><span class=o>=</span><span class=n>lr</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>mining</span><span class=o>=</span><span class=n>mining</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>train_dataloader</span><span class=p>,</span> <span class=n>val_dataloader</span> <span class=o>=</span> <span class=n>get_dataloaders</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>input_size</span><span class=o>=</span><span class=n>input_size</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=n>shuffle</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>early_stopping</span> <span class=o>=</span> <span class=n>EarlyStopping</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>monitor</span><span class=o>=</span><span class=s2>&#34;validation_loss&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>patience</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>trainer</span> <span class=o>=</span> <span class=n>pl</span><span class=o>.</span><span class=n>Trainer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>gpus</span><span class=o>=</span><span class=mi>1</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=mi>0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>max_epochs</span><span class=o>=</span><span class=n>epochs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>callbacks</span><span class=o>=</span><span class=p>[</span><span class=n>early_stopping</span><span class=p>,</span> <span class=n>ModelSummary</span><span class=p>(</span><span class=n>max_depth</span><span class=o>=</span><span class=mi>3</span><span class=p>)],</span>
</span></span><span class=line><span class=cl>        <span class=n>enable_checkpointing</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>log_every_n_steps</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>Quaterion</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>trainable_model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>trainer</span><span class=o>=</span><span class=n>trainer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train_dataloader</span><span class=o>=</span><span class=n>train_dataloader</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>val_dataloader</span><span class=o>=</span><span class=n>val_dataloader</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>save_servable</span><span class=p>(</span><span class=n>save_dir</span><span class=p>)</span>
</span></span></code></pre></div><h2 id=evaluation>Evaluation</h2><p>Let&rsquo;s see what we have achieved with these simple steps.
<a href=https://github.com/qdrant/quaterion/blob/master/examples/cars/evaluate.py target=_blank rel="noopener nofollow"><code>evaluate.py</code></a> has two functions to evaluate both the baseline model and the tuned similarity model.
We will review only the latter for brevity.
In addition to the ease of restoring a <code>SimilarityModel</code>, this code snippet also shows
how to use <a href=https://quaterion.qdrant.tech/quaterion.eval.evaluator.html#quaterion.eval.evaluator.Evaluator target=_blank rel="noopener nofollow"><code>Evaluator</code></a>
to evaluate the performance of a <code>SimilarityModel</code> on a given dataset
by given evaluation metrics.</p><figure><img src=https://storage.googleapis.com/quaterion/docs/original_vs_tuned_cars.png alt="Comparison of original and tuned models for retrieval"><figcaption><p>Comparison of original and tuned models for retrieval</p></figcaption></figure><p>Full evaluation of a dataset usually grows exponentially,
and thus you may want to perform a partial evaluation on a sampled subset.
In this case, you may use <a href=https://quaterion.qdrant.tech/quaterion.eval.samplers.html target=_blank rel="noopener nofollow">samplers</a>
to limit the evaluation.
Similar to <code>Quaterion.fit()</code> used for training, <a href=https://quaterion.qdrant.tech/quaterion.main.html#quaterion.main.Quaterion.evaluate target=_blank rel="noopener nofollow"><code>Quaterion.evaluate()</code></a>
runs a complete evaluation loop. It takes the following as arguments:</p><ul><li>An <code>Evaluator</code> instance created with given evaluation metrics and a <code>Sampler</code>,</li><li>The <code>SimilarityModel</code> to be evaluated,</li><li>And the evaluation dataset.</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>eval_tuned_encoder</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>device</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Evaluating tuned encoder...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>tuned_cars_model</span> <span class=o>=</span> <span class=n>SimilarityModel</span><span class=o>.</span><span class=n>load</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>dirname</span><span class=p>(</span><span class=vm>__file__</span><span class=p>),</span> <span class=s2>&#34;cars_encoders&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>tuned_cars_model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>result</span> <span class=o>=</span> <span class=n>Quaterion</span><span class=o>.</span><span class=n>evaluate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>evaluator</span><span class=o>=</span><span class=n>Evaluator</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>metrics</span><span class=o>=</span><span class=n>RetrievalRPrecision</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>sampler</span><span class=o>=</span><span class=n>GroupSampler</span><span class=p>(</span><span class=n>sample_size</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>,</span> <span class=n>log_progress</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=n>tuned_cars_model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>dataset</span><span class=o>=</span><span class=n>dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span></span></code></pre></div><h2 id=conclusion>Conclusion</h2><p>In this tutorial, we trained a similarity model to search for similar cars from novel categories unseen in the training phase.
Then, we evaluated it on a test dataset by the Retrieval R-Precision metric.
The base model scored 0.1207,
and our tuned model hit 0.2540, a twice higher score.
These scores can be seen in the following figure:</p><figure><img src=https://qdrant.tech/articles_data/cars-recognition/cars_metrics.png alt="Metrics for the base and tuned models"><figcaption><p>Metrics for the base and tuned models</p></figcaption></figure></article><section class="docs-feedback d-print-none"><h5 class=docs-feedback__title>Was this page useful?</h5><div class=docs-feedback__buttons><button class="button button_outlined button_sm docs-feedback__button" id=feedback__answer_yes>
<img src=https://qdrant.tech/icons/outline/thumb-up.svg alt="Thumb up icon">
Yes
</button>
<button class="button button_outlined button_sm docs-feedback__button" id=feedback__answer_no>
<img src=https://qdrant.tech/icons/outline/thumb-down.svg alt="Thumb down icon">
No</button></div></section><section class="docs-feedback__responses d-none"><p class="docs-feedback__response docs-feedback__response_yes" id=feedback__response_yes>Thank you for your feedback! 🙏</p><p class="docs-feedback__response docs-feedback__response_no" id=feedback__response_no>We are sorry to hear that. 😔 You can <a class=text-brand-p href=https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/cars-recognition.md target=_blank>edit</a> this page on GitHub, or <a class=text-brand-p href=https://github.com/qdrant/landing_page/issues/new/choose target=_blank>create</a> a GitHub issue.</p></section><script>const buttonsSection=document.querySelector(".docs-feedback"),responsesSection=document.querySelector(".docs-feedback__responses"),yesButton=document.querySelector("#feedback__answer_yes"),noButton=document.querySelector("#feedback__answer_no"),yesResponse=document.querySelector("#feedback__response_yes"),noResponse=document.querySelector("#feedback__response_no"),toggleResponses=()=>{buttonsSection.classList.add("d-none"),responsesSection.classList.remove("d-none")};yesButton.addEventListener("click",()=>{yesResponse.classList.add("feedback__response_visible"),toggleResponses()}),noButton.addEventListener("click",()=>{noResponse.classList.add("feedback__response_visible"),toggleResponses()})</script></div><div class=table-of-contents><p class=table-of-contents__head>On this page:</p><nav id=TableOfContents><ul><li><a href=#a-closer-look-at-quaterion>A closer look at Quaterion</a></li><li><a href=#dataset>Dataset</a></li><li><a href=#trainable-model>Trainable Model</a></li><li><a href=#encoder>Encoder</a></li><li><a href=#training>Training</a></li><li><a href=#evaluation>Evaluation</a></li><li><a href=#conclusion>Conclusion</a></li></ul></nav><ul class=table-of-contents__external-links><li class=table-of-contents__link><a href=https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/cars-recognition.md target=_blank><svg width="16" height="17" viewBox="0 0 16 17" fill="none"><g clip-path="url(#clip0_6269_955)"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 .700012c-4.4.0-8 3.599998-8 7.999998C0 12.2333 2.26667 15.2333 5.46667 16.3 5.86667 16.3667 6 16.1 6 15.9S6 15.2333 6 14.5667C3.8 15.0333 3.33333 13.5 3.33333 13.5 3 12.5667 2.46667 12.3 2.46667 12.3 1.66667 11.8333 2.46667 11.8333 2.46667 11.8333 3.26667 11.9 3.66667 12.6333 3.66667 12.6333 4.4 13.8333 5.53333 13.5 6 13.3 6.06667 12.7667 6.26667 12.4333 6.53333 12.2333 4.73333 12.0333 2.86667 11.3667 2.86667 8.30001c0-.86666.33333-1.6.8-2.13333.0-.26667-.33334-1.06667.13333-2.13333.0.0.66667-.200000000000001 2.2.8.66667-.2 1.33333-.26667 2-.26667S9.33333 4.63335 10 4.83335c1.5333-1.06667 2.2-.8 2.2-.8C12.6667 5.16668 12.3333 5.96668 12.2667 6.16668 12.8 6.70001 13.0667 7.43335 13.0667 8.30001c0 3.06669-1.8667 3.73329-3.6667 3.93329C9.66667 12.5 9.93333 12.9667 9.93333 13.7c0 1.0667.0 1.9333.0 2.2C9.93333 16.1 10.0667 16.3667 10.4667 16.3c3.2-1.0667 5.4666-4.0667 5.4666-7.59999C16 4.30001 12.4.700012 8 .700012z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_6269_955"><rect width="16" height="16" fill="#fff" transform="translate(0 0.5)"/></clipPath></defs></svg>
Edit on Github</a></li><li class=table-of-contents__link><a href=https://github.com/qdrant/landing_page/issues/new/choose target=_blank><svg width="16" height="17" viewBox="0 0 16 17" fill="none"><g clip-path="url(#clip0_6269_1540)"><path d="M16 9.83331V8.49998H13.9347C13.79 7.33465 13.3947 6.24065 12.8 5.31065l1.476-1.478L13.3327 2.89065 11.9633 4.26198c-.24-.248-.496600000000001-.474-.772-.676C11.0967 3.25665 10.9507 2.95398 10.7673 2.67598l1.038-1.038L10.8627.695312 9.82867 1.72931C9.29867 1.37798 8.672 1.16665 8 1.16665c-.672.0-1.29867.21133-1.828.56266L5.138.695312l-.94267.942668 1.038 1.038c-.18333.27733-.32933.58-.424.90867-.27533.202-.532.42933-.77266.67733L2.66733 2.89065l-.94333.942L3.2 5.30998c-.59467.93-.99 2.02467-1.13467 3.19H0V9.83331H2.01467C2.07333 11.276 2.50533 12.6026 3.204 13.688l-1.48 1.478L2.666 16.1093l1.37-1.368C4.93733 15.67 6.07667 16.288 7.33333 16.452V6.49998H8.66667V16.452C9.92333 16.2873 11.0627 15.67 11.964 14.7413l1.37 1.368L14.276 15.166l-1.48-1.478C13.4947 12.602 13.9267 11.2753 13.9853 9.83331H16z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_6269_1540"><rect width="16" height="16" fill="#fff" transform="translate(0 0.5)"/></clipPath></defs></svg>
Create an issue</a></li></ul></div><footer class="docs-footer w-100 py-0 pt-0 pb-4 pb-xl-0"><div class=docs-footer__cta><h4>Ready to get started with Qdrant?</h4><a href=https://qdrant.to/cloud/ class="button button_outlined button_sm" target=_blank>Start Free</a></div><div class=docs-footer__bottom><div class=docs-footer__bottom-content><span>© 2025 Qdrant.</span><div class=footer__bottom-links><a href=https://qdrant.tech/legal/terms_and_conditions/>Terms</a>
<a href=https://qdrant.tech/legal/privacy-policy/>Privacy Policy</a>
<a href=https://qdrant.tech/legal/impressum/>Impressum</a></div></div></div></footer></div></div></div></div></section></main></body><script src=https://cdn.cookielaw.org/scripttemplates/otSDKStub.js type=text/javascript data-domain-script=01960152-5e40-782d-af01-f7f5768a214e></script><script async type=text/javascript>function OptanonWrapper(){const e=new CustomEvent("onetrust_loaded");document.dispatchEvent(e)}</script><script>!function(){const o="eQYi1nZE2zQSmnHuxjMRlDd2uLl65oHe";var n,s,t="analytics",e=window[t]=window[t]||[];if(!e.initialize)if(e.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{e.invoked=!0,e.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","debug","page","screen","once","off","on","addSourceMiddleware","addIntegrationMiddleware","setAnonymousId","addDestinationMiddleware","register"],e.factory=function(n){return function(){if(window[t].initialized)return window[t][n].apply(window[t],arguments);var o,s=Array.prototype.slice.call(arguments);return["track","screen","alias","group","page","identify"].indexOf(n)>-1&&(o=document.querySelector("link[rel='canonical']"),s.push({__t:"bpc",c:o&&o.getAttribute("href")||void 0,p:location.pathname,u:location.href,s:location.search,t:document.title,r:document.referrer})),s.unshift(n),e.push(s),e}};for(n=0;n<e.methods.length;n++)s=e.methods[n],e[s]=e.factory(s);e.load=function(n,s){var i,o=document.createElement("script");o.type="text/javascript",o.async=!0,o.setAttribute("data-global-segment-analytics-key",t),o.src="https://evs.analytics.qdrant.tech/5caWuitPgcGFN5Q7HMpTaj/vEkmzjuRSqeXGbhGAFTWex.min.js",i=document.getElementsByTagName("script")[0],i.parentNode.insertBefore(o,i),e._loadOptions=s},e._writeKey=o,e._cdn="https://evs.analytics.qdrant.tech",e.SNIPPET_VERSION="5.2.0",e.load(o)}}()</script><script src=https://qdrant.tech/js/google-setup.min.14728a3ae9bd931593645b6ddbfe801d400cd2970006e782cb67f3966654248ca962dbaf4cf371493a2d326861b3a691a99d6d8349c8b2752339ab91d3787069.js></script><script src=https://qdrant.tech/js/index.min.e37feda1952d752f5568e1ebc55e183629e4d361f4df09edeed70b4a4327d601161c4147bdbe4149b4a3cdc1ed43f1bf1a2f2340a421f1aa821103980dfe0bda.js></script><script src=https://qdrant.tech/js/search/search.min.e58e7ea98cb549ea9d3ed7e68876abe323cfb323432038820f38a71c40e309deed0fba615e2d3346825229a81e0a76bbadf6f8a816ddad3438abdabfef4ebc09.js type=module></script><script src=https://qdrant.tech/js/search/scroll.min.f4ed4453a3af0adb0d4f49333cbb7892ff5430483a567d0d2dfbd4655fb203d22f22f46aff3d9f38fa5fd96dde5f30227afd0ce1d9f838f5cd5295fc83856ec9.js></script><script src=https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js></script><script src=https://qdrant.tech/js/copy-code.min.95b03a45b2ab4b7a608ecfd4b5919c8572a5b2cd1463f52561cd10976abf3b74334f91324c0e620cb80afac46026a0b18cce6fb753d8495f74c6d478c8ca1d03.js></script><script src=https://qdrant.tech/js/lang-switcher.min.63da11cef09772078425b1ee56415b9c37842a9399f2ba2d2f5efbf72fb751686c410bd50e9bcd283c8231cb97c1973199d4923beef29d8b06e59d9983a6ba51.js></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src=https://qdrant.tech/js/vendor/anchor.min.0e138e17ebcf1c1147a7a3a81d9ac3c601622eedc479f1636470eb2552470f4e27c9a8efe6e8378995dedc1ab67029d8989536ea76f0857d45d1615ae772b8a1.js></script><script>document.addEventListener("keydown",function(e){if((e.metaKey||e.ctrlKey)&&e.key==="k"){e.preventDefault();let t=document.querySelector('[data-target="#searchModal"]');t&&t?.click()}})</script><script>window.addEventListener("message",e=>{if(e.data.type==="hsFormCallback"&&e.data.eventName==="onFormReady"){const t=document.querySelector(`form[data-form-id="${e.data.id}"]`);if(t){const e=t.querySelector('[name="last_form_fill_url"]');e&&(e.value=window.location.href);const n=t.querySelector('[name="referrer_url"]');n&&(n.value=document.referrer)}}})</script></html>