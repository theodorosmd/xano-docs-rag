<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta charset=UTF-8><title>Optimizing OpenAI Embeddings: Enhance Efficiency with Qdrant's Binary Quantization - Qdrant</title>
<link rel=icon href=https://qdrant.tech/favicon/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=https://qdrant.tech/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://qdrant.tech/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://qdrant.tech/favicon/favicon-16x16.png><link rel=manifest href=https://qdrant.tech/favicon/site.webmanifest><link rel=mask-icon href=https://qdrant.tech/favicon/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#2b5797"><meta name=msapplication-config content="/favicon/browserconfig.xml"><meta name=theme-color content="#ffffff"><meta name=partition content="learn"><link href=https://qdrant.tech/css/search/search.min.09596ee2b3c94d0ac82a1c33199cabdb3e0210b1ee46aaf1515200e9e484d05dd9e27cc1e861c58cc2e582af162f63b8e180ff2a12f7a6592b7aeaa0a7125130.css rel=stylesheet integrity="sha512-CVlu4rPJTQrIKhwzGZyr2z4CELHuRqrxUVIA6eSE0F3Z4nzB6GHFjMLlgq8WL2O44YD/KhL3plkreuqgpxJRMA=="><link href=https://qdrant.tech/css/documentation.min.de204cdcfc410689a41c17bcdad0a34f2caaa50cc8505c820adaab481cef2d69a920b0a32e0d624701c29487e3271b694559d98c5047cbfaa5aa475f638011e5.css rel=stylesheet integrity="sha512-3iBM3PxBBomkHBe82tCjTyyqpQzIUFyCCtqrSBzvLWmpILCjLg1iRwHClIfjJxtpRVnZjFBHy/qlqkdfY4AR5Q=="><link href=https://qdrant.tech/css/main.min.c1e379ad4cf03647832f6a0f040754b0be3e79934db2c29f50b396327c1ec7ac45f778abadbd93f5a8bc431850d1b0d9c9eff34c0171cd4236e83c5e324c1a0e.css rel=stylesheet integrity crossorigin=anonymous><meta name=generator content="Hugo 0.141.0"><meta name=description content="Explore how Qdrant's Binary Quantization can significantly improve the efficiency and performance of OpenAI's Ada-003 embeddings. Learn best practices for real-time search applications."><meta name=keywords content="vector search engine,neural network,matching,SaaS,approximate nearest neighbor search,image search,recommender system,vectors,knn algorithm,hnsw,vector search,embeddings,similarity,simaes networks,BERT,transformer,word2vec,fasttext,qdrant"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@id":"https://qdrant.tech/articles/binary-quantization-openai/#article","@type":"Article","abstract":"Explore how Qdrants Binary Quantization can significantly improve the efficiency and performance of OpenAIs Ada003 embeddings Learn best practices for realtime search applications","author":{"@type":"Person","name":"Nirant Kasliwal"},"dateModified":"2024-02-21 13:12:08 -0800 -0800","datePublished":"2024-02-21 13:12:08 -0800 -0800","description":"Explore how Qdrants Binary Quantization can significantly improve the efficiency and performance of OpenAIs Ada003 embeddings Learn best practices for realtime search applications","headline":"Optimizing OpenAI Embeddings: Enhance Efficiency with Qdrant\u0026#39;s Binary Quantization","image":["https://qdrant.tech/articles_data/binary-quantization-openai/preview/social-preview.png"],"name":"Optimizing OpenAI Embeddings: Enhance Efficiency with Qdrant\u0026#39;s Binary Quantization","url":"https://qdrant.tech/articles/binary-quantization-openai/","wordCount":"2062"},{"@id":"https://qdrant.tech/articles/binary-quantization-openai/#organization","@type":"Organization","address":{"@type":"PostalAddress","addressCountry":"DE","addressLocality":"Berlin","addressRegion":"Berlin","postalCode":"10115","streetAddress":"Chausseestra√üe 86"},"contactPoint":{"@type":"ContactPoint","contactType":"customer support","email":"info@qdrant.com","telephone":"+49 3040797694"},"description":"Qdrant is an Open-Source Vector Database and Vector Search Engine written in Rust. It provides fast and scalable vector similarity search service with convenient API.","email":"info@qdrant.com","founders":[{"@type":"Person","name":"map[email:info@qdrant.tech name:Andrey Vasnetsov]"},{"@type":"Person","name":"Andre Zayarni"}],"foundingDate":"2021","keywords":["vector search engine","neural network","matching","SaaS","approximate nearest neighbor search","image search","recommender system","vectors","knn algorithm","hnsw","vector search","embeddings","similarity","simaes networks","BERT","transformer","word2vec","fasttext","Qdrant"],"legalName":"Qdrant Solutions GmbH","location":"Berlin, Germany","logo":"https://qdrant.tech/images/logo_with_text.png","name":"Qdrant","sameAs":["https://github.com/qdrant/qdrant","https://qdrant.to/discord","https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA","https://www.linkedin.com/company/qdrant/","https://twitter.com/qdrant_engine"],"url":"https://qdrant.tech"}]}</script><meta property="og:url" content="https://qdrant.tech/articles/binary-quantization-openai/"><meta property="og:type" content="website"><meta property="og:title" content="Optimizing OpenAI Embeddings: Enhance Efficiency with Qdrant's Binary Quantization - Qdrant"><meta name=twitter:card content="summary_large_image"><meta name=twitter:domain content="qdrant"><meta name=twitter:url content="https://qdrant.tech/articles/binary-quantization-openai/"><meta name=twitter:title content="Optimizing OpenAI Embeddings: Enhance Efficiency with Qdrant's Binary Quantization - Qdrant"><meta property="og:description" content="Explore how Qdrant's Binary Quantization can significantly improve the efficiency and performance of OpenAI's Ada-003 embeddings. Learn best practices for real-time search applications."><meta name=twitter:description content="Explore how Qdrant's Binary Quantization can significantly improve the efficiency and performance of OpenAI's Ada-003 embeddings. Learn best practices for real-time search applications."><meta name=image property="og:image" content="https://qdrant.tech/articles_data/binary-quantization-openai/preview/social-preview.png"><meta name=image property="og:image:secure_url" content="https://qdrant.tech/articles_data/binary-quantization-openai/preview/social-preview.png"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name=twitter:image:src content="https://qdrant.tech/articles_data/binary-quantization-openai/preview/social-preview.png"><meta name=author content="Nirant Kasliwal"><link rel=canonical href=https://qdrant.tech/articles/binary-quantization-openai/><script type=text/javascript src=//js-eu1.hsforms.net/forms/embed/v2.js></script><script src=https://qdrant.tech/js/documentation.min.594fc9226f6fb87b8c3b0cafb9d5c0b0bcd95f47d292b929aab04315e0506706b2f376dc4fae9961dc3082138cb19d45b2a3370ee8e881bbf4b8c91dcb735c32.js></script></head><body><main><header class=docs-header><div class="main-menu z-5"><a href=https://qdrant.tech/><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div></a><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><div class="d-block d-xl-none"><button role=button class=theme-switch></button></div><button type=button class=main-menu__trigger><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M1 12H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 5H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M1 19H23" stroke="#e1e5f0" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></button></div><ul class=main-menu__links><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/>Qdrant</a></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/cloud-intro/>Cloud</a></li><li class=main-menu__item><a class=menu-link href=https://qdrant.tech/documentation/build/>Build</a></li><li class=main-menu__item><a class=menu-linkactive href=https://qdrant.tech/articles/>Learn</a></li><li class=main-menu__item><a class=menu-link href=https://api.qdrant.tech/api-reference target=_blank>API Reference</a></li></ul><div class=main-menu__buttons><div class=main-menu__buttons-input><button class="qdr-search-input-btn q-input input_md input_light-bg" type=button name=search data-target=#searchModal>
Search</button></div><button role=button class=theme-switch></button>
<a data-metric-loc=nav href=https://cloud.qdrant.io/login class="menu-link mx-3" target=_blank>Log in</a>
<a data-metric-loc=nav href=https://cloud.qdrant.io/signup class="button button_contained button_sm" target=_blank>Start Free</a></div></div><div class=menu-mobile><div class=menu-mobile__header><div class=logo><img class=logo__img src=https://qdrant.tech/img/qdrant-logo.svg alt=logo></div><div class="d-flex d-xl-none justify-content-end align-items-center gap-4"><div class="d-block d-xl-none"><button role=button class=theme-switch></button></div><button type=button class=menu-mobile__close><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><g id="Close"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M19.778 5.63606C20.1685 5.24554 20.1685 4.61237 19.778 4.22185 19.3874 3.83132 18.7543 3.83132 18.3637 4.22185L11.9998 10.5858 5.63586 4.22185c-.39052-.39053-1.02369-.39053-1.41421.0C3.83112 4.61237 3.83112 5.24554 4.22165 5.63606L10.5856 12l-6.364 6.364C3.83108 18.7545 3.83108 19.3877 4.2216 19.7782 4.61213 20.1687 5.24529 20.1687 5.63582 19.7782l6.36398-6.364 6.364 6.364C18.7543 20.1687 19.3875 20.1687 19.778 19.7782 20.1685 19.3877 20.1685 18.7545 19.778 18.364L13.414 12l6.364-6.36394z" fill="#e1e5f0"/></g></svg></button></div></div><div class=main-menu__buttons-input><button class="qdr-search-input-btn q-input input_md input_light-bg" type=button name=search data-target=#searchModal>
Search</button></div><ul class=menu-mobile__items><li class=menu-mobile__item data-path=menu-0><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Documentation"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M4.25 1c-1.10092.0-2.12247.23681-2.88689.64443C.620129 2.04063.0 2.67297.0 3.5v11c0 .2761.223858.5.5.5s.5-.2239.5-.5c0-.278.21937-.6456.83364-.9732C2.42647 13.2107 3.27992 13 4.25 13 5.22008 13 6.07353 13.2107 6.66636 13.5268c.61427.3276.83364.6952.83364.9732.0.2761.22386.5.5.5s.5-.2239.5-.5c0-.278.21937-.6456.833640000000001-.9732C9.92647 13.2107 10.7799 13 11.75 13S13.5735 13.2107 14.1664 13.5268C14.7806 13.8544 15 14.222 15 14.5c0 .2761.2239.5.5.5s.5-.2239.5-.5V3.5C16 2.67297 15.3799 2.04063 14.6369 1.64443 13.8725 1.23681 12.8509 1 11.75 1s-2.12247.23681-2.88689.64443C8.53799 1.8178 8.2364 2.03638 8 2.29671c-.2364-.26033-.53799-.47891-.86311-.65228C6.37247 1.23681 5.35092 1 4.25 1zM1.36311 12.6444C1.23778 12.7113 1.11595 12.7848 1 12.8649V3.5c0-.27797.21937-.64563.83364-.97318C2.42647 2.21069 3.27992 2 4.25 2c.97008.0 1.82353.21069 2.41636.52682C7.28063 2.85437 7.5 3.22203 7.5 3.5v9.3649C7.38405 12.7848 7.26222 12.7113 7.13689 12.6444 6.37247 12.2368 5.35092 12 4.25 12 3.14908 12 2.12753 12.2368 1.36311 12.6444zM8.5 12.8649C8.61595 12.7848 8.73778 12.7113 8.86311 12.6444 9.62753 12.2368 10.6491 12 11.75 12S13.8725 12.2368 14.6369 12.6444C14.7622 12.7113 14.8841 12.7848 15 12.8649V3.5C15 3.22203 14.7806 2.85437 14.1664 2.52682 13.5735 2.21069 12.7201 2 11.75 2s-1.82353.21069-2.41636.52682C8.71937 2.85437 8.5 3.22203 8.5 3.5v9.3649z"/></g></svg>
Qdrant</a></div></li><li class=menu-mobile__item data-path=menu-1><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/cloud-intro/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Cloud"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M7.5 2C4.57416 2 2.18128 4.28566 2.00983 7.16851.8403 7.57763.0 8.68965.0 10c0 1.6571 1.34286 3 3 3H13c1.6571.0 3-1.3429 3-3 0-1.65714-1.3429-3-3-3L12.9776 7.00009C12.7249 4.19714 10.3686 2 7.5 2zM3.00107 7.48137 3.00008 7.47308C3.01457 5.0006 5.02412 3 7.5 3c2.47599.0 4.4856 2.00079 4.4999 4.47342L11.9987 7.4836C11.9969 7.50027 11.995 7.52348 11.995 7.551 11.995 7.701 12.0623 7.84308 12.1785 7.93804 12.2946 8.03301 12.4472 8.07082 12.5942 8.04106 12.726 8.01438 12.8617 8 13 8c1.1049.0 2 .89514 2 2C15 11.1049 14.1049 12 13 12H3C1.89514 12 1 11.1049 1 10 1 9.03225 1.68901 8.22422 2.60364 8.04017 2.83708 7.9932 3.005 7.78812 3.005 7.55 3.005 7.52154 3.00291 7.49773 3.00107 7.48137z"/></g></svg>
Cloud</a></div></li><li class=menu-mobile__item data-path=menu-2><div class=menu-mobile__item-content><a href=https://qdrant.tech/documentation/build/><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Blog"><path id="Union" fill-rule="evenodd" clip-rule="evenodd" d="M0 1.5C0 1.22386.223858 1 .5 1h5c.27614.0.5.22386.5.5v5c0 .27614-.22386.5-.5.5H.5C.223858 7 0 6.77614.0 6.5v-5zM1 2V6H5V2H1zm7 .5c0-.27614.22386-.5.5-.5h7c.2761.0.5.22386.5.5s-.2239.5-.5.5h-7C8.22386 3 8 2.77614 8 2.5zM8.5 6c-.27614.0-.5.22386-.5.5s.22386.5.5.5h7c.2761.0.5-.22386.5-.5s-.2239-.5-.5-.5h-7zM0 10.5c0-.2761.223858-.5.5-.5h15c.2761.0.5.2239.5.5s-.2239.5-.5.5H.5c-.276142.0-.5-.2239-.5-.5zM.5 14c-.276142.0-.5.2239-.5.5s.223858.5.5.5h15c.2761.0.5-.2239.5-.5s-.2239-.5-.5-.5H.5z"/></g></svg>
Build</a></div></li><li class=menu-mobile__item data-path=menu-3><div class=menu-mobile__item-content><a class=active href=https://qdrant.tech/articles/><svg width="16" height="16" viewBox="0 0 16 16" fill="none" stroke="#e1e5f0"><g id="Group"><path id="Vector" d="M10.084 1.84094l4.059 4.059" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_2" d="M8.49188 2.72406c-1.22044-.53042-2.59304-.59475-3.85774-.1808-1.2647.41395-2.33363 1.27742-3.00426 2.4268l2.34 2.34" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_3" d="M13.2657 7.47302C13.8062 8.69691 13.8769 10.077 13.4645 11.3497c-.4125 1.2728-1.2792 2.3491-2.4348 3.0233l-2.35001-2.35" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_4" d="M6.81217 13.049l-3.861-3.861S6.24917.983 15.5002.5c-.523 9.211-8.68803 12.549-8.68803 12.549z" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_5" d="M3.59892 12.4008C3.34181 12.1441 2.99331 12 2.62995 12c-.36335.0-.71186.1441-.96897.4008-.46665.4664-.63131 1.941-.65931 2.2322C.997021 14.6793 1.0021 14.726 1.01659 14.7701 1.03108 14.8143 1.05465 14.8549 1.08579 14.8895 1.11693 14.924 1.15495 14.9516 1.19741 14.9705 1.23987 14.9895 1.28583 14.9994 1.33233 14.9995 1.34298 15.0002 1.35367 15.0002 1.36433 14.9995 1.65565 14.9715 3.1316 14.8063 3.59759 14.3405 3.85501 14.0834 3.99975 13.7346 4 13.3709 4.00025 13.0072 3.85599 12.6582 3.59892 12.4008z" stroke-linecap="round" stroke-linejoin="round"/><path id="Vector_6" d="M9 8c.55228.0 1-.44772 1-1S9.55228 6 9 6 8 6.44772 8 7s.44772 1 1 1z"/></g></svg>
Learn</a></div></li><li class=menu-mobile__item data-path=menu-4><div class=menu-mobile__item-content><a href=https://api.qdrant.tech/api-reference target=_blank><svg width="16" height="16" viewBox="0 0 16 16" fill="#e1e5f0"><g id="Menu/Roadmap" clip-path="url(#clip0_7182_4311)"><path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M13.5 1c-.8284.0-1.5.67157-1.5 1.5S12.6716 4 13.5 4 15 3.32843 15 2.5 14.3284 1 13.5 1zM11 2.5C11 1.11929 12.1193.0 13.5.0S16 1.11929 16 2.5 14.8807 5 13.5 5 11 3.88071 11 2.5zM2.5 12c-.82843.0-1.5.6716-1.5 1.5S1.67157 15 2.5 15 4 14.3284 4 13.5 3.32843 12 2.5 12zM0 13.5C0 12.1193 1.11929 11 2.5 11S5 12.1193 5 13.5 3.88071 16 2.5 16 0 14.8807.0 13.5zM3.65901 1.65901C4.08097 1.23705 4.65326 1 5.25 1s1.16903.23705 1.59099.65901C7.26295 2.08097 7.5 2.65326 7.5 3.25v9.5c0 .862.34241 1.6886.9519 2.2981C9.0614 15.6576 9.88805 16 10.75 16c.862.0 1.6886-.3424 2.2981-.9519S14 13.612 14 12.75V6.5c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v6.25C13 13.3467 12.7629 13.919 12.341 14.341 11.919 14.7629 11.3467 15 10.75 15S9.58097 14.7629 9.15901 14.341C8.73705 13.919 8.5 13.3467 8.5 12.75V3.25C8.5 2.38805 8.15759 1.5614 7.5481.951903 6.9386.34241 6.11195.0 5.25.0S3.5614.34241 2.9519.951903C2.34241 1.5614 2 2.38805 2 3.25V9.5c0 .27614.22386.5.5.5s.5-.22386.5-.5V3.25c0-.59674.23705-1.16903.65901-1.59099z"/></g><defs><clipPath id="clip0_7182_4311"><rect width="16" height="16" fill="#fff"/></clipPath></defs></svg>
API Reference</a></div></li></ul><div class=docs-menu><div id=sidebar class=docs-menu__content><h3 class=docs-menu__links-title>Learn</h3><nav><div class=docs-menu__links-group><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/vector-search-manuals/>Vector Search Manuals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/qdrant-internals/>Qdrant Internals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/data-exploration/>Data Exploration</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/machine-learning/>Machine Learning</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/rag-and-genai/>RAG & GenAI</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/practicle-examples/>Practical Examples</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/ecosystem/>Ecosystem</a></div></div></nav></div></div></div></header><section class="docs documentation"><div class=documentation__container><div class="d-flex flex-column flex-xl-row"><div class=docs-menu><div id=sidebar class=docs-menu__content><h3 class=docs-menu__links-title>Learn</h3><nav><div class=docs-menu__links-group><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/vector-search-manuals/>Vector Search Manuals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/qdrant-internals/>Qdrant Internals</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/data-exploration/>Data Exploration</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/machine-learning/>Machine Learning</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/rag-and-genai/>RAG & GenAI</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/practicle-examples/>Practical Examples</a></div><div class="docs-menu__articles-link docs-menu__links-group-heading"><a href=https://qdrant.tech/articles/ecosystem/>Ecosystem</a></div></div></nav></div></div><div class=documentation__content><div class=documentation__content-wrapper><div class=documentation__article-wrapper><ul class=docs-breadcrumbs><li class=docs-breadcrumbs__crumb><a href=https://qdrant.tech/articles/>Articles</a></li><li class=docs-breadcrumbs__crumb-separator></li><li class=docs-breadcrumbs__crumb>Optimizing OpenAI Embeddings: Enhance Efficiency with Qdrant's Binary Quantization</li></ul><article class=documentation-article><div class=documentation-article__header><a href=https://qdrant.tech/articles/practicle-examples/ class=documentation-article__header-link><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path d="M14.6668 8.00004H1.3335m0 0L6.00016 12.6667M1.3335 8.00004 6.00016 3.33337" stroke="#8f98b3" stroke-width="1.33333" stroke-linecap="round" stroke-linejoin="round"/></svg>
Back to Practical Examples</a><h1 class=documentation-article__header-title>Optimizing OpenAI Embeddings: Enhance Efficiency with Qdrant's Binary Quantization</h1><div class=documentation-article__header-about><p>Nirant Kasliwal</p><span>&#183;</span><p>February 21, 2024</p></div><picture class=documentation-article__header-preview><source srcset=https://qdrant.tech/articles_data/binary-quantization-openai/preview/title.webp type=image/webp><img alt="Optimizing OpenAI Embeddings: Enhance Efficiency with Qdrant's Binary Quantization" src=https://qdrant.tech/articles_data/binary-quantization-openai/preview/title.jpg></picture></div><p>OpenAI Ada-003 embeddings are a powerful tool for natural language processing (NLP). However, the size of the embeddings are a challenge, especially with real-time search and retrieval. In this article, we explore how you can use Qdrant&rsquo;s Binary Quantization to enhance the performance and efficiency of OpenAI embeddings.</p><p>In this post, we discuss:</p><ul><li>The significance of OpenAI embeddings and real-world challenges.</li><li>Qdrant&rsquo;s Binary Quantization, and how it can improve the performance of OpenAI embeddings</li><li>Results of an experiment that highlights improvements in search efficiency and accuracy</li><li>Implications of these findings for real-world applications</li><li>Best practices for leveraging Binary Quantization to enhance OpenAI embeddings</li></ul><p>If you&rsquo;re new to Binary Quantization, consider reading our article which walks you through the concept and <a href=https://qdrant.tech/articles/binary-quantization/>how to use it with Qdrant</a></p><p>You can also try out these techniques as described in <a href=https://github.com/qdrant/examples/blob/openai-3/binary-quantization-openai/README.md target=_blank rel="noopener nofollow">Binary Quantization OpenAI</a>, which includes Jupyter notebooks.</p><h2 id=new-openai-embeddings-performance-and-changes>New OpenAI embeddings: performance and changes</h2><p>As the technology of embedding models has advanced, demand has grown. Users are looking more for powerful and efficient text-embedding models. OpenAI&rsquo;s Ada-003 embeddings offer state-of-the-art performance on a wide range of NLP tasks, including those noted in <a href=https://huggingface.co/spaces/mteb/leaderboard target=_blank rel="noopener nofollow">MTEB</a> and <a href=https://openai.com/blog/new-embedding-models-and-api-updates target=_blank rel="noopener nofollow">MIRACL</a>.</p><p>These models include multilingual support in over 100 languages. The transition from text-embedding-ada-002 to text-embedding-3-large has led to a significant jump in performance scores (from 31.4% to 54.9% on MIRACL).</p><h4 id=matryoshka-representation-learning>Matryoshka representation learning</h4><p>The new OpenAI models have been trained with a novel approach called &ldquo;<a href=https://aniketrege.github.io/blog/2024/mrl/ target=_blank rel="noopener nofollow">Matryoshka Representation Learning</a>&rdquo;. Developers can set up embeddings of different sizes (number of dimensions). In this post, we use small and large variants. Developers can select embeddings which balances accuracy and size.</p><p>Here, we show how the accuracy of binary quantization is quite good across different dimensions &ndash; for both the models.</p><h2 id=enhanced-performance-and-efficiency-with-binary-quantization>Enhanced performance and efficiency with binary quantization</h2><p>By reducing storage needs, you can scale applications with lower costs. This addresses a critical challenge posed by the original embedding sizes. Binary Quantization also speeds the search process. It simplifies the complex distance calculations between vectors into more manageable bitwise operations, which supports potentially real-time searches across vast datasets.</p><p>The accompanying graph illustrates the promising accuracy levels achievable with binary quantization across different model sizes, showcasing its practicality without severely compromising on performance. This dual advantage of storage reduction and accelerated search capabilities underscores the transformative potential of Binary Quantization in deploying OpenAI embeddings more effectively across various real-world applications.</p><p><img src=https://qdrant.tech/blog/openai/Accuracy_Models.png alt></p><p>The efficiency gains from Binary Quantization are as follows:</p><ul><li>Reduced storage footprint: It helps with large-scale datasets. It also saves on memory, and scales up to 30x at the same cost.</li><li>Enhanced speed of data retrieval: Smaller data sizes generally leads to faster searches.</li><li>Accelerated search process: It is based on simplified distance calculations between vectors to bitwise operations. This enables real-time querying even in extensive databases.</li></ul><h3 id=experiment-setup-openai-embeddings-in-focus>Experiment setup: OpenAI embeddings in focus</h3><p>To identify Binary Quantization&rsquo;s impact on search efficiency and accuracy, we designed our experiment on OpenAI text-embedding models. These models, which capture nuanced linguistic features and semantic relationships, are the backbone of our analysis. We then delve deep into the potential enhancements offered by Qdrant&rsquo;s Binary Quantization feature.</p><p>This approach not only leverages the high-caliber OpenAI embeddings but also provides a broad basis for evaluating the search mechanism under scrutiny.</p><h4 id=dataset>Dataset</h4><p>The research employs 100K random samples from the <a href=https://huggingface.co/datasets/KShivendu/dbpedia-entities-openai-1M target=_blank rel="noopener nofollow">OpenAI 1M</a> 1M dataset, focusing on 100 randomly selected records. These records serve as queries in the experiment, aiming to assess how Binary Quantization influences search efficiency and precision within the dataset. We then use the embeddings of the queries to search for the nearest neighbors in the dataset.</p><h4 id=parameters-oversampling-rescoring-and-search-limits>Parameters: oversampling, rescoring, and search limits</h4><p>For each record, we run a parameter sweep over the number of oversampling, rescoring, and search limits. We can then understand the impact of these parameters on search accuracy and efficiency. Our experiment was designed to assess the impact of Binary Quantization under various conditions, based on the following parameters:</p><ul><li><p><strong>Oversampling</strong>: By oversampling, we can limit the loss of information inherent in quantization. This also helps to preserve the semantic richness of your OpenAI embeddings. We experimented with different oversampling factors, and identified the impact on the accuracy and efficiency of search. Spoiler: higher oversampling factors tend to improve the accuracy of searches. However, they usually require more computational resources.</p></li><li><p><strong>Rescoring</strong>: Rescoring refines the first results of an initial binary search. This process leverages the original high-dimensional vectors to refine the search results, <strong>always</strong> improving accuracy. We toggled rescoring on and off to measure effectiveness, when combined with Binary Quantization. We also measured the impact on search performance.</p></li><li><p><strong>Search Limits</strong>: We specify the number of results from the search process. We experimented with various search limits to measure their impact the accuracy and efficiency. We explored the trade-offs between search depth and performance. The results provide insight for applications with different precision and speed requirements.</p></li></ul><p>Through this detailed setup, our experiment sought to shed light on the nuanced interplay between Binary Quantization and the high-quality embeddings produced by OpenAI&rsquo;s models. By meticulously adjusting and observing the outcomes under different conditions, we aimed to uncover actionable insights that could empower users to harness the full potential of Qdrant in combination with OpenAI&rsquo;s embeddings, regardless of their specific application needs.</p><h3 id=results-binary-quantizations-impact-on-openai-embeddings>Results: binary quantization&rsquo;s impact on OpenAI embeddings</h3><p>To analyze the impact of rescoring (<code>True</code> or <code>False</code>), we compared results across different model configurations and search limits. Rescoring sets up a more precise search, based on results from an initial query.</p><h4 id=rescoring>Rescoring</h4><p><img src=https://qdrant.tech/blog/openai/Rescoring_Impact.png alt="Graph that measures the impact of rescoring"></p><p>Here are some key observations, which analyzes the impact of rescoring (<code>True</code> or <code>False</code>):</p><ol><li><p><strong>Significantly Improved Accuracy</strong>:</p><ul><li>Across all models and dimension configurations, enabling rescoring (<code>True</code>) consistently results in higher accuracy scores compared to when rescoring is disabled (<code>False</code>).</li><li>The improvement in accuracy is true across various search limits (10, 20, 50, 100).</li></ul></li><li><p><strong>Model and Dimension Specific Observations</strong>:</p><ul><li>For the <code>text-embedding-3-large</code> model with 3072 dimensions, rescoring boosts the accuracy from an average of about 76-77% without rescoring to 97-99% with rescoring, depending on the search limit and oversampling rate.</li><li>The accuracy improvement with increased oversampling is more pronounced when rescoring is enabled, indicating a better utilization of the additional binary codes in refining search results.</li><li>With the <code>text-embedding-3-small</code> model at 512 dimensions, accuracy increases from around 53-55% without rescoring to 71-91% with rescoring, highlighting the significant impact of rescoring, especially at lower dimensions.</li></ul></li></ol><p>In contrast, for lower dimension models (such as text-embedding-3-small with 512 dimensions), the incremental accuracy gains from increased oversampling levels are less significant, even with rescoring enabled. This suggests a diminishing return on accuracy improvement with higher oversampling in lower dimension spaces.</p><ol start=3><li><strong>Influence of Search Limit</strong>:<ul><li>The performance gain from rescoring seems to be relatively stable across different search limits, suggesting that rescoring consistently enhances accuracy regardless of the number of top results considered.</li></ul></li></ol><p>In summary, enabling rescoring dramatically improves search accuracy across all tested configurations. It is crucial feature for applications where precision is paramount. The consistent performance boost provided by rescoring underscores its value in refining search results, particularly when working with complex, high-dimensional data like OpenAI embeddings. This enhancement is critical for applications that demand high accuracy, such as semantic search, content discovery, and recommendation systems, where the quality of search results directly impacts user experience and satisfaction.</p><h3 id=dataset-combinations>Dataset combinations</h3><p>For those exploring the integration of text embedding models with Qdrant, it&rsquo;s crucial to consider various model configurations for optimal performance. The dataset combinations defined above illustrate different configurations to test against Qdrant. These combinations vary by two primary attributes:</p><ol><li><p><strong>Model Name</strong>: Signifying the specific text embedding model variant, such as &ldquo;text-embedding-3-large&rdquo; or &ldquo;text-embedding-3-small&rdquo;. This distinction correlates with the model&rsquo;s capacity, with &ldquo;large&rdquo; models offering more detailed embeddings at the cost of increased computational resources.</p></li><li><p><strong>Dimensions</strong>: This refers to the size of the vector embeddings produced by the model. Options range from 512 to 3072 dimensions. Higher dimensions could lead to more precise embeddings but might also increase the search time and memory usage in Qdrant.</p></li></ol><p>Optimizing these parameters is a balancing act between search accuracy and resource efficiency. Testing across these combinations allows users to identify the configuration that best meets their specific needs, considering the trade-offs between computational resources and the quality of search results.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>dataset_combinations</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;model_name&#34;</span><span class=p>:</span> <span class=s2>&#34;text-embedding-3-large&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;dimensions&#34;</span><span class=p>:</span> <span class=mi>3072</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;model_name&#34;</span><span class=p>:</span> <span class=s2>&#34;text-embedding-3-large&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;dimensions&#34;</span><span class=p>:</span> <span class=mi>1024</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;model_name&#34;</span><span class=p>:</span> <span class=s2>&#34;text-embedding-3-large&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;dimensions&#34;</span><span class=p>:</span> <span class=mi>1536</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;model_name&#34;</span><span class=p>:</span> <span class=s2>&#34;text-embedding-3-small&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;dimensions&#34;</span><span class=p>:</span> <span class=mi>512</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;model_name&#34;</span><span class=p>:</span> <span class=s2>&#34;text-embedding-3-small&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;dimensions&#34;</span><span class=p>:</span> <span class=mi>1024</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;model_name&#34;</span><span class=p>:</span> <span class=s2>&#34;text-embedding-3-small&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;dimensions&#34;</span><span class=p>:</span> <span class=mi>1536</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span></code></pre></div><h4 id=exploring-dataset-combinations-and-their-impacts-on-model-performance>Exploring dataset combinations and their impacts on model performance</h4><p>The code snippet iterates through predefined dataset and model combinations. For each combination, characterized by the model name and its dimensions, the corresponding experiment&rsquo;s results are loaded. These results, which are stored in JSON format, include performance metrics like accuracy under different configurations: with and without oversampling, and with and without a rescore step.</p><p>Following the extraction of these metrics, the code computes the average accuracy across different settings, excluding extreme cases of very low limits (specifically, limits of 1 and 5). This computation groups the results by oversampling, rescore presence, and limit, before calculating the mean accuracy for each subgroup.</p><p>After gathering and processing this data, the average accuracies are organized into a pivot table. This table is indexed by the limit (the number of top results considered), and columns are formed based on combinations of oversampling and rescoring.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>combination</span> <span class=ow>in</span> <span class=n>dataset_combinations</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>model_name</span> <span class=o>=</span> <span class=n>combination</span><span class=p>[</span><span class=s2>&#34;model_name&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>dimensions</span> <span class=o>=</span> <span class=n>combination</span><span class=p>[</span><span class=s2>&#34;dimensions&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Model: </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>, dimensions: </span><span class=si>{</span><span class=n>dimensions</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_json</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;../results/results-</span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>-</span><span class=si>{</span><span class=n>dimensions</span><span class=si>}</span><span class=s2>.json&#34;</span><span class=p>,</span> <span class=n>lines</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>average_accuracy</span> <span class=o>=</span> <span class=n>results</span><span class=p>[</span><span class=n>results</span><span class=p>[</span><span class=s2>&#34;limit&#34;</span><span class=p>]</span> <span class=o>!=</span> <span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>average_accuracy</span> <span class=o>=</span> <span class=n>average_accuracy</span><span class=p>[</span><span class=n>average_accuracy</span><span class=p>[</span><span class=s2>&#34;limit&#34;</span><span class=p>]</span> <span class=o>!=</span> <span class=mi>5</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>average_accuracy</span> <span class=o>=</span> <span class=n>average_accuracy</span><span class=o>.</span><span class=n>groupby</span><span class=p>([</span><span class=s2>&#34;oversampling&#34;</span><span class=p>,</span> <span class=s2>&#34;rescore&#34;</span><span class=p>,</span> <span class=s2>&#34;limit&#34;</span><span class=p>])[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;accuracy&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>average_accuracy</span> <span class=o>=</span> <span class=n>average_accuracy</span><span class=o>.</span><span class=n>reset_index</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>acc</span> <span class=o>=</span> <span class=n>average_accuracy</span><span class=o>.</span><span class=n>pivot</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>index</span><span class=o>=</span><span class=s2>&#34;limit&#34;</span><span class=p>,</span> <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;oversampling&#34;</span><span class=p>,</span> <span class=s2>&#34;rescore&#34;</span><span class=p>],</span> <span class=n>values</span><span class=o>=</span><span class=s2>&#34;accuracy&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>acc</span><span class=p>)</span>
</span></span></code></pre></div><p>Here is a selected slice of these results, with <code>rescore=True</code>:</p><div class=table-responsive><table class="table mb-5"><thead><tr><th>Method</th><th>Dimensionality</th><th>Test Dataset</th><th>Recall</th><th>Oversampling</th></tr></thead><tbody><tr><td>OpenAI text-embedding-3-large (highest MTEB score from the table)</td><td>3072</td><td><a href=https://huggingface.co/datasets/Qdrant/dbpedia-entities-openai3-text-embedding-3-large-3072-1M target=_blank rel="noopener nofollow">DBpedia 1M</a></td><td>0.9966</td><td>3x</td></tr><tr><td>OpenAI text-embedding-3-small</td><td>1536</td><td><a href=https://huggingface.co/datasets/Qdrant/dbpedia-entities-openai3-text-embedding-3-small-1536-100K target=_blank rel="noopener nofollow">DBpedia 100K</a></td><td>0.9847</td><td>3x</td></tr><tr><td>OpenAI text-embedding-3-large</td><td>1536</td><td><a href=https://huggingface.co/datasets/Qdrant/dbpedia-entities-openai3-text-embedding-3-large-1536-1M target=_blank rel="noopener nofollow">DBpedia 1M</a></td><td>0.9826</td><td>3x</td></tr></tbody></table></div><h4 id=impact-of-oversampling>Impact of oversampling</h4><p>You can use oversampling in machine learning to counteract imbalances in datasets.
It works well when one class significantly outnumbers others. This imbalance
can skew the performance of models, which favors the majority class at the
expense of others. By creating additional samples from the minority classes,
oversampling helps equalize the representation of classes in the training dataset, thus enabling more fair and accurate modeling of real-world scenarios.</p><p>The screenshot showcases the effect of oversampling on model performance metrics. While the actual metrics aren&rsquo;t shown, we expect to see improvements in measures such as precision, recall, or F1-score. These improvements illustrate the effectiveness of oversampling in creating a more balanced dataset. It allows the model to learn a better representation of all classes, not just the dominant one.</p><p>Without an explicit code snippet or output, we focus on the role of oversampling in model fairness and performance. Through graphical representation, you can set up before-and-after comparisons. These comparisons illustrate the contribution to machine learning projects.</p><p><img src=https://qdrant.tech/blog/openai/Oversampling_Impact.png alt="Measuring the impact of oversampling"></p><h3 id=leveraging-binary-quantization-best-practices>Leveraging binary quantization: best practices</h3><p>We recommend the following best practices for leveraging Binary Quantization to enhance OpenAI embeddings:</p><ol><li>Embedding Model: Use the text-embedding-3-large from MTEB. It is most accurate among those tested.</li><li>Dimensions: Use the highest dimension available for the model, to maximize accuracy. The results are true for English and other languages.</li><li>Oversampling: Use an oversampling factor of 3 for the best balance between accuracy and efficiency. This factor is suitable for a wide range of applications.</li><li>Rescoring: Enable rescoring to improve the accuracy of search results.</li><li>RAM: Store the full vectors and payload on disk. Limit what you load from memory to the binary quantization index. This helps reduce the memory footprint and improve the overall efficiency of the system. The incremental latency from the disk read is negligible compared to the latency savings from the binary scoring in Qdrant, which uses SIMD instructions where possible.</li></ol><h2 id=whats-next>What&rsquo;s next?</h2><p>Binary quantization is exceptional if you need to work with large volumes of data under high recall expectations. You can try this feature either by spinning up a <a href=https://hub.docker.com/r/qdrant/qdrant target=_blank rel="noopener nofollow">Qdrant container image</a> locally or, having us create one for you through a <a href=https://cloud.qdrant.io/login target=_blank rel="noopener nofollow">free account</a> in our cloud hosted service.</p><p>The article gives examples of data sets and configuration you can use to get going. Our documentation covers <a href=https://qdrant.tech/documentation/tutorials/bulk-upload/>adding large datasets to Qdrant</a> to your Qdrant instance as well as <a href=https://qdrant.tech/documentation/guides/quantization/>more quantization methods</a>.</p><p>Want to discuss these findings and learn more about Binary Quantization? <a href=https://discord.gg/qdrant target=_blank rel="noopener nofollow">Join our Discord community.</a></p></article><section class="docs-feedback d-print-none"><h5 class=docs-feedback__title>Was this page useful?</h5><div class=docs-feedback__buttons><button class="button button_outlined button_sm docs-feedback__button" id=feedback__answer_yes>
<img src=https://qdrant.tech/icons/outline/thumb-up.svg alt="Thumb up icon">
Yes
</button>
<button class="button button_outlined button_sm docs-feedback__button" id=feedback__answer_no>
<img src=https://qdrant.tech/icons/outline/thumb-down.svg alt="Thumb down icon">
No</button></div></section><section class="docs-feedback__responses d-none"><p class="docs-feedback__response docs-feedback__response_yes" id=feedback__response_yes>Thank you for your feedback! üôè</p><p class="docs-feedback__response docs-feedback__response_no" id=feedback__response_no>We are sorry to hear that. üòî You can <a class=text-brand-p href=https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/binary-quantization-openai.md target=_blank>edit</a> this page on GitHub, or <a class=text-brand-p href=https://github.com/qdrant/landing_page/issues/new/choose target=_blank>create</a> a GitHub issue.</p></section><script>const buttonsSection=document.querySelector(".docs-feedback"),responsesSection=document.querySelector(".docs-feedback__responses"),yesButton=document.querySelector("#feedback__answer_yes"),noButton=document.querySelector("#feedback__answer_no"),yesResponse=document.querySelector("#feedback__response_yes"),noResponse=document.querySelector("#feedback__response_no"),toggleResponses=()=>{buttonsSection.classList.add("d-none"),responsesSection.classList.remove("d-none")};yesButton.addEventListener("click",()=>{yesResponse.classList.add("feedback__response_visible"),toggleResponses()}),noButton.addEventListener("click",()=>{noResponse.classList.add("feedback__response_visible"),toggleResponses()})</script></div><div class=table-of-contents><p class=table-of-contents__head>On this page:</p><nav id=TableOfContents><ul><li><a href=#new-openai-embeddings-performance-and-changes>New OpenAI embeddings: performance and changes</a><ul><li></li></ul></li><li><a href=#enhanced-performance-and-efficiency-with-binary-quantization>Enhanced performance and efficiency with binary quantization</a><ul><li><a href=#experiment-setup-openai-embeddings-in-focus>Experiment setup: OpenAI embeddings in focus</a></li><li><a href=#results-binary-quantizations-impact-on-openai-embeddings>Results: binary quantization&rsquo;s impact on OpenAI embeddings</a></li><li><a href=#dataset-combinations>Dataset combinations</a></li><li><a href=#leveraging-binary-quantization-best-practices>Leveraging binary quantization: best practices</a></li></ul></li><li><a href=#whats-next>What&rsquo;s next?</a></li></ul></nav><ul class=table-of-contents__external-links><li class=table-of-contents__link><a href=https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/binary-quantization-openai.md target=_blank><svg width="16" height="17" viewBox="0 0 16 17" fill="none"><g clip-path="url(#clip0_6269_955)"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 .700012c-4.4.0-8 3.599998-8 7.999998C0 12.2333 2.26667 15.2333 5.46667 16.3 5.86667 16.3667 6 16.1 6 15.9S6 15.2333 6 14.5667C3.8 15.0333 3.33333 13.5 3.33333 13.5 3 12.5667 2.46667 12.3 2.46667 12.3 1.66667 11.8333 2.46667 11.8333 2.46667 11.8333 3.26667 11.9 3.66667 12.6333 3.66667 12.6333 4.4 13.8333 5.53333 13.5 6 13.3 6.06667 12.7667 6.26667 12.4333 6.53333 12.2333 4.73333 12.0333 2.86667 11.3667 2.86667 8.30001c0-.86666.33333-1.6.8-2.13333.0-.26667-.33334-1.06667.13333-2.13333.0.0.66667-.200000000000001 2.2.8.66667-.2 1.33333-.26667 2-.26667S9.33333 4.63335 10 4.83335c1.5333-1.06667 2.2-.8 2.2-.8C12.6667 5.16668 12.3333 5.96668 12.2667 6.16668 12.8 6.70001 13.0667 7.43335 13.0667 8.30001c0 3.06669-1.8667 3.73329-3.6667 3.93329C9.66667 12.5 9.93333 12.9667 9.93333 13.7c0 1.0667.0 1.9333.0 2.2C9.93333 16.1 10.0667 16.3667 10.4667 16.3c3.2-1.0667 5.4666-4.0667 5.4666-7.59999C16 4.30001 12.4.700012 8 .700012z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_6269_955"><rect width="16" height="16" fill="#fff" transform="translate(0 0.5)"/></clipPath></defs></svg>
Edit on Github</a></li><li class=table-of-contents__link><a href=https://github.com/qdrant/landing_page/issues/new/choose target=_blank><svg width="16" height="17" viewBox="0 0 16 17" fill="none"><g clip-path="url(#clip0_6269_1540)"><path d="M16 9.83331V8.49998H13.9347C13.79 7.33465 13.3947 6.24065 12.8 5.31065l1.476-1.478L13.3327 2.89065 11.9633 4.26198c-.24-.248-.496600000000001-.474-.772-.676C11.0967 3.25665 10.9507 2.95398 10.7673 2.67598l1.038-1.038L10.8627.695312 9.82867 1.72931C9.29867 1.37798 8.672 1.16665 8 1.16665c-.672.0-1.29867.21133-1.828.56266L5.138.695312l-.94267.942668 1.038 1.038c-.18333.27733-.32933.58-.424.90867-.27533.202-.532.42933-.77266.67733L2.66733 2.89065l-.94333.942L3.2 5.30998c-.59467.93-.99 2.02467-1.13467 3.19H0V9.83331H2.01467C2.07333 11.276 2.50533 12.6026 3.204 13.688l-1.48 1.478L2.666 16.1093l1.37-1.368C4.93733 15.67 6.07667 16.288 7.33333 16.452V6.49998H8.66667V16.452C9.92333 16.2873 11.0627 15.67 11.964 14.7413l1.37 1.368L14.276 15.166l-1.48-1.478C13.4947 12.602 13.9267 11.2753 13.9853 9.83331H16z" fill="#f0f3fa"/></g><defs><clipPath id="clip0_6269_1540"><rect width="16" height="16" fill="#fff" transform="translate(0 0.5)"/></clipPath></defs></svg>
Create an issue</a></li></ul></div><footer class="docs-footer w-100 py-0 pt-0 pb-4 pb-xl-0"><div class=docs-footer__cta><h4>Ready to get started with Qdrant?</h4><a href=https://qdrant.to/cloud/ class="button button_outlined button_sm" target=_blank>Start Free</a></div><div class=docs-footer__bottom><div class=docs-footer__bottom-content><span>¬© 2025 Qdrant.</span><div class=footer__bottom-links><a href=https://qdrant.tech/legal/terms_and_conditions/>Terms</a>
<a href=https://qdrant.tech/legal/privacy-policy/>Privacy Policy</a>
<a href=https://qdrant.tech/legal/impressum/>Impressum</a></div></div></div></footer></div></div></div></div></section></main></body><script src=https://cdn.cookielaw.org/scripttemplates/otSDKStub.js type=text/javascript data-domain-script=01960152-5e40-782d-af01-f7f5768a214e></script><script async type=text/javascript>function OptanonWrapper(){const e=new CustomEvent("onetrust_loaded");document.dispatchEvent(e)}</script><script>!function(){const o="eQYi1nZE2zQSmnHuxjMRlDd2uLl65oHe";var n,s,t="analytics",e=window[t]=window[t]||[];if(!e.initialize)if(e.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{e.invoked=!0,e.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","debug","page","screen","once","off","on","addSourceMiddleware","addIntegrationMiddleware","setAnonymousId","addDestinationMiddleware","register"],e.factory=function(n){return function(){if(window[t].initialized)return window[t][n].apply(window[t],arguments);var o,s=Array.prototype.slice.call(arguments);return["track","screen","alias","group","page","identify"].indexOf(n)>-1&&(o=document.querySelector("link[rel='canonical']"),s.push({__t:"bpc",c:o&&o.getAttribute("href")||void 0,p:location.pathname,u:location.href,s:location.search,t:document.title,r:document.referrer})),s.unshift(n),e.push(s),e}};for(n=0;n<e.methods.length;n++)s=e.methods[n],e[s]=e.factory(s);e.load=function(n,s){var i,o=document.createElement("script");o.type="text/javascript",o.async=!0,o.setAttribute("data-global-segment-analytics-key",t),o.src="https://evs.analytics.qdrant.tech/5caWuitPgcGFN5Q7HMpTaj/vEkmzjuRSqeXGbhGAFTWex.min.js",i=document.getElementsByTagName("script")[0],i.parentNode.insertBefore(o,i),e._loadOptions=s},e._writeKey=o,e._cdn="https://evs.analytics.qdrant.tech",e.SNIPPET_VERSION="5.2.0",e.load(o)}}()</script><script src=https://qdrant.tech/js/google-setup.min.14728a3ae9bd931593645b6ddbfe801d400cd2970006e782cb67f3966654248ca962dbaf4cf371493a2d326861b3a691a99d6d8349c8b2752339ab91d3787069.js></script><script src=https://qdrant.tech/js/index.min.e37feda1952d752f5568e1ebc55e183629e4d361f4df09edeed70b4a4327d601161c4147bdbe4149b4a3cdc1ed43f1bf1a2f2340a421f1aa821103980dfe0bda.js></script><script src=https://qdrant.tech/js/search/search.min.e58e7ea98cb549ea9d3ed7e68876abe323cfb323432038820f38a71c40e309deed0fba615e2d3346825229a81e0a76bbadf6f8a816ddad3438abdabfef4ebc09.js type=module></script><script src=https://qdrant.tech/js/search/scroll.min.f4ed4453a3af0adb0d4f49333cbb7892ff5430483a567d0d2dfbd4655fb203d22f22f46aff3d9f38fa5fd96dde5f30227afd0ce1d9f838f5cd5295fc83856ec9.js></script><script src=https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js></script><script src=https://qdrant.tech/js/copy-code.min.95b03a45b2ab4b7a608ecfd4b5919c8572a5b2cd1463f52561cd10976abf3b74334f91324c0e620cb80afac46026a0b18cce6fb753d8495f74c6d478c8ca1d03.js></script><script src=https://qdrant.tech/js/lang-switcher.min.63da11cef09772078425b1ee56415b9c37842a9399f2ba2d2f5efbf72fb751686c410bd50e9bcd283c8231cb97c1973199d4923beef29d8b06e59d9983a6ba51.js></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src=https://qdrant.tech/js/vendor/anchor.min.0e138e17ebcf1c1147a7a3a81d9ac3c601622eedc479f1636470eb2552470f4e27c9a8efe6e8378995dedc1ab67029d8989536ea76f0857d45d1615ae772b8a1.js></script><script>document.addEventListener("keydown",function(e){if((e.metaKey||e.ctrlKey)&&e.key==="k"){e.preventDefault();let t=document.querySelector('[data-target="#searchModal"]');t&&t?.click()}})</script><script>window.addEventListener("message",e=>{if(e.data.type==="hsFormCallback"&&e.data.eventName==="onFormReady"){const t=document.querySelector(`form[data-form-id="${e.data.id}"]`);if(t){const e=t.querySelector('[name="last_form_fill_url"]');e&&(e.value=window.location.href);const n=t.querySelector('[name="referrer_url"]');n&&(n.value=document.referrer)}}})</script></html>