<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>Building a serverless RAG application with LlamaIndex and Azure OpenAI — LlamaIndex - Build Knowledge Assistants over your Enterprise Data</title><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><meta name="title" content="Building a serverless RAG application with LlamaIndex and Azure OpenAI — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta name="description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:title" content="Building a serverless RAG application with LlamaIndex and Azure OpenAI — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="og:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:image" content="https://cdn.sanity.io/images/7m9jw85w/production/ecd41ae473c595aa2602aa86e7031c2dc79103b2-2978x1800.png"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="Building a serverless RAG application with LlamaIndex and Azure OpenAI — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="twitter:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="twitter:image" content="https://cdn.sanity.io/images/7m9jw85w/production/ecd41ae473c595aa2602aa86e7031c2dc79103b2-2978x1800.png"/><link rel="alternate" type="application/rss+xml" href="https://www.llamaindex.ai/blog/feed"/><meta name="next-head-count" content="20"/><script>
            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WWRFB36R');
            </script><link rel="preload" href="/_next/static/css/41c9222e47d080c9.css" as="style"/><link rel="stylesheet" href="/_next/static/css/41c9222e47d080c9.css" data-n-g=""/><link rel="preload" href="/_next/static/css/97c33c8d95f1230e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/97c33c8d95f1230e.css" data-n-p=""/><link rel="preload" href="/_next/static/css/e009059e80bf60c5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e009059e80bf60c5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-1b629d9c8fb16f34.js" defer=""></script><script src="/_next/static/chunks/framework-df1f68dff096b68a.js" defer=""></script><script src="/_next/static/chunks/main-eca7952a704663f8.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c7c49437be49d2ad.js" defer=""></script><script src="/_next/static/chunks/d9067523-4985945b21298365.js" defer=""></script><script src="/_next/static/chunks/41155975-60c12da9ce9fa0b2.js" defer=""></script><script src="/_next/static/chunks/cb355538-cee2ea45674d9de3.js" defer=""></script><script src="/_next/static/chunks/9494-dff62cb53535dd7d.js" defer=""></script><script src="/_next/static/chunks/4063-39a391a51171ff87.js" defer=""></script><script src="/_next/static/chunks/6889-edfa85b69b88a372.js" defer=""></script><script src="/_next/static/chunks/5575-11ee0a29eaffae61.js" defer=""></script><script src="/_next/static/chunks/3444-95c636af25a42734.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-82c8e764e69afd2c.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_buildManifest.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_ssgManifest.js" defer=""></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WWRFB36R" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div class="__variable_d65c78 __variable_b1ea77 __variable_eb7534"><a class="Announcement_announcement__2ohK8" href="http://48755185.hs-sites.com/llamaindex-0">Meet LlamaIndex at the Databricks Data + AI Summit!<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M8.293 5.293a1 1 0 0 1 1.414 0l6 6a1 1 0 0 1 0 1.414l-6 6a1 1 0 0 1-1.414-1.414L13.586 12 8.293 6.707a1 1 0 0 1 0-1.414Z" clip-rule="evenodd"></path></svg></a><header class="Header_header__hO3lJ"><button class="Hamburger_hamburger__17auO Header_hamburger__lUulX"><svg width="28" height="28" viewBox="0 0 28 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.5 14H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" id="hamburger-stroke-top" class="Hamburger_hamburgerStrokeMiddle__I7VpD"></path><path d="M3.5 7H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeTop__oOhFM"></path><path d="M3.5 21H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeBottom__GIQR2"></path></svg></button><a aria-label="Homepage" href="/"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" class="Header_logo__e5KhT" style="color:transparent" src="/llamaindex.svg"/></a><nav aria-label="Main" data-orientation="horizontal" dir="ltr" style="--content-position:0px"><div style="position:relative"><ul data-orientation="horizontal" class="Nav_MenuList__PrCDJ" dir="ltr"><li><button id="radix-:R6tm:-trigger-radix-:R5mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R5mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Products</button></li><li><button id="radix-:R6tm:-trigger-radix-:R9mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R9mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Solutions</button></li><li><a class="Nav_Link__ZrzFc" href="/community" data-radix-collection-item="">Community</a></li><li><a class="Nav_Link__ZrzFc" href="/pricing" data-radix-collection-item="">Pricing</a></li><li><a class="Nav_Link__ZrzFc" href="/blog" data-radix-collection-item="">Blog</a></li><li><a class="Nav_Link__ZrzFc" href="/customers" data-radix-collection-item="">Customer stories</a></li><li><a class="Nav_Link__ZrzFc" href="/careers" data-radix-collection-item="">Careers</a></li></ul></div><div class="Nav_ViewportPosition__jmyHM"></div></nav><div class="Header_secondNav__YJvm8"><nav><a href="/contact" class="Link_link__71cl8 Link_link-variant-tertiary__BYxn_ Header_bookADemo__qCuxV">Book a demo</a></nav><a href="https://cloud.llamaindex.ai/" class="Button_button-variant-default__Oi__n Button_button__aJ0V6 Header_button__1HFhY" data-tracking-variant="default"> <!-- -->Get started</a></div><div class="MobileMenu_mobileMenu__g5Fa6"><nav class="MobileMenu_nav__EmtTw"><ul><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Products<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaparse"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.6654 1.66675V6.66675H16.6654M8.33203 10.8334L6.66536 12.5001L8.33203 14.1667M11.6654 14.1667L13.332 12.5001L11.6654 10.8334M12.082 1.66675H4.9987C4.55667 1.66675 4.13275 1.84234 3.82019 2.1549C3.50763 2.46746 3.33203 2.89139 3.33203 3.33341V16.6667C3.33203 17.1088 3.50763 17.5327 3.82019 17.8453C4.13275 18.1578 4.55667 18.3334 4.9987 18.3334H14.9987C15.4407 18.3334 15.8646 18.1578 16.1772 17.8453C16.4898 17.5327 16.6654 17.1088 16.6654 16.6667V6.25008L12.082 1.66675Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Document parsing</div><p class="MobileMenu_ListItemText__n_MHY">The first and leading GenAI-native parser over your most complex data.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaextract"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.668 1.66675V5.00008C11.668 5.44211 11.8436 5.86603 12.1561 6.17859C12.4687 6.49115 12.8926 6.66675 13.3346 6.66675H16.668M3.33464 5.83341V3.33341C3.33464 2.89139 3.51023 2.46746 3.82279 2.1549C4.13535 1.84234 4.55927 1.66675 5.0013 1.66675H12.5013L16.668 5.83341V16.6667C16.668 17.1088 16.4924 17.5327 16.1798 17.8453C15.8672 18.1578 15.4433 18.3334 15.0013 18.3334L5.05379 18.3326C4.72458 18.3755 4.39006 18.3191 4.09312 18.1706C3.79618 18.0221 3.55034 17.7884 3.38713 17.4992M4.16797 9.16675L1.66797 11.6667M1.66797 11.6667L4.16797 14.1667M1.66797 11.6667H10.0013" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Data extraction</div><p class="MobileMenu_ListItemText__n_MHY">Extract structured data from documents using a schema-driven engine.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/enterprise"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.16667 15.8333C12.8486 15.8333 15.8333 12.8486 15.8333 9.16667C15.8333 5.48477 12.8486 2.5 9.16667 2.5C5.48477 2.5 2.5 5.48477 2.5 9.16667C2.5 12.8486 5.48477 15.8333 9.16667 15.8333Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M17.5 17.5L13.875 13.875" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Knowledge Management</div><p class="MobileMenu_ListItemText__n_MHY">Connect, transform, and index your enterprise data into an agent-accessible knowledge base</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/framework"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.0013 6.66659V3.33325H6.66797M1.66797 11.6666H3.33464M16.668 11.6666H18.3346M12.5013 10.8333V12.4999M7.5013 10.8333V12.4999M5.0013 6.66659H15.0013C15.9218 6.66659 16.668 7.41278 16.668 8.33325V14.9999C16.668 15.9204 15.9218 16.6666 15.0013 16.6666H5.0013C4.08083 16.6666 3.33464 15.9204 3.33464 14.9999V8.33325C3.33464 7.41278 4.08083 6.66659 5.0013 6.66659Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Agent Framework</div><p class="MobileMenu_ListItemText__n_MHY">Orchestrate and deploy multi-agent applications over your data with the #1 agent framework.</p></a></li></ul></details></li><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Solutions<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/finance"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 6.66675H8.33073C7.8887 6.66675 7.46478 6.84234 7.15222 7.1549C6.83966 7.46746 6.66406 7.89139 6.66406 8.33342C6.66406 8.77544 6.83966 9.19937 7.15222 9.51193C7.46478 9.82449 7.8887 10.0001 8.33073 10.0001H11.6641C12.1061 10.0001 12.53 10.1757 12.8426 10.4882C13.1551 10.8008 13.3307 11.2247 13.3307 11.6667C13.3307 12.1088 13.1551 12.5327 12.8426 12.8453C12.53 13.1578 12.1061 13.3334 11.6641 13.3334H6.66406M9.9974 15.0001V5.00008M18.3307 10.0001C18.3307 14.6025 14.5998 18.3334 9.9974 18.3334C5.39502 18.3334 1.66406 14.6025 1.66406 10.0001C1.66406 5.39771 5.39502 1.66675 9.9974 1.66675C14.5998 1.66675 18.3307 5.39771 18.3307 10.0001Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Financial Analysts</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/administrative-operations"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1.66406 6.66659V15.8333C1.66406 16.2753 1.83966 16.6992 2.15222 17.0118C2.46478 17.3243 2.8887 17.4999 3.33073 17.4999H14.9974M16.6641 14.1666C17.1061 14.1666 17.53 13.991 17.8426 13.6784C18.1551 13.3659 18.3307 12.9419 18.3307 12.4999V7.49992C18.3307 7.05789 18.1551 6.63397 17.8426 6.32141C17.53 6.00885 17.1061 5.83325 16.6641 5.83325H13.4141C13.1353 5.83598 12.8604 5.76876 12.6143 5.63774C12.3683 5.50671 12.159 5.31606 12.0057 5.08325L11.3307 4.08325C11.179 3.85281 10.9724 3.66365 10.7295 3.53275C10.4866 3.40185 10.215 3.3333 9.93906 3.33325H6.66406C6.22204 3.33325 5.79811 3.50885 5.48555 3.82141C5.17299 4.13397 4.9974 4.55789 4.9974 4.99992V12.4999C4.9974 12.9419 5.17299 13.3659 5.48555 13.6784C5.79811 13.991 6.22204 14.1666 6.66406 14.1666H16.6641Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Administrative Operations</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/engineering"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 15L18.3307 10L13.3307 5M6.66406 5L1.66406 10L6.66406 15" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Engineering &amp; R&amp;D</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/customer-support"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.9974 7.50008H16.6641C17.1061 7.50008 17.53 7.67568 17.8426 7.98824C18.1551 8.3008 18.3307 8.72472 18.3307 9.16675V18.3334L14.9974 15.0001H9.9974C9.55537 15.0001 9.13145 14.8245 8.81888 14.5119C8.50632 14.1994 8.33073 13.7754 8.33073 13.3334V12.5001M11.6641 7.50008C11.6641 7.94211 11.4885 8.36603 11.1759 8.67859C10.8633 8.99115 10.4394 9.16675 9.9974 9.16675H4.9974L1.66406 12.5001V3.33341C1.66406 2.41675 2.41406 1.66675 3.33073 1.66675H9.9974C10.4394 1.66675 10.8633 1.84234 11.1759 2.1549C11.4885 2.46746 11.6641 2.89139 11.6641 3.33341V7.50008Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Customer Support</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/healthcare-pharma"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M17.0128 3.81671C16.5948 3.39719 16.098 3.06433 15.551 2.8372C15.004 2.61008 14.4176 2.49316 13.8253 2.49316C13.2331 2.49316 12.6466 2.61008 12.0996 2.8372C11.5527 3.06433 11.0559 3.39719 10.6378 3.81671L9.99617 4.46671L9.3545 3.81671C8.93643 3.39719 8.43967 3.06433 7.89268 2.8372C7.3457 2.61008 6.75926 2.49316 6.167 2.49316C5.57474 2.49316 4.9883 2.61008 4.44132 2.8372C3.89433 3.06433 3.39756 3.39719 2.9795 3.81671C1.21283 5.58338 1.1045 8.56671 3.3295 10.8334L9.99617 17.5L16.6628 10.8334C18.8878 8.56671 18.7795 5.58338 17.0128 3.81671Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M2.91406 9.99992H7.91406L8.33073 9.16659L9.9974 12.9166L11.6641 7.08325L12.9141 9.99992H17.0807" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Healthcare / Pharma</div></a></li></ul></details></li><li><a class="MobileMenu_Link__5frcx" href="/community">Community</a></li><li><a class="MobileMenu_Link__5frcx" href="/pricing">Pricing</a></li><li><a class="MobileMenu_Link__5frcx" href="/blog">Blog</a></li><li><a class="MobileMenu_Link__5frcx" href="/customers">Customer stories</a></li><li><a class="MobileMenu_Link__5frcx" href="/careers">Careers</a></li></ul></nav><a href="/contact" class="Button_button-variant-ghost__o2AbG Button_button__aJ0V6" data-tracking-variant="ghost"> <!-- -->Talk to us</a><ul class="Socials_socials__8Y_s5 Socials_socials-theme-dark__Hq8lc MobileMenu_socials__JykCO"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu MobileMenu_copyright__nKVOs">© <!-- -->2025<!-- --> LlamaIndex</p></div></header><main><section class="BlogPost_post__JHNzd"><img alt="" loading="lazy" width="800" height="900" decoding="async" data-nimg="1" class="BlogPost_featuredImage__KGxwX" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fecd41ae473c595aa2602aa86e7031c2dc79103b2-2978x1800.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fecd41ae473c595aa2602aa86e7031c2dc79103b2-2978x1800.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fecd41ae473c595aa2602aa86e7031c2dc79103b2-2978x1800.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><p class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-600__fKYth BlogPost_date__6uxQw"><a class="BlogPost_author__mesdl" href="/blog/author/wassim-chegham">Wassim Chegham</a> <!-- -->•<!-- --> <!-- -->2024-08-27</p><h1 class="Text_text__zPO0D Text_text-size-32__koGps BlogPost_title__b2lqJ">Building a serverless RAG application with LlamaIndex and Azure OpenAI</h1><ul class="BlogPost_tags__13pBH"><li><a class="Badge_badge___1ssn" href="/blog/tag/rag"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">RAG</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/serverless"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Serverless</span></a></li></ul><div class="BlogPost_htmlPost__Z5oDL"><p class="Text_text__zPO0D Text_text-size-16__PkjFu">A guide to get started creating RAG applications with LlamaIndex using Azure OpenAI and deployed on Microsoft Azure.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">If you are reading this, chances are you have used generative AI like ChatGPT or Azure OpenAI. You have utilized it to enhance your daily work processes or integrated AI into your application to provide a better customer experience.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Ideally you want your intelligent apps to use your own business data when providing responses to your customers. To address this need, you require your application to implement an architecture known as <a href="https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">R</a>etrieval-Augmented Generation (RAG). LlamaIndex is a great framework that helps you achieve this goal, which is the focus of this article.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">In this article you will learn about:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">The RAG architecture and how LlamaIndex can help you implement RAG multi-agent applications.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">The architecture of a sample LlamaIndex application.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">The deployment of a LlamaIndex application to Microsoft Azure using the Azure Developer CLI, azd.</li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">What is RAG - Retrieval-Augmented Generation?</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Retrieval-Augmented Generation (RAG) is a framework that improves AI text generation by combining two key components:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Retriever: This part searches a large collection of documents to find relevant information related to a given query.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Generator: This model uses the retrieved information to generate a more accurate and contextually rich response.</li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu">By combining these two components, RAG allows AI models to pull in external knowledge, resulting in higher quality and more relevant responses.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">How does LlamaIndex implement RAG?</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">To implement a RAG system using LlamaIndex, you can follow these general steps, which include setting up the data ingestion, and the generation components:</p><ol><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Data Ingestion:<ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Load your documents into LlamaIndex using a document loader such as SimpleDirectoryReader. This reader, for example, helps in importing data from various sources such as PDFs, APIs, or SQL databases.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Break down large documents into smaller, manageable chunks using the SentenceSplitter.</li></ul></li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Index Creation:<ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Create a <a href="https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-create-index?tabs=config-2023-11-01%2Crest-2023-11-01%2Cpush%2Cportal-check-index" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">vector index</a> of these document chunks using <a href="https://docs.llamaindex.ai/en/latest/module_guides/indexing/vector_store_index/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">VectorStoreIndex</a>. This allows for efficient similarity searches based on embeddings.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Optionally, for complex datasets, you can use recursive retrieval techniques to manage hierarchically structured data and retrieve relevant sections based on user queries.</li></ul></li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Query Engine Setup:<ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Convert the vector index into a query engine using asQueryEngine with parameters such as similarityTopKto define how many top documents should be retrieved.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">For more advanced setups, use <a href="https://docs.llamaindex.ai/en/stable/use_cases/agents/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">agents</a>. Create a multi-agent system where each agent is responsible for specific documents, and a top-level agent coordinates the overall retrieval process.</li></ul></li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Retrieval and Generation:<ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Implement the RAG pipeline by defining an objective function that takes user queries and retrieves relevant document chunks. This function can also evaluate the retrieval chunks to ensure they match the user&#x27;s query.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Use the RetrieverQueryEngineto perform the actual retrieval and query processing. This can include additional post-processing steps like re-ranking the retrieved documents using tools such as CohereRerank.</li></ul></li></ol><p class="Text_text__zPO0D Text_text-size-16__PkjFu">For a practical example, we have provided you with a sample application to demonstrate a complete RAG implementation using Azure OpenAI as the AI provider.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Practical RAG sample application</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">For the remainer of this article, we&#x27;ll focus on the use case of building a RAG type application on Azure using LlamaIndex and Azure OpenAI. You will use one of the provided starter templates: TypeScript or Python.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Requirements to run the samples</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">First let&#x27;s explain what you&#x27;ll need:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><a href="https://learn.microsoft.com/en-us/azure/developer/azure-developer-cli/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Azure Developer CLI, azd</a>: this is a CLI, a command line tool that can easily deploy your entire app, backend, frontend, databases etc. You can use azd with <a href="https://learn.microsoft.com/azure/developer/azure-developer-cli/azd-templates" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">extensible blueprint templates</a> that includes everything you need to get an application up and running on Azure.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure account: you will need an Azure account to deploy things. get an <a href="https://azure.microsoft.com/free/cognitive-search/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Azure account for free</a> and you&#x27;ll get some free Azure credits to get started</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Samples: we&#x27;ve created two samples that will deploy a RAG type application on Azure. The azd starter templates are designed to help you create a serverless RAG application with LlamaIndex and Azure OpenAI in a few simple steps. We are going to highlight two sample applications that were created based on the great <a href="https://www.llamaindex.ai/blog/create-llama-a-command-line-tool-to-generate-llamaindex-apps-8f7683021191" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">create-llama tool</a>:</li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu">1. For TypeScript: <a href="https://github.com/Azure-Samples/llama-index-javascript" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">https://github.com/Azure-Samples/llama-index-javascript</a> </p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2. For Python: <a href="https://github.com/Azure-Samples/llama-index-python" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">https://github.com/Azure-Samples/llama-index-python</a> </p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">High level architecture</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Both sample applications are built based on the same architecture:</p><figure><img alt="" loading="lazy" width="1489" height="900" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fecd41ae473c595aa2602aa86e7031c2dc79103b2-2978x1800.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fecd41ae473c595aa2602aa86e7031c2dc79103b2-2978x1800.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=3840&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fecd41ae473c595aa2602aa86e7031c2dc79103b2-2978x1800.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=3840&amp;q=75"/></figure><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The architecture of the application relies on the following services and components:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure OpenAIrepresents the AI provider that we send the user&#x27;s queries to.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaIndexis the framework that helps us ingest, transform and vectorize our content (PDF file) and create a search index from our data.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure Container Apps is the container environment where the application is hosted.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure Managed Identity helps us ensure best in class security and eliminates the requirements for you as a developer to deal with credentials and API keys.</li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu">To learn more about what Cloud resources get deployed on Azure, check out the <a href="https://github.com/Azure-Samples/llama-index-javascript/blob/main/infra/main.bicep" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">infra folder</a> available in all our samples.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Example user workflows</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The sample application contains logic code for the following two workflows:</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">1. Data ingestion, where data is fetched and vectorized and search indexes are created. Vector indexes are stored in the <a href="https://github.com/Azure-Samples/llama-index-javascript/tree/main/cache" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">cache sub folder</a>. The data itself lives in a <a href="https://github.com/Azure-Samples/llama-index-javascript/tree/main/data" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">data folder</a>. Should you want to add more files like additional PDFs or Word files, this is where you should add them. There are existing Vector indexes but if you need to generate new ones (if you change the content of the data folder), you can run the following command:</p><pre><code>npm run generate</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">This command will invoke the following code in TypeScript:</p><pre><code><span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span> <span class="hljs-title function_">generateDatasource</span>(<span class="hljs-params"></span>) { 
  <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(<span class="hljs-string">`Generating storage context...`</span>); 
  <span class="hljs-comment">// Split documents, create embeddings and store them in the storage context </span>
  <span class="hljs-keyword">const</span> ms = <span class="hljs-keyword">await</span> <span class="hljs-title function_">getRuntime</span>(<span class="hljs-keyword">async</span> () =&gt; { 
    <span class="hljs-keyword">const</span> storageContext = <span class="hljs-keyword">await</span> <span class="hljs-title function_">storageContextFromDefaults</span>({ 
      <span class="hljs-attr">persistDir</span>: <span class="hljs-variable constant_">STORAGE_CACHE_DIR</span>, 
    }); 
    <span class="hljs-keyword">const</span> documents = <span class="hljs-keyword">await</span> <span class="hljs-title function_">getDocuments</span>(); 
    <span class="hljs-keyword">await</span> <span class="hljs-title class_">VectorStoreIndex</span>.<span class="hljs-title function_">fromDocuments</span>(documents, { 
      storageContext, 
    }); 
  }); </code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">or in Python:</p><pre><code><span class="hljs-built_in">cd</span> backend 
poetry run generate </code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">which will invoke this code:</p><pre><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_datasource</span>(): 
    init_settings() 
    logger.info(<span class="hljs-string">&quot;Creating new index&quot;</span>) 
    storage_dir = os.environ.get(<span class="hljs-string">&quot;STORAGE_DIR&quot;</span>, <span class="hljs-string">&quot;storage&quot;</span>) 
    <span class="hljs-comment"># load the documents and create the index </span>
    documents = get_documents() 
    index = VectorStoreIndex.from_documents( 
        documents, 
    ) 
    <span class="hljs-comment"># store it for later </span>
    index.storage_context.persist(storage_dir) 
    logger.info(<span class="hljs-string">f&quot;Finished creating new index. Stored in <span class="hljs-subst">{storage_dir}</span>&quot;</span>) </code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2. Serving prompt requests. In this part of the application, we receive user input i.e.prompts, which are sent to Azure OpenAI. To augment these prompts a chat engine is created consisting of a connection to the LLM and the vector index <a href="https://github.com/Azure-Samples/llama-index-javascript/blob/8156d98ac5e1376954a7e03252bae718e4abc638/app/api/chat/engine/chat.ts#L16" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">loaded as a retriever</a>. Configuring access to Azure OpenAI is made easy with a few lines:</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">In TypeScript:</p><pre><code><span class="hljs-keyword">const</span> credential = <span class="hljs-keyword">new</span> <span class="hljs-title class_">DefaultAzureCredential</span>(); 
  <span class="hljs-keyword">const</span> azureADTokenProvider = <span class="hljs-title function_">getBearerTokenProvider</span>( 
    credential, 
    <span class="hljs-string">&quot;https://cognitiveservices.azure.com/.default&quot;</span>, 
  ); 
  
  <span class="hljs-keyword">const</span> azure = { 
    azureADTokenProvider, 
    <span class="hljs-attr">deployment</span>: <span class="hljs-string">&quot;gpt-35-turbo&quot;</span>, 
  }; 

  <span class="hljs-title class_">Settings</span>.<span class="hljs-property">llm</span> = <span class="hljs-keyword">new</span> <span class="hljs-title class_">OpenAI</span>({ azure }); </code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Or in Python:</p><pre><code>credential = DefaultAzureCredential() 
token_provider = get_bearer_token_provider( 
  credential,  
  <span class="hljs-string">&quot;https://cognitiveservices.azure.com/.default&quot;</span>
) 
llm_config = { 
  <span class="hljs-string">&quot;engine&quot;</span>: llm_deployment, 
  <span class="hljs-string">&quot;azure_endpoint&quot;</span>: azure_openai_endpoint, 
  <span class="hljs-string">&quot;azure_ad_token_provider&quot;</span>: token_provider, 
  <span class="hljs-string">&quot;use_azure_ad&quot;</span>: <span class="hljs-literal">True</span>, 
  <span class="hljs-string">&quot;temperature&quot;</span>:<span class="hljs-built_in">float</span>(os.getenv(<span class="hljs-string">&quot;LLM_TEMPERATURE&quot;</span>, DEFAULT_TEMPERATURE)), 
  <span class="hljs-string">&quot;max_tokens&quot;</span>: <span class="hljs-built_in">int</span>(max_tokens) <span class="hljs-keyword">if</span> max_tokens <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>, 
} 

Settings.llm = AzureOpenAI(**llm_config) </code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">In this sample, we use the @azure/identity Node.js or PyPI package and import the DefaultAzureCredential chained credential strategy that seamlessly checks and uses a valid token from an existing Azure session, based on what is available in the current environment without changing your code.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">When your application is hosted in Azure, managed identity is also used for seamless authentication in your production environments.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Important packages used for the JavaScript sample</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Here&#x27;s some packages used in the solution worth mentioning. For a detailed list of all packages used, <a href="https://github.com/Azure-Samples/llama-index-javascript/blob/939dcb192482b94ba9977f4c12de7f501fa669c3/package.json" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">check out the package.json file</a>.</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">The <a href="https://github.com/run-llama/LlamaIndexTS/tree/main/packages/llamaindex" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">llamaindex core library</a> providing core functionality on connecting to LLMs, facilitates vector index creation and more.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><a href="https://docs.llamaindex.ai/en/stable/api_reference/readers/smart_pdf_loader/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">@llamaindex/pdf-viewer</a> is used to retrieve structured information from a PDF like tables, lists, paragraphs more and is part of the chunking process, where the data is divided into smaller strips, e.g.chunks, and each chunk is turned into vectorized form so it can be used later for semantic comparison.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">As discussed earlier, <a href="https://github.com/Azure/azure-sdk-for-js/blob/main/sdk/identity/identity/samples/AzureIdentityExamples.md" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">@azure/identity</a> is used to connect to Azure using Azure Managed Identity, (managed identity means Azure handles the identity for you via <a href="https://www.microsoft.com/security/business/identity-access/microsoft-entra-id" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Microsoft EntraID</a> instead of using API keys which are considered less secure).</li></ul><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Important packages used for the Python sample</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The Python sample uses <a href="https://python-poetry.org/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Poetry</a> for dependency management and installation. For a detailed list of all packages used, checkout the <a href="https://github.com/Azure-Samples/llama-index-python/blob/main/backend/pyproject.toml" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">pyproject.toml file</a>.</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">The <a href="https://github.com/run-llama/llama_index" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">llamaindex core Python library</a> providing core functionality on connecting to LLMs, facilitates vector index creation and more.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><a href="https://www.bing.com/search?q=fastapi&amp;cvid=6e1fad60b08040f9b9661945410756c2&amp;gs_lcrp=EgZjaHJvbWUqBggAEEUYOzIGCAAQRRg7MgYIARBFGDsyBwgCEOkHGEAyBggDEAAYQDIGCAQQABhAMgYIBRAAGEAyBggGEEUYPDIGCAcQRRg9MgYICBBFGDwyCAgJEOkHGPxV0gEIMjE3NWowajmoAgCwAgE&amp;FORM=ANAB01&amp;PC=U531" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">FastAPI</a>, a Python web framework is used to create the API that takes in the user input and returns a response.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">The Python <a href="https://pypi.org/project/azure-identity/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">azure-identity</a> package is used to connect to Azure using Azure Managed Identity, (managed identity means Azure handles the identity for you via <a href="https://www.microsoft.com/security/business/identity-access/microsoft-entra-id" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Microsoft EntraID</a> instead of using API keys which are considered less secure).</li></ul><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Running the samples</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Before running any of the samples, and using Azure OpenAI, it is worth mentioning that you need to provision the necessary Azure resources.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">You can run these templates by using GitHub Codespaces. Follow these links and then click &quot;Create codespace&quot; as shown to launch a VS Code instance in your browser (this may take a few minutes while the containers are built):</p><figure><img alt="" loading="lazy" width="494" height="451" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F3462c2cd2602095cbbbb6d5432b033e55ef87b5f-988x902.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F3462c2cd2602095cbbbb6d5432b033e55ef87b5f-988x902.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1080&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F3462c2cd2602095cbbbb6d5432b033e55ef87b5f-988x902.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1080&amp;q=75"/></figure><p class="Text_text__zPO0D Text_text-size-16__PkjFu">For TypeScript: <a href="https://github.com/Azure-Samples/llama-index-javascript" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">https://github.com/Azure-Samples/llama-index-javascript</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">For Python: <a href="https://github.com/Azure-Samples/llama-index-python" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">https://github.com/Azure-Samples/llama-index-python</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">1.Open a terminal window in your Codespaces instance.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2. Type the following command to sign into your Azure account:</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><code class="SanityPortableText_inlineCode__cI85z">azd auth login</code></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">3. Run the next command to provision, package and deploy the sample application to Azure:</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><code class="SanityPortableText_inlineCode__cI85z">azd up</code></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Once the command completes, you should see output from the terminal indicating success.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Congratulations! At this point, you should be able to access your deployed application from the provided URL endpoint. To run and develop on the application locally, you need to:</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">4. <!-- -->Run the following commands to install the application dependencies and run the app:</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><code class="SanityPortableText_inlineCode__cI85z">npm install</code></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><code class="SanityPortableText_inlineCode__cI85z">npm run dev</code></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">This will open the application on the default port 3000 in your Codespaces instance, or <a href="http://localhost:3000/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">http://localhost:3000</a> in your browser locally. You should see your application rendered like so:</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">NOTE: If you would like to run these samples locally in VS Code Dev Containers or directly on your filesystem, the <a href="https://github.com/Azure-Samples/llama-index-javascript?tab=readme-ov-file#local-environment" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">README</a> files in the samples have all the details about the tools and requirements.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">What&#x27;s next?</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">This guide has demonstrated how to build a serverless RAG (Retrieval-Augmented Generation) application using LlamaIndex and Azure OpenAI, deployed on Microsoft Azure. The key argument presented is that integrating your own business data into AI applications enhances the relevance and quality of responses, a crucial need for intelligent apps serving customers.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">In this post we addressed the implementation of RAG architecture with LlamaIndex, detailing the steps from data ingestion and index creation to query engine setup and deployment on Azure. By following this guide, you can leverage Azure&#x27;s robust infrastructure and LlamaIndex&#x27;s capabilities to create powerful AI applications that provide contextually enriched responses based on your data.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">By deploying on Azure, you also benefit from scalability, security, and ease of management, reinforcing the practical application of the RAG model in real-world scenarios.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We&#x27;re excited to see what you build with these sample applications. Feel free to fork them and like the GitHub repositories to receive the latest changes and new features.</p></div><div class="BlogPost_relatedPosts__0z6SN"><h2 class="Text_text__zPO0D Text_text-align-center__HhKqo Text_text-size-16__PkjFu Text_text-weight-400__5ENkK Text_text-family-spaceGrotesk__E4zcE BlogPost_relatedPostsTitle___JIrW">Related articles</h2><ul class="BlogPost_relatedPostsList__uOKzB"><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9fdb15bafdf8c0921f36c6cd8cdac43c8ca87e27-2232x1562.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9fdb15bafdf8c0921f36c6cd8cdac43c8ca87e27-2232x1562.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9fdb15bafdf8c0921f36c6cd8cdac43c8ca87e27-2232x1562.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/rag-is-dead-long-live-agentic-retrieval">RAG is dead, long live agentic retrieval</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2025-05-29</p></div></li><li><div class="CardBlog_card__mm0Zw CardBlog_featuredCard__5FPeD"><div class="CardBlog_grid__5PeSv"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F13ef1e27c4ec6c9a72d2ce1fae36f5acac0062ba-1263x631.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F13ef1e27c4ec6c9a72d2ce1fae36f5acac0062ba-1263x631.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F13ef1e27c4ec6c9a72d2ce1fae36f5acac0062ba-1263x631.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><div class="CardBlog_thumbnailGradient__x5CbY"><p class="Text_text__zPO0D Text_text-size-36__cH7Hj Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/beyond-chatbots-adopting-agentic-document-workflows-for-enterprises">Beyond chatbots: adopting Agentic Document Workflows for enterprises</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu CardBlog_date__E1rJK">2025-04-23</p></div></div></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F5033e2512495122c811ac69425cc77a83c7fa00a-3311x1647.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F5033e2512495122c811ac69425cc77a83c7fa00a-3311x1647.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F5033e2512495122c811ac69425cc77a83c7fa00a-3311x1647.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/building-blocks-of-llm-report-generation-beyond-basic-rag">Building Blocks of LLM Report Generation: Beyond Basic RAG</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-11-05</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fbf0ee27ad4e3e17598a1e664653b59217e89dfdb-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fbf0ee27ad4e3e17598a1e664653b59217e89dfdb-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fbf0ee27ad4e3e17598a1e664653b59217e89dfdb-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/efficient-chunk-size-optimization-for-rag-pipelines-with-llamacloud">Efficient Chunk Size Optimization for RAG Pipelines with LlamaCloud</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-08-21</p></div></li></ul></div></section></main><footer class="Footer_footer__eNA9m"><div class="Footer_navContainer__7bvx4"><div class="Footer_logoContainer__3EpzI"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" style="color:transparent" src="/llamaindex.svg"/><div class="Footer_socialContainer__GdOgk"><ul class="Socials_socials__8Y_s5"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul></div></div><div class="Footer_nav__BLEuE"><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/">LlamaIndex</a></h3><ul><li><a href="/blog"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Blog</span></a></li><li><a href="/partners"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Partners</span></a></li><li><a href="/careers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Careers</span></a></li><li><a href="/contact"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Contact</span></a></li><li><a href="/brand"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Brand</span></a></li><li><a href="https://llamaindex.statuspage.io" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Status</span></a></li><li><a href="https://app.vanta.com/runllama.ai/trust/pkcgbjf8b3ihxjpqdx17nu" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Trust Center</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/enterprise">Enterprise</a></h3><ul><li><a href="https://cloud.llamaindex.ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaCloud</span></a></li><li><a href="https://cloud.llamaindex.ai/parse" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaParse</span></a></li><li><a href="/customers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Customers</span></a></li><li><a href="/llamacloud-sharepoint-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SharePoint</span></a></li><li><a href="/llamacloud-aws-s3-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">AWS S3</span></a></li><li><a href="/llamacloud-azure-blob-storage-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure Blob Storage</span></a></li><li><a href="/llamacloud-google-drive-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Google Drive</span></a></li> </ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/framework">Framework</a></h3><ul><li><a href="https://pypi.org/project/llama-index/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python package</span></a></li><li><a href="https://docs.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python docs</span></a></li><li><a href="https://www.npmjs.com/package/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript package</span></a></li><li><a href="https://ts.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript docs</span></a></li><li><a href="https://llamahub.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaHub</span></a></li><li><a href="https://github.com/run-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">GitHub</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/community">Community</a></h3><ul><li><a href="/community#newsletter"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Newsletter</span></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Discord</span></a></li><li><a href="https://www.linkedin.com/company/91154103/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LinkedIn</span></a></li><li><a href="https://twitter.com/llama_index"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Twitter/X</span></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">YouTube</span></a></li><li><a href="https://bsky.app/profile/llamaindex.bsky.social"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">BlueSky</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e">Starter projects</h3><ul><li><a href="https://www.npmjs.com/package/create-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">create-llama</span></a></li><li><a href="https://secinsights.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SEC Insights</span></a></li><li><a href="https://github.com/run-llama/llamabot"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaBot</span></a></li><li><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/rag_cli.html"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">RAG CLI</span></a></li></ul></div></div></div><div class="Footer_copyrightContainer__mBKsT"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA">© <!-- -->2025<!-- --> LlamaIndex</p><div class="Footer_legalNav__O1yJA"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/privacy-notice.pdf">Privacy Notice</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/terms-of-service.pdf">Terms of Service</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="https://bit.ly/llamaindexdpa">Data Processing Addendum</a></p></div></div></footer></div><svg xmlns="http://www.w3.org/2000/svg" class="flt_svg" style="display:none"><defs><filter id="flt_tag"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="2"></feGaussianBlur><feColorMatrix in="blur" result="flt_tag" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="flt_tag" operator="atop"></feComposite></filter><filter id="svg_blur_large"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="8"></feGaussianBlur><feColorMatrix in="blur" result="svg_blur_large" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="svg_blur_large" operator="atop"></feComposite></filter></defs></svg></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"page":{"announcement":{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"},"post":{"_createdAt":"2024-08-27T19:57:18Z","_id":"0a7c9562-807f-4357-baa0-8631bc039d80","_rev":"TLgH6AcXrxoqw75SBDhf7p","_type":"blogPost","_updatedAt":"2025-05-21T20:36:26Z","announcement":[{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"}],"authors":[{"_createdAt":"2024-08-27T19:40:01Z","_id":"672a2293-553c-4b1f-bbf0-9b4791695c81","_rev":"z5QCsnUcWA7e16WbDMWu8Z","_type":"people","_updatedAt":"2024-08-27T19:40:12Z","name":"Wassim Chegham","slug":{"_type":"slug","current":"wassim-chegham"}}],"featured":false,"image":{"_type":"image","asset":{"_ref":"image-ecd41ae473c595aa2602aa86e7031c2dc79103b2-2978x1800-png","_type":"reference"}},"mainImage":"https://cdn.sanity.io/images/7m9jw85w/production/ecd41ae473c595aa2602aa86e7031c2dc79103b2-2978x1800.png","publishedDate":"2024-08-27","relatedPosts":[{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-9fdb15bafdf8c0921f36c6cd8cdac43c8ca87e27-2232x1562-png","_type":"reference"}},"publishedDate":"2025-05-29","slug":"rag-is-dead-long-live-agentic-retrieval","title":"RAG is dead, long live agentic retrieval"},{"featured":true,"image":{"_type":"image","asset":{"_ref":"image-13ef1e27c4ec6c9a72d2ce1fae36f5acac0062ba-1263x631-png","_type":"reference"}},"publishedDate":"2025-04-23","slug":"beyond-chatbots-adopting-agentic-document-workflows-for-enterprises","title":"Beyond chatbots: adopting Agentic Document Workflows for enterprises"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-5033e2512495122c811ac69425cc77a83c7fa00a-3311x1647-png","_type":"reference"}},"publishedDate":"2024-11-05","slug":"building-blocks-of-llm-report-generation-beyond-basic-rag","title":"Building Blocks of LLM Report Generation: Beyond Basic RAG"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-bf0ee27ad4e3e17598a1e664653b59217e89dfdb-1024x1024-webp","_type":"reference"}},"publishedDate":"2024-08-21","slug":"efficient-chunk-size-optimization-for-rag-pipelines-with-llamacloud","title":"Efficient Chunk Size Optimization for RAG Pipelines with LlamaCloud"}],"slug":{"_type":"slug","current":"building-a-serverless-rag-application-with-llamaindex-and-azure-openai"},"tags":[{"_createdAt":"2024-02-22T20:19:11Z","_id":"893258fa-46ae-4ae2-b1a3-acb12849ab60","_rev":"RDEDF5eNko8cW03GEH0cXj","_type":"blogTag","_updatedAt":"2024-08-21T19:17:20Z","slug":{"_type":"slug","current":"rag"},"title":"RAG"},{"_createdAt":"2024-08-27T19:40:32Z","_id":"51e3cc2e-c35d-4245-8fa2-45ad984cee04","_rev":"rvkEcJvPV7yMfzvL6ZG3jj","_type":"blogTag","_updatedAt":"2024-08-27T19:40:40Z","slug":{"_type":"slug","current":"serverless"},"title":"Serverless"}],"text":[{"_key":"32c09c401401","_type":"block","children":[{"_key":"1fce78c3bc870","_type":"span","marks":[],"text":"A guide to get started creating RAG applications with LlamaIndex using Azure OpenAI and deployed on Microsoft Azure."}],"markDefs":[],"style":"normal"},{"_key":"ffeb71cb30ab","_type":"block","children":[{"_key":"f9282e5f65ad0","_type":"span","marks":[],"text":"If you are reading this, chances are you have used generative AI like ChatGPT or Azure OpenAI. You have utilized it to enhance your daily work processes or integrated AI into your application to provide a better customer experience."}],"markDefs":[],"style":"normal"},{"_key":"19dab8a592c3","_type":"block","children":[{"_key":"59d68599f0750","_type":"span","marks":[],"text":"Ideally you want your intelligent apps to use your own business data when providing responses to your customers. To address this need, you require your application to implement an architecture known as "},{"_key":"59d68599f0751","_type":"span","marks":["8e151df244a2"],"text":"R"},{"_key":"59d68599f0752","_type":"span","marks":[],"text":"etrieval-Augmented Generation (RAG). LlamaIndex is a great framework that helps you achieve this goal, which is the focus of this article."}],"markDefs":[{"_key":"8e151df244a2","_type":"link","href":"https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview"}],"style":"normal"},{"_key":"96908c7797f4","_type":"block","children":[{"_key":"5662538da21f0","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"918a98df5a7d","_type":"block","children":[{"_key":"6515fd3500950","_type":"span","marks":[],"text":"In this article you will learn about:"}],"markDefs":[],"style":"normal"},{"_key":"afab4617105c","_type":"block","children":[{"_key":"cc1dc3897b340","_type":"span","marks":[],"text":"The RAG architecture and how LlamaIndex can help you implement RAG multi-agent applications."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"35f96ecb8617","_type":"block","children":[{"_key":"a46c5458d0cd0","_type":"span","marks":[],"text":"The architecture of a sample LlamaIndex application."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"5306dabacdef","_type":"block","children":[{"_key":"15a9cb91adf10","_type":"span","marks":[],"text":"The deployment of a LlamaIndex application to Microsoft Azure using the Azure Developer CLI, azd."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"8e15dfa19838","_type":"block","children":[{"_key":"10d8ec12ba2a0","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"82f51c56d42f","_type":"block","children":[{"_key":"5de4aac93e560","_type":"span","marks":[],"text":"What is RAG - Retrieval-Augmented Generation?"}],"markDefs":[],"style":"h2"},{"_key":"e9e2bebe33ab","_type":"block","children":[{"_key":"9d510c0057f20","_type":"span","marks":[],"text":"Retrieval-Augmented Generation (RAG) is a framework that improves AI text generation by combining two key components:"}],"markDefs":[],"style":"normal"},{"_key":"6ee488d9bbfe","_type":"block","children":[{"_key":"161b8c5002110","_type":"span","marks":[],"text":"Retriever: This part searches a large collection of documents to find relevant information related to a given query."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"86259ed0912b","_type":"block","children":[{"_key":"2b056b54be050","_type":"span","marks":[],"text":"Generator: This model uses the retrieved information to generate a more accurate and contextually rich response."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"bf5a39e92ff2","_type":"block","children":[{"_key":"1e7ff55453a20","_type":"span","marks":[],"text":"By combining these two components, RAG allows AI models to pull in external knowledge, resulting in higher quality and more relevant responses."}],"markDefs":[],"style":"normal"},{"_key":"e9cbae4442cc","_type":"block","children":[{"_key":"1e0bc3c65f790","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"86fa21723991","_type":"block","children":[{"_key":"dfeb62860c6b0","_type":"span","marks":[],"text":"How does LlamaIndex implement RAG?"}],"markDefs":[],"style":"h2"},{"_key":"4be369435a96","_type":"block","children":[{"_key":"36f165a3ff5c0","_type":"span","marks":[],"text":"To implement a RAG system using LlamaIndex, you can follow these general steps, which include setting up the data ingestion, and the generation components:"}],"markDefs":[],"style":"normal"},{"_key":"9869d472d274","_type":"block","children":[{"_key":"0616a5efcfb40","_type":"span","marks":[],"text":"Data Ingestion:"}],"level":1,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"ffa9744ccc3c","_type":"block","children":[{"_key":"01280e03ac0e0","_type":"span","marks":[],"text":"Load your documents into LlamaIndex using a document loader such as SimpleDirectoryReader. This reader, for example, helps in importing data from various sources such as PDFs, APIs, or SQL databases."}],"level":2,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"09e8f091132a","_type":"block","children":[{"_key":"2d2e830235da","_type":"span","marks":[],"text":"Break down large documents into smaller, manageable chunks using the SentenceSplitter."}],"level":2,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"1a5589a42966","_type":"block","children":[{"_key":"a9c8e13a144b0","_type":"span","marks":[],"text":"Index Creation:"}],"level":1,"listItem":"number","markDefs":[{"_key":"4b1883908d4f","_type":"link","href":"https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-create-index?tabs=config-2023-11-01%2Crest-2023-11-01%2Cpush%2Cportal-check-index"},{"_key":"88abf252e6e5","_type":"link","href":"https://docs.llamaindex.ai/en/latest/module_guides/indexing/vector_store_index/"}],"style":"normal"},{"_key":"b0f56cf9732f","_type":"block","children":[{"_key":"0590834e3d72","_type":"span","marks":[],"text":"Create a "},{"_key":"99bef36948ad1","_type":"span","marks":["4b1883908d4f"],"text":"vector index"},{"_key":"99bef36948ad2","_type":"span","marks":[],"text":" of these document chunks using "},{"_key":"99bef36948ad3","_type":"span","marks":["88abf252e6e5"],"text":"VectorStoreIndex"},{"_key":"99bef36948ad4","_type":"span","marks":[],"text":". This allows for efficient similarity searches based on embeddings."}],"level":2,"listItem":"bullet","markDefs":[{"_key":"4b1883908d4f","_type":"link","href":"https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-create-index?tabs=config-2023-11-01%2Crest-2023-11-01%2Cpush%2Cportal-check-index"},{"_key":"88abf252e6e5","_type":"link","href":"https://docs.llamaindex.ai/en/latest/module_guides/indexing/vector_store_index/"}],"style":"normal"},{"_key":"07098f1a198a","_type":"block","children":[{"_key":"ee6093d22e3c","_type":"span","marks":[],"text":"Optionally, for complex datasets, you can use recursive retrieval techniques to manage hierarchically structured data and retrieve relevant sections based on user queries."}],"level":2,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"4d09bc5fa429","_type":"block","children":[{"_key":"1d53901365790","_type":"span","marks":[],"text":"Query Engine Setup:"}],"level":1,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"781d8e3e34dc","_type":"block","children":[{"_key":"944e83d0b6500","_type":"span","marks":[],"text":"Convert the vector index into a query engine using asQueryEngine with parameters such as similarityTopKto define how many top documents should be retrieved."}],"level":2,"listItem":"bullet","markDefs":[{"_key":"4ba59f53380b","_type":"link","href":"https://docs.llamaindex.ai/en/stable/use_cases/agents/"}],"style":"normal"},{"_key":"574cbf02dfdf","_type":"block","children":[{"_key":"82d50f7cacc0","_type":"span","marks":[],"text":"For more advanced setups, use "},{"_key":"2fc0052b0cfd1","_type":"span","marks":["4ba59f53380b"],"text":"agents"},{"_key":"2fc0052b0cfd2","_type":"span","marks":[],"text":". Create a multi-agent system where each agent is responsible for specific documents, and a top-level agent coordinates the overall retrieval process."}],"level":2,"listItem":"bullet","markDefs":[{"_key":"4ba59f53380b","_type":"link","href":"https://docs.llamaindex.ai/en/stable/use_cases/agents/"}],"style":"normal"},{"_key":"e47b0f0c06eb","_type":"block","children":[{"_key":"988109cb9dec0","_type":"span","marks":[],"text":"Retrieval and Generation:"}],"level":1,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"a4d5d611ce59","_type":"block","children":[{"_key":"67a61a963535","_type":"span","marks":[],"text":"Implement the RAG pipeline by defining an objective function that takes user queries and retrieves relevant document chunks. This function can also evaluate the retrieval chunks to ensure they match the user's query."}],"level":2,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"5c971353f66c","_type":"block","children":[{"_key":"39e0c7774e78","_type":"span","marks":[],"text":"Use the RetrieverQueryEngineto perform the actual retrieval and query processing. This can include additional post-processing steps like re-ranking the retrieved documents using tools such as CohereRerank."}],"level":2,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"f4d127674b64","_type":"block","children":[{"_key":"bacf30fe556b0","_type":"span","marks":[],"text":"For a practical example, we have provided you with a sample application to demonstrate a complete RAG implementation using Azure OpenAI as the AI provider."}],"markDefs":[],"style":"normal"},{"_key":"f7eaa733b6c4","_type":"block","children":[{"_key":"ffd094fab53f0","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"b0cb17ff8c0b","_type":"block","children":[{"_key":"b7cfdc45005f0","_type":"span","marks":[],"text":"Practical RAG sample application"}],"markDefs":[],"style":"h2"},{"_key":"9a88225072dd","_type":"block","children":[{"_key":"04e057ab4d280","_type":"span","marks":[],"text":"For the remainer of this article, we'll focus on the use case of building a RAG type application on Azure using LlamaIndex and Azure OpenAI. You will use one of the provided starter templates: TypeScript or Python."}],"markDefs":[],"style":"normal"},{"_key":"43d1670222ec","_type":"block","children":[{"_key":"064aa8277d390","_type":"span","marks":[],"text":"Requirements to run the samples"}],"markDefs":[],"style":"normal"},{"_key":"c756b0829bc8","_type":"block","children":[{"_key":"6570a39fed030","_type":"span","marks":[],"text":"First let's explain what you'll need:"}],"markDefs":[],"style":"normal"},{"_key":"7e673a068e10","_type":"block","children":[{"_key":"daf21972f3430","_type":"span","marks":["ad22b2f29445"],"text":"Azure Developer CLI, azd"},{"_key":"65293128100f","_type":"span","marks":[],"text":": this is a CLI, a command line tool that can easily deploy your entire app, backend, frontend, databases etc. You can use azd with "},{"_key":"daf21972f3432","_type":"span","marks":["0ae49cdafe22"],"text":"extensible blueprint templates"},{"_key":"daf21972f3433","_type":"span","marks":[],"text":" that includes everything you need to get an application up and running on Azure."}],"level":1,"listItem":"bullet","markDefs":[{"_key":"ad22b2f29445","_type":"link","href":"https://learn.microsoft.com/en-us/azure/developer/azure-developer-cli/"},{"_key":"0ae49cdafe22","_type":"link","href":"https://learn.microsoft.com/azure/developer/azure-developer-cli/azd-templates"}],"style":"normal"},{"_key":"408659708183","_type":"block","children":[{"_key":"446210e70b0c0","_type":"span","marks":[],"text":"Azure account: you will need an Azure account to deploy things. get an "},{"_key":"446210e70b0c1","_type":"span","marks":["175cd6fe766c"],"text":"Azure account for free"},{"_key":"446210e70b0c2","_type":"span","marks":[],"text":" and you'll get some free Azure credits to get started"}],"level":1,"listItem":"bullet","markDefs":[{"_key":"175cd6fe766c","_type":"link","href":"https://azure.microsoft.com/free/cognitive-search/"}],"style":"normal"},{"_key":"9b96a94e2ec4","_type":"block","children":[{"_key":"a61f29c199280","_type":"span","marks":[],"text":"Samples: we've created two samples that will deploy a RAG type application on Azure. The azd starter templates are designed to help you create a serverless RAG application with LlamaIndex and Azure OpenAI in a few simple steps. We are going to highlight two sample applications that were created based on the great "},{"_key":"a61f29c199281","_type":"span","marks":["30e4a84de259"],"text":"create-llama tool"},{"_key":"a61f29c199282","_type":"span","marks":[],"text":":"}],"level":1,"listItem":"bullet","markDefs":[{"_key":"30e4a84de259","_type":"link","href":"https://www.llamaindex.ai/blog/create-llama-a-command-line-tool-to-generate-llamaindex-apps-8f7683021191"},{"_key":"3e30b8583caf","_type":"link","href":"https://github.com/Azure-Samples/llama-index-javascript"}],"style":"normal"},{"_key":"5186930f866b","_type":"block","children":[{"_key":"8a19b4c62aca","_type":"span","marks":[],"text":"1. For TypeScript: "},{"_key":"370298fc6aed1","_type":"span","marks":["3e30b8583caf"],"text":"https://github.com/Azure-Samples/llama-index-javascript"},{"_key":"370298fc6aed2","_type":"span","marks":[],"text":" "}],"markDefs":[{"_key":"3e30b8583caf","_type":"link","href":"https://github.com/Azure-Samples/llama-index-javascript"},{"_key":"154b399267ac","_type":"link","href":"https://github.com/Azure-Samples/llama-index-python"}],"style":"normal"},{"_key":"4e97de3e06e4","_type":"block","children":[{"_key":"74af28a7fb9a","_type":"span","marks":[],"text":"2. For Python: "},{"_key":"224e9db194b11","_type":"span","marks":["154b399267ac"],"text":"https://github.com/Azure-Samples/llama-index-python"},{"_key":"224e9db194b12","_type":"span","marks":[],"text":" "}],"markDefs":[{"_key":"154b399267ac","_type":"link","href":"https://github.com/Azure-Samples/llama-index-python"}],"style":"normal"},{"_key":"00598e18bf15","_type":"block","children":[{"_key":"82ad17ebbd570","_type":"span","marks":[],"text":"High level architecture"}],"markDefs":[],"style":"h2"},{"_key":"480b38cf206a","_type":"block","children":[{"_key":"158ee3bd45af0","_type":"span","marks":[],"text":"Both sample applications are built based on the same architecture:"}],"markDefs":[],"style":"normal"},{"_key":"2bf82a222282","_type":"image","asset":{"_ref":"image-ecd41ae473c595aa2602aa86e7031c2dc79103b2-2978x1800-png","_type":"reference"}},{"_key":"58582f4b6059","_type":"block","children":[{"_key":"fc476e5f7f2f0","_type":"span","marks":[],"text":"The architecture of the application relies on the following services and components:"}],"markDefs":[],"style":"normal"},{"_key":"002084688a69","_type":"block","children":[{"_key":"e889837d22550","_type":"span","marks":[],"text":"Azure OpenAIrepresents the AI provider that we send the user's queries to."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"9bde64352d4a","_type":"block","children":[{"_key":"098e8670e3800","_type":"span","marks":[],"text":"LlamaIndexis the framework that helps us ingest, transform and vectorize our content (PDF file) and create a search index from our data."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"d68867ecc5e4","_type":"block","children":[{"_key":"65cf17e06c2d0","_type":"span","marks":[],"text":"Azure Container Apps is the container environment where the application is hosted."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"e952906d027c","_type":"block","children":[{"_key":"e5e86d5f78e60","_type":"span","marks":[],"text":"Azure Managed Identity helps us ensure best in class security and eliminates the requirements for you as a developer to deal with credentials and API keys."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"1208bd11cac4","_type":"block","children":[{"_key":"8bfc86c373d70","_type":"span","marks":[],"text":"To learn more about what Cloud resources get deployed on Azure, check out the "},{"_key":"8bfc86c373d71","_type":"span","marks":["7297d13921f6"],"text":"infra folder"},{"_key":"8bfc86c373d72","_type":"span","marks":[],"text":" available in all our samples."}],"markDefs":[{"_key":"7297d13921f6","_type":"link","href":"https://github.com/Azure-Samples/llama-index-javascript/blob/main/infra/main.bicep"}],"style":"normal"},{"_key":"45957bd027b2","_type":"block","children":[{"_key":"82b03bfcf1f90","_type":"span","marks":[],"text":"Example user workflows"}],"markDefs":[],"style":"h2"},{"_key":"3b0834902af9","_type":"block","children":[{"_key":"78293571f1320","_type":"span","marks":[],"text":"The sample application contains logic code for the following two workflows:"}],"markDefs":[],"style":"normal"},{"_key":"3c477313458f","_type":"block","children":[{"_key":"e0b7725822480","_type":"span","marks":[],"text":"1. Data ingestion, where data is fetched and vectorized and search indexes are created. Vector indexes are stored in the "},{"_key":"e0b7725822481","_type":"span","marks":["b903123cafc8"],"text":"cache sub folder"},{"_key":"249834d139f8","_type":"span","marks":[],"text":". The data itself lives in a "},{"_key":"e0b7725822483","_type":"span","marks":["41056a27eb65"],"text":"data folder"},{"_key":"e0b7725822484","_type":"span","marks":[],"text":". Should you want to add more files like additional PDFs or Word files, this is where you should add them. There are existing Vector indexes but if you need to generate new ones (if you change the content of the data folder), you can run the following command:"}],"markDefs":[{"_key":"b903123cafc8","_type":"link","href":"https://github.com/Azure-Samples/llama-index-javascript/tree/main/cache"},{"_key":"41056a27eb65","_type":"link","href":"https://github.com/Azure-Samples/llama-index-javascript/tree/main/data"}],"style":"normal"},{"_key":"4d179f857685","_type":"codeBlock","code":"npm run generate","language":"sh"},{"_key":"b665ef8c8862","_type":"block","children":[{"_key":"37130d64e1ef0","_type":"span","marks":[],"text":"This command will invoke the following code in TypeScript:"}],"markDefs":[],"style":"normal"},{"_key":"6c48a12139f3","_type":"codeBlock","code":"async function generateDatasource() { \n  console.log(`Generating storage context...`); \n  // Split documents, create embeddings and store them in the storage context \n  const ms = await getRuntime(async () =\u003e { \n    const storageContext = await storageContextFromDefaults({ \n      persistDir: STORAGE_CACHE_DIR, \n    }); \n    const documents = await getDocuments(); \n    await VectorStoreIndex.fromDocuments(documents, { \n      storageContext, \n    }); \n  }); ","language":"typescript"},{"_key":"eb97e5234f34","_type":"block","children":[{"_key":"72dc8531b212","_type":"span","marks":[],"text":"or in Python:"}],"markDefs":[],"style":"normal"},{"_key":"904e43ac9969","_type":"codeBlock","code":"cd backend \npoetry run generate ","language":"sh"},{"_key":"8aab32bdec33","_type":"block","children":[{"_key":"273a4377d22f","_type":"span","marks":[],"text":"which will invoke this code:"}],"markDefs":[],"style":"normal"},{"_key":"537a8265f153","_type":"codeBlock","code":"def generate_datasource(): \n    init_settings() \n    logger.info(\"Creating new index\") \n    storage_dir = os.environ.get(\"STORAGE_DIR\", \"storage\") \n    # load the documents and create the index \n    documents = get_documents() \n    index = VectorStoreIndex.from_documents( \n        documents, \n    ) \n    # store it for later \n    index.storage_context.persist(storage_dir) \n    logger.info(f\"Finished creating new index. Stored in {storage_dir}\") ","language":"python"},{"_key":"fbc63a17cc97","_type":"block","children":[{"_key":"5063cde6ea1e0","_type":"span","marks":[],"text":"2. Serving prompt requests. In this part of the application, we receive user input i.e.prompts, which are sent to Azure OpenAI. To augment these prompts a chat engine is created consisting of a connection to the LLM and the vector index "},{"_key":"5063cde6ea1e1","_type":"span","marks":["e736889a754d"],"text":"loaded as a retriever"},{"_key":"5063cde6ea1e2","_type":"span","marks":[],"text":". Configuring access to Azure OpenAI is made easy with a few lines:"}],"markDefs":[{"_key":"e736889a754d","_type":"link","href":"https://github.com/Azure-Samples/llama-index-javascript/blob/8156d98ac5e1376954a7e03252bae718e4abc638/app/api/chat/engine/chat.ts#L16"}],"style":"normal"},{"_key":"3be207fdaee5","_type":"block","children":[{"_key":"1b5a28d22b12","_type":"span","marks":[],"text":"In TypeScript:"}],"markDefs":[],"style":"normal"},{"_key":"189b9fdb210c","_type":"codeBlock","code":"const credential = new DefaultAzureCredential(); \n  const azureADTokenProvider = getBearerTokenProvider( \n    credential, \n    \"https://cognitiveservices.azure.com/.default\", \n  ); \n  \n  const azure = { \n    azureADTokenProvider, \n    deployment: \"gpt-35-turbo\", \n  }; \n\n  Settings.llm = new OpenAI({ azure }); ","language":"typescript"},{"_key":"1685f63657b3","_type":"block","children":[{"_key":"6ba36733cc13","_type":"span","marks":[],"text":"Or in Python:"}],"markDefs":[],"style":"normal"},{"_key":"a5486ea052d8","_type":"codeBlock","code":"credential = DefaultAzureCredential() \ntoken_provider = get_bearer_token_provider( \n  credential,  \n  \"https://cognitiveservices.azure.com/.default\"\n) \nllm_config = { \n  \"engine\": llm_deployment, \n  \"azure_endpoint\": azure_openai_endpoint, \n  \"azure_ad_token_provider\": token_provider, \n  \"use_azure_ad\": True, \n  \"temperature\":float(os.getenv(\"LLM_TEMPERATURE\", DEFAULT_TEMPERATURE)), \n  \"max_tokens\": int(max_tokens) if max_tokens is not None else None, \n} \n\nSettings.llm = AzureOpenAI(**llm_config) ","language":"python"},{"_key":"3bfd0d148516","_type":"block","children":[{"_key":"1ca0b03781eb0","_type":"span","marks":[],"text":"In this sample, we use the @azure/identity Node.js or PyPI package and import the DefaultAzureCredential chained credential strategy that seamlessly checks and uses a valid token from an existing Azure session, based on what is available in the current environment without changing your code."}],"markDefs":[],"style":"normal"},{"_key":"5ebb4fa45977","_type":"block","children":[{"_key":"ea855328e8210","_type":"span","marks":[],"text":"When your application is hosted in Azure, managed identity is also used for seamless authentication in your production environments."}],"markDefs":[],"style":"normal"},{"_key":"ec4581961aad","_type":"block","children":[{"_key":"ac0faff44e7d0","_type":"span","marks":[],"text":"Important packages used for the JavaScript sample"}],"markDefs":[],"style":"normal"},{"_key":"f1cf784e9119","_type":"block","children":[{"_key":"2c694a070eff0","_type":"span","marks":[],"text":"Here's some packages used in the solution worth mentioning. For a detailed list of all packages used, "},{"_key":"2c694a070eff1","_type":"span","marks":["d7e7b5820ded"],"text":"check out the package.json file"},{"_key":"2c694a070eff2","_type":"span","marks":[],"text":"."}],"markDefs":[{"_key":"d7e7b5820ded","_type":"link","href":"https://github.com/Azure-Samples/llama-index-javascript/blob/939dcb192482b94ba9977f4c12de7f501fa669c3/package.json"}],"style":"normal"},{"_key":"be222f25a1c8","_type":"block","children":[{"_key":"0fef9009ade00","_type":"span","marks":[],"text":"The "},{"_key":"0fef9009ade01","_type":"span","marks":["f9239e6c0941"],"text":"llamaindex core library"},{"_key":"0fef9009ade02","_type":"span","marks":[],"text":" providing core functionality on connecting to LLMs, facilitates vector index creation and more."}],"level":1,"listItem":"bullet","markDefs":[{"_key":"f9239e6c0941","_type":"link","href":"https://github.com/run-llama/LlamaIndexTS/tree/main/packages/llamaindex"}],"style":"normal"},{"_key":"679ae07dffd5","_type":"block","children":[{"_key":"ff7f571e7d180","_type":"span","marks":["137b42f49a75"],"text":"@llamaindex/pdf-viewer"},{"_key":"ff7f571e7d181","_type":"span","marks":[],"text":" is used to retrieve structured information from a PDF like tables, lists, paragraphs more and is part of the chunking process, where the data is divided into smaller strips, e.g.chunks, and each chunk is turned into vectorized form so it can be used later for semantic comparison."}],"level":1,"listItem":"bullet","markDefs":[{"_key":"137b42f49a75","_type":"link","href":"https://docs.llamaindex.ai/en/stable/api_reference/readers/smart_pdf_loader/"}],"style":"normal"},{"_key":"ead5fb1338ef","_type":"block","children":[{"_key":"4dbd1d0d35030","_type":"span","marks":[],"text":"As discussed earlier, "},{"_key":"4dbd1d0d35031","_type":"span","marks":["642563c7e5d8"],"text":"@azure/identity"},{"_key":"4dbd1d0d35032","_type":"span","marks":[],"text":" is used to connect to Azure using Azure Managed Identity, (managed identity means Azure handles the identity for you via "},{"_key":"4dbd1d0d35033","_type":"span","marks":["373c28723f5b"],"text":"Microsoft EntraID"},{"_key":"4dbd1d0d35034","_type":"span","marks":[],"text":" instead of using API keys which are considered less secure)."}],"level":1,"listItem":"bullet","markDefs":[{"_key":"642563c7e5d8","_type":"link","href":"https://github.com/Azure/azure-sdk-for-js/blob/main/sdk/identity/identity/samples/AzureIdentityExamples.md"},{"_key":"373c28723f5b","_type":"link","href":"https://www.microsoft.com/security/business/identity-access/microsoft-entra-id"}],"style":"normal"},{"_key":"96358e5feb9f","_type":"block","children":[{"_key":"568883850b850","_type":"span","marks":[],"text":"Important packages used for the Python sample"}],"markDefs":[],"style":"h2"},{"_key":"167730d825f5","_type":"block","children":[{"_key":"74cc692f90b10","_type":"span","marks":[],"text":"The Python sample uses "},{"_key":"74cc692f90b11","_type":"span","marks":["5749c9621435"],"text":"Poetry"},{"_key":"74cc692f90b12","_type":"span","marks":[],"text":" for dependency management and installation. For a detailed list of all packages used, checkout the "},{"_key":"74cc692f90b13","_type":"span","marks":["6ade9703d185"],"text":"pyproject.toml file"},{"_key":"74cc692f90b14","_type":"span","marks":[],"text":"."}],"markDefs":[{"_key":"5749c9621435","_type":"link","href":"https://python-poetry.org/"},{"_key":"6ade9703d185","_type":"link","href":"https://github.com/Azure-Samples/llama-index-python/blob/main/backend/pyproject.toml"}],"style":"normal"},{"_key":"20ccd7799a6b","_type":"block","children":[{"_key":"2e6a0b339b9c0","_type":"span","marks":[],"text":"The "},{"_key":"2e6a0b339b9c1","_type":"span","marks":["4582d8795f48"],"text":"llamaindex core Python library"},{"_key":"2e6a0b339b9c2","_type":"span","marks":[],"text":" providing core functionality on connecting to LLMs, facilitates vector index creation and more."}],"level":1,"listItem":"bullet","markDefs":[{"_key":"4582d8795f48","_type":"link","href":"https://github.com/run-llama/llama_index"}],"style":"normal"},{"_key":"33b101b283cc","_type":"block","children":[{"_key":"9095b60c57bc0","_type":"span","marks":["ede4329ec6a9"],"text":"FastAPI"},{"_key":"9095b60c57bc1","_type":"span","marks":[],"text":", a Python web framework is used to create the API that takes in the user input and returns a response."}],"level":1,"listItem":"bullet","markDefs":[{"_key":"ede4329ec6a9","_type":"link","href":"https://www.bing.com/search?q=fastapi\u0026cvid=6e1fad60b08040f9b9661945410756c2\u0026gs_lcrp=EgZjaHJvbWUqBggAEEUYOzIGCAAQRRg7MgYIARBFGDsyBwgCEOkHGEAyBggDEAAYQDIGCAQQABhAMgYIBRAAGEAyBggGEEUYPDIGCAcQRRg9MgYICBBFGDwyCAgJEOkHGPxV0gEIMjE3NWowajmoAgCwAgE\u0026FORM=ANAB01\u0026PC=U531"}],"style":"normal"},{"_key":"132995f650ff","_type":"block","children":[{"_key":"5091f26716920","_type":"span","marks":[],"text":"The Python "},{"_key":"5091f26716921","_type":"span","marks":["2a240cca92dc"],"text":"azure-identity"},{"_key":"5091f26716922","_type":"span","marks":[],"text":" package is used to connect to Azure using Azure Managed Identity, (managed identity means Azure handles the identity for you via "},{"_key":"5091f26716923","_type":"span","marks":["d247b4b17919"],"text":"Microsoft EntraID"},{"_key":"5091f26716924","_type":"span","marks":[],"text":" instead of using API keys which are considered less secure)."}],"level":1,"listItem":"bullet","markDefs":[{"_key":"2a240cca92dc","_type":"link","href":"https://pypi.org/project/azure-identity/"},{"_key":"d247b4b17919","_type":"link","href":"https://www.microsoft.com/security/business/identity-access/microsoft-entra-id"}],"style":"normal"},{"_key":"63e796ba48e0","_type":"block","children":[{"_key":"fb2f046750630","_type":"span","marks":[],"text":"Running the samples"}],"markDefs":[],"style":"h2"},{"_key":"e5f3bb2bd231","_type":"block","children":[{"_key":"bea235324b2e0","_type":"span","marks":[],"text":"Before running any of the samples, and using Azure OpenAI, it is worth mentioning that you need to provision the necessary Azure resources."}],"markDefs":[],"style":"normal"},{"_key":"acf71ec4f368","_type":"block","children":[{"_key":"10473540adfa0","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"98ccef35da23","_type":"block","children":[{"_key":"8865181d8b2e0","_type":"span","marks":[],"text":"You can run these templates by using GitHub Codespaces. Follow these links and then click \"Create codespace\" as shown to launch a VS Code instance in your browser (this may take a few minutes while the containers are built):"}],"markDefs":[],"style":"normal"},{"_key":"1379041fbe3a","_type":"image","asset":{"_ref":"image-3462c2cd2602095cbbbb6d5432b033e55ef87b5f-988x902-png","_type":"reference"}},{"_key":"a2d5bb66f97e","_type":"block","children":[{"_key":"1ac078efe8e2","_type":"span","marks":[],"text":"For TypeScript: "},{"_key":"0918387e999c","_type":"span","marks":["16763e197727"],"text":"https://github.com/Azure-Samples/llama-index-javascript"}],"markDefs":[{"_key":"16763e197727","_type":"link","href":"https://github.com/Azure-Samples/llama-index-javascript"}],"style":"normal"},{"_key":"1c20c7e83d70","_type":"block","children":[{"_key":"f27af026c123","_type":"span","marks":[],"text":"For Python: "},{"_key":"6ed642428165","_type":"span","marks":["eca940975204"],"text":"https://github.com/Azure-Samples/llama-index-python"}],"markDefs":[{"_key":"eca940975204","_type":"link","href":"https://github.com/Azure-Samples/llama-index-python"}],"style":"normal"},{"_key":"dd666271ad0a","_type":"block","children":[{"_key":"cb329d83070f","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"dbe5617b831e","_type":"block","children":[{"_key":"3f0412aff323","_type":"span","marks":[],"text":"1.Open a terminal window in your Codespaces instance."}],"markDefs":[],"style":"normal"},{"_key":"b3a95b644412","_type":"block","children":[{"_key":"f4d1c0319740","_type":"span","marks":[],"text":"2. Type the following command to sign into your Azure account:"}],"markDefs":[],"style":"normal"},{"_key":"a7085e8ba301","_type":"block","children":[{"_key":"a2c0f2be1bff0","_type":"span","marks":["code"],"text":"azd auth login"}],"markDefs":[],"style":"normal"},{"_key":"ec03ca10576f","_type":"block","children":[{"_key":"cafc758e55e7","_type":"span","marks":[],"text":"3. Run the next command to provision, package and deploy the sample application to Azure:"}],"markDefs":[],"style":"normal"},{"_key":"841f1dd8fd2f","_type":"block","children":[{"_key":"400d3c2663180","_type":"span","marks":["code"],"text":"azd up"}],"markDefs":[],"style":"normal"},{"_key":"2f4425b638f7","_type":"block","children":[{"_key":"9d62e52aa2850","_type":"span","marks":[],"text":"Once the command completes, you should see output from the terminal indicating success."}],"markDefs":[],"style":"normal"},{"_key":"5f9b30163f3e","_type":"block","children":[{"_key":"8dc0fb39b1e2","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"7c25d4947492","_type":"block","children":[{"_key":"428b6622f23f0","_type":"span","marks":[],"text":"Congratulations! At this point, you should be able to access your deployed application from the provided URL endpoint. To run and develop on the application locally, you need to:"}],"markDefs":[],"style":"normal"},{"_key":"6b5f73964526","_type":"block","children":[{"_key":"1ebc9debbd22","_type":"span","marks":[],"text":"4. "},{"_key":"6ad8d528fb48","_type":"span","marks":[],"text":"Run the following commands to install the application dependencies and run the app:"}],"markDefs":[],"style":"normal"},{"_key":"d83e6b5ab3c9","_type":"block","children":[{"_key":"fc3e5af53f870","_type":"span","marks":["code"],"text":"npm install"}],"markDefs":[],"style":"normal"},{"_key":"0faa2d772d05","_type":"block","children":[{"_key":"61837a9c63000","_type":"span","marks":["code"],"text":"npm run dev"}],"markDefs":[],"style":"normal"},{"_key":"5a48e1aeeeed","_type":"block","children":[{"_key":"dca3d24b65e2","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"b90bf26e748e","_type":"block","children":[{"_key":"606aaf949f810","_type":"span","marks":[],"text":"This will open the application on the default port 3000 in your Codespaces instance, or "},{"_key":"606aaf949f811","_type":"span","marks":["10d0b66d154b"],"text":"http://localhost:3000"},{"_key":"606aaf949f812","_type":"span","marks":[],"text":" in your browser locally. You should see your application rendered like so:"}],"markDefs":[{"_key":"10d0b66d154b","_type":"link","href":"http://localhost:3000/"}],"style":"normal"},{"_key":"c0e847cb7e99","_type":"block","children":[{"_key":"b445b1c7ca530","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"bf8e2175c817","_type":"block","children":[{"_key":"86c3edddf6830","_type":"span","marks":[],"text":"NOTE: If you would like to run these samples locally in VS Code Dev Containers or directly on your filesystem, the "},{"_key":"86c3edddf6831","_type":"span","marks":["67347c05703a"],"text":"README"},{"_key":"86c3edddf6832","_type":"span","marks":[],"text":" files in the samples have all the details about the tools and requirements."}],"markDefs":[{"_key":"67347c05703a","_type":"link","href":"https://github.com/Azure-Samples/llama-index-javascript?tab=readme-ov-file#local-environment"}],"style":"normal"},{"_key":"71622fe98202","_type":"block","children":[{"_key":"1cdcd2769b9e0","_type":"span","marks":[],"text":"What's next?"}],"markDefs":[],"style":"h2"},{"_key":"d397966926a7","_type":"block","children":[{"_key":"85886a19f9f60","_type":"span","marks":[],"text":"This guide has demonstrated how to build a serverless RAG (Retrieval-Augmented Generation) application using LlamaIndex and Azure OpenAI, deployed on Microsoft Azure. The key argument presented is that integrating your own business data into AI applications enhances the relevance and quality of responses, a crucial need for intelligent apps serving customers."}],"markDefs":[],"style":"normal"},{"_key":"23fe94566632","_type":"block","children":[{"_key":"fd3410bdd9470","_type":"span","marks":[],"text":"In this post we addressed the implementation of RAG architecture with LlamaIndex, detailing the steps from data ingestion and index creation to query engine setup and deployment on Azure. By following this guide, you can leverage Azure's robust infrastructure and LlamaIndex's capabilities to create powerful AI applications that provide contextually enriched responses based on your data."}],"markDefs":[],"style":"normal"},{"_key":"6306d6c9a5f4","_type":"block","children":[{"_key":"a2edc8e9014a0","_type":"span","marks":[],"text":"By deploying on Azure, you also benefit from scalability, security, and ease of management, reinforcing the practical application of the RAG model in real-world scenarios."}],"markDefs":[],"style":"normal"},{"_key":"a1d6938ab4ee","_type":"block","children":[{"_key":"996b9e65bdb10","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"81290472692a","_type":"block","children":[{"_key":"d88d7780e2ca0","_type":"span","marks":[],"text":"We're excited to see what you build with these sample applications. Feel free to fork them and like the GitHub repositories to receive the latest changes and new features."}],"markDefs":[],"style":"normal"}],"title":"Building a serverless RAG application with LlamaIndex and Azure OpenAI"},"publishedDate":"Invalid Date"},"params":{"slug":"building-a-serverless-rag-application-with-llamaindex-and-azure-openai"},"draftMode":false,"token":""},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"building-a-serverless-rag-application-with-llamaindex-and-azure-openai"},"buildId":"C8J-EMc_4OCN1ch65l4fl","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>