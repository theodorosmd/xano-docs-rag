<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>Customizing property graph index in LlamaIndex — LlamaIndex - Build Knowledge Assistants over your Enterprise Data</title><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><meta name="title" content="Customizing property graph index in LlamaIndex — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta name="description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:title" content="Customizing property graph index in LlamaIndex — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="og:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:image" content="https://cdn.sanity.io/images/7m9jw85w/production/257208ac7bda29e95139ab4736474d8022317f37-1024x1024.webp"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="Customizing property graph index in LlamaIndex — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="twitter:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="twitter:image" content="https://cdn.sanity.io/images/7m9jw85w/production/257208ac7bda29e95139ab4736474d8022317f37-1024x1024.webp"/><link rel="alternate" type="application/rss+xml" href="https://www.llamaindex.ai/blog/feed"/><meta name="next-head-count" content="20"/><script>
            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WWRFB36R');
            </script><link rel="preload" href="/_next/static/css/41c9222e47d080c9.css" as="style"/><link rel="stylesheet" href="/_next/static/css/41c9222e47d080c9.css" data-n-g=""/><link rel="preload" href="/_next/static/css/97c33c8d95f1230e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/97c33c8d95f1230e.css" data-n-p=""/><link rel="preload" href="/_next/static/css/e009059e80bf60c5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e009059e80bf60c5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-1b629d9c8fb16f34.js" defer=""></script><script src="/_next/static/chunks/framework-df1f68dff096b68a.js" defer=""></script><script src="/_next/static/chunks/main-eca7952a704663f8.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c7c49437be49d2ad.js" defer=""></script><script src="/_next/static/chunks/d9067523-4985945b21298365.js" defer=""></script><script src="/_next/static/chunks/41155975-60c12da9ce9fa0b2.js" defer=""></script><script src="/_next/static/chunks/cb355538-cee2ea45674d9de3.js" defer=""></script><script src="/_next/static/chunks/9494-dff62cb53535dd7d.js" defer=""></script><script src="/_next/static/chunks/4063-39a391a51171ff87.js" defer=""></script><script src="/_next/static/chunks/6889-edfa85b69b88a372.js" defer=""></script><script src="/_next/static/chunks/5575-11ee0a29eaffae61.js" defer=""></script><script src="/_next/static/chunks/3444-95c636af25a42734.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-82c8e764e69afd2c.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_buildManifest.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_ssgManifest.js" defer=""></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WWRFB36R" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div class="__variable_d65c78 __variable_b1ea77 __variable_eb7534"><a class="Announcement_announcement__2ohK8" href="http://48755185.hs-sites.com/llamaindex-0">Meet LlamaIndex at the Databricks Data + AI Summit!<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M8.293 5.293a1 1 0 0 1 1.414 0l6 6a1 1 0 0 1 0 1.414l-6 6a1 1 0 0 1-1.414-1.414L13.586 12 8.293 6.707a1 1 0 0 1 0-1.414Z" clip-rule="evenodd"></path></svg></a><header class="Header_header__hO3lJ"><button class="Hamburger_hamburger__17auO Header_hamburger__lUulX"><svg width="28" height="28" viewBox="0 0 28 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.5 14H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" id="hamburger-stroke-top" class="Hamburger_hamburgerStrokeMiddle__I7VpD"></path><path d="M3.5 7H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeTop__oOhFM"></path><path d="M3.5 21H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeBottom__GIQR2"></path></svg></button><a aria-label="Homepage" href="/"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" class="Header_logo__e5KhT" style="color:transparent" src="/llamaindex.svg"/></a><nav aria-label="Main" data-orientation="horizontal" dir="ltr" style="--content-position:0px"><div style="position:relative"><ul data-orientation="horizontal" class="Nav_MenuList__PrCDJ" dir="ltr"><li><button id="radix-:R6tm:-trigger-radix-:R5mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R5mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Products</button></li><li><button id="radix-:R6tm:-trigger-radix-:R9mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R9mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Solutions</button></li><li><a class="Nav_Link__ZrzFc" href="/community" data-radix-collection-item="">Community</a></li><li><a class="Nav_Link__ZrzFc" href="/pricing" data-radix-collection-item="">Pricing</a></li><li><a class="Nav_Link__ZrzFc" href="/blog" data-radix-collection-item="">Blog</a></li><li><a class="Nav_Link__ZrzFc" href="/customers" data-radix-collection-item="">Customer stories</a></li><li><a class="Nav_Link__ZrzFc" href="/careers" data-radix-collection-item="">Careers</a></li></ul></div><div class="Nav_ViewportPosition__jmyHM"></div></nav><div class="Header_secondNav__YJvm8"><nav><a href="/contact" class="Link_link__71cl8 Link_link-variant-tertiary__BYxn_ Header_bookADemo__qCuxV">Book a demo</a></nav><a href="https://cloud.llamaindex.ai/" class="Button_button-variant-default__Oi__n Button_button__aJ0V6 Header_button__1HFhY" data-tracking-variant="default"> <!-- -->Get started</a></div><div class="MobileMenu_mobileMenu__g5Fa6"><nav class="MobileMenu_nav__EmtTw"><ul><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Products<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaparse"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.6654 1.66675V6.66675H16.6654M8.33203 10.8334L6.66536 12.5001L8.33203 14.1667M11.6654 14.1667L13.332 12.5001L11.6654 10.8334M12.082 1.66675H4.9987C4.55667 1.66675 4.13275 1.84234 3.82019 2.1549C3.50763 2.46746 3.33203 2.89139 3.33203 3.33341V16.6667C3.33203 17.1088 3.50763 17.5327 3.82019 17.8453C4.13275 18.1578 4.55667 18.3334 4.9987 18.3334H14.9987C15.4407 18.3334 15.8646 18.1578 16.1772 17.8453C16.4898 17.5327 16.6654 17.1088 16.6654 16.6667V6.25008L12.082 1.66675Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Document parsing</div><p class="MobileMenu_ListItemText__n_MHY">The first and leading GenAI-native parser over your most complex data.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaextract"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.668 1.66675V5.00008C11.668 5.44211 11.8436 5.86603 12.1561 6.17859C12.4687 6.49115 12.8926 6.66675 13.3346 6.66675H16.668M3.33464 5.83341V3.33341C3.33464 2.89139 3.51023 2.46746 3.82279 2.1549C4.13535 1.84234 4.55927 1.66675 5.0013 1.66675H12.5013L16.668 5.83341V16.6667C16.668 17.1088 16.4924 17.5327 16.1798 17.8453C15.8672 18.1578 15.4433 18.3334 15.0013 18.3334L5.05379 18.3326C4.72458 18.3755 4.39006 18.3191 4.09312 18.1706C3.79618 18.0221 3.55034 17.7884 3.38713 17.4992M4.16797 9.16675L1.66797 11.6667M1.66797 11.6667L4.16797 14.1667M1.66797 11.6667H10.0013" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Data extraction</div><p class="MobileMenu_ListItemText__n_MHY">Extract structured data from documents using a schema-driven engine.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/enterprise"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.16667 15.8333C12.8486 15.8333 15.8333 12.8486 15.8333 9.16667C15.8333 5.48477 12.8486 2.5 9.16667 2.5C5.48477 2.5 2.5 5.48477 2.5 9.16667C2.5 12.8486 5.48477 15.8333 9.16667 15.8333Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M17.5 17.5L13.875 13.875" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Knowledge Management</div><p class="MobileMenu_ListItemText__n_MHY">Connect, transform, and index your enterprise data into an agent-accessible knowledge base</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/framework"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.0013 6.66659V3.33325H6.66797M1.66797 11.6666H3.33464M16.668 11.6666H18.3346M12.5013 10.8333V12.4999M7.5013 10.8333V12.4999M5.0013 6.66659H15.0013C15.9218 6.66659 16.668 7.41278 16.668 8.33325V14.9999C16.668 15.9204 15.9218 16.6666 15.0013 16.6666H5.0013C4.08083 16.6666 3.33464 15.9204 3.33464 14.9999V8.33325C3.33464 7.41278 4.08083 6.66659 5.0013 6.66659Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Agent Framework</div><p class="MobileMenu_ListItemText__n_MHY">Orchestrate and deploy multi-agent applications over your data with the #1 agent framework.</p></a></li></ul></details></li><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Solutions<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/finance"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 6.66675H8.33073C7.8887 6.66675 7.46478 6.84234 7.15222 7.1549C6.83966 7.46746 6.66406 7.89139 6.66406 8.33342C6.66406 8.77544 6.83966 9.19937 7.15222 9.51193C7.46478 9.82449 7.8887 10.0001 8.33073 10.0001H11.6641C12.1061 10.0001 12.53 10.1757 12.8426 10.4882C13.1551 10.8008 13.3307 11.2247 13.3307 11.6667C13.3307 12.1088 13.1551 12.5327 12.8426 12.8453C12.53 13.1578 12.1061 13.3334 11.6641 13.3334H6.66406M9.9974 15.0001V5.00008M18.3307 10.0001C18.3307 14.6025 14.5998 18.3334 9.9974 18.3334C5.39502 18.3334 1.66406 14.6025 1.66406 10.0001C1.66406 5.39771 5.39502 1.66675 9.9974 1.66675C14.5998 1.66675 18.3307 5.39771 18.3307 10.0001Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Financial Analysts</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/administrative-operations"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1.66406 6.66659V15.8333C1.66406 16.2753 1.83966 16.6992 2.15222 17.0118C2.46478 17.3243 2.8887 17.4999 3.33073 17.4999H14.9974M16.6641 14.1666C17.1061 14.1666 17.53 13.991 17.8426 13.6784C18.1551 13.3659 18.3307 12.9419 18.3307 12.4999V7.49992C18.3307 7.05789 18.1551 6.63397 17.8426 6.32141C17.53 6.00885 17.1061 5.83325 16.6641 5.83325H13.4141C13.1353 5.83598 12.8604 5.76876 12.6143 5.63774C12.3683 5.50671 12.159 5.31606 12.0057 5.08325L11.3307 4.08325C11.179 3.85281 10.9724 3.66365 10.7295 3.53275C10.4866 3.40185 10.215 3.3333 9.93906 3.33325H6.66406C6.22204 3.33325 5.79811 3.50885 5.48555 3.82141C5.17299 4.13397 4.9974 4.55789 4.9974 4.99992V12.4999C4.9974 12.9419 5.17299 13.3659 5.48555 13.6784C5.79811 13.991 6.22204 14.1666 6.66406 14.1666H16.6641Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Administrative Operations</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/engineering"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 15L18.3307 10L13.3307 5M6.66406 5L1.66406 10L6.66406 15" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Engineering &amp; R&amp;D</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/customer-support"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.9974 7.50008H16.6641C17.1061 7.50008 17.53 7.67568 17.8426 7.98824C18.1551 8.3008 18.3307 8.72472 18.3307 9.16675V18.3334L14.9974 15.0001H9.9974C9.55537 15.0001 9.13145 14.8245 8.81888 14.5119C8.50632 14.1994 8.33073 13.7754 8.33073 13.3334V12.5001M11.6641 7.50008C11.6641 7.94211 11.4885 8.36603 11.1759 8.67859C10.8633 8.99115 10.4394 9.16675 9.9974 9.16675H4.9974L1.66406 12.5001V3.33341C1.66406 2.41675 2.41406 1.66675 3.33073 1.66675H9.9974C10.4394 1.66675 10.8633 1.84234 11.1759 2.1549C11.4885 2.46746 11.6641 2.89139 11.6641 3.33341V7.50008Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Customer Support</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/healthcare-pharma"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M17.0128 3.81671C16.5948 3.39719 16.098 3.06433 15.551 2.8372C15.004 2.61008 14.4176 2.49316 13.8253 2.49316C13.2331 2.49316 12.6466 2.61008 12.0996 2.8372C11.5527 3.06433 11.0559 3.39719 10.6378 3.81671L9.99617 4.46671L9.3545 3.81671C8.93643 3.39719 8.43967 3.06433 7.89268 2.8372C7.3457 2.61008 6.75926 2.49316 6.167 2.49316C5.57474 2.49316 4.9883 2.61008 4.44132 2.8372C3.89433 3.06433 3.39756 3.39719 2.9795 3.81671C1.21283 5.58338 1.1045 8.56671 3.3295 10.8334L9.99617 17.5L16.6628 10.8334C18.8878 8.56671 18.7795 5.58338 17.0128 3.81671Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M2.91406 9.99992H7.91406L8.33073 9.16659L9.9974 12.9166L11.6641 7.08325L12.9141 9.99992H17.0807" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Healthcare / Pharma</div></a></li></ul></details></li><li><a class="MobileMenu_Link__5frcx" href="/community">Community</a></li><li><a class="MobileMenu_Link__5frcx" href="/pricing">Pricing</a></li><li><a class="MobileMenu_Link__5frcx" href="/blog">Blog</a></li><li><a class="MobileMenu_Link__5frcx" href="/customers">Customer stories</a></li><li><a class="MobileMenu_Link__5frcx" href="/careers">Careers</a></li></ul></nav><a href="/contact" class="Button_button-variant-ghost__o2AbG Button_button__aJ0V6" data-tracking-variant="ghost"> <!-- -->Talk to us</a><ul class="Socials_socials__8Y_s5 Socials_socials-theme-dark__Hq8lc MobileMenu_socials__JykCO"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu MobileMenu_copyright__nKVOs">© <!-- -->2025<!-- --> LlamaIndex</p></div></header><main><section class="BlogPost_post__JHNzd"><img alt="" loading="lazy" width="800" height="512" decoding="async" data-nimg="1" class="BlogPost_featuredImage__KGxwX" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F257208ac7bda29e95139ab4736474d8022317f37-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F257208ac7bda29e95139ab4736474d8022317f37-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F257208ac7bda29e95139ab4736474d8022317f37-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><p class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-600__fKYth BlogPost_date__6uxQw"><a class="BlogPost_author__mesdl" href="/blog/author/tomaz-bratanic">Tomaz Bratanic</a> <!-- -->•<!-- --> <!-- -->2024-06-11</p><h1 class="Text_text__zPO0D Text_text-size-32__koGps BlogPost_title__b2lqJ">Customizing property graph index in LlamaIndex</h1><ul class="BlogPost_tags__13pBH"><li><a class="Badge_badge___1ssn" href="/blog/tag/neo4j"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Neo4j</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/knowledge-graphs"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Knowledge Graphs</span></a></li></ul><div class="BlogPost_htmlPost__Z5oDL"><paragraphXLarge class="Text_text__zPO0D Text_text-size-28__dLWMG">Learn how to implement entity deduplication and custom retrieval methods to increase GraphRAG accuracy</paragraphXLarge><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><em>This is a guest post by Neo4J</em></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The <a href="https://www.llamaindex.ai/blog/introducing-the-property-graph-index-a-powerful-new-way-to-build-knowledge-graphs-with-llms" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">property graph index</a> is an excellent addition to LlamaIndex and an upgrade from the previous knowledge graph integration. First, the data representation is slightly different. In the previous integration, the graph was represented with triples, but now we have a proper property graph integration where nodes have labels and optionally node properties.</p><figure><img alt="" loading="lazy" width="700" height="682.5" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4b662997f8f9cb5c520d1d0b137a0b6a1562a079-1400x1365.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=750&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4b662997f8f9cb5c520d1d0b137a0b6a1562a079-1400x1365.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4b662997f8f9cb5c520d1d0b137a0b6a1562a079-1400x1365.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><figcaption>Example of a property graph model.</figcaption></figure><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Each node is assigned a label indicating its type, such as Person, Organization, Project, or Department. Nodes and relationships may also store node properties for other relevant details, such as the date of birth or project start and end date, as shown in this example.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Second, the property graph index is designed to be modular, so you can use one or multiple (custom) knowledge graph constructors as well as retrievers, making it an incredible tool to build your first knowledge graph or customize the implementation for your specific needs.</p><figure><img alt="" loading="lazy" width="515" height="216.5" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F8f5b2be7d62b266b597d235e77fcac50b0bb2c45-1030x433.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F8f5b2be7d62b266b597d235e77fcac50b0bb2c45-1030x433.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=1080&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F8f5b2be7d62b266b597d235e77fcac50b0bb2c45-1030x433.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=1080&amp;q=75"/><figcaption>Property graph workflow</figcaption></figure><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The image illustrates the property graph integration within the LlamaIndex , beginning with documents being passed to graph constructors. These constructors are modular components responsible for extracting structured information, which is then stored in a knowledge graph. The graph can be built using various or custom modules, highlighting the system’s flexibility to adapt to different data sources or extraction needs.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Graph retrievers then access the knowledge graph to retrieve data. This stage is also modular, allowing for the use of multiple retrievers or custom solutions designed to query specific types of data or relationships within the graph. Finally, the retrieved data is used by a LLM to generate an answer, representing the output or the insight derived from the process. This flow emphasizes a highly adaptable and scalable system where each component can be independently modified or replaced to enhance the overall functionality or to tailor it to specific requirements.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">In this blog post you will learn how to:</p><ol><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Construct a knowledge graph using a schema-guided extraction</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Perform entity deduplication using a combination of text embedding and word similarity techniques</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Design a custom graph retriever</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Finally, you will implement a question answering flow using the custom retriever</li></ol><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The code is available on <a href="https://github.com/tomasonjo/blogs/blob/master/llm/llama_index_neo4j_custom_retriever.ipynb" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">GitHub</a>.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Environment setup</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">In this blog post, we will use Neo4j as the underlying graph store. The easiest way is to get started is to a free instance on <a href="https://neo4j.com/cloud/platform/aura-graph-database/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Neo4j Aura</a>, which offers cloud instances of the Neo4j database. Alternatively, you can also set up a local instance of the Neo4j database by downloading the <a href="https://neo4j.com/download/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Neo4j Desktop</a> application and creating a local database instance.</p><pre><code><span class="hljs-keyword">from</span> llama_index.graph_stores.neo4j <span class="hljs-keyword">import</span> Neo4jPGStore

username=<span class="hljs-string">&quot;neo4j&quot;</span>
password=<span class="hljs-string">&quot;stump-inlet-student&quot;</span>
url=<span class="hljs-string">&quot;bolt://52.201.215.224:7687&quot;</span>

graph_store = Neo4jPGStore(
    username=username,
    password=password,
    url=url,
)</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Additionally, you will require a working OpenAI API key.</p><pre><code><span class="hljs-keyword">import</span> os

os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="hljs-string">&quot;sk-&quot;</span></code></pre><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Dataset</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">In this blog post, we will use a <a href="https://www.diffbot.com/solutions/news-monitoring/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">sample news article dataset fetched from Diffbot</a>, which I’ve made available on <a href="https://github.com/tomasonjo/blog-datasets/blob/main/news_articles.csv" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">GitHub for easier access</a>.</p><figure><img alt="" loading="lazy" width="700" height="140" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F65765704521d37c2cec1e400bc22c7dc97c6a65a-1400x280.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=750&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F65765704521d37c2cec1e400bc22c7dc97c6a65a-1400x280.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F65765704521d37c2cec1e400bc22c7dc97c6a65a-1400x280.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><figcaption>Sample records from the dataset.</figcaption></figure><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Since the property graph index operates with documents, we have to wrap the text from the news as LlamaIndex documents.</p><pre><code><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> llama_index.core <span class="hljs-keyword">import</span> Document

news = pd.read_csv(
  <span class="hljs-string">&quot;https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/news_articles.csv&quot;</span>)
documents = [Document(text=<span class="hljs-string">f&quot;<span class="hljs-subst">{row[<span class="hljs-string">&#x27;title&#x27;</span>]}</span>: <span class="hljs-subst">{row[<span class="hljs-string">&#x27;text&#x27;</span>]}</span>&quot;</span>) <span class="hljs-keyword">for</span> i, row <span class="hljs-keyword">in</span> news.iterrows()]</code></pre><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Graph construction</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">As mentioned, LlamaIndex provides multiple <a href="https://docs.llamaindex.ai/en/latest/module_guides/indexing/lpg_index_guide/#construction" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">out-of-the-box graph constructors</a>. In this example, we will use the <a href="https://docs.llamaindex.ai/en/latest/module_guides/indexing/lpg_index_guide/#schemallmpathextractor" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">SchemaLLMPathExtractor</a>, which allows us to define the schema of the graph structure we want to extract from documents.</p><figure><img alt="" loading="lazy" width="325" height="287.5" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F5982966b7ff647fce94f039ddb4186a4917f5c04-650x575.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=384&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F5982966b7ff647fce94f039ddb4186a4917f5c04-650x575.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=750&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F5982966b7ff647fce94f039ddb4186a4917f5c04-650x575.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=750&amp;q=75"/><figcaption>Schema-guided graph structure extraction.</figcaption></figure><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We begin by defining the types of nodes and relationships we want the LLM to extract.</p><pre><code>entities = <span class="hljs-type">Literal</span>[<span class="hljs-string">&quot;PERSON&quot;</span>, <span class="hljs-string">&quot;LOCATION&quot;</span>, <span class="hljs-string">&quot;ORGANIZATION&quot;</span>, <span class="hljs-string">&quot;PRODUCT&quot;</span>, <span class="hljs-string">&quot;EVENT&quot;</span>]
relations = <span class="hljs-type">Literal</span>[
    <span class="hljs-string">&quot;SUPPLIER_OF&quot;</span>,
    <span class="hljs-string">&quot;COMPETITOR&quot;</span>,
    <span class="hljs-string">&quot;PARTNERSHIP&quot;</span>,
    <span class="hljs-string">&quot;ACQUISITION&quot;</span>,
    <span class="hljs-string">&quot;WORKS_AT&quot;</span>,
    <span class="hljs-string">&quot;SUBSIDIARY&quot;</span>,
    <span class="hljs-string">&quot;BOARD_MEMBER&quot;</span>,
    <span class="hljs-string">&quot;CEO&quot;</span>,
    <span class="hljs-string">&quot;PROVIDES&quot;</span>,
    <span class="hljs-string">&quot;HAS_EVENT&quot;</span>,
    <span class="hljs-string">&quot;IN_LOCATION&quot;</span>,
]</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">As you can see, we are focusing our graph extraction around people and organizations. Next, we will specify the relationships associated with each node label.</p><pre><code><span class="hljs-comment"># define which entities can have which relations</span>
validation_schema = {
    <span class="hljs-string">&quot;Person&quot;</span>: [<span class="hljs-string">&quot;WORKS_AT&quot;</span>, <span class="hljs-string">&quot;BOARD_MEMBER&quot;</span>, <span class="hljs-string">&quot;CEO&quot;</span>, <span class="hljs-string">&quot;HAS_EVENT&quot;</span>],
    <span class="hljs-string">&quot;Organization&quot;</span>: [
        <span class="hljs-string">&quot;SUPPLIER_OF&quot;</span>,
        <span class="hljs-string">&quot;COMPETITOR&quot;</span>,
        <span class="hljs-string">&quot;PARTNERSHIP&quot;</span>,
        <span class="hljs-string">&quot;ACQUISITION&quot;</span>,
        <span class="hljs-string">&quot;WORKS_AT&quot;</span>,
        <span class="hljs-string">&quot;SUBSIDIARY&quot;</span>,
        <span class="hljs-string">&quot;BOARD_MEMBER&quot;</span>,
        <span class="hljs-string">&quot;CEO&quot;</span>,
        <span class="hljs-string">&quot;PROVIDES&quot;</span>,
        <span class="hljs-string">&quot;HAS_EVENT&quot;</span>,
        <span class="hljs-string">&quot;IN_LOCATION&quot;</span>,
    ],
    <span class="hljs-string">&quot;Product&quot;</span>: [<span class="hljs-string">&quot;PROVIDES&quot;</span>],
    <span class="hljs-string">&quot;Event&quot;</span>: [<span class="hljs-string">&quot;HAS_EVENT&quot;</span>, <span class="hljs-string">&quot;IN_LOCATION&quot;</span>],
    <span class="hljs-string">&quot;Location&quot;</span>: [<span class="hljs-string">&quot;HAPPENED_AT&quot;</span>, <span class="hljs-string">&quot;IN_LOCATION&quot;</span>],
}</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">For example, a person can have the following relationships:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">WORKS_AT</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">BOARD_MEMBER</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">CEO</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">HAS_EVENT</li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The schema is quite specific except for the EVENT node label, which is slightly more ambiguous and allows the LLM to capture various types of information.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Now that we have defined the graph schema, we can input it into the <code class="SanityPortableText_inlineCode__cI85z">SchemaLLMPathExtractor</code> and use it to construct a graph.</p><pre><code><span class="hljs-keyword">from</span> llama_index.core <span class="hljs-keyword">import</span> PropertyGraphIndex

kg_extractor = SchemaLLMPathExtractor(
    llm=llm,
    possible_entities=entities,
    possible_relations=relations,
    kg_validation_schema=validation_schema,
    <span class="hljs-comment"># if false, allows for values outside of the schema</span>
    <span class="hljs-comment"># useful for using the schema as a suggestion</span>
    strict=<span class="hljs-literal">True</span>,
)

NUMBER_OF_ARTICLES = <span class="hljs-number">250</span>

index = PropertyGraphIndex.from_documents(
    documents[:NUMBER_OF_ARTICLES],
    kg_extractors=[kg_extractor],
    llm=llm,
    embed_model=embed_model,
    property_graph_store=graph_store,
    show_progress=<span class="hljs-literal">True</span>,
)</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">This code extracts graph information from 250 news articles, but you can adjust the number how you see fit. There are 2500 articles in total.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><em>Note that extracting 250 articles takes about 7 minutes with GPT-4o. However, you can accelerate the process by employing parallelization through the</em> <em><code class="SanityPortableText_inlineCode__cI85z">num_workers</code></em> <em>parameter.</em></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We can visualize a small subgraph to inspect what was stored.</p><figure><img alt="" loading="lazy" width="700" height="525" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F13f69fa01ec07df7fbcc8cf46ff48ca7ed00a1ef-1400x1050.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=750&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F13f69fa01ec07df7fbcc8cf46ff48ca7ed00a1ef-1400x1050.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F13f69fa01ec07df7fbcc8cf46ff48ca7ed00a1ef-1400x1050.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><figcaption>Text chunks are blue, while entity nodes are all the rest.</figcaption></figure><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The constructed graph contains both text chunks (blue), which contain text and embeddings. If an entity was mentioned in the text chunk, there is a <code class="SanityPortableText_inlineCode__cI85z">MENTIONS</code> relationships between the text chunk and entity. Additionally, entities can have relationships to other entities.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Entity deduplication</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Entity deduplication or disambiguation is an important but often overlooked step in graph construction. Essentially, it is a cleaning step where you try to match multiple nodes that represent a single entity and merge them together into a single node for better graph structural integrity.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">For example, in our constructed graph I could find some examples that could be merged.</p><figure><img alt="" loading="lazy" width="700" height="600.5" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fccff59fb99d275ab16a40bd314c5e3ac64f60941-1400x1201.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=750&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fccff59fb99d275ab16a40bd314c5e3ac64f60941-1400x1201.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fccff59fb99d275ab16a40bd314c5e3ac64f60941-1400x1201.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><figcaption>Potential entity duplicates.</figcaption></figure><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We will use a combination of text embedding similarity and word distance to find potential duplicates. We start by defining the vector index on our entities in the graph.<br/></p><pre><code>graph_store.structured_query(<span class="hljs-string">&quot;&quot;&quot;
CREATE VECTOR INDEX entity IF NOT EXISTS
FOR (m:`__Entity__`)
ON m.embedding
OPTIONS {indexConfig: {
 `vector.dimensions`: 1536,
 `vector.similarity_function`: &#x27;cosine&#x27;
}}
&quot;&quot;&quot;</span>)</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The next Cypher query finds duplicates and is quite involved and I took me, Michael Hunger, and Eric Monk a couple of hours to perfect it.</p><pre><code>similarity_threshold = <span class="hljs-number">0.9</span>
word_edit_distance = <span class="hljs-number">5</span>
data = graph_store.structured_query(<span class="hljs-string">&quot;&quot;&quot;
MATCH (e:__Entity__)
CALL {
  WITH e
  CALL db.index.vector.queryNodes(&#x27;entity&#x27;, 10, e.embedding)
  YIELD node, score
  WITH node, score
  WHERE score &gt; toFLoat($cutoff)
      AND (toLower(node.name) CONTAINS toLower(e.name) OR toLower(e.name) CONTAINS toLower(node.name)
           OR apoc.text.distance(toLower(node.name), toLower(e.name)) &lt; $distance)
      AND labels(e) = labels(node)
  WITH node, score
  ORDER BY node.name
  RETURN collect(node) AS nodes
}
WITH distinct nodes
WHERE size(nodes) &gt; 1
WITH collect([n in nodes | n.name]) AS results
UNWIND range(0, size(results)-1, 1) as index
WITH results, index, results[index] as result
WITH apoc.coll.sort(reduce(acc = result, index2 IN range(0, size(results)-1, 1) |
        CASE WHEN index &lt;&gt; index2 AND
            size(apoc.coll.intersection(acc, results[index2])) &gt; 0
            THEN apoc.coll.union(acc, results[index2])
            ELSE acc
        END
)) as combinedResult
WITH distinct(combinedResult) as combinedResult
// extra filtering
WITH collect(combinedResult) as allCombinedResults
UNWIND range(0, size(allCombinedResults)-1, 1) as combinedResultIndex
WITH allCombinedResults[combinedResultIndex] as combinedResult, combinedResultIndex, allCombinedResults
WHERE NOT any(x IN range(0,size(allCombinedResults)-1,1) 
    WHERE x &lt;&gt; combinedResultIndex
    AND apoc.coll.containsAll(allCombinedResults[x], combinedResult)
)
RETURN combinedResult  
&quot;&quot;&quot;</span>, param_map={<span class="hljs-string">&#x27;cutoff&#x27;</span>: similarity_threshold, <span class="hljs-string">&#x27;distance&#x27;</span>: word_edit_distance})
<span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> data:
    <span class="hljs-built_in">print</span>(row)</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Without getting into too many details, we use a combination of text embeddings and word distance to find potential duplicates in our graph. You can tune <code class="SanityPortableText_inlineCode__cI85z">similarity_threshold</code> and <code class="SanityPortableText_inlineCode__cI85z">word_distance</code> to find the best combination that detects as many duplicates without too much false positives. Unfortunately, entity disambiguation is a hard problem and there are no perfect solutions. With this approach, we get quite good results, but there are some false positives in there as well:</p><pre><code>[<span class="hljs-string">&#x27;1963 AFL Draft&#x27;</span>, <span class="hljs-string">&#x27;1963 NFL Draft&#x27;</span>]
[<span class="hljs-string">&#x27;June 14, 2023&#x27;</span>, <span class="hljs-string">&#x27;June 15 2023&#x27;</span>]
[<span class="hljs-string">&#x27;BTC Halving&#x27;</span>, <span class="hljs-string">&#x27;BTC Halving 2016&#x27;</span>, <span class="hljs-string">&#x27;BTC Halving 2020&#x27;</span>, <span class="hljs-string">&#x27;BTC Halving 2024&#x27;</span>, <span class="hljs-string">&#x27;Bitcoin Halving&#x27;</span>, <span class="hljs-string">&#x27;Bitcoin Halving 2024&#x27;</span>]</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">It is up to you to tweak the dials, and maybe add some manual exceptions before merging duplicate nodes.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Implementing a custom retriever</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Great, we have constructed a knowledge graph based on the news dataset. Now, let’s examine our retriever options. At the moment, there are <a href="https://docs.llamaindex.ai/en/latest/module_guides/indexing/lpg_index_guide/#retrieval-and-querying" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">four existing retrievers available</a>:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><a href="https://docs.llamaindex.ai/en/latest/module_guides/indexing/lpg_index_guide/#default-llmsynonymretriever" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">LLMSynonymRetriever</a>: takes the query, and tries to generate keywords and synonyms to retrieve nodes (and therefore the paths connected to those nodes).</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><a href="https://docs.llamaindex.ai/en/latest/module_guides/indexing/lpg_index_guide/#default-if-supported-vectorcontextretriever" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">VectorContextRetriever</a>: retrieves nodes based on their vector similarity, and then fetches the paths connected to those nodes</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><a href="https://docs.llamaindex.ai/en/latest/module_guides/indexing/lpg_index_guide/#texttocypherretriever" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">TextToCypherRetriever</a>: uses a graph store schema, your query, and a prompt template in order to generate and execute a cypher query</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><a href="https://docs.llamaindex.ai/en/latest/module_guides/indexing/lpg_index_guide/#cyphertemplateretriever" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">CypherTemplateRetriever</a>: Rather than letting the LLM have free-range of generating any cypher statement, we can instead provide a cypher template and have the LLM fill in the parameters.</li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Additionally, implementing a custom retriever is straightforward, so that is exactly what we will do here. Our custom retriever will first identify entities in the input query and then execute the VectorContextRetriever for each identified entity separately.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">First, we will define the entity extraction model and prompt.</p><pre><code><span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel
<span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Optional</span>, <span class="hljs-type">List</span>


<span class="hljs-keyword">class</span> <span class="hljs-title class_">Entities</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):
    <span class="hljs-string">&quot;&quot;&quot;List of named entities in the text such as names of people, organizations, concepts, and locations&quot;&quot;&quot;</span>
    names: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]]


prompt_template_entities = <span class="hljs-string">&quot;&quot;&quot;
Extract all named entities such as names of people, organizations, concepts, and locations
from the following text:
{text}
&quot;&quot;&quot;</span></code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Now we can progress to the custom retriever implementation.</p><pre><code><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Any</span>, <span class="hljs-type">Optional</span>

<span class="hljs-keyword">from</span> llama_index.core.embeddings <span class="hljs-keyword">import</span> BaseEmbedding
<span class="hljs-keyword">from</span> llama_index.core.retrievers <span class="hljs-keyword">import</span> CustomPGRetriever, VectorContextRetriever
<span class="hljs-keyword">from</span> llama_index.core.vector_stores.types <span class="hljs-keyword">import</span> VectorStore
<span class="hljs-keyword">from</span> llama_index.program.openai <span class="hljs-keyword">import</span> OpenAIPydanticProgram


<span class="hljs-keyword">class</span> <span class="hljs-title class_">MyCustomRetriever</span>(<span class="hljs-title class_ inherited__">CustomPGRetriever</span>):
    <span class="hljs-string">&quot;&quot;&quot;Custom retriever with entity detection.&quot;&quot;&quot;</span>
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init</span>(<span class="hljs-params">
        self,
        <span class="hljs-comment">## vector context retriever params</span>
        embed_model: <span class="hljs-type">Optional</span>[BaseEmbedding] = <span class="hljs-literal">None</span>,
        vector_store: <span class="hljs-type">Optional</span>[VectorStore] = <span class="hljs-literal">None</span>,
        similarity_top_k: <span class="hljs-built_in">int</span> = <span class="hljs-number">4</span>,
        path_depth: <span class="hljs-built_in">int</span> = <span class="hljs-number">1</span>,
        include_text: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span>,
        **kwargs: <span class="hljs-type">Any</span>,
    </span>) -&gt; <span class="hljs-literal">None</span>:
        <span class="hljs-string">&quot;&quot;&quot;Uses any kwargs passed in from class constructor.&quot;&quot;&quot;</span>
        self.entity_extraction = OpenAIPydanticProgram.from_defaults(
            output_cls=Entities, prompt_template_str=prompt_template_entities
        )
        self.vector_retriever = VectorContextRetriever(
            self.graph_store,
            include_text=self.include_text,
            embed_model=embed_model,
            similarity_top_k=similarity_top_k,
            path_depth=path_depth,
        )

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">custom_retrieve</span>(<span class="hljs-params">self, query_str: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">str</span>:
        <span class="hljs-string">&quot;&quot;&quot;Define custom retriever with entity detection.

        Could return `str`, `TextNode`, `NodeWithScore`, or a list of those.
        &quot;&quot;&quot;</span>
        entities = self.entity_extraction(text=query_str).names
        result_nodes = []
        <span class="hljs-keyword">if</span> entities:
            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Detected entities: <span class="hljs-subst">{entities}</span>&quot;</span>)
            <span class="hljs-keyword">for</span> entity <span class="hljs-keyword">in</span> entities:
                result_nodes.extend(self.vector_retriever.retrieve(entity))
        <span class="hljs-keyword">else</span>:
            result_nodes.extend(self.vector_retriever.retrieve(query_str))
        final_text = <span class="hljs-string">&quot;\n\n&quot;</span>.join(
            [n.get_content(metadata_mode=<span class="hljs-string">&quot;llm&quot;</span>) <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> result_nodes]
        )
        <span class="hljs-keyword">return</span> final_text</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The <code class="SanityPortableText_inlineCode__cI85z">MyCustomRetriever</code> class has only two methods. You can use the <code class="SanityPortableText_inlineCode__cI85z">init</code> method to instantiate any functions or classes you will be using in the retriever. In this example, we instantiate the entity detection OpenAI program along with the vector context retriever.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The <code class="SanityPortableText_inlineCode__cI85z">custom_retrieve</code> method is called during retrieval. In our custom retriever implementation, we first identify any relevant entities in the text. If any entities are found, we iterate and execute the vector context retriever for each entity. On the other hand, if no entities are identified we pass the entire input to the vector context retriever.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">As you can observe, you can easily customize the retriever for your use-case by incorporating existing retrievers or starting from scratch as you can easily execute Cypher statements by using the <code class="SanityPortableText_inlineCode__cI85z">structured_query</code> method of the graph store.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Question-answering flow</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Let’s wrap it up by using the custom retriever to answer an example question. We need to pass the retriever to the <code class="SanityPortableText_inlineCode__cI85z">RetrieverQueryEngine</code> .</p><pre><code><span class="hljs-keyword">from</span> llama_index.core.query_engine <span class="hljs-keyword">import</span> RetrieverQueryEngine

custom_sub_retriever = MyCustomRetriever(
    index.property_graph_store,
    include_text=<span class="hljs-literal">True</span>,
    vector_store=index.vector_store,
    embed_model=embed_model
)

query_engine = RetrieverQueryEngine.from_args(
    index.as_retriever(sub_retrievers=[custom_sub_retriever]), llm=llm
)</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Let’s test it out!</p><pre><code>response = query_engine.query(
    <span class="hljs-string">&quot;What do you know about Maliek Collins or Darragh O’Brien?&quot;</span>
)
<span class="hljs-built_in">print</span>(<span class="hljs-built_in">str</span>(response))
<span class="hljs-comment"># Detected entities: [&#x27;Maliek Collins&#x27;, &quot;Darragh O&#x27;Brien&quot;]</span>
<span class="hljs-comment"># Maliek Collins is a defensive tackle who has played for the Dallas Cowboys, Las Vegas Raiders, and Houston Texans. Recently, he signed a two-year contract extension with the Houston Texans worth $23 million, including a $20 million guarantee. This new deal represents a raise from his previous contract, where he earned $17 million with $8.5 million guaranteed. Collins is expected to be a key piece in the Texans&#x27; defensive line and fit well into their 4-3 alignment.</span>
<span class="hljs-comment"># Darragh O’Brien is the Minister for Housing and has been involved in the State’s industrial relations process and the Government. He was recently involved in a debate in the Dáil regarding the pay and working conditions of retained firefighters, which led to a heated exchange and almost resulted in the suspension of the session. O’Brien expressed confidence that the dispute could be resolved and encouraged unions to re-engage with the industrial relations process.</span></code></pre><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Summary</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">In this blog post, we’ve explored the intricacies of customizing the property graph index within LlamaIndex, focusing on implementing entity deduplication and designing custom retrieval methods to enhance GraphRAG accuracy. The property graph index allows for a modular and flexible approach, utilizing various graph constructors and retrievers to tailor the implementation to your specific needs. Whether you’re building your first knowledge graph or optimizing for a unique dataset, these customizable components offer a powerful toolkit. We invite you to test out the property graph index integration to see how they can elevate your knowledge graph projects.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">As always, the code is available on <a href="https://github.com/tomasonjo/blogs/blob/master/llm/llama_index_neo4j_custom_retriever.ipynb" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">GitHub</a>.</p></div><div class="BlogPost_relatedPosts__0z6SN"><h2 class="Text_text__zPO0D Text_text-align-center__HhKqo Text_text-size-16__PkjFu Text_text-weight-400__5ENkK Text_text-family-spaceGrotesk__E4zcE BlogPost_relatedPostsTitle___JIrW">Related articles</h2><ul class="BlogPost_relatedPostsList__uOKzB"><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fa9bea7ec41e5dc8374f7b0ceb81ab0ac0c8ed51d-720x516.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fa9bea7ec41e5dc8374f7b0ceb81ab0ac0c8ed51d-720x516.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fa9bea7ec41e5dc8374f7b0ceb81ab0ac0c8ed51d-720x516.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/building-knowledge-graph-agents-with-llamaindex-workflows">Building knowledge graph agents with LlamaIndex Workflows</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2025-01-15</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9c496e451841627addd5e7afd5428e907bb9e5e4-1256x634.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9c496e451841627addd5e7afd5428e907bb9e5e4-1256x634.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9c496e451841627addd5e7afd5428e907bb9e5e4-1256x634.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/constructing-a-knowledge-graph-with-llamaindex-and-memgraph">Constructing a Knowledge Graph with LlamaIndex and Memgraph</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-11-21</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fe8afb8b2b1304f867e0becfc4d5ddbbd9dd94ec1-1784x1044.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fe8afb8b2b1304f867e0becfc4d5ddbbd9dd94ec1-1784x1044.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fe8afb8b2b1304f867e0becfc4d5ddbbd9dd94ec1-1784x1044.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/introducing-the-property-graph-index-a-powerful-new-way-to-build-knowledge-graphs-with-llms">Introducing the Property Graph Index: A Powerful New Way to Build Knowledge Graphs with LLMs</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-05-29</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4c1bcee45c3c241ee5ea8904ab8768a67cc029b2-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4c1bcee45c3c241ee5ea8904ab8768a67cc029b2-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4c1bcee45c3c241ee5ea8904ab8768a67cc029b2-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/multimodal-rag-pipeline-with-llamaindex-and-neo4j-a2c542eb0206">Multimodal RAG pipeline with LlamaIndex and Neo4j</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2023-12-18</p></div></li></ul></div></section></main><footer class="Footer_footer__eNA9m"><div class="Footer_navContainer__7bvx4"><div class="Footer_logoContainer__3EpzI"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" style="color:transparent" src="/llamaindex.svg"/><div class="Footer_socialContainer__GdOgk"><ul class="Socials_socials__8Y_s5"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul></div></div><div class="Footer_nav__BLEuE"><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/">LlamaIndex</a></h3><ul><li><a href="/blog"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Blog</span></a></li><li><a href="/partners"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Partners</span></a></li><li><a href="/careers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Careers</span></a></li><li><a href="/contact"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Contact</span></a></li><li><a href="/brand"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Brand</span></a></li><li><a href="https://llamaindex.statuspage.io" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Status</span></a></li><li><a href="https://app.vanta.com/runllama.ai/trust/pkcgbjf8b3ihxjpqdx17nu" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Trust Center</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/enterprise">Enterprise</a></h3><ul><li><a href="https://cloud.llamaindex.ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaCloud</span></a></li><li><a href="https://cloud.llamaindex.ai/parse" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaParse</span></a></li><li><a href="/customers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Customers</span></a></li><li><a href="/llamacloud-sharepoint-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SharePoint</span></a></li><li><a href="/llamacloud-aws-s3-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">AWS S3</span></a></li><li><a href="/llamacloud-azure-blob-storage-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure Blob Storage</span></a></li><li><a href="/llamacloud-google-drive-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Google Drive</span></a></li> </ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/framework">Framework</a></h3><ul><li><a href="https://pypi.org/project/llama-index/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python package</span></a></li><li><a href="https://docs.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python docs</span></a></li><li><a href="https://www.npmjs.com/package/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript package</span></a></li><li><a href="https://ts.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript docs</span></a></li><li><a href="https://llamahub.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaHub</span></a></li><li><a href="https://github.com/run-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">GitHub</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/community">Community</a></h3><ul><li><a href="/community#newsletter"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Newsletter</span></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Discord</span></a></li><li><a href="https://www.linkedin.com/company/91154103/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LinkedIn</span></a></li><li><a href="https://twitter.com/llama_index"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Twitter/X</span></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">YouTube</span></a></li><li><a href="https://bsky.app/profile/llamaindex.bsky.social"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">BlueSky</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e">Starter projects</h3><ul><li><a href="https://www.npmjs.com/package/create-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">create-llama</span></a></li><li><a href="https://secinsights.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SEC Insights</span></a></li><li><a href="https://github.com/run-llama/llamabot"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaBot</span></a></li><li><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/rag_cli.html"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">RAG CLI</span></a></li></ul></div></div></div><div class="Footer_copyrightContainer__mBKsT"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA">© <!-- -->2025<!-- --> LlamaIndex</p><div class="Footer_legalNav__O1yJA"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/privacy-notice.pdf">Privacy Notice</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/terms-of-service.pdf">Terms of Service</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="https://bit.ly/llamaindexdpa">Data Processing Addendum</a></p></div></div></footer></div><svg xmlns="http://www.w3.org/2000/svg" class="flt_svg" style="display:none"><defs><filter id="flt_tag"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="2"></feGaussianBlur><feColorMatrix in="blur" result="flt_tag" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="flt_tag" operator="atop"></feComposite></filter><filter id="svg_blur_large"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="8"></feGaussianBlur><feColorMatrix in="blur" result="svg_blur_large" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="svg_blur_large" operator="atop"></feComposite></filter></defs></svg></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"page":{"announcement":{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"},"post":{"_createdAt":"2024-06-11T19:49:48Z","_id":"36ca05d9-e95b-4292-aa85-d4f6589cc7d4","_rev":"Ys5IzmCaJ2UnW2RAX7U8Ni","_type":"blogPost","_updatedAt":"2025-05-21T20:37:06Z","announcement":[{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"}],"authors":[{"_createdAt":"2024-02-22T19:51:08Z","_id":"72d3c868-ff34-414f-bef2-e8c64c71164d","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"people","_updatedAt":"2024-02-24T20:08:04Z","name":"Tomaz Bratanic","slug":{"_type":"slug","current":"tomaz-bratanic"}}],"featured":false,"image":{"_type":"image","asset":{"_ref":"image-257208ac7bda29e95139ab4736474d8022317f37-1024x1024-webp","_type":"reference"}},"mainImage":"https://cdn.sanity.io/images/7m9jw85w/production/257208ac7bda29e95139ab4736474d8022317f37-1024x1024.webp","publishedDate":"2024-06-11","relatedPosts":[{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-a9bea7ec41e5dc8374f7b0ceb81ab0ac0c8ed51d-720x516-webp","_type":"reference"}},"publishedDate":"2025-01-15","slug":"building-knowledge-graph-agents-with-llamaindex-workflows","title":"Building knowledge graph agents with LlamaIndex Workflows"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-9c496e451841627addd5e7afd5428e907bb9e5e4-1256x634-png","_type":"reference"}},"publishedDate":"2024-11-21","slug":"constructing-a-knowledge-graph-with-llamaindex-and-memgraph","title":"Constructing a Knowledge Graph with LlamaIndex and Memgraph"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-e8afb8b2b1304f867e0becfc4d5ddbbd9dd94ec1-1784x1044-png","_type":"reference"}},"publishedDate":"2024-05-29","slug":"introducing-the-property-graph-index-a-powerful-new-way-to-build-knowledge-graphs-with-llms","title":"Introducing the Property Graph Index: A Powerful New Way to Build Knowledge Graphs with LLMs"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-4c1bcee45c3c241ee5ea8904ab8768a67cc029b2-1024x1024-png","_type":"reference"}},"publishedDate":"2023-12-18","slug":"multimodal-rag-pipeline-with-llamaindex-and-neo4j-a2c542eb0206","title":"Multimodal RAG pipeline with LlamaIndex and Neo4j"}],"slug":{"_type":"slug","current":"customizing-property-graph-index-in-llamaindex"},"tags":[{"_createdAt":"2024-02-22T20:19:12Z","_id":"e0f36642-bcbb-4d57-9a52-9be0428386c9","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:12Z","slug":{"_type":"slug","current":"neo4j"},"title":"Neo4j"},{"_createdAt":"2024-05-29T17:02:40Z","_id":"067170d7-e13f-45c7-bf89-74d521336787","_rev":"9mesbPtC9rOYXgtTRMRqBa","_type":"blogTag","_updatedAt":"2024-05-29T17:02:40Z","slug":{"_type":"slug","current":"knowledge-graphs"},"title":"Knowledge Graphs"}],"text":[{"_key":"6bd399f95396","_type":"block","children":[{"_key":"c58df61718e00","_type":"span","marks":[],"text":"Learn how to implement entity deduplication and custom retrieval methods to increase GraphRAG accuracy"}],"markDefs":[],"style":"paragraphXLarge"},{"_key":"39bca236cc22","_type":"block","children":[{"_key":"632f0060b995","_type":"span","marks":["em"],"text":"This is a guest post by Neo4J"}],"markDefs":[],"style":"normal"},{"_key":"e34c5bedd877","_type":"block","children":[{"_key":"905a8d6cb1c30","_type":"span","marks":[],"text":"The "},{"_key":"905a8d6cb1c31","_type":"span","marks":["b8d6475ab6b5"],"text":"property graph index"},{"_key":"905a8d6cb1c32","_type":"span","marks":[],"text":" is an excellent addition to LlamaIndex and an upgrade from the previous knowledge graph integration. First, the data representation is slightly different. In the previous integration, the graph was represented with triples, but now we have a proper property graph integration where nodes have labels and optionally node properties."}],"markDefs":[{"_key":"b8d6475ab6b5","_type":"link","href":"https://www.llamaindex.ai/blog/introducing-the-property-graph-index-a-powerful-new-way-to-build-knowledge-graphs-with-llms"}],"style":"normal"},{"_key":"6bba2d819369","_type":"image","asset":{"_ref":"image-4b662997f8f9cb5c520d1d0b137a0b6a1562a079-1400x1365-webp","_type":"reference"},"caption":"Example of a property graph model."},{"_key":"6cf05d211aae","_type":"block","children":[{"_key":"71b62b0868150","_type":"span","marks":[],"text":"Each node is assigned a label indicating its type, such as Person, Organization, Project, or Department. Nodes and relationships may also store node properties for other relevant details, such as the date of birth or project start and end date, as shown in this example."}],"markDefs":[],"style":"normal"},{"_key":"c450728742d2","_type":"block","children":[{"_key":"56f0f662354f0","_type":"span","marks":[],"text":"Second, the property graph index is designed to be modular, so you can use one or multiple (custom) knowledge graph constructors as well as retrievers, making it an incredible tool to build your first knowledge graph or customize the implementation for your specific needs."}],"markDefs":[],"style":"normal"},{"_key":"badb44bc275f","_type":"image","asset":{"_ref":"image-8f5b2be7d62b266b597d235e77fcac50b0bb2c45-1030x433-webp","_type":"reference"},"caption":"Property graph workflow"},{"_key":"11773c9e8e26","_type":"block","children":[{"_key":"5468045f27e20","_type":"span","marks":[],"text":"The image illustrates the property graph integration within the LlamaIndex , beginning with documents being passed to graph constructors. These constructors are modular components responsible for extracting structured information, which is then stored in a knowledge graph. The graph can be built using various or custom modules, highlighting the system’s flexibility to adapt to different data sources or extraction needs."}],"markDefs":[],"style":"normal"},{"_key":"657cc12dcc7c","_type":"block","children":[{"_key":"19603fb3e76d0","_type":"span","marks":[],"text":"Graph retrievers then access the knowledge graph to retrieve data. This stage is also modular, allowing for the use of multiple retrievers or custom solutions designed to query specific types of data or relationships within the graph. Finally, the retrieved data is used by a LLM to generate an answer, representing the output or the insight derived from the process. This flow emphasizes a highly adaptable and scalable system where each component can be independently modified or replaced to enhance the overall functionality or to tailor it to specific requirements."}],"markDefs":[],"style":"normal"},{"_key":"9c5a553f86bd","_type":"block","children":[{"_key":"a6a825767b3a0","_type":"span","marks":[],"text":"In this blog post you will learn how to:"}],"markDefs":[],"style":"normal"},{"_key":"b32386fbff5f","_type":"block","children":[{"_key":"5d2b1bf7dfeb0","_type":"span","marks":[],"text":"Construct a knowledge graph using a schema-guided extraction"}],"level":1,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"72d35c6e9a14","_type":"block","children":[{"_key":"a46016892d200","_type":"span","marks":[],"text":"Perform entity deduplication using a combination of text embedding and word similarity techniques"}],"level":1,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"0a1932be0343","_type":"block","children":[{"_key":"ef87afd473340","_type":"span","marks":[],"text":"Design a custom graph retriever"}],"level":1,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"cdf1d2167cee","_type":"block","children":[{"_key":"96defc041a5f0","_type":"span","marks":[],"text":"Finally, you will implement a question answering flow using the custom retriever"}],"level":1,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"ce3b19748c57","_type":"block","children":[{"_key":"dcf50d5520ef0","_type":"span","marks":[],"text":"The code is available on "},{"_key":"dcf50d5520ef1","_type":"span","marks":["dd7458f1e98d"],"text":"GitHub"},{"_key":"dcf50d5520ef2","_type":"span","marks":[],"text":"."}],"markDefs":[{"_key":"dd7458f1e98d","_type":"link","href":"https://github.com/tomasonjo/blogs/blob/master/llm/llama_index_neo4j_custom_retriever.ipynb"}],"style":"normal"},{"_key":"2b2045487f79","_type":"block","children":[{"_key":"0d0251e70b870","_type":"span","marks":[],"text":"Environment setup"}],"markDefs":[],"style":"h2"},{"_key":"28c176f13b03","_type":"block","children":[{"_key":"2cb9ad108eb70","_type":"span","marks":[],"text":"In this blog post, we will use Neo4j as the underlying graph store. The easiest way is to get started is to a free instance on "},{"_key":"2cb9ad108eb71","_type":"span","marks":["6b6a2c62116e"],"text":"Neo4j Aura"},{"_key":"2cb9ad108eb72","_type":"span","marks":[],"text":", which offers cloud instances of the Neo4j database. Alternatively, you can also set up a local instance of the Neo4j database by downloading the "},{"_key":"2cb9ad108eb73","_type":"span","marks":["261f90205d94"],"text":"Neo4j Desktop"},{"_key":"2cb9ad108eb74","_type":"span","marks":[],"text":" application and creating a local database instance."}],"markDefs":[{"_key":"6b6a2c62116e","_type":"link","href":"https://neo4j.com/cloud/platform/aura-graph-database/"},{"_key":"261f90205d94","_type":"link","href":"https://neo4j.com/download/"}],"style":"normal"},{"_key":"691e3fd67d0d","_type":"codeBlock","code":"from llama_index.graph_stores.neo4j import Neo4jPGStore\n\nusername=\"neo4j\"\npassword=\"stump-inlet-student\"\nurl=\"bolt://52.201.215.224:7687\"\n\ngraph_store = Neo4jPGStore(\n    username=username,\n    password=password,\n    url=url,\n)","language":"python"},{"_key":"a91d13219e8f","_type":"block","children":[{"_key":"9d05c2ef4dde0","_type":"span","marks":[],"text":"Additionally, you will require a working OpenAI API key."}],"markDefs":[],"style":"normal"},{"_key":"403f5f1c7250","_type":"codeBlock","code":"import os\n\nos.environ[\"OPENAI_API_KEY\"] = \"sk-\"","language":"python"},{"_key":"fdd9f50ec3c1","_type":"block","children":[{"_key":"9cc5e2010c280","_type":"span","marks":[],"text":"Dataset"}],"markDefs":[],"style":"h2"},{"_key":"4d7f411c3bc2","_type":"block","children":[{"_key":"45a53d2ad94b0","_type":"span","marks":[],"text":"In this blog post, we will use a "},{"_key":"45a53d2ad94b1","_type":"span","marks":["e4823f8cd7be"],"text":"sample news article dataset fetched from Diffbot"},{"_key":"45a53d2ad94b2","_type":"span","marks":[],"text":", which I’ve made available on "},{"_key":"45a53d2ad94b3","_type":"span","marks":["d1c0d636f732"],"text":"GitHub for easier access"},{"_key":"45a53d2ad94b4","_type":"span","marks":[],"text":"."}],"markDefs":[{"_key":"e4823f8cd7be","_type":"link","href":"https://www.diffbot.com/solutions/news-monitoring/"},{"_key":"d1c0d636f732","_type":"link","href":"https://github.com/tomasonjo/blog-datasets/blob/main/news_articles.csv"}],"style":"normal"},{"_key":"bcbd84930ea9","_type":"image","asset":{"_ref":"image-65765704521d37c2cec1e400bc22c7dc97c6a65a-1400x280-webp","_type":"reference"},"caption":"Sample records from the dataset."},{"_key":"e785c84b6ae2","_type":"block","children":[{"_key":"4393379207ee0","_type":"span","marks":[],"text":"Since the property graph index operates with documents, we have to wrap the text from the news as LlamaIndex documents."}],"markDefs":[],"style":"normal"},{"_key":"820f9add4a1f","_type":"codeBlock","code":"import pandas as pd\nfrom llama_index.core import Document\n\nnews = pd.read_csv(\n  \"https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/news_articles.csv\")\ndocuments = [Document(text=f\"{row['title']}: {row['text']}\") for i, row in news.iterrows()]","language":"python"},{"_key":"4a992732ed12","_type":"block","children":[{"_key":"4e2bccec68820","_type":"span","marks":[],"text":"Graph construction"}],"markDefs":[],"style":"h2"},{"_key":"95f158d4b39b","_type":"block","children":[{"_key":"30bd235200460","_type":"span","marks":[],"text":"As mentioned, LlamaIndex provides multiple "},{"_key":"30bd235200461","_type":"span","marks":["7896784424fb"],"text":"out-of-the-box graph constructors"},{"_key":"30bd235200462","_type":"span","marks":[],"text":". In this example, we will use the "},{"_key":"30bd235200463","_type":"span","marks":["825d55c05cc2"],"text":"SchemaLLMPathExtractor"},{"_key":"30bd235200464","_type":"span","marks":[],"text":", which allows us to define the schema of the graph structure we want to extract from documents."}],"markDefs":[{"_key":"7896784424fb","_type":"link","href":"https://docs.llamaindex.ai/en/latest/module_guides/indexing/lpg_index_guide/#construction"},{"_key":"825d55c05cc2","_type":"link","href":"https://docs.llamaindex.ai/en/latest/module_guides/indexing/lpg_index_guide/#schemallmpathextractor"}],"style":"normal"},{"_key":"395688c38530","_type":"image","asset":{"_ref":"image-5982966b7ff647fce94f039ddb4186a4917f5c04-650x575-webp","_type":"reference"},"caption":"Schema-guided graph structure extraction."},{"_key":"7b7e98048ae2","_type":"block","children":[{"_key":"5c19406e3caa0","_type":"span","marks":[],"text":"We begin by defining the types of nodes and relationships we want the LLM to extract."}],"markDefs":[],"style":"normal"},{"_key":"21e9f1d83e81","_type":"codeBlock","code":"entities = Literal[\"PERSON\", \"LOCATION\", \"ORGANIZATION\", \"PRODUCT\", \"EVENT\"]\nrelations = Literal[\n    \"SUPPLIER_OF\",\n    \"COMPETITOR\",\n    \"PARTNERSHIP\",\n    \"ACQUISITION\",\n    \"WORKS_AT\",\n    \"SUBSIDIARY\",\n    \"BOARD_MEMBER\",\n    \"CEO\",\n    \"PROVIDES\",\n    \"HAS_EVENT\",\n    \"IN_LOCATION\",\n]","language":"python"},{"_key":"ad0b554d3465","_type":"block","children":[{"_key":"6854742edb990","_type":"span","marks":[],"text":"As you can see, we are focusing our graph extraction around people and organizations. Next, we will specify the relationships associated with each node label."}],"markDefs":[],"style":"normal"},{"_key":"80c3b655c3cd","_type":"codeBlock","code":"# define which entities can have which relations\nvalidation_schema = {\n    \"Person\": [\"WORKS_AT\", \"BOARD_MEMBER\", \"CEO\", \"HAS_EVENT\"],\n    \"Organization\": [\n        \"SUPPLIER_OF\",\n        \"COMPETITOR\",\n        \"PARTNERSHIP\",\n        \"ACQUISITION\",\n        \"WORKS_AT\",\n        \"SUBSIDIARY\",\n        \"BOARD_MEMBER\",\n        \"CEO\",\n        \"PROVIDES\",\n        \"HAS_EVENT\",\n        \"IN_LOCATION\",\n    ],\n    \"Product\": [\"PROVIDES\"],\n    \"Event\": [\"HAS_EVENT\", \"IN_LOCATION\"],\n    \"Location\": [\"HAPPENED_AT\", \"IN_LOCATION\"],\n}","language":"python"},{"_key":"e044bcd36ecf","_type":"block","children":[{"_key":"f0937460215b0","_type":"span","marks":[],"text":"For example, a person can have the following relationships:"}],"markDefs":[],"style":"normal"},{"_key":"6b50c5caed2d","_type":"block","children":[{"_key":"f9220f64a5790","_type":"span","marks":[],"text":"WORKS_AT"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"0ed451ac3dbf","_type":"block","children":[{"_key":"21ec8122bfb90","_type":"span","marks":[],"text":"BOARD_MEMBER"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"e46db770b7b0","_type":"block","children":[{"_key":"3b99a6932c410","_type":"span","marks":[],"text":"CEO"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"10756ef6b6bc","_type":"block","children":[{"_key":"6362b98691860","_type":"span","marks":[],"text":"HAS_EVENT"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"ba3179d92b91","_type":"block","children":[{"_key":"fd8fb7d1b7ce0","_type":"span","marks":[],"text":"The schema is quite specific except for the EVENT node label, which is slightly more ambiguous and allows the LLM to capture various types of information."}],"markDefs":[],"style":"normal"},{"_key":"9a80eac169c6","_type":"block","children":[{"_key":"6908b56c6b340","_type":"span","marks":[],"text":"Now that we have defined the graph schema, we can input it into the "},{"_key":"6908b56c6b341","_type":"span","marks":["code"],"text":"SchemaLLMPathExtractor"},{"_key":"6908b56c6b342","_type":"span","marks":[],"text":" and use it to construct a graph."}],"markDefs":[],"style":"normal"},{"_key":"087f7871615f","_type":"codeBlock","code":"from llama_index.core import PropertyGraphIndex\n\nkg_extractor = SchemaLLMPathExtractor(\n    llm=llm,\n    possible_entities=entities,\n    possible_relations=relations,\n    kg_validation_schema=validation_schema,\n    # if false, allows for values outside of the schema\n    # useful for using the schema as a suggestion\n    strict=True,\n)\n\nNUMBER_OF_ARTICLES = 250\n\nindex = PropertyGraphIndex.from_documents(\n    documents[:NUMBER_OF_ARTICLES],\n    kg_extractors=[kg_extractor],\n    llm=llm,\n    embed_model=embed_model,\n    property_graph_store=graph_store,\n    show_progress=True,\n)","language":"python"},{"_key":"6822dd1cb468","_type":"block","children":[{"_key":"3641c9a912860","_type":"span","marks":[],"text":"This code extracts graph information from 250 news articles, but you can adjust the number how you see fit. There are 2500 articles in total."}],"markDefs":[],"style":"normal"},{"_key":"b08fbd442436","_type":"block","children":[{"_key":"b1e29159fa5b0","_type":"span","marks":["em"],"text":"Note that extracting 250 articles takes about 7 minutes with GPT-4o. However, you can accelerate the process by employing parallelization through the"},{"_key":"b1e29159fa5b1","_type":"span","marks":[],"text":" "},{"_key":"b1e29159fa5b2","_type":"span","marks":["code","em"],"text":"num_workers"},{"_key":"b1e29159fa5b3","_type":"span","marks":[],"text":" "},{"_key":"b1e29159fa5b4","_type":"span","marks":["em"],"text":"parameter."}],"markDefs":[],"style":"normal"},{"_key":"96864b47d139","_type":"block","children":[{"_key":"9454c9ed430e0","_type":"span","marks":[],"text":"We can visualize a small subgraph to inspect what was stored."}],"markDefs":[],"style":"normal"},{"_key":"20c566e74826","_type":"image","asset":{"_ref":"image-13f69fa01ec07df7fbcc8cf46ff48ca7ed00a1ef-1400x1050-webp","_type":"reference"},"caption":"Text chunks are blue, while entity nodes are all the rest."},{"_key":"0631b888e73c","_type":"block","children":[{"_key":"1eaf7001ef5f0","_type":"span","marks":[],"text":"The constructed graph contains both text chunks (blue), which contain text and embeddings. If an entity was mentioned in the text chunk, there is a "},{"_key":"1eaf7001ef5f1","_type":"span","marks":["code"],"text":"MENTIONS"},{"_key":"1eaf7001ef5f2","_type":"span","marks":[],"text":" relationships between the text chunk and entity. Additionally, entities can have relationships to other entities."}],"markDefs":[],"style":"normal"},{"_key":"609e2e1932f7","_type":"block","children":[{"_key":"27f9bb19bf2d0","_type":"span","marks":[],"text":"Entity deduplication"}],"markDefs":[],"style":"h2"},{"_key":"74540806f35d","_type":"block","children":[{"_key":"301ecc92c48e0","_type":"span","marks":[],"text":"Entity deduplication or disambiguation is an important but often overlooked step in graph construction. Essentially, it is a cleaning step where you try to match multiple nodes that represent a single entity and merge them together into a single node for better graph structural integrity."}],"markDefs":[],"style":"normal"},{"_key":"237709ac3eea","_type":"block","children":[{"_key":"7ed6149576cb0","_type":"span","marks":[],"text":"For example, in our constructed graph I could find some examples that could be merged."}],"markDefs":[],"style":"normal"},{"_key":"7f02d26fcdb5","_type":"image","asset":{"_ref":"image-ccff59fb99d275ab16a40bd314c5e3ac64f60941-1400x1201-webp","_type":"reference"},"caption":"Potential entity duplicates."},{"_key":"e783a9ce90e3","_type":"block","children":[{"_key":"00474c5631850","_type":"span","marks":[],"text":"We will use a combination of text embedding similarity and word distance to find potential duplicates. We start by defining the vector index on our entities in the graph.\n"}],"markDefs":[],"style":"normal"},{"_key":"949dab59f771","_type":"codeBlock","code":"graph_store.structured_query(\"\"\"\nCREATE VECTOR INDEX entity IF NOT EXISTS\nFOR (m:`__Entity__`)\nON m.embedding\nOPTIONS {indexConfig: {\n `vector.dimensions`: 1536,\n `vector.similarity_function`: 'cosine'\n}}\n\"\"\")","language":"python"},{"_key":"22a09c7b92fc","_type":"block","children":[{"_key":"b249ffc386b10","_type":"span","marks":[],"text":"The next Cypher query finds duplicates and is quite involved and I took me, Michael Hunger, and Eric Monk a couple of hours to perfect it."}],"markDefs":[],"style":"normal"},{"_key":"2870b69ff3b7","_type":"codeBlock","code":"similarity_threshold = 0.9\nword_edit_distance = 5\ndata = graph_store.structured_query(\"\"\"\nMATCH (e:__Entity__)\nCALL {\n  WITH e\n  CALL db.index.vector.queryNodes('entity', 10, e.embedding)\n  YIELD node, score\n  WITH node, score\n  WHERE score \u003e toFLoat($cutoff)\n      AND (toLower(node.name) CONTAINS toLower(e.name) OR toLower(e.name) CONTAINS toLower(node.name)\n           OR apoc.text.distance(toLower(node.name), toLower(e.name)) \u003c $distance)\n      AND labels(e) = labels(node)\n  WITH node, score\n  ORDER BY node.name\n  RETURN collect(node) AS nodes\n}\nWITH distinct nodes\nWHERE size(nodes) \u003e 1\nWITH collect([n in nodes | n.name]) AS results\nUNWIND range(0, size(results)-1, 1) as index\nWITH results, index, results[index] as result\nWITH apoc.coll.sort(reduce(acc = result, index2 IN range(0, size(results)-1, 1) |\n        CASE WHEN index \u003c\u003e index2 AND\n            size(apoc.coll.intersection(acc, results[index2])) \u003e 0\n            THEN apoc.coll.union(acc, results[index2])\n            ELSE acc\n        END\n)) as combinedResult\nWITH distinct(combinedResult) as combinedResult\n// extra filtering\nWITH collect(combinedResult) as allCombinedResults\nUNWIND range(0, size(allCombinedResults)-1, 1) as combinedResultIndex\nWITH allCombinedResults[combinedResultIndex] as combinedResult, combinedResultIndex, allCombinedResults\nWHERE NOT any(x IN range(0,size(allCombinedResults)-1,1) \n    WHERE x \u003c\u003e combinedResultIndex\n    AND apoc.coll.containsAll(allCombinedResults[x], combinedResult)\n)\nRETURN combinedResult  \n\"\"\", param_map={'cutoff': similarity_threshold, 'distance': word_edit_distance})\nfor row in data:\n    print(row)","language":"python"},{"_key":"256703d1dc36","_type":"block","children":[{"_key":"da1087241f0a0","_type":"span","marks":[],"text":"Without getting into too many details, we use a combination of text embeddings and word distance to find potential duplicates in our graph. You can tune "},{"_key":"da1087241f0a1","_type":"span","marks":["code"],"text":"similarity_threshold"},{"_key":"da1087241f0a2","_type":"span","marks":[],"text":" and "},{"_key":"da1087241f0a3","_type":"span","marks":["code"],"text":"word_distance"},{"_key":"da1087241f0a4","_type":"span","marks":[],"text":" to find the best combination that detects as many duplicates without too much false positives. Unfortunately, entity disambiguation is a hard problem and there are no perfect solutions. With this approach, we get quite good results, but there are some false positives in there as well:"}],"markDefs":[],"style":"normal"},{"_key":"2671f8dd7c4e","_type":"codeBlock","code":"['1963 AFL Draft', '1963 NFL Draft']\n['June 14, 2023', 'June 15 2023']\n['BTC Halving', 'BTC Halving 2016', 'BTC Halving 2020', 'BTC Halving 2024', 'Bitcoin Halving', 'Bitcoin Halving 2024']","language":"python"},{"_key":"aeaad04606a0","_type":"block","children":[{"_key":"a013073e17a00","_type":"span","marks":[],"text":"It is up to you to tweak the dials, and maybe add some manual exceptions before merging duplicate nodes."}],"markDefs":[],"style":"normal"},{"_key":"c6276d3d1a6c","_type":"block","children":[{"_key":"c5fb0c465cfc0","_type":"span","marks":[],"text":"Implementing a custom retriever"}],"markDefs":[],"style":"h2"},{"_key":"74b8c13af30b","_type":"block","children":[{"_key":"d8cd021839fb0","_type":"span","marks":[],"text":"Great, we have constructed a knowledge graph based on the news dataset. Now, let’s examine our retriever options. At the moment, there are "},{"_key":"d8cd021839fb1","_type":"span","marks":["940d579496a6"],"text":"four existing retrievers available"},{"_key":"d8cd021839fb2","_type":"span","marks":[],"text":":"}],"markDefs":[{"_key":"940d579496a6","_type":"link","href":"https://docs.llamaindex.ai/en/latest/module_guides/indexing/lpg_index_guide/#retrieval-and-querying"}],"style":"normal"},{"_key":"b914390baa2a","_type":"block","children":[{"_key":"8404e983d8b80","_type":"span","marks":["52d54aa4ea97"],"text":"LLMSynonymRetriever"},{"_key":"8404e983d8b81","_type":"span","marks":[],"text":": takes the query, and tries to generate keywords and synonyms to retrieve nodes (and therefore the paths connected to those nodes)."}],"level":1,"listItem":"bullet","markDefs":[{"_key":"52d54aa4ea97","_type":"link","href":"https://docs.llamaindex.ai/en/latest/module_guides/indexing/lpg_index_guide/#default-llmsynonymretriever"}],"style":"normal"},{"_key":"4b01a299e91d","_type":"block","children":[{"_key":"347edfa1c3160","_type":"span","marks":["636f37818925"],"text":"VectorContextRetriever"},{"_key":"347edfa1c3161","_type":"span","marks":[],"text":": retrieves nodes based on their vector similarity, and then fetches the paths connected to those nodes"}],"level":1,"listItem":"bullet","markDefs":[{"_key":"636f37818925","_type":"link","href":"https://docs.llamaindex.ai/en/latest/module_guides/indexing/lpg_index_guide/#default-if-supported-vectorcontextretriever"}],"style":"normal"},{"_key":"2b5f113ea25e","_type":"block","children":[{"_key":"e1c3627a78620","_type":"span","marks":["06450dd612cf"],"text":"TextToCypherRetriever"},{"_key":"e1c3627a78621","_type":"span","marks":[],"text":": uses a graph store schema, your query, and a prompt template in order to generate and execute a cypher query"}],"level":1,"listItem":"bullet","markDefs":[{"_key":"06450dd612cf","_type":"link","href":"https://docs.llamaindex.ai/en/latest/module_guides/indexing/lpg_index_guide/#texttocypherretriever"}],"style":"normal"},{"_key":"af887be034fc","_type":"block","children":[{"_key":"18371ef0867a0","_type":"span","marks":["6e45e5118be7"],"text":"CypherTemplateRetriever"},{"_key":"18371ef0867a1","_type":"span","marks":[],"text":": Rather than letting the LLM have free-range of generating any cypher statement, we can instead provide a cypher template and have the LLM fill in the parameters."}],"level":1,"listItem":"bullet","markDefs":[{"_key":"6e45e5118be7","_type":"link","href":"https://docs.llamaindex.ai/en/latest/module_guides/indexing/lpg_index_guide/#cyphertemplateretriever"}],"style":"normal"},{"_key":"daa187ac898a","_type":"block","children":[{"_key":"4dc20eddcf730","_type":"span","marks":[],"text":"Additionally, implementing a custom retriever is straightforward, so that is exactly what we will do here. Our custom retriever will first identify entities in the input query and then execute the VectorContextRetriever for each identified entity separately."}],"markDefs":[],"style":"normal"},{"_key":"2bdd9298a593","_type":"block","children":[{"_key":"29f74a8530100","_type":"span","marks":[],"text":"First, we will define the entity extraction model and prompt."}],"markDefs":[],"style":"normal"},{"_key":"3b273bb3d27a","_type":"codeBlock","code":"from pydantic import BaseModel\nfrom typing import Optional, List\n\n\nclass Entities(BaseModel):\n    \"\"\"List of named entities in the text such as names of people, organizations, concepts, and locations\"\"\"\n    names: Optional[List[str]]\n\n\nprompt_template_entities = \"\"\"\nExtract all named entities such as names of people, organizations, concepts, and locations\nfrom the following text:\n{text}\n\"\"\"","language":"python"},{"_key":"07b0013d6e8d","_type":"block","children":[{"_key":"a5bffc18d7d70","_type":"span","marks":[],"text":"Now we can progress to the custom retriever implementation."}],"markDefs":[],"style":"normal"},{"_key":"0c9fcb8f69c7","_type":"codeBlock","code":"from typing import Any, Optional\n\nfrom llama_index.core.embeddings import BaseEmbedding\nfrom llama_index.core.retrievers import CustomPGRetriever, VectorContextRetriever\nfrom llama_index.core.vector_stores.types import VectorStore\nfrom llama_index.program.openai import OpenAIPydanticProgram\n\n\nclass MyCustomRetriever(CustomPGRetriever):\n    \"\"\"Custom retriever with entity detection.\"\"\"\n    def init(\n        self,\n        ## vector context retriever params\n        embed_model: Optional[BaseEmbedding] = None,\n        vector_store: Optional[VectorStore] = None,\n        similarity_top_k: int = 4,\n        path_depth: int = 1,\n        include_text: bool = True,\n        **kwargs: Any,\n    ) -\u003e None:\n        \"\"\"Uses any kwargs passed in from class constructor.\"\"\"\n        self.entity_extraction = OpenAIPydanticProgram.from_defaults(\n            output_cls=Entities, prompt_template_str=prompt_template_entities\n        )\n        self.vector_retriever = VectorContextRetriever(\n            self.graph_store,\n            include_text=self.include_text,\n            embed_model=embed_model,\n            similarity_top_k=similarity_top_k,\n            path_depth=path_depth,\n        )\n\n    def custom_retrieve(self, query_str: str) -\u003e str:\n        \"\"\"Define custom retriever with entity detection.\n\n        Could return `str`, `TextNode`, `NodeWithScore`, or a list of those.\n        \"\"\"\n        entities = self.entity_extraction(text=query_str).names\n        result_nodes = []\n        if entities:\n            print(f\"Detected entities: {entities}\")\n            for entity in entities:\n                result_nodes.extend(self.vector_retriever.retrieve(entity))\n        else:\n            result_nodes.extend(self.vector_retriever.retrieve(query_str))\n        final_text = \"\\n\\n\".join(\n            [n.get_content(metadata_mode=\"llm\") for n in result_nodes]\n        )\n        return final_text","language":"python"},{"_key":"c492b53e1f5d","_type":"block","children":[{"_key":"d3cf0b87b4f50","_type":"span","marks":[],"text":"The "},{"_key":"d3cf0b87b4f51","_type":"span","marks":["code"],"text":"MyCustomRetriever"},{"_key":"d3cf0b87b4f52","_type":"span","marks":[],"text":" class has only two methods. You can use the "},{"_key":"d3cf0b87b4f53","_type":"span","marks":["code"],"text":"init"},{"_key":"d3cf0b87b4f54","_type":"span","marks":[],"text":" method to instantiate any functions or classes you will be using in the retriever. In this example, we instantiate the entity detection OpenAI program along with the vector context retriever."}],"markDefs":[],"style":"normal"},{"_key":"2e9ad852b06f","_type":"block","children":[{"_key":"09f4443573cf0","_type":"span","marks":[],"text":"The "},{"_key":"09f4443573cf1","_type":"span","marks":["code"],"text":"custom_retrieve"},{"_key":"09f4443573cf2","_type":"span","marks":[],"text":" method is called during retrieval. In our custom retriever implementation, we first identify any relevant entities in the text. If any entities are found, we iterate and execute the vector context retriever for each entity. On the other hand, if no entities are identified we pass the entire input to the vector context retriever."}],"markDefs":[],"style":"normal"},{"_key":"111a89ac17dd","_type":"block","children":[{"_key":"9161b97bb3fe0","_type":"span","marks":[],"text":"As you can observe, you can easily customize the retriever for your use-case by incorporating existing retrievers or starting from scratch as you can easily execute Cypher statements by using the "},{"_key":"9161b97bb3fe1","_type":"span","marks":["code"],"text":"structured_query"},{"_key":"9161b97bb3fe2","_type":"span","marks":[],"text":" method of the graph store."}],"markDefs":[],"style":"normal"},{"_key":"a99ea860887a","_type":"block","children":[{"_key":"1ea844b3ac200","_type":"span","marks":[],"text":"Question-answering flow"}],"markDefs":[],"style":"h2"},{"_key":"53fe08f58599","_type":"block","children":[{"_key":"b6983819df1a0","_type":"span","marks":[],"text":"Let’s wrap it up by using the custom retriever to answer an example question. We need to pass the retriever to the "},{"_key":"b6983819df1a1","_type":"span","marks":["code"],"text":"RetrieverQueryEngine"},{"_key":"b6983819df1a2","_type":"span","marks":[],"text":" ."}],"markDefs":[],"style":"normal"},{"_key":"5477155a1502","_type":"codeBlock","code":"from llama_index.core.query_engine import RetrieverQueryEngine\n\ncustom_sub_retriever = MyCustomRetriever(\n    index.property_graph_store,\n    include_text=True,\n    vector_store=index.vector_store,\n    embed_model=embed_model\n)\n\nquery_engine = RetrieverQueryEngine.from_args(\n    index.as_retriever(sub_retrievers=[custom_sub_retriever]), llm=llm\n)","language":"python"},{"_key":"47e5940589b1","_type":"block","children":[{"_key":"1fb7d3af75590","_type":"span","marks":[],"text":"Let’s test it out!"}],"markDefs":[],"style":"normal"},{"_key":"d3f0c90c053e","_type":"codeBlock","code":"response = query_engine.query(\n    \"What do you know about Maliek Collins or Darragh O’Brien?\"\n)\nprint(str(response))\n# Detected entities: ['Maliek Collins', \"Darragh O'Brien\"]\n# Maliek Collins is a defensive tackle who has played for the Dallas Cowboys, Las Vegas Raiders, and Houston Texans. Recently, he signed a two-year contract extension with the Houston Texans worth $23 million, including a $20 million guarantee. This new deal represents a raise from his previous contract, where he earned $17 million with $8.5 million guaranteed. Collins is expected to be a key piece in the Texans' defensive line and fit well into their 4-3 alignment.\n# Darragh O’Brien is the Minister for Housing and has been involved in the State’s industrial relations process and the Government. He was recently involved in a debate in the Dáil regarding the pay and working conditions of retained firefighters, which led to a heated exchange and almost resulted in the suspension of the session. O’Brien expressed confidence that the dispute could be resolved and encouraged unions to re-engage with the industrial relations process.","language":"python"},{"_key":"0ab15ca122b7","_type":"block","children":[{"_key":"69694cac524a0","_type":"span","marks":[],"text":"Summary"}],"markDefs":[],"style":"h2"},{"_key":"4f7f6c7869ca","_type":"block","children":[{"_key":"a670d936eb5a0","_type":"span","marks":[],"text":"In this blog post, we’ve explored the intricacies of customizing the property graph index within LlamaIndex, focusing on implementing entity deduplication and designing custom retrieval methods to enhance GraphRAG accuracy. The property graph index allows for a modular and flexible approach, utilizing various graph constructors and retrievers to tailor the implementation to your specific needs. Whether you’re building your first knowledge graph or optimizing for a unique dataset, these customizable components offer a powerful toolkit. We invite you to test out the property graph index integration to see how they can elevate your knowledge graph projects."}],"markDefs":[],"style":"normal"},{"_key":"8cf01fe68bd7","_type":"block","children":[{"_key":"90196d8c79be0","_type":"span","marks":[],"text":"As always, the code is available on "},{"_key":"90196d8c79be1","_type":"span","marks":["e1357b8d0388"],"text":"GitHub"},{"_key":"90196d8c79be2","_type":"span","marks":[],"text":"."}],"markDefs":[{"_key":"e1357b8d0388","_type":"link","href":"https://github.com/tomasonjo/blogs/blob/master/llm/llama_index_neo4j_custom_retriever.ipynb"}],"style":"normal"}],"title":"Customizing property graph index in LlamaIndex"},"publishedDate":"Invalid Date"},"params":{"slug":"customizing-property-graph-index-in-llamaindex"},"draftMode":false,"token":""},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"customizing-property-graph-index-in-llamaindex"},"buildId":"C8J-EMc_4OCN1ch65l4fl","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>