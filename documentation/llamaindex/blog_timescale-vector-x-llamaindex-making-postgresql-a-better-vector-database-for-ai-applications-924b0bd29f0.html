<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>Timescale Vector x LlamaIndex: Making PostgreSQL a Better Vector Database for AI Applications — LlamaIndex - Build Knowledge Assistants over your Enterprise Data</title><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><meta name="title" content="Timescale Vector x LlamaIndex: Making PostgreSQL a Better Vector Database for AI Applications — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta name="description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:title" content="Timescale Vector x LlamaIndex: Making PostgreSQL a Better Vector Database for AI Applications — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="og:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:image" content="https://cdn.sanity.io/images/7m9jw85w/production/052f06ed820cbc8594226339312addade98b50a3-2400x1350.png"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="Timescale Vector x LlamaIndex: Making PostgreSQL a Better Vector Database for AI Applications — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="twitter:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="twitter:image" content="https://cdn.sanity.io/images/7m9jw85w/production/052f06ed820cbc8594226339312addade98b50a3-2400x1350.png"/><link rel="alternate" type="application/rss+xml" href="https://www.llamaindex.ai/blog/feed"/><meta name="next-head-count" content="20"/><script>
            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WWRFB36R');
            </script><link rel="preload" href="/_next/static/css/41c9222e47d080c9.css" as="style"/><link rel="stylesheet" href="/_next/static/css/41c9222e47d080c9.css" data-n-g=""/><link rel="preload" href="/_next/static/css/97c33c8d95f1230e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/97c33c8d95f1230e.css" data-n-p=""/><link rel="preload" href="/_next/static/css/e009059e80bf60c5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e009059e80bf60c5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-1b629d9c8fb16f34.js" defer=""></script><script src="/_next/static/chunks/framework-df1f68dff096b68a.js" defer=""></script><script src="/_next/static/chunks/main-eca7952a704663f8.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c7c49437be49d2ad.js" defer=""></script><script src="/_next/static/chunks/d9067523-4985945b21298365.js" defer=""></script><script src="/_next/static/chunks/41155975-60c12da9ce9fa0b2.js" defer=""></script><script src="/_next/static/chunks/cb355538-cee2ea45674d9de3.js" defer=""></script><script src="/_next/static/chunks/9494-dff62cb53535dd7d.js" defer=""></script><script src="/_next/static/chunks/4063-39a391a51171ff87.js" defer=""></script><script src="/_next/static/chunks/6889-edfa85b69b88a372.js" defer=""></script><script src="/_next/static/chunks/5575-11ee0a29eaffae61.js" defer=""></script><script src="/_next/static/chunks/3444-95c636af25a42734.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-82c8e764e69afd2c.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_buildManifest.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_ssgManifest.js" defer=""></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WWRFB36R" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div class="__variable_d65c78 __variable_b1ea77 __variable_eb7534"><a class="Announcement_announcement__2ohK8" href="http://48755185.hs-sites.com/llamaindex-0">Meet LlamaIndex at the Databricks Data + AI Summit!<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M8.293 5.293a1 1 0 0 1 1.414 0l6 6a1 1 0 0 1 0 1.414l-6 6a1 1 0 0 1-1.414-1.414L13.586 12 8.293 6.707a1 1 0 0 1 0-1.414Z" clip-rule="evenodd"></path></svg></a><header class="Header_header__hO3lJ"><button class="Hamburger_hamburger__17auO Header_hamburger__lUulX"><svg width="28" height="28" viewBox="0 0 28 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.5 14H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" id="hamburger-stroke-top" class="Hamburger_hamburgerStrokeMiddle__I7VpD"></path><path d="M3.5 7H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeTop__oOhFM"></path><path d="M3.5 21H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeBottom__GIQR2"></path></svg></button><a aria-label="Homepage" href="/"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" class="Header_logo__e5KhT" style="color:transparent" src="/llamaindex.svg"/></a><nav aria-label="Main" data-orientation="horizontal" dir="ltr" style="--content-position:0px"><div style="position:relative"><ul data-orientation="horizontal" class="Nav_MenuList__PrCDJ" dir="ltr"><li><button id="radix-:R6tm:-trigger-radix-:R5mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R5mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Products</button></li><li><button id="radix-:R6tm:-trigger-radix-:R9mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R9mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Solutions</button></li><li><a class="Nav_Link__ZrzFc" href="/community" data-radix-collection-item="">Community</a></li><li><a class="Nav_Link__ZrzFc" href="/pricing" data-radix-collection-item="">Pricing</a></li><li><a class="Nav_Link__ZrzFc" href="/blog" data-radix-collection-item="">Blog</a></li><li><a class="Nav_Link__ZrzFc" href="/customers" data-radix-collection-item="">Customer stories</a></li><li><a class="Nav_Link__ZrzFc" href="/careers" data-radix-collection-item="">Careers</a></li></ul></div><div class="Nav_ViewportPosition__jmyHM"></div></nav><div class="Header_secondNav__YJvm8"><nav><a href="/contact" class="Link_link__71cl8 Link_link-variant-tertiary__BYxn_ Header_bookADemo__qCuxV">Book a demo</a></nav><a href="https://cloud.llamaindex.ai/" class="Button_button-variant-default__Oi__n Button_button__aJ0V6 Header_button__1HFhY" data-tracking-variant="default"> <!-- -->Get started</a></div><div class="MobileMenu_mobileMenu__g5Fa6"><nav class="MobileMenu_nav__EmtTw"><ul><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Products<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaparse"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.6654 1.66675V6.66675H16.6654M8.33203 10.8334L6.66536 12.5001L8.33203 14.1667M11.6654 14.1667L13.332 12.5001L11.6654 10.8334M12.082 1.66675H4.9987C4.55667 1.66675 4.13275 1.84234 3.82019 2.1549C3.50763 2.46746 3.33203 2.89139 3.33203 3.33341V16.6667C3.33203 17.1088 3.50763 17.5327 3.82019 17.8453C4.13275 18.1578 4.55667 18.3334 4.9987 18.3334H14.9987C15.4407 18.3334 15.8646 18.1578 16.1772 17.8453C16.4898 17.5327 16.6654 17.1088 16.6654 16.6667V6.25008L12.082 1.66675Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Document parsing</div><p class="MobileMenu_ListItemText__n_MHY">The first and leading GenAI-native parser over your most complex data.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaextract"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.668 1.66675V5.00008C11.668 5.44211 11.8436 5.86603 12.1561 6.17859C12.4687 6.49115 12.8926 6.66675 13.3346 6.66675H16.668M3.33464 5.83341V3.33341C3.33464 2.89139 3.51023 2.46746 3.82279 2.1549C4.13535 1.84234 4.55927 1.66675 5.0013 1.66675H12.5013L16.668 5.83341V16.6667C16.668 17.1088 16.4924 17.5327 16.1798 17.8453C15.8672 18.1578 15.4433 18.3334 15.0013 18.3334L5.05379 18.3326C4.72458 18.3755 4.39006 18.3191 4.09312 18.1706C3.79618 18.0221 3.55034 17.7884 3.38713 17.4992M4.16797 9.16675L1.66797 11.6667M1.66797 11.6667L4.16797 14.1667M1.66797 11.6667H10.0013" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Data extraction</div><p class="MobileMenu_ListItemText__n_MHY">Extract structured data from documents using a schema-driven engine.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/enterprise"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.16667 15.8333C12.8486 15.8333 15.8333 12.8486 15.8333 9.16667C15.8333 5.48477 12.8486 2.5 9.16667 2.5C5.48477 2.5 2.5 5.48477 2.5 9.16667C2.5 12.8486 5.48477 15.8333 9.16667 15.8333Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M17.5 17.5L13.875 13.875" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Knowledge Management</div><p class="MobileMenu_ListItemText__n_MHY">Connect, transform, and index your enterprise data into an agent-accessible knowledge base</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/framework"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.0013 6.66659V3.33325H6.66797M1.66797 11.6666H3.33464M16.668 11.6666H18.3346M12.5013 10.8333V12.4999M7.5013 10.8333V12.4999M5.0013 6.66659H15.0013C15.9218 6.66659 16.668 7.41278 16.668 8.33325V14.9999C16.668 15.9204 15.9218 16.6666 15.0013 16.6666H5.0013C4.08083 16.6666 3.33464 15.9204 3.33464 14.9999V8.33325C3.33464 7.41278 4.08083 6.66659 5.0013 6.66659Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Agent Framework</div><p class="MobileMenu_ListItemText__n_MHY">Orchestrate and deploy multi-agent applications over your data with the #1 agent framework.</p></a></li></ul></details></li><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Solutions<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/finance"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 6.66675H8.33073C7.8887 6.66675 7.46478 6.84234 7.15222 7.1549C6.83966 7.46746 6.66406 7.89139 6.66406 8.33342C6.66406 8.77544 6.83966 9.19937 7.15222 9.51193C7.46478 9.82449 7.8887 10.0001 8.33073 10.0001H11.6641C12.1061 10.0001 12.53 10.1757 12.8426 10.4882C13.1551 10.8008 13.3307 11.2247 13.3307 11.6667C13.3307 12.1088 13.1551 12.5327 12.8426 12.8453C12.53 13.1578 12.1061 13.3334 11.6641 13.3334H6.66406M9.9974 15.0001V5.00008M18.3307 10.0001C18.3307 14.6025 14.5998 18.3334 9.9974 18.3334C5.39502 18.3334 1.66406 14.6025 1.66406 10.0001C1.66406 5.39771 5.39502 1.66675 9.9974 1.66675C14.5998 1.66675 18.3307 5.39771 18.3307 10.0001Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Financial Analysts</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/administrative-operations"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1.66406 6.66659V15.8333C1.66406 16.2753 1.83966 16.6992 2.15222 17.0118C2.46478 17.3243 2.8887 17.4999 3.33073 17.4999H14.9974M16.6641 14.1666C17.1061 14.1666 17.53 13.991 17.8426 13.6784C18.1551 13.3659 18.3307 12.9419 18.3307 12.4999V7.49992C18.3307 7.05789 18.1551 6.63397 17.8426 6.32141C17.53 6.00885 17.1061 5.83325 16.6641 5.83325H13.4141C13.1353 5.83598 12.8604 5.76876 12.6143 5.63774C12.3683 5.50671 12.159 5.31606 12.0057 5.08325L11.3307 4.08325C11.179 3.85281 10.9724 3.66365 10.7295 3.53275C10.4866 3.40185 10.215 3.3333 9.93906 3.33325H6.66406C6.22204 3.33325 5.79811 3.50885 5.48555 3.82141C5.17299 4.13397 4.9974 4.55789 4.9974 4.99992V12.4999C4.9974 12.9419 5.17299 13.3659 5.48555 13.6784C5.79811 13.991 6.22204 14.1666 6.66406 14.1666H16.6641Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Administrative Operations</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/engineering"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 15L18.3307 10L13.3307 5M6.66406 5L1.66406 10L6.66406 15" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Engineering &amp; R&amp;D</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/customer-support"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.9974 7.50008H16.6641C17.1061 7.50008 17.53 7.67568 17.8426 7.98824C18.1551 8.3008 18.3307 8.72472 18.3307 9.16675V18.3334L14.9974 15.0001H9.9974C9.55537 15.0001 9.13145 14.8245 8.81888 14.5119C8.50632 14.1994 8.33073 13.7754 8.33073 13.3334V12.5001M11.6641 7.50008C11.6641 7.94211 11.4885 8.36603 11.1759 8.67859C10.8633 8.99115 10.4394 9.16675 9.9974 9.16675H4.9974L1.66406 12.5001V3.33341C1.66406 2.41675 2.41406 1.66675 3.33073 1.66675H9.9974C10.4394 1.66675 10.8633 1.84234 11.1759 2.1549C11.4885 2.46746 11.6641 2.89139 11.6641 3.33341V7.50008Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Customer Support</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/healthcare-pharma"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M17.0128 3.81671C16.5948 3.39719 16.098 3.06433 15.551 2.8372C15.004 2.61008 14.4176 2.49316 13.8253 2.49316C13.2331 2.49316 12.6466 2.61008 12.0996 2.8372C11.5527 3.06433 11.0559 3.39719 10.6378 3.81671L9.99617 4.46671L9.3545 3.81671C8.93643 3.39719 8.43967 3.06433 7.89268 2.8372C7.3457 2.61008 6.75926 2.49316 6.167 2.49316C5.57474 2.49316 4.9883 2.61008 4.44132 2.8372C3.89433 3.06433 3.39756 3.39719 2.9795 3.81671C1.21283 5.58338 1.1045 8.56671 3.3295 10.8334L9.99617 17.5L16.6628 10.8334C18.8878 8.56671 18.7795 5.58338 17.0128 3.81671Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M2.91406 9.99992H7.91406L8.33073 9.16659L9.9974 12.9166L11.6641 7.08325L12.9141 9.99992H17.0807" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Healthcare / Pharma</div></a></li></ul></details></li><li><a class="MobileMenu_Link__5frcx" href="/community">Community</a></li><li><a class="MobileMenu_Link__5frcx" href="/pricing">Pricing</a></li><li><a class="MobileMenu_Link__5frcx" href="/blog">Blog</a></li><li><a class="MobileMenu_Link__5frcx" href="/customers">Customer stories</a></li><li><a class="MobileMenu_Link__5frcx" href="/careers">Careers</a></li></ul></nav><a href="/contact" class="Button_button-variant-ghost__o2AbG Button_button__aJ0V6" data-tracking-variant="ghost"> <!-- -->Talk to us</a><ul class="Socials_socials__8Y_s5 Socials_socials-theme-dark__Hq8lc MobileMenu_socials__JykCO"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu MobileMenu_copyright__nKVOs">© <!-- -->2025<!-- --> LlamaIndex</p></div></header><main><section class="BlogPost_post__JHNzd"><img alt="" loading="lazy" width="800" height="675" decoding="async" data-nimg="1" class="BlogPost_featuredImage__KGxwX" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F052f06ed820cbc8594226339312addade98b50a3-2400x1350.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F052f06ed820cbc8594226339312addade98b50a3-2400x1350.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F052f06ed820cbc8594226339312addade98b50a3-2400x1350.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><p class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-600__fKYth BlogPost_date__6uxQw"><a class="BlogPost_author__mesdl" href="/blog/author/jerry-liu">Jerry Liu</a> <!-- -->•<!-- --> <!-- -->2023-09-27</p><h1 class="Text_text__zPO0D Text_text-size-32__koGps BlogPost_title__b2lqJ">Timescale Vector x LlamaIndex: Making PostgreSQL a Better Vector Database for AI Applications</h1><ul class="BlogPost_tags__13pBH"><li><a class="Badge_badge___1ssn" href="/blog/tag/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Llamaindex</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/nlp"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">NLP</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/llm"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">LLM</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">AI</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/timescaledb"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Timescaledb</span></a></li></ul><div class="BlogPost_htmlPost__Z5oDL"><p>Authors: Avthar Sewrathan, Matvey Arye, Jerry Liu, Yi Ding</p><p>Introducing the <a href="https://www.timescale.com/ai" rel="noopener ugc nofollow" target="_blank">Timescale Vector</a> integration for LlamaIndex. Timescale Vector enables LlamaIndex developers to build better AI applications with PostgreSQL as their vector database: with faster vector similarity search, efficient time-based search filtering, and the operational simplicity of a single, easy-to-use cloud PostgreSQL database for not only vector embeddings but an AI application’s relational and time-series data too.</p><p>PostgreSQL is the world’s most loved database, according to the <a href="https://survey.stackoverflow.co/2023/#section-most-popular-technologies-databases" rel="noopener ugc nofollow" target="_blank">Stack Overflow 2023 Developer Survey</a>. And for a good reason: it’s been battle-hardened by production use for over three decades, it’s robust and reliable, and it has a rich ecosystem of tools, drivers, and connectors.</p><p>And while pgvector, the open-source extension for vector data on PostgreSQL, is a wonderful extension (and all its features are offered as part of Timescale Vector), it is just one piece of the puzzle in providing a production-grade experience for AI application developers on PostgreSQL. After speaking with numerous developers at nimble startups and established industry giants, we saw the need to enhance pgvector to cater to the performance and operational needs of developers building AI applications.</p><p>Here’s the TL;DR on how Timescale Vector helps you build better AI applications with LlamaIndex:</p><ul><li><strong>Faster similarity search on millions of vectors: </strong>Thanks to the introduction of a new search index inspired by the DiskANN algorithm, <a href="https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/?utm_campaign=vectorlaunch&amp;utm_source=llamaindex&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Timescale Vector achieves 3X faster search speed at ~99% recall than a specialized database</a> and outperforms all existing PostgreSQL search indexes by between 39.39% and 1,590.33% on a dataset of one million OpenAI embeddings. Plus, enabling product quantization yields a <a href="https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/?utm_campaign=vectorlaunch&amp;utm_source=llamaindex&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">10x index space savings compared to pgvector</a>. Timescale Vector also offers pgvector’s Hierarchical Navigable Small Worlds (HNSW) and Inverted File Flat (IVFFlat) indexing algorithms.</li><li><strong>Efficient similarity search with time-based filtering: </strong>Timescale Vector optimizes time-based vector search queries, leveraging the automatic time-based partitioning and indexing of <a href="https://docs.timescale.com/use-timescale/latest/hypertables/" rel="noopener ugc nofollow" target="_blank">Timescale’s hypertables</a> to efficiently find recent embeddings, constrain vector search by a time range or document age, and store and retrieve large language model (LLM) response and chat history with ease. Time-based semantic search also enables you to use Retrieval Augmented Generation (RAG) with time-based context retrieval to give users more useful LLM responses.</li><li><strong>Simplified AI infra stack:</strong> By combining vector embeddings, relational data, and time-series data in one PostgreSQL database, Timescale Vector eliminates the operational complexity that comes with managing multiple database systems at scale.</li><li><strong>Simplified metadata handling and multi-attribute filtering: </strong>Developers can leverage all PostgreSQL data types to store and filter metadata and JOIN vector search results with relational data for more contextually relevant responses. In future releases, Timescale Vector will further optimize rich multi-attribute filtering, enabling even faster similarity searches when filtering on metadata.</li></ul><p>On top of these innovations for vector workloads, Timescale Vector provides a robust, production-ready cloud PostgreSQL platform with flexible pricing, enterprise-grade security, and free expert support.</p><p>In the rest of this post, we’ll dive deeper (with code!) into the unique capabilities Timescale Vector enables for developers wanting to use PostgreSQL as their vector database with LlamaIndex:</p><ul><li>Faster similarity search with DiskANN, HNSW and IVFFlat index types.</li><li>Efficient similarity search when filtering vectors by time.</li><li>Retrieval Augmented Generation (RAG) with time-based context retrieval.</li></ul><p>(If you want to jump straight to the code, explore <a href="https://gpt-index.readthedocs.io/en/stable/examples/vector_stores/Timescalevector.html" rel="noopener ugc nofollow" target="_blank">this tutorial</a>).</p><p><strong>🎉 </strong><a href="https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch&amp;utm_source=llamaindex&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"><strong>LlamaIndex Users Get 3 Months of Timescale Vector for Free</strong></a></p><p>We’re giving LlamaIndex users an extended 90-day trial of Timescale Vector. This makes it easy to test and develop your applications on Timescale Vector, as you won’t be charged for any cloud PostgreSQL databases you spin up during your trial period. <a href="https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch&amp;utm_source=llamaindex&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Try Timescale Vector for free today</a>.</p><h1>Faster Vector Similarity Search in PostgreSQL</h1><p>Timescale Vector speeds up Approximate Nearest Neighbor (ANN) search on large-scale vector datasets, enhancing pgvector with a state-of-the-art ANN index inspired by the <a href="https://www.microsoft.com/en-us/research/publication/diskann-fast-accurate-billion-point-nearest-neighbor-search-on-a-single-node/" rel="noopener ugc nofollow" target="_blank">DiskANN</a> algorithm. Timescale Vector also offers pgvector’s HNSW and IVFFlat indexing algorithms, giving developers the flexibility to choose the right index for their use case.</p><p>Our performance benchmarks using the <a href="https://github.com/erikbern/ann-benchmarks/" rel="noopener ugc nofollow" target="_blank">ANN benchmarks</a> suite show that Timescale Vector achieves between 39.43% and 1,590.33% faster search speed at ~99% recall than all existing PostgreSQL search indexes, and 3X faster search speed at ~99% recall than specialized vector databases on a dataset of one million OpenAI embeddings. You can <a href="https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/?utm_campaign=vectorlaunch&amp;utm_source=llamaindex&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">read more about the performance benchmark methodology, the databases compared and results here</a>.</p><figure><figcaption class="pz fe qa ny nz qb qc be b bf z dt"><em class="qd">Timescale Vector’s new DiskANN-inspired index outperforms all existing PostgreSQL index types when performing approximate nearest neighbor searches at 99 % recall on 1 million OpenAI embeddings.</em></figcaption><img src="/blog/images/1*FJl9RN0Se1eKDsd97bn02A.png" alt="" width="700" height="478"></figure><p>Using Timescale Vector’s DiskANN, HNSW, or IVFFLAT indexes in LlamaIndex is incredibly straightforward.</p><p>Simply create a Timescale Vector vector store and add the <a href="https://gpt-index.readthedocs.io/en/latest/core_modules/data_modules/documents_and_nodes/usage_nodes.html" rel="noopener ugc nofollow" target="_blank">data nodes</a> you want to query as shown below:</p><pre><span id="e55c" class="qi ow gt qf b bf qj qk l ql qm"><span class="hljs-keyword">from</span> llama_index.vector_stores <span class="hljs-keyword">import</span> TimescaleVectorStore

<span class="hljs-comment"># Create a timescale vector store with specified params</span>
ts_vector_store = TimescaleVectorStore.from_params(
   service_url=TIMESCALE_SERVICE_URL,
   table_name=<span class="hljs-string">"your_table_name"</span>,
   time_partition_interval= timedelta(days=<span class="hljs-number">7</span>),
)
ts_vector_store.add(nodes)</span></pre><p>Then run:</p><pre><span id="b587" class="qi ow gt qf b bf qj qk l ql qm"># Create a timescale vector index (DiskANN)
ts_vector_store.create_index()</span></pre><p>This will create a timescale-vector index with the default parameters.</p><p>We should point out that the term “index” is a bit overloaded. For many VectorStores, an index is the thing that stores your data (in relational databases this is often called a table), but in the PostgreSQL world an index is something that speeds up search, and we are using the latter meaning here.</p><p>We can also specify the exact parameters for index creation in the <code class="cw qn qo qp qf b">create_index</code> command as follows:</p><pre><span id="69b5" class="qi ow gt qf b bf qj qk l ql qm"><span class="hljs-meta"># create new timescale vector index (DiskANN) with specified parameters</span>
ts_vector_store.<span class="hljs-built_in">create_index</span>(<span class="hljs-string">"tsv"</span>, max_alpha=<span class="hljs-number">1.0</span>, num_neighbors=<span class="hljs-number">50</span>)</span></pre><p>Advantages to this Timescale Vector’s new DiskANN-inspired vector search index include the following:</p><ul><li>Faster vector search at 99% accuracy in PostgreSQL.</li><li>Optimized for running on disks, not only in memory use.</li><li>Quantization optimization compatible with PostgreSQL, reducing the vector size and consequently shrinking the index size (<a href="https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/?utm_campaign=vectorlaunch&amp;utm_source=llamaindex&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">by 10x in some cases</a>!) and expediting searches.</li><li>Efficient hybrid search or filtering additional dimensions.</li></ul><p>For more on how Timescale Vector’s new index works, <a href="https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/?utm_campaign=vectorlaunch&amp;utm_source=llamaindex&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">see this blog post</a>.</p><p>Pgvector is packaged as part of Timescale Vector, so you can also access pgvector’s HNSW and IVFFLAT indexing algorithms in your LlamaIndex applications. The ability to conveniently create ANN search indexes from your LlamaIndex application code makes it easy to create different indexes and compare their performance:</p><pre><span id="57fe" class="qi ow gt qf b bf qj qk l ql qm"># Create an HNSW index
# Note: You don't need to specify m and ef_construction parameters as we set smart defaults.
ts_vector_store.create_index("hnsw", m=16, ef_construction=64)

# Create an IVFFLAT index
# Note: You don't need to specify num_lists and num_records parameters as we set smart defaults.
ts_vector_store.create_index("ivfflat", num_lists=20, num_records=1000)</span></pre><h1>Add Efficient Time-Based Search Functionality to Your LlamaIndex AI Application</h1><p>Timescale Vector optimizes time-based vector search,<strong> </strong>leveraging the automatic time-based partitioning and indexing of <a href="https://docs.timescale.com/use-timescale/latest/hypertables/" rel="noopener ugc nofollow" target="_blank">Timescale’s hypertables</a> to efficiently search vectors by time and similarity.</p><p>Time is often an important metadata component for vector embeddings. Sources of embeddings, like documents, images, and web pages, often have a timestamp associated with them, for example, their creation date, publishing date, or the date they were last updated, to name but a few.</p><p>We can take advantage of this time metadata in our collections of vector embeddings to enrich the quality and applicability of search results by retrieving vectors that are not just semantically similar but also pertinent to a specific time frame.</p><p>Here are some examples where time-based retrieval of vectors can improve your LlamaIndex applications:</p><ul><li><strong>Finding recent embeddings: </strong>Finding the most recent embeddings that are semantically similar to a query vector. For example, finding the most recent news, documents, or social media posts related to elections.</li><li><strong>Search within a time-range: </strong>Constraining similarity search to only vectors within a relevant time range. For example, asking time-based questions about a knowledge base (“What new features were added between January and March 2023?”).</li><li><strong>Chat history: </strong>Storing and retrieving LLM response history. For example, chatbot chat history.</li></ul><p>Let’s take a look at an example of performing time-based searches on a <a href="https://chat.openai.com/share/0612295b-a408-4e02-9ac2-3dc231fa89d1" rel="noopener ugc nofollow" target="_blank">git log dataset</a>. In a git log, each entry has a timestamp, an author, and some information about the commit.</p><p>To illustrate how to use TimescaleVector’s time-based vector search functionality, we’ll ask questions about the git log history for TimescaleDB. Each git commit entry has a timestamp associated with it, as well as a message and other metadata (e.g., author).</p><p>We’ll illustrate how to create nodes with a time-based UUID and how to run similarity searches with time range filters using the Timescale Vector vector store..</p><h1>Create nodes from each commit in the gitlog</h1><p>First, we load the git log entries from the <a href="https://s3.amazonaws.com/assets.timescale.com/ai/commit_history.csv" rel="noopener ugc nofollow" target="_blank">demo CSV file</a> using Pandas:</p><pre><span id="a7b2" class="qi ow gt qf b bf qj qk l ql qm"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path


<span class="hljs-comment"># Read the CSV file into a DataFrame</span>
file_path = Path(<span class="hljs-string">"../data/csv/commit_history.csv"</span>)
df = pd.read_csv(file_path)</span></pre><p>Next, we’ll create nodes of type `TextNode` for each commit in our git log dataset, extracting the relevant information and assigning it to the node’s text and metadata, respectively.</p><pre><span id="e107" class="qi ow gt qf b bf qj qk l ql qm"><span class="hljs-keyword">from</span> llama_index.schema <span class="hljs-keyword">import</span> TextNode, NodeRelationship, RelatedNodeInfo
<span class="hljs-comment"># Create a Node object from a single row of data</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">create_node</span>(<span class="hljs-params">row</span>):
   record = row.to_dict()
   record_name = split_name(record[<span class="hljs-string">"author"</span>])
   record_content = <span class="hljs-built_in">str</span>(record[<span class="hljs-string">"date"</span>]) + <span class="hljs-string">" "</span> + record_name + <span class="hljs-string">" "</span> + <span class="hljs-built_in">str</span>(record[<span class="hljs-string">"change summary"</span>]) + <span class="hljs-string">" "</span> + <span class="hljs-built_in">str</span>(record[<span class="hljs-string">"change details"</span>])
   node = TextNode(
       id_=create_uuid(record[<span class="hljs-string">"date"</span>]),
       text= record_content,
       metadata={
           <span class="hljs-string">'commit'</span>: record[<span class="hljs-string">"commit"</span>],
           <span class="hljs-string">'author'</span>: record_name,
           <span class="hljs-string">'date'</span>: create_date(record[<span class="hljs-string">"date"</span>]),
       }
   )
   <span class="hljs-keyword">return</span> node

nodes = [create_node(row) <span class="hljs-keyword">for</span> _, row <span class="hljs-keyword">in</span> df.iterrows()]</span></pre><p><strong>Note: </strong>The code above references two helper functions to get things in the right format (`split_name()` and `create_date()`), which we’ve omitted for brevity. The full code is included in the tutorial linked in the Resources section at the end of this post.</p><h1>Create UUIDs for each node based on the date of each git commit</h1><p>We will take a closer look at a helper function we use to create each node’s <code class="cw qn qo qp qf b">id_</code>. For time-based search in LlamaIndex, Timescale Vector uses the ‘datetime’ portion of a UUID v1 to place vectors in the correct time partition. <a href="https://github.com/timescale/python-vector" rel="noopener ugc nofollow" target="_blank">Timescale Vector’s Python client library</a> provides a simple-to-use function named `uuid_from_time` to create a UUID v1 from a Python DateTime object, which we’ll then use as our `ids` for the TextNodes.</p><pre><span id="19d5" class="qi ow gt qf b bf qj qk l ql qm"><span class="hljs-keyword">from</span> timescale_vector <span class="hljs-keyword">import</span> client
<span class="hljs-comment"># Function to take in a date string in the past and return a uuid v1</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">create_uuid</span>(<span class="hljs-params">date_string: <span class="hljs-built_in">str</span></span>):
   <span class="hljs-keyword">if</span> date_string <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
       <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span>
   time_format = <span class="hljs-string">'%a %b %d %H:%M:%S %Y %z'</span>
   datetime_obj = datetime.strptime(date_string, time_format)
   uuid = client.uuid_from_time(datetime_obj)
   <span class="hljs-keyword">return</span> <span class="hljs-built_in">str</span>(uuid)</span></pre><p>Since we are dealing with timestamps in the past, we take advantage of the `uuid_from_time` function to help generate the correct UUIDs for each node. If you want the current date and time associated with your Nodes (or Documents) for time-based search, you can skip this step. A UUID associated with the current date and time will be automatically generated as the nodes are added to the table in Timescale Vector by default.</p><p>Let’s take a look at the contents of a node:</p><pre><span id="7381" class="qi ow gt qf b bf qj qk l ql qm">print(nodes[0].get_content(metadata_mode="all"))</span></pre><pre><span id="7200" class="qi ow gt qf b bf qj qk l ql qm">commit: 44e41c12ab25e36c202f58e068ced262eadc8d16
author: Lakshmi Narayanan Sreethar
date: 2023-09-5 21:03:21+0850

Tue Sep 5 21:03:21 2023 +0530 Lakshmi Narayanan Sreethar Fix segfault in set_integer_now_func When an invalid function oid is passed to set_integer_now_func, it finds out that the function oid is invalid but before throwing the error, it calls ReleaseSysCache on an invalid tuple causing a segfault. Fixed that by removing the invalid call to ReleaseSysCache.  Fixes #6037</span></pre><h1>Create vector embeddings for the text of each node</h1><p>Next, we’ll create vector embeddings of the content of each node so that we can perform similarity searches on the text associated with each node. We’ll use the `OpenAIEmbedding` model to create the embeddings.</p><pre><span id="0a73" class="qi ow gt qf b bf qj qk l ql qm"><span class="hljs-comment"># Create embeddings for nodes</span>
<span class="hljs-keyword">from</span> llama_index.embeddings <span class="hljs-keyword">import</span> OpenAIEmbedding
embedding_model = OpenAIEmbedding()

<span class="hljs-keyword">for</span> node <span class="hljs-keyword">in</span> nodes:
   node_embedding = embedding_model.get_text_embedding(
       node.get_content(metadata_mode=<span class="hljs-string">"all"</span>)
   )
   node.embedding = node_embedding</span></pre><h1>Load nodes into Timescale Vector vector store</h1><p>Next, we’ll create a `TimescaleVectorStore` instance and add the nodes we created to it.</p><pre><span id="550c" class="qi ow gt qf b bf qj qk l ql qm"># Create a timescale vector store and add the newly created nodes to it
ts_vector_store = TimescaleVectorStore.from_params(
   service_url=TIMESCALE_SERVICE_URL,
   table_name="li_commit_history",
   time_partition_interval= timedelta(days=7),
)
ts_vector_store.add(nodes)</span></pre><p>To take advantage of Timescale Vector’s efficient time-based search, we need to specify the `time_partition_interval` argument when instantiating a Timescale Vector vector store. This argument represents the length of each interval for partitioning the data by time. Each partition will consist of data that falls within the specified length of time.</p><p>In the example above, we use seven days for simplicity, but you can pick whatever value makes sense for the queries used by your application — for example, if you query recent vectors frequently, you might want to use a smaller time delta like one day, or if you query vectors over a decade-long time period, then you might want to use a larger time delta like six months or one year. As a rule of thumb, common queries should touch only a couple of partitions and at the same time your full dataset should fit within a 1000 partitions, but don’t stress too much — the system is not very sensitive to this value.</p><h1>Similarity search with time filters</h1><p>Now that we’ve loaded our nodes that contain vector embeddings data and metadata into a Timescale Vector vector store, and enabled automatic time-based partitioning on the table our vectors and metadata are stored in, we can query our vector store with time-based filters as follows:</p><pre><span id="62ab" class="qi ow gt qf b bf qj qk l ql qm"># Query the <span class="hljs-built_in">vector</span> database
vector_store_query = VectorStoreQuery(query_embedding = query_embedding, similarity_top_k=<span class="hljs-number">5</span>)

# Time filter variables <span class="hljs-keyword">for</span> query
start_dt = datetime(<span class="hljs-number">2023</span>, <span class="hljs-number">8</span>, <span class="hljs-number">1</span>, <span class="hljs-number">22</span>, <span class="hljs-number">10</span>, <span class="hljs-number">35</span>) # Start date = <span class="hljs-number">1</span> August <span class="hljs-number">2023</span>, <span class="hljs-number">22</span>:<span class="hljs-number">10</span>:<span class="hljs-number">35</span>
end_dt = datetime(<span class="hljs-number">2023</span>, <span class="hljs-number">8</span>, <span class="hljs-number">30</span>, <span class="hljs-number">22</span>, <span class="hljs-number">10</span>, <span class="hljs-number">35</span>) # End date = <span class="hljs-number">30</span> August <span class="hljs-number">2023</span>, <span class="hljs-number">22</span>:<span class="hljs-number">10</span>:<span class="hljs-number">35</span>

<span class="hljs-meta"># return most similar vectors to query between start date and end date date range</span>
<span class="hljs-meta"># returns a VectorStoreQueryResult object</span>
query_result = ts_vector_store.query(vector_store_query, start_date = start_dt, end_date = end_dt)</span></pre><p>Let’s take a look at the date and contents of the nodes returned by our query:</p><pre><span id="666f" class="qi ow gt qf b bf qj qk l ql qm"><span class="hljs-comment"># for each node in the query result, print the node metadata date</span>
<span class="hljs-keyword">for</span> node <span class="hljs-keyword">in</span> query_result.nodes:
   <span class="hljs-built_in">print</span>(<span class="hljs-string">"-"</span> * <span class="hljs-number">80</span>)
   <span class="hljs-built_in">print</span>(node.metadata[<span class="hljs-string">"date"</span>])
   <span class="hljs-built_in">print</span>(node.get_content(metadata_mode=<span class="hljs-string">"all"</span>))</span></pre><pre><span id="c98b" class="qi ow gt qf b bf qj qk l ql qm">--------------------------------------------------------------------------------
2023-08-3 14:30:23+0500
commit:  7aeed663b9c0f337b530fd6cad47704a51a9b2ec
author: Dmitry Simonenko
date: 2023-08-3 14:30:23+0500

Thu Aug 3 14:30:23 2023 +0300 Dmitry Simonenko Feature flags for TimescaleDB features This PR adds..
--------------------------------------------------------------------------------
2023-08-29 18:13:24+0320
commit:  e4facda540286b0affba47ccc63959fefe2a7b26
author: Sven Klemm
date: 2023-08-29 18:13:24+0320

Tue Aug 29 18:13:24 2023 +0200 Sven Klemm Add compatibility layer for _timescaledb_internal functions With timescaledb 2.12 all the functions present in _timescaledb_internal were…
--------------------------------------------------------------------------------
2023-08-22 12:01:19+0320
commit:  cf04496e4b4237440274eb25e4e02472fc4e06fc
author: Sven Klemm
date: 2023-08-22 12:01:19+0320

Tue Aug 22 12:01:19 2023 +0200 Sven Klemm Move utility functions to _timescaledb_functions schema To increase schema security we do not want to mix…
--------------------------------------------------------------------------------
2023-08-29 10:49:47+0320
commit:  a9751ccd5eb030026d7b975d22753f5964972389
author: Sven Klemm
date: 2023-08-29 10:49:47+0320

Tue Aug 29 10:49:47 2023 +0200 Sven Klemm Move partitioning functions to _timescaledb_functions schema To increase schema security…
--------------------------------------------------------------------------------
2023-08-9 15:26:03+0500
commit:  44eab9cf9bef34274c88efd37a750eaa74cd8044
author: Konstantina Skovola
date: 2023-08-9 15:26:03+0500

Wed Aug 9 15:26:03 2023 +0300 Konstantina Skovola Release 2.11.2 This release contains bug fixes since the 2.11.1 release…</span></pre><p>Success! Notice how only vectors with timestamps within the specified start and end date ranges of 1 August, 2023, and 30 August, 2023, are included in the results.</p><p>Here’s some intuition for why Timescale Vector’s time-based partitioning speeds up ANN queries with time-based filters.</p><p>Timescale Vector partitions the data by time and creates ANN indexes on each partition individually. Then, during search, we perform a three-step process:</p><ul><li>Step 1: filter our partitions that don’t match the time predicate.</li><li>Step 2: perform the similarity search on all matching partitions.</li><li>Step 3: combine all the results from each partition in step 2, rerank, and filter out results by time.</li></ul><p>Timescale Vector leverages <a href="https://docs.timescale.com/use-timescale/latest/hypertables/about-hypertables/" rel="noopener ugc nofollow" target="_blank">TimescaleDB’s hypertables</a>, which automatically partition vectors and associated metadata by a timestamp. This enables efficient querying on vectors by both similarity to a query vector and time, as partitions not in the time window of the query are ignored, making the search a lot more efficient by filtering out whole swaths of data in one go.</p><p>When performing a vector similarity search on `TimescaleVectorStore`, rather than specifying the start and end dates for our search, we can also specify a time filter with a provided start date and time delta later:</p><pre><span id="8eba" class="qi ow gt qf b bf qj qk l ql qm"># return most similar vectors to query from start date and a time delta later
query_result = ts_vector_store.query(vector_store_query, start_date = start_dt, time_delta = td)</span></pre><p>And we can specify a time filter within a provided end_date and time delta earlier. This syntax is very useful for filtering your search results to contain vectors before a certain date cutoff.</p><pre><span id="4769" class="qi ow gt qf b bf qj qk l ql qm"># return most similar vectors to query from end date and a time delta earlier
query_result = ts_vector_store.query(vector_store_query, end_date = end_dt, time_delta = td)</span></pre><h1>Powering Retrieval Augmented Generation With Time-Based Context Retrieval in LlamaIndex Applications With Timescale Vector</h1><p>Let’s put everything together and look at how to use the TimescaleVectorStore to power RAG on the git log dataset we examined above.</p><p>To do this, we can use the TimescaleVectorStore as a <a href="https://gpt-index.readthedocs.io/en/latest/api_reference/query/query_engines.html" rel="noopener ugc nofollow" target="_blank">QueryEngine</a>. When creating the query engine, we use TimescaleVector’s time filters to constrain the search to a relevant time range by passing our time filter parameters as `vector_strore_kwargs`.</p><pre><span id="a136" class="qi ow gt qf b bf qj qk l ql qm"><span class="hljs-keyword">from</span> llama_index <span class="hljs-keyword">import</span> VectorStoreIndex
<span class="hljs-keyword">from</span> llama_index.storage <span class="hljs-keyword">import</span> StorageContext

index = VectorStoreIndex.from_vector_store(ts_vector_store)
query_engine = index.as_query_engine(vector_store_kwargs = ({<span class="hljs-string">"start_date"</span>: start_dt, <span class="hljs-string">"end_date"</span>:end_dt}))

query_str = <span class="hljs-string">"What's new with TimescaleDB functions? When were these changes made and by whom?"</span>
response = query_engine.query(query_str)
<span class="hljs-built_in">print</span>(<span class="hljs-built_in">str</span>(response))</span></pre><p>We asked the LLM a question about our gitlog, namely, “What’s new with TimescaleDB functions. When were these changes made and by whom?”</p><p>Here’s the response we get, which synthesizes the nodes returned from semantic search with time-based filtering on the Timescale VectorStore:</p><pre><span id="48aa" class="qi ow gt qf b bf qj qk l ql qm">TimescaleDB functions have undergone changes recently. These changes include the addition of several GUCs (Global User Configuration) that allow for enabling or disabling major TimescaleDB features. Additionally, a compatibility layer has been added for the "_timescaledb_internal" functions, which were moved into the "_timescaledb_functions" schema to enhance schema security. These changes were made by Dmitry Simonenko and Sven Klemm. The specific dates of these changes are August 3, 2023, and August 29, 2023, respectively.</span></pre><p>This is a simple example of a powerful concept — using time-based context retrieval in your RAG applications can help provide more relevant answers to your users. This time-based context retrieval can be helpful to any dataset with a natural language and time component. Timescale Vector uniquely enables this thanks to its efficient time-based similarity search capabilities, and taking advantage of it in your LlamaIndex application is easy thanks to the Timescale Vector integration.</p><h1>Resources and next steps</h1><p>Now that you’ve learned how Timescale Vector can help you power better AI applications with PostgreSQL, it’s your turn to dive in. Take the next step in your learning journey by following one of the tutorials or reading one of the blog posts in the resource set below:</p><ul><li><a href="https://gpt-index.readthedocs.io/en/stable/examples/vector_stores/Timescalevector.html" rel="noopener ugc nofollow" target="_blank"><strong>Up and Running Tutorial</strong></a><strong>: </strong>learn how to use Timescale Vector in LlamaIndex using a real-world dataset. You’ll learn how to use Timescale Vector as a Vectorstore, Retriever, and QueryEngine and perform time-based similarity search on vectors.</li><li><a href="https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/?utm_campaign=vectorlaunch&amp;utm_source=llamaindex&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"><strong>Timescale Vector explainer</strong></a>: learn more about the internals of Timescale Vector.</li><li><a href="https://www.timescale.com/ai" rel="noopener ugc nofollow" target="_blank"><strong>Timescale Vector website</strong></a><strong>: </strong>learn more about Timescale Vector and Timescale’s AI Launch Week.</li></ul><p><strong>🎉 And a reminder: </strong><a href="https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch&amp;utm_source=llamaindex&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"><strong>LlamaIndex Users get Timescale Vector free for 90 days</strong></a></p><p>We’re giving LlamaIndex users an extended 90-day trial of Timescale Vector. This makes it easy to test and develop your applications on Timescale Vector, as you won’t be charged for any cloud PostgreSQL databases you spin up during your trial period. <a href="https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch&amp;utm_source=llamaindex&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Try Timescale Vector for free today</a>.</p></div><div class="BlogPost_relatedPosts__0z6SN"><h2 class="Text_text__zPO0D Text_text-align-center__HhKqo Text_text-size-16__PkjFu Text_text-weight-400__5ENkK Text_text-family-spaceGrotesk__E4zcE BlogPost_relatedPostsTitle___JIrW">Related articles</h2><ul class="BlogPost_relatedPostsList__uOKzB"><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Faa21c9d353919277d4fce16f174e54280bda8660-1920x832.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Faa21c9d353919277d4fce16f174e54280bda8660-1920x832.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Faa21c9d353919277d4fce16f174e54280bda8660-1920x832.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/jamba-instruct-s-256k-context-window-on-llamaindex">Jamba-Instruct&#x27;s 256k context window on LlamaIndex</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-07-31</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F31290fcec6832b337689a39c17adf5d995ff46b6-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F31290fcec6832b337689a39c17adf5d995ff46b6-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F31290fcec6832b337689a39c17adf5d995ff46b6-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/llamaindex-newsletter-2024-04-02">LlamaIndex Newsletter 2024-04-02</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-04-02</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F67e9da6888edfa6119225413068198422f1eaf77-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F67e9da6888edfa6119225413068198422f1eaf77-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F67e9da6888edfa6119225413068198422f1eaf77-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/llamaindex-newsletter-2024-03-26">LlamaIndex Newsletter 2024-03-26</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-03-26</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F23819f5bd086643f28ca7d2746a9e400f28cdbee-1023x561.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F23819f5bd086643f28ca7d2746a9e400f28cdbee-1023x561.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F23819f5bd086643f28ca7d2746a9e400f28cdbee-1023x561.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations">Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-03-19</p></div></li></ul></div></section></main><footer class="Footer_footer__eNA9m"><div class="Footer_navContainer__7bvx4"><div class="Footer_logoContainer__3EpzI"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" style="color:transparent" src="/llamaindex.svg"/><div class="Footer_socialContainer__GdOgk"><ul class="Socials_socials__8Y_s5"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul></div></div><div class="Footer_nav__BLEuE"><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/">LlamaIndex</a></h3><ul><li><a href="/blog"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Blog</span></a></li><li><a href="/partners"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Partners</span></a></li><li><a href="/careers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Careers</span></a></li><li><a href="/contact"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Contact</span></a></li><li><a href="/brand"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Brand</span></a></li><li><a href="https://llamaindex.statuspage.io" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Status</span></a></li><li><a href="https://app.vanta.com/runllama.ai/trust/pkcgbjf8b3ihxjpqdx17nu" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Trust Center</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/enterprise">Enterprise</a></h3><ul><li><a href="https://cloud.llamaindex.ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaCloud</span></a></li><li><a href="https://cloud.llamaindex.ai/parse" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaParse</span></a></li><li><a href="/customers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Customers</span></a></li><li><a href="/llamacloud-sharepoint-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SharePoint</span></a></li><li><a href="/llamacloud-aws-s3-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">AWS S3</span></a></li><li><a href="/llamacloud-azure-blob-storage-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure Blob Storage</span></a></li><li><a href="/llamacloud-google-drive-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Google Drive</span></a></li> </ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/framework">Framework</a></h3><ul><li><a href="https://pypi.org/project/llama-index/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python package</span></a></li><li><a href="https://docs.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python docs</span></a></li><li><a href="https://www.npmjs.com/package/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript package</span></a></li><li><a href="https://ts.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript docs</span></a></li><li><a href="https://llamahub.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaHub</span></a></li><li><a href="https://github.com/run-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">GitHub</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/community">Community</a></h3><ul><li><a href="/community#newsletter"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Newsletter</span></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Discord</span></a></li><li><a href="https://www.linkedin.com/company/91154103/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LinkedIn</span></a></li><li><a href="https://twitter.com/llama_index"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Twitter/X</span></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">YouTube</span></a></li><li><a href="https://bsky.app/profile/llamaindex.bsky.social"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">BlueSky</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e">Starter projects</h3><ul><li><a href="https://www.npmjs.com/package/create-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">create-llama</span></a></li><li><a href="https://secinsights.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SEC Insights</span></a></li><li><a href="https://github.com/run-llama/llamabot"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaBot</span></a></li><li><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/rag_cli.html"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">RAG CLI</span></a></li></ul></div></div></div><div class="Footer_copyrightContainer__mBKsT"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA">© <!-- -->2025<!-- --> LlamaIndex</p><div class="Footer_legalNav__O1yJA"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/privacy-notice.pdf">Privacy Notice</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/terms-of-service.pdf">Terms of Service</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="https://bit.ly/llamaindexdpa">Data Processing Addendum</a></p></div></div></footer></div><svg xmlns="http://www.w3.org/2000/svg" class="flt_svg" style="display:none"><defs><filter id="flt_tag"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="2"></feGaussianBlur><feColorMatrix in="blur" result="flt_tag" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="flt_tag" operator="atop"></feComposite></filter><filter id="svg_blur_large"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="8"></feGaussianBlur><feColorMatrix in="blur" result="svg_blur_large" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="svg_blur_large" operator="atop"></feComposite></filter></defs></svg></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"page":{"announcement":{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"},"post":{"_createdAt":"2024-02-22T21:47:07Z","_id":"70c51608-8741-421d-8ff3-d35fc9fb90da","_rev":"05dtDS0H5iRVsxYMarZDh3","_type":"blogPost","_updatedAt":"2025-05-21T20:38:08Z","announcement":[{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"}],"authors":[{"_createdAt":"2024-02-22T19:59:39Z","_id":"26898661-ce74-4e56-a3bb-21000059ea8d","_rev":"1yZmiycp7gyBYGbmM40Ock","_type":"people","_updatedAt":"2025-05-07T15:41:41Z","image":{"_type":"image","asset":{"_ref":"image-e4426ff6862cbb8bec81b8407730e6e1e9383c8f-2176x2176-jpg","_type":"reference"}},"name":"Jerry Liu","position":"CEO","slug":{"_type":"slug","current":"jerry-liu"}}],"featured":false,"htmlContent":"\u003cp\u003eAuthors: Avthar Sewrathan, Matvey Arye, Jerry Liu, Yi Ding\u003c/p\u003e\u003cp\u003eIntroducing the \u003ca href=\"https://www.timescale.com/ai\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTimescale Vector\u003c/a\u003e integration for LlamaIndex. Timescale Vector enables LlamaIndex developers to build better AI applications with PostgreSQL as their vector database: with faster vector similarity search, efficient time-based search filtering, and the operational simplicity of a single, easy-to-use cloud PostgreSQL database for not only vector embeddings but an AI application’s relational and time-series data too.\u003c/p\u003e\u003cp\u003ePostgreSQL is the world’s most loved database, according to the \u003ca href=\"https://survey.stackoverflow.co/2023/#section-most-popular-technologies-databases\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eStack Overflow 2023 Developer Survey\u003c/a\u003e. And for a good reason: it’s been battle-hardened by production use for over three decades, it’s robust and reliable, and it has a rich ecosystem of tools, drivers, and connectors.\u003c/p\u003e\u003cp\u003eAnd while pgvector, the open-source extension for vector data on PostgreSQL, is a wonderful extension (and all its features are offered as part of Timescale Vector), it is just one piece of the puzzle in providing a production-grade experience for AI application developers on PostgreSQL. After speaking with numerous developers at nimble startups and established industry giants, we saw the need to enhance pgvector to cater to the performance and operational needs of developers building AI applications.\u003c/p\u003e\u003cp\u003eHere’s the TL;DR on how Timescale Vector helps you build better AI applications with LlamaIndex:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eFaster similarity search on millions of vectors: \u003c/strong\u003eThanks to the introduction of a new search index inspired by the DiskANN algorithm, \u003ca href=\"https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/?utm_campaign=vectorlaunch\u0026amp;utm_source=llamaindex\u0026amp;utm_medium=referral\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTimescale Vector achieves 3X faster search speed at ~99% recall than a specialized database\u003c/a\u003e and outperforms all existing PostgreSQL search indexes by between 39.39% and 1,590.33% on a dataset of one million OpenAI embeddings. Plus, enabling product quantization yields a \u003ca href=\"https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/?utm_campaign=vectorlaunch\u0026amp;utm_source=llamaindex\u0026amp;utm_medium=referral\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e10x index space savings compared to pgvector\u003c/a\u003e. Timescale Vector also offers pgvector’s Hierarchical Navigable Small Worlds (HNSW) and Inverted File Flat (IVFFlat) indexing algorithms.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eEfficient similarity search with time-based filtering: \u003c/strong\u003eTimescale Vector optimizes time-based vector search queries, leveraging the automatic time-based partitioning and indexing of \u003ca href=\"https://docs.timescale.com/use-timescale/latest/hypertables/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTimescale’s hypertables\u003c/a\u003e to efficiently find recent embeddings, constrain vector search by a time range or document age, and store and retrieve large language model (LLM) response and chat history with ease. Time-based semantic search also enables you to use Retrieval Augmented Generation (RAG) with time-based context retrieval to give users more useful LLM responses.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eSimplified AI infra stack:\u003c/strong\u003e By combining vector embeddings, relational data, and time-series data in one PostgreSQL database, Timescale Vector eliminates the operational complexity that comes with managing multiple database systems at scale.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eSimplified metadata handling and multi-attribute filtering: \u003c/strong\u003eDevelopers can leverage all PostgreSQL data types to store and filter metadata and JOIN vector search results with relational data for more contextually relevant responses. In future releases, Timescale Vector will further optimize rich multi-attribute filtering, enabling even faster similarity searches when filtering on metadata.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOn top of these innovations for vector workloads, Timescale Vector provides a robust, production-ready cloud PostgreSQL platform with flexible pricing, enterprise-grade security, and free expert support.\u003c/p\u003e\u003cp\u003eIn the rest of this post, we’ll dive deeper (with code!) into the unique capabilities Timescale Vector enables for developers wanting to use PostgreSQL as their vector database with LlamaIndex:\u003c/p\u003e\u003cul\u003e\u003cli\u003eFaster similarity search with DiskANN, HNSW and IVFFlat index types.\u003c/li\u003e\u003cli\u003eEfficient similarity search when filtering vectors by time.\u003c/li\u003e\u003cli\u003eRetrieval Augmented Generation (RAG) with time-based context retrieval.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e(If you want to jump straight to the code, explore \u003ca href=\"https://gpt-index.readthedocs.io/en/stable/examples/vector_stores/Timescalevector.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ethis tutorial\u003c/a\u003e).\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e🎉 \u003c/strong\u003e\u003ca href=\"https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch\u0026amp;utm_source=llamaindex\u0026amp;utm_medium=referral\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eLlamaIndex Users Get 3 Months of Timescale Vector for Free\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\u003cp\u003eWe’re giving LlamaIndex users an extended 90-day trial of Timescale Vector. This makes it easy to test and develop your applications on Timescale Vector, as you won’t be charged for any cloud PostgreSQL databases you spin up during your trial period. \u003ca href=\"https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch\u0026amp;utm_source=llamaindex\u0026amp;utm_medium=referral\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTry Timescale Vector for free today\u003c/a\u003e.\u003c/p\u003e\u003ch1\u003eFaster Vector Similarity Search in PostgreSQL\u003c/h1\u003e\u003cp\u003eTimescale Vector speeds up Approximate Nearest Neighbor (ANN) search on large-scale vector datasets, enhancing pgvector with a state-of-the-art ANN index inspired by the \u003ca href=\"https://www.microsoft.com/en-us/research/publication/diskann-fast-accurate-billion-point-nearest-neighbor-search-on-a-single-node/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDiskANN\u003c/a\u003e algorithm. Timescale Vector also offers pgvector’s HNSW and IVFFlat indexing algorithms, giving developers the flexibility to choose the right index for their use case.\u003c/p\u003e\u003cp\u003eOur performance benchmarks using the \u003ca href=\"https://github.com/erikbern/ann-benchmarks/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eANN benchmarks\u003c/a\u003e suite show that Timescale Vector achieves between 39.43% and 1,590.33% faster search speed at ~99% recall than all existing PostgreSQL search indexes, and 3X faster search speed at ~99% recall than specialized vector databases on a dataset of one million OpenAI embeddings. You can \u003ca href=\"https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/?utm_campaign=vectorlaunch\u0026amp;utm_source=llamaindex\u0026amp;utm_medium=referral\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eread more about the performance benchmark methodology, the databases compared and results here\u003c/a\u003e.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption class=\"pz fe qa ny nz qb qc be b bf z dt\"\u003e\u003cem class=\"qd\"\u003eTimescale Vector’s new DiskANN-inspired index outperforms all existing PostgreSQL index types when performing approximate nearest neighbor searches at 99 % recall on 1 million OpenAI embeddings.\u003c/em\u003e\u003c/figcaption\u003e\u003cimg src=\"/blog/images/1*FJl9RN0Se1eKDsd97bn02A.png\" alt=\"\" width=\"700\" height=\"478\"\u003e\u003c/figure\u003e\u003cp\u003eUsing Timescale Vector’s DiskANN, HNSW, or IVFFLAT indexes in LlamaIndex is incredibly straightforward.\u003c/p\u003e\u003cp\u003eSimply create a Timescale Vector vector store and add the \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/core_modules/data_modules/documents_and_nodes/usage_nodes.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003edata nodes\u003c/a\u003e you want to query as shown below:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"e55c\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.vector_stores \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e TimescaleVectorStore\n\n\u003cspan class=\"hljs-comment\"\u003e# Create a timescale vector store with specified params\u003c/span\u003e\nts_vector_store = TimescaleVectorStore.from_params(\n   service_url=TIMESCALE_SERVICE_URL,\n   table_name=\u003cspan class=\"hljs-string\"\u003e\"your_table_name\"\u003c/span\u003e,\n   time_partition_interval= timedelta(days=\u003cspan class=\"hljs-number\"\u003e7\u003c/span\u003e),\n)\nts_vector_store.add(nodes)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003eThen run:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"b587\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003e# Create a timescale vector index (DiskANN)\nts_vector_store.create_index()\u003c/span\u003e\u003c/pre\u003e\u003cp\u003eThis will create a timescale-vector index with the default parameters.\u003c/p\u003e\u003cp\u003eWe should point out that the term “index” is a bit overloaded. For many VectorStores, an index is the thing that stores your data (in relational databases this is often called a table), but in the PostgreSQL world an index is something that speeds up search, and we are using the latter meaning here.\u003c/p\u003e\u003cp\u003eWe can also specify the exact parameters for index creation in the \u003ccode class=\"cw qn qo qp qf b\"\u003ecreate_index\u003c/code\u003e command as follows:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"69b5\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003e\u003cspan class=\"hljs-meta\"\u003e# create new timescale vector index (DiskANN) with specified parameters\u003c/span\u003e\nts_vector_store.\u003cspan class=\"hljs-built_in\"\u003ecreate_index\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"tsv\"\u003c/span\u003e, max_alpha=\u003cspan class=\"hljs-number\"\u003e1.0\u003c/span\u003e, num_neighbors=\u003cspan class=\"hljs-number\"\u003e50\u003c/span\u003e)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003eAdvantages to this Timescale Vector’s new DiskANN-inspired vector search index include the following:\u003c/p\u003e\u003cul\u003e\u003cli\u003eFaster vector search at 99% accuracy in PostgreSQL.\u003c/li\u003e\u003cli\u003eOptimized for running on disks, not only in memory use.\u003c/li\u003e\u003cli\u003eQuantization optimization compatible with PostgreSQL, reducing the vector size and consequently shrinking the index size (\u003ca href=\"https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/?utm_campaign=vectorlaunch\u0026amp;utm_source=llamaindex\u0026amp;utm_medium=referral\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eby 10x in some cases\u003c/a\u003e!) and expediting searches.\u003c/li\u003e\u003cli\u003eEfficient hybrid search or filtering additional dimensions.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eFor more on how Timescale Vector’s new index works, \u003ca href=\"https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/?utm_campaign=vectorlaunch\u0026amp;utm_source=llamaindex\u0026amp;utm_medium=referral\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003esee this blog post\u003c/a\u003e.\u003c/p\u003e\u003cp\u003ePgvector is packaged as part of Timescale Vector, so you can also access pgvector’s HNSW and IVFFLAT indexing algorithms in your LlamaIndex applications. The ability to conveniently create ANN search indexes from your LlamaIndex application code makes it easy to create different indexes and compare their performance:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"57fe\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003e# Create an HNSW index\n# Note: You don't need to specify m and ef_construction parameters as we set smart defaults.\nts_vector_store.create_index(\"hnsw\", m=16, ef_construction=64)\n\n# Create an IVFFLAT index\n# Note: You don't need to specify num_lists and num_records parameters as we set smart defaults.\nts_vector_store.create_index(\"ivfflat\", num_lists=20, num_records=1000)\u003c/span\u003e\u003c/pre\u003e\u003ch1\u003eAdd Efficient Time-Based Search Functionality to Your LlamaIndex AI Application\u003c/h1\u003e\u003cp\u003eTimescale Vector optimizes time-based vector search,\u003cstrong\u003e \u003c/strong\u003eleveraging the automatic time-based partitioning and indexing of \u003ca href=\"https://docs.timescale.com/use-timescale/latest/hypertables/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTimescale’s hypertables\u003c/a\u003e to efficiently search vectors by time and similarity.\u003c/p\u003e\u003cp\u003eTime is often an important metadata component for vector embeddings. Sources of embeddings, like documents, images, and web pages, often have a timestamp associated with them, for example, their creation date, publishing date, or the date they were last updated, to name but a few.\u003c/p\u003e\u003cp\u003eWe can take advantage of this time metadata in our collections of vector embeddings to enrich the quality and applicability of search results by retrieving vectors that are not just semantically similar but also pertinent to a specific time frame.\u003c/p\u003e\u003cp\u003eHere are some examples where time-based retrieval of vectors can improve your LlamaIndex applications:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eFinding recent embeddings: \u003c/strong\u003eFinding the most recent embeddings that are semantically similar to a query vector. For example, finding the most recent news, documents, or social media posts related to elections.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eSearch within a time-range: \u003c/strong\u003eConstraining similarity search to only vectors within a relevant time range. For example, asking time-based questions about a knowledge base (“What new features were added between January and March 2023?”).\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eChat history: \u003c/strong\u003eStoring and retrieving LLM response history. For example, chatbot chat history.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eLet’s take a look at an example of performing time-based searches on a \u003ca href=\"https://chat.openai.com/share/0612295b-a408-4e02-9ac2-3dc231fa89d1\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003egit log dataset\u003c/a\u003e. In a git log, each entry has a timestamp, an author, and some information about the commit.\u003c/p\u003e\u003cp\u003eTo illustrate how to use TimescaleVector’s time-based vector search functionality, we’ll ask questions about the git log history for TimescaleDB. Each git commit entry has a timestamp associated with it, as well as a message and other metadata (e.g., author).\u003c/p\u003e\u003cp\u003eWe’ll illustrate how to create nodes with a time-based UUID and how to run similarity searches with time range filters using the Timescale Vector vector store..\u003c/p\u003e\u003ch1\u003eCreate nodes from each commit in the gitlog\u003c/h1\u003e\u003cp\u003eFirst, we load the git log entries from the \u003ca href=\"https://s3.amazonaws.com/assets.timescale.com/ai/commit_history.csv\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003edemo CSV file\u003c/a\u003e using Pandas:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"a7b2\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e pd\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e pathlib \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Path\n\n\n\u003cspan class=\"hljs-comment\"\u003e# Read the CSV file into a DataFrame\u003c/span\u003e\nfile_path = Path(\u003cspan class=\"hljs-string\"\u003e\"../data/csv/commit_history.csv\"\u003c/span\u003e)\ndf = pd.read_csv(file_path)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003eNext, we’ll create nodes of type `TextNode` for each commit in our git log dataset, extracting the relevant information and assigning it to the node’s text and metadata, respectively.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"e107\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.schema \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e TextNode, NodeRelationship, RelatedNodeInfo\n\u003cspan class=\"hljs-comment\"\u003e# Create a Node object from a single row of data\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003ecreate_node\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003erow\u003c/span\u003e):\n   record = row.to_dict()\n   record_name = split_name(record[\u003cspan class=\"hljs-string\"\u003e\"author\"\u003c/span\u003e])\n   record_content = \u003cspan class=\"hljs-built_in\"\u003estr\u003c/span\u003e(record[\u003cspan class=\"hljs-string\"\u003e\"date\"\u003c/span\u003e]) + \u003cspan class=\"hljs-string\"\u003e\" \"\u003c/span\u003e + record_name + \u003cspan class=\"hljs-string\"\u003e\" \"\u003c/span\u003e + \u003cspan class=\"hljs-built_in\"\u003estr\u003c/span\u003e(record[\u003cspan class=\"hljs-string\"\u003e\"change summary\"\u003c/span\u003e]) + \u003cspan class=\"hljs-string\"\u003e\" \"\u003c/span\u003e + \u003cspan class=\"hljs-built_in\"\u003estr\u003c/span\u003e(record[\u003cspan class=\"hljs-string\"\u003e\"change details\"\u003c/span\u003e])\n   node = TextNode(\n       id_=create_uuid(record[\u003cspan class=\"hljs-string\"\u003e\"date\"\u003c/span\u003e]),\n       text= record_content,\n       metadata={\n           \u003cspan class=\"hljs-string\"\u003e'commit'\u003c/span\u003e: record[\u003cspan class=\"hljs-string\"\u003e\"commit\"\u003c/span\u003e],\n           \u003cspan class=\"hljs-string\"\u003e'author'\u003c/span\u003e: record_name,\n           \u003cspan class=\"hljs-string\"\u003e'date'\u003c/span\u003e: create_date(record[\u003cspan class=\"hljs-string\"\u003e\"date\"\u003c/span\u003e]),\n       }\n   )\n   \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e node\n\nnodes = [create_node(row) \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e _, row \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e df.iterrows()]\u003c/span\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eNote: \u003c/strong\u003eThe code above references two helper functions to get things in the right format (`split_name()` and `create_date()`), which we’ve omitted for brevity. The full code is included in the tutorial linked in the Resources section at the end of this post.\u003c/p\u003e\u003ch1\u003eCreate UUIDs for each node based on the date of each git commit\u003c/h1\u003e\u003cp\u003eWe will take a closer look at a helper function we use to create each node’s \u003ccode class=\"cw qn qo qp qf b\"\u003eid_\u003c/code\u003e. For time-based search in LlamaIndex, Timescale Vector uses the ‘datetime’ portion of a UUID v1 to place vectors in the correct time partition. \u003ca href=\"https://github.com/timescale/python-vector\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTimescale Vector’s Python client library\u003c/a\u003e provides a simple-to-use function named `uuid_from_time` to create a UUID v1 from a Python DateTime object, which we’ll then use as our `ids` for the TextNodes.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"19d5\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e timescale_vector \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e client\n\u003cspan class=\"hljs-comment\"\u003e# Function to take in a date string in the past and return a uuid v1\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003ecreate_uuid\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003edate_string: \u003cspan class=\"hljs-built_in\"\u003estr\u003c/span\u003e\u003c/span\u003e):\n   \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e date_string \u003cspan class=\"hljs-keyword\"\u003eis\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e:\n       \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e\n   time_format = \u003cspan class=\"hljs-string\"\u003e'%a %b %d %H:%M:%S %Y %z'\u003c/span\u003e\n   datetime_obj = datetime.strptime(date_string, time_format)\n   uuid = client.uuid_from_time(datetime_obj)\n   \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003estr\u003c/span\u003e(uuid)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003eSince we are dealing with timestamps in the past, we take advantage of the `uuid_from_time` function to help generate the correct UUIDs for each node. If you want the current date and time associated with your Nodes (or Documents) for time-based search, you can skip this step. A UUID associated with the current date and time will be automatically generated as the nodes are added to the table in Timescale Vector by default.\u003c/p\u003e\u003cp\u003eLet’s take a look at the contents of a node:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"7381\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003eprint(nodes[0].get_content(metadata_mode=\"all\"))\u003c/span\u003e\u003c/pre\u003e\u003cpre\u003e\u003cspan id=\"7200\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003ecommit: 44e41c12ab25e36c202f58e068ced262eadc8d16\nauthor: Lakshmi Narayanan Sreethar\ndate: 2023-09-5 21:03:21+0850\n\nTue Sep 5 21:03:21 2023 +0530 Lakshmi Narayanan Sreethar Fix segfault in set_integer_now_func When an invalid function oid is passed to set_integer_now_func, it finds out that the function oid is invalid but before throwing the error, it calls ReleaseSysCache on an invalid tuple causing a segfault. Fixed that by removing the invalid call to ReleaseSysCache.  Fixes #6037\u003c/span\u003e\u003c/pre\u003e\u003ch1\u003eCreate vector embeddings for the text of each node\u003c/h1\u003e\u003cp\u003eNext, we’ll create vector embeddings of the content of each node so that we can perform similarity searches on the text associated with each node. We’ll use the `OpenAIEmbedding` model to create the embeddings.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"0a73\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003e\u003cspan class=\"hljs-comment\"\u003e# Create embeddings for nodes\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.embeddings \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e OpenAIEmbedding\nembedding_model = OpenAIEmbedding()\n\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e node \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e nodes:\n   node_embedding = embedding_model.get_text_embedding(\n       node.get_content(metadata_mode=\u003cspan class=\"hljs-string\"\u003e\"all\"\u003c/span\u003e)\n   )\n   node.embedding = node_embedding\u003c/span\u003e\u003c/pre\u003e\u003ch1\u003eLoad nodes into Timescale Vector vector store\u003c/h1\u003e\u003cp\u003eNext, we’ll create a `TimescaleVectorStore` instance and add the nodes we created to it.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"550c\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003e# Create a timescale vector store and add the newly created nodes to it\nts_vector_store = TimescaleVectorStore.from_params(\n   service_url=TIMESCALE_SERVICE_URL,\n   table_name=\"li_commit_history\",\n   time_partition_interval= timedelta(days=7),\n)\nts_vector_store.add(nodes)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003eTo take advantage of Timescale Vector’s efficient time-based search, we need to specify the `time_partition_interval` argument when instantiating a Timescale Vector vector store. This argument represents the length of each interval for partitioning the data by time. Each partition will consist of data that falls within the specified length of time.\u003c/p\u003e\u003cp\u003eIn the example above, we use seven days for simplicity, but you can pick whatever value makes sense for the queries used by your application — for example, if you query recent vectors frequently, you might want to use a smaller time delta like one day, or if you query vectors over a decade-long time period, then you might want to use a larger time delta like six months or one year. As a rule of thumb, common queries should touch only a couple of partitions and at the same time your full dataset should fit within a 1000 partitions, but don’t stress too much — the system is not very sensitive to this value.\u003c/p\u003e\u003ch1\u003eSimilarity search with time filters\u003c/h1\u003e\u003cp\u003eNow that we’ve loaded our nodes that contain vector embeddings data and metadata into a Timescale Vector vector store, and enabled automatic time-based partitioning on the table our vectors and metadata are stored in, we can query our vector store with time-based filters as follows:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"62ab\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003e# Query the \u003cspan class=\"hljs-built_in\"\u003evector\u003c/span\u003e database\nvector_store_query = VectorStoreQuery(query_embedding = query_embedding, similarity_top_k=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e)\n\n# Time filter variables \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e query\nstart_dt = datetime(\u003cspan class=\"hljs-number\"\u003e2023\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e22\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e35\u003c/span\u003e) # Start date = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e August \u003cspan class=\"hljs-number\"\u003e2023\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e22\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e35\u003c/span\u003e\nend_dt = datetime(\u003cspan class=\"hljs-number\"\u003e2023\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e30\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e22\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e35\u003c/span\u003e) # End date = \u003cspan class=\"hljs-number\"\u003e30\u003c/span\u003e August \u003cspan class=\"hljs-number\"\u003e2023\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e22\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e35\u003c/span\u003e\n\n\u003cspan class=\"hljs-meta\"\u003e# return most similar vectors to query between start date and end date date range\u003c/span\u003e\n\u003cspan class=\"hljs-meta\"\u003e# returns a VectorStoreQueryResult object\u003c/span\u003e\nquery_result = ts_vector_store.query(vector_store_query, start_date = start_dt, end_date = end_dt)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003eLet’s take a look at the date and contents of the nodes returned by our query:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"666f\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003e\u003cspan class=\"hljs-comment\"\u003e# for each node in the query result, print the node metadata date\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e node \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e query_result.nodes:\n   \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"-\"\u003c/span\u003e * \u003cspan class=\"hljs-number\"\u003e80\u003c/span\u003e)\n   \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(node.metadata[\u003cspan class=\"hljs-string\"\u003e\"date\"\u003c/span\u003e])\n   \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(node.get_content(metadata_mode=\u003cspan class=\"hljs-string\"\u003e\"all\"\u003c/span\u003e))\u003c/span\u003e\u003c/pre\u003e\u003cpre\u003e\u003cspan id=\"c98b\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003e--------------------------------------------------------------------------------\n2023-08-3 14:30:23+0500\ncommit:  7aeed663b9c0f337b530fd6cad47704a51a9b2ec\nauthor: Dmitry Simonenko\ndate: 2023-08-3 14:30:23+0500\n\nThu Aug 3 14:30:23 2023 +0300 Dmitry Simonenko Feature flags for TimescaleDB features This PR adds..\n--------------------------------------------------------------------------------\n2023-08-29 18:13:24+0320\ncommit:  e4facda540286b0affba47ccc63959fefe2a7b26\nauthor: Sven Klemm\ndate: 2023-08-29 18:13:24+0320\n\nTue Aug 29 18:13:24 2023 +0200 Sven Klemm Add compatibility layer for _timescaledb_internal functions With timescaledb 2.12 all the functions present in _timescaledb_internal were…\n--------------------------------------------------------------------------------\n2023-08-22 12:01:19+0320\ncommit:  cf04496e4b4237440274eb25e4e02472fc4e06fc\nauthor: Sven Klemm\ndate: 2023-08-22 12:01:19+0320\n\nTue Aug 22 12:01:19 2023 +0200 Sven Klemm Move utility functions to _timescaledb_functions schema To increase schema security we do not want to mix…\n--------------------------------------------------------------------------------\n2023-08-29 10:49:47+0320\ncommit:  a9751ccd5eb030026d7b975d22753f5964972389\nauthor: Sven Klemm\ndate: 2023-08-29 10:49:47+0320\n\nTue Aug 29 10:49:47 2023 +0200 Sven Klemm Move partitioning functions to _timescaledb_functions schema To increase schema security…\n--------------------------------------------------------------------------------\n2023-08-9 15:26:03+0500\ncommit:  44eab9cf9bef34274c88efd37a750eaa74cd8044\nauthor: Konstantina Skovola\ndate: 2023-08-9 15:26:03+0500\n\nWed Aug 9 15:26:03 2023 +0300 Konstantina Skovola Release 2.11.2 This release contains bug fixes since the 2.11.1 release…\u003c/span\u003e\u003c/pre\u003e\u003cp\u003eSuccess! Notice how only vectors with timestamps within the specified start and end date ranges of 1 August, 2023, and 30 August, 2023, are included in the results.\u003c/p\u003e\u003cp\u003eHere’s some intuition for why Timescale Vector’s time-based partitioning speeds up ANN queries with time-based filters.\u003c/p\u003e\u003cp\u003eTimescale Vector partitions the data by time and creates ANN indexes on each partition individually. Then, during search, we perform a three-step process:\u003c/p\u003e\u003cul\u003e\u003cli\u003eStep 1: filter our partitions that don’t match the time predicate.\u003c/li\u003e\u003cli\u003eStep 2: perform the similarity search on all matching partitions.\u003c/li\u003e\u003cli\u003eStep 3: combine all the results from each partition in step 2, rerank, and filter out results by time.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eTimescale Vector leverages \u003ca href=\"https://docs.timescale.com/use-timescale/latest/hypertables/about-hypertables/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTimescaleDB’s hypertables\u003c/a\u003e, which automatically partition vectors and associated metadata by a timestamp. This enables efficient querying on vectors by both similarity to a query vector and time, as partitions not in the time window of the query are ignored, making the search a lot more efficient by filtering out whole swaths of data in one go.\u003c/p\u003e\u003cp\u003eWhen performing a vector similarity search on `TimescaleVectorStore`, rather than specifying the start and end dates for our search, we can also specify a time filter with a provided start date and time delta later:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"8eba\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003e# return most similar vectors to query from start date and a time delta later\nquery_result = ts_vector_store.query(vector_store_query, start_date = start_dt, time_delta = td)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003eAnd we can specify a time filter within a provided end_date and time delta earlier. This syntax is very useful for filtering your search results to contain vectors before a certain date cutoff.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"4769\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003e# return most similar vectors to query from end date and a time delta earlier\nquery_result = ts_vector_store.query(vector_store_query, end_date = end_dt, time_delta = td)\u003c/span\u003e\u003c/pre\u003e\u003ch1\u003ePowering Retrieval Augmented Generation With Time-Based Context Retrieval in LlamaIndex Applications With Timescale Vector\u003c/h1\u003e\u003cp\u003eLet’s put everything together and look at how to use the TimescaleVectorStore to power RAG on the git log dataset we examined above.\u003c/p\u003e\u003cp\u003eTo do this, we can use the TimescaleVectorStore as a \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/api_reference/query/query_engines.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eQueryEngine\u003c/a\u003e. When creating the query engine, we use TimescaleVector’s time filters to constrain the search to a relevant time range by passing our time filter parameters as `vector_strore_kwargs`.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"a136\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e VectorStoreIndex\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.storage \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e StorageContext\n\nindex = VectorStoreIndex.from_vector_store(ts_vector_store)\nquery_engine = index.as_query_engine(vector_store_kwargs = ({\u003cspan class=\"hljs-string\"\u003e\"start_date\"\u003c/span\u003e: start_dt, \u003cspan class=\"hljs-string\"\u003e\"end_date\"\u003c/span\u003e:end_dt}))\n\nquery_str = \u003cspan class=\"hljs-string\"\u003e\"What's new with TimescaleDB functions? When were these changes made and by whom?\"\u003c/span\u003e\nresponse = query_engine.query(query_str)\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-built_in\"\u003estr\u003c/span\u003e(response))\u003c/span\u003e\u003c/pre\u003e\u003cp\u003eWe asked the LLM a question about our gitlog, namely, “What’s new with TimescaleDB functions. When were these changes made and by whom?”\u003c/p\u003e\u003cp\u003eHere’s the response we get, which synthesizes the nodes returned from semantic search with time-based filtering on the Timescale VectorStore:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"48aa\" class=\"qi ow gt qf b bf qj qk l ql qm\"\u003eTimescaleDB functions have undergone changes recently. These changes include the addition of several GUCs (Global User Configuration) that allow for enabling or disabling major TimescaleDB features. Additionally, a compatibility layer has been added for the \"_timescaledb_internal\" functions, which were moved into the \"_timescaledb_functions\" schema to enhance schema security. These changes were made by Dmitry Simonenko and Sven Klemm. The specific dates of these changes are August 3, 2023, and August 29, 2023, respectively.\u003c/span\u003e\u003c/pre\u003e\u003cp\u003eThis is a simple example of a powerful concept — using time-based context retrieval in your RAG applications can help provide more relevant answers to your users. This time-based context retrieval can be helpful to any dataset with a natural language and time component. Timescale Vector uniquely enables this thanks to its efficient time-based similarity search capabilities, and taking advantage of it in your LlamaIndex application is easy thanks to the Timescale Vector integration.\u003c/p\u003e\u003ch1\u003eResources and next steps\u003c/h1\u003e\u003cp\u003eNow that you’ve learned how Timescale Vector can help you power better AI applications with PostgreSQL, it’s your turn to dive in. Take the next step in your learning journey by following one of the tutorials or reading one of the blog posts in the resource set below:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://gpt-index.readthedocs.io/en/stable/examples/vector_stores/Timescalevector.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eUp and Running Tutorial\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e: \u003c/strong\u003elearn how to use Timescale Vector in LlamaIndex using a real-world dataset. You’ll learn how to use Timescale Vector as a Vectorstore, Retriever, and QueryEngine and perform time-based similarity search on vectors.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/?utm_campaign=vectorlaunch\u0026amp;utm_source=llamaindex\u0026amp;utm_medium=referral\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eTimescale Vector explainer\u003c/strong\u003e\u003c/a\u003e: learn more about the internals of Timescale Vector.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.timescale.com/ai\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eTimescale Vector website\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e: \u003c/strong\u003elearn more about Timescale Vector and Timescale’s AI Launch Week.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003e🎉 And a reminder: \u003c/strong\u003e\u003ca href=\"https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch\u0026amp;utm_source=llamaindex\u0026amp;utm_medium=referral\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eLlamaIndex Users get Timescale Vector free for 90 days\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\u003cp\u003eWe’re giving LlamaIndex users an extended 90-day trial of Timescale Vector. This makes it easy to test and develop your applications on Timescale Vector, as you won’t be charged for any cloud PostgreSQL databases you spin up during your trial period. \u003ca href=\"https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch\u0026amp;utm_source=llamaindex\u0026amp;utm_medium=referral\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTry Timescale Vector for free today\u003c/a\u003e.\u003c/p\u003e","image":{"_type":"image","asset":{"_ref":"image-052f06ed820cbc8594226339312addade98b50a3-2400x1350-png","_type":"reference"}},"mainImage":"https://cdn.sanity.io/images/7m9jw85w/production/052f06ed820cbc8594226339312addade98b50a3-2400x1350.png","publishedDate":"2023-09-27","relatedPosts":[{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-aa21c9d353919277d4fce16f174e54280bda8660-1920x832-png","_type":"reference"}},"publishedDate":"2024-07-31","slug":"jamba-instruct-s-256k-context-window-on-llamaindex","title":"Jamba-Instruct's 256k context window on LlamaIndex"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-31290fcec6832b337689a39c17adf5d995ff46b6-1024x1024-webp","_type":"reference"}},"publishedDate":"2024-04-02","slug":"llamaindex-newsletter-2024-04-02","title":"LlamaIndex Newsletter 2024-04-02"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-67e9da6888edfa6119225413068198422f1eaf77-1024x1024-png","_type":"reference"}},"publishedDate":"2024-03-26","slug":"llamaindex-newsletter-2024-03-26","title":"LlamaIndex Newsletter 2024-03-26"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-23819f5bd086643f28ca7d2746a9e400f28cdbee-1023x561-png","_type":"reference"}},"publishedDate":"2024-03-19","slug":"supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations","title":"Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations"}],"slug":{"_type":"slug","current":"timescale-vector-x-llamaindex-making-postgresql-a-better-vector-database-for-ai-applications-924b0bd29f0"},"tags":[{"_createdAt":"2024-02-22T20:19:11Z","_id":"17d4fc95-517c-4f4a-95ce-bf753e802ac4","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"llamaindex"},"title":"Llamaindex"},{"_createdAt":"2024-02-22T20:19:13Z","_id":"78713226-8bff-400f-bbfe-fd8a3d90be1d","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:13Z","slug":{"_type":"slug","current":"nlp"},"title":"NLP"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"aa7d304e-787e-4a6c-80cb-8911afd4c788","_rev":"jbUo4a8sS9GhVRG46mMVHT","_type":"blogTag","_updatedAt":"2024-03-13T16:00:26Z","slug":{"_type":"slug","current":"llm"},"title":"LLM"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"d0a79109-34ab-41fa-a8f4-0b3522970c7d","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"ai"},"title":"AI"},{"_createdAt":"2024-02-22T20:19:14Z","_id":"c827845c-d83a-4965-b353-468ef5f5c4aa","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:14Z","slug":{"_type":"slug","current":"timescaledb"},"title":"Timescaledb"}],"title":"Timescale Vector x LlamaIndex: Making PostgreSQL a Better Vector Database for AI Applications"},"publishedDate":"Invalid Date"},"params":{"slug":"timescale-vector-x-llamaindex-making-postgresql-a-better-vector-database-for-ai-applications-924b0bd29f0"},"draftMode":false,"token":""},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"timescale-vector-x-llamaindex-making-postgresql-a-better-vector-database-for-ai-applications-924b0bd29f0"},"buildId":"C8J-EMc_4OCN1ch65l4fl","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>