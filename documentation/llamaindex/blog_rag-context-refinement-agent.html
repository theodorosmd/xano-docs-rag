<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>RAG Context Refinement Agent — LlamaIndex - Build Knowledge Assistants over your Enterprise Data</title><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><meta name="title" content="RAG Context Refinement Agent — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta name="description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:title" content="RAG Context Refinement Agent — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="og:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:image" content="https://cdn.sanity.io/images/7m9jw85w/production/d9d35d832985fa8837a7cd34d87f3a5f5431f7f8-1429x628.png"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="RAG Context Refinement Agent — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="twitter:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="twitter:image" content="https://cdn.sanity.io/images/7m9jw85w/production/d9d35d832985fa8837a7cd34d87f3a5f5431f7f8-1429x628.png"/><link rel="alternate" type="application/rss+xml" href="https://www.llamaindex.ai/blog/feed"/><meta name="next-head-count" content="20"/><script>
            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WWRFB36R');
            </script><link rel="preload" href="/_next/static/css/41c9222e47d080c9.css" as="style"/><link rel="stylesheet" href="/_next/static/css/41c9222e47d080c9.css" data-n-g=""/><link rel="preload" href="/_next/static/css/97c33c8d95f1230e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/97c33c8d95f1230e.css" data-n-p=""/><link rel="preload" href="/_next/static/css/e009059e80bf60c5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e009059e80bf60c5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-1b629d9c8fb16f34.js" defer=""></script><script src="/_next/static/chunks/framework-df1f68dff096b68a.js" defer=""></script><script src="/_next/static/chunks/main-eca7952a704663f8.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c7c49437be49d2ad.js" defer=""></script><script src="/_next/static/chunks/d9067523-4985945b21298365.js" defer=""></script><script src="/_next/static/chunks/41155975-60c12da9ce9fa0b2.js" defer=""></script><script src="/_next/static/chunks/cb355538-cee2ea45674d9de3.js" defer=""></script><script src="/_next/static/chunks/9494-dff62cb53535dd7d.js" defer=""></script><script src="/_next/static/chunks/4063-39a391a51171ff87.js" defer=""></script><script src="/_next/static/chunks/6889-edfa85b69b88a372.js" defer=""></script><script src="/_next/static/chunks/5575-11ee0a29eaffae61.js" defer=""></script><script src="/_next/static/chunks/3444-95c636af25a42734.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-82c8e764e69afd2c.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_buildManifest.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_ssgManifest.js" defer=""></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WWRFB36R" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div class="__variable_d65c78 __variable_b1ea77 __variable_eb7534"><a class="Announcement_announcement__2ohK8" href="http://48755185.hs-sites.com/llamaindex-0">Meet LlamaIndex at the Databricks Data + AI Summit!<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M8.293 5.293a1 1 0 0 1 1.414 0l6 6a1 1 0 0 1 0 1.414l-6 6a1 1 0 0 1-1.414-1.414L13.586 12 8.293 6.707a1 1 0 0 1 0-1.414Z" clip-rule="evenodd"></path></svg></a><header class="Header_header__hO3lJ"><button class="Hamburger_hamburger__17auO Header_hamburger__lUulX"><svg width="28" height="28" viewBox="0 0 28 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.5 14H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" id="hamburger-stroke-top" class="Hamburger_hamburgerStrokeMiddle__I7VpD"></path><path d="M3.5 7H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeTop__oOhFM"></path><path d="M3.5 21H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeBottom__GIQR2"></path></svg></button><a aria-label="Homepage" href="/"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" class="Header_logo__e5KhT" style="color:transparent" src="/llamaindex.svg"/></a><nav aria-label="Main" data-orientation="horizontal" dir="ltr" style="--content-position:0px"><div style="position:relative"><ul data-orientation="horizontal" class="Nav_MenuList__PrCDJ" dir="ltr"><li><button id="radix-:R6tm:-trigger-radix-:R5mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R5mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Products</button></li><li><button id="radix-:R6tm:-trigger-radix-:R9mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R9mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Solutions</button></li><li><a class="Nav_Link__ZrzFc" href="/community" data-radix-collection-item="">Community</a></li><li><a class="Nav_Link__ZrzFc" href="/pricing" data-radix-collection-item="">Pricing</a></li><li><a class="Nav_Link__ZrzFc" href="/blog" data-radix-collection-item="">Blog</a></li><li><a class="Nav_Link__ZrzFc" href="/customers" data-radix-collection-item="">Customer stories</a></li><li><a class="Nav_Link__ZrzFc" href="/careers" data-radix-collection-item="">Careers</a></li></ul></div><div class="Nav_ViewportPosition__jmyHM"></div></nav><div class="Header_secondNav__YJvm8"><nav><a href="/contact" class="Link_link__71cl8 Link_link-variant-tertiary__BYxn_ Header_bookADemo__qCuxV">Book a demo</a></nav><a href="https://cloud.llamaindex.ai/" class="Button_button-variant-default__Oi__n Button_button__aJ0V6 Header_button__1HFhY" data-tracking-variant="default"> <!-- -->Get started</a></div><div class="MobileMenu_mobileMenu__g5Fa6"><nav class="MobileMenu_nav__EmtTw"><ul><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Products<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaparse"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.6654 1.66675V6.66675H16.6654M8.33203 10.8334L6.66536 12.5001L8.33203 14.1667M11.6654 14.1667L13.332 12.5001L11.6654 10.8334M12.082 1.66675H4.9987C4.55667 1.66675 4.13275 1.84234 3.82019 2.1549C3.50763 2.46746 3.33203 2.89139 3.33203 3.33341V16.6667C3.33203 17.1088 3.50763 17.5327 3.82019 17.8453C4.13275 18.1578 4.55667 18.3334 4.9987 18.3334H14.9987C15.4407 18.3334 15.8646 18.1578 16.1772 17.8453C16.4898 17.5327 16.6654 17.1088 16.6654 16.6667V6.25008L12.082 1.66675Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Document parsing</div><p class="MobileMenu_ListItemText__n_MHY">The first and leading GenAI-native parser over your most complex data.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaextract"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.668 1.66675V5.00008C11.668 5.44211 11.8436 5.86603 12.1561 6.17859C12.4687 6.49115 12.8926 6.66675 13.3346 6.66675H16.668M3.33464 5.83341V3.33341C3.33464 2.89139 3.51023 2.46746 3.82279 2.1549C4.13535 1.84234 4.55927 1.66675 5.0013 1.66675H12.5013L16.668 5.83341V16.6667C16.668 17.1088 16.4924 17.5327 16.1798 17.8453C15.8672 18.1578 15.4433 18.3334 15.0013 18.3334L5.05379 18.3326C4.72458 18.3755 4.39006 18.3191 4.09312 18.1706C3.79618 18.0221 3.55034 17.7884 3.38713 17.4992M4.16797 9.16675L1.66797 11.6667M1.66797 11.6667L4.16797 14.1667M1.66797 11.6667H10.0013" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Data extraction</div><p class="MobileMenu_ListItemText__n_MHY">Extract structured data from documents using a schema-driven engine.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/enterprise"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.16667 15.8333C12.8486 15.8333 15.8333 12.8486 15.8333 9.16667C15.8333 5.48477 12.8486 2.5 9.16667 2.5C5.48477 2.5 2.5 5.48477 2.5 9.16667C2.5 12.8486 5.48477 15.8333 9.16667 15.8333Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M17.5 17.5L13.875 13.875" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Knowledge Management</div><p class="MobileMenu_ListItemText__n_MHY">Connect, transform, and index your enterprise data into an agent-accessible knowledge base</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/framework"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.0013 6.66659V3.33325H6.66797M1.66797 11.6666H3.33464M16.668 11.6666H18.3346M12.5013 10.8333V12.4999M7.5013 10.8333V12.4999M5.0013 6.66659H15.0013C15.9218 6.66659 16.668 7.41278 16.668 8.33325V14.9999C16.668 15.9204 15.9218 16.6666 15.0013 16.6666H5.0013C4.08083 16.6666 3.33464 15.9204 3.33464 14.9999V8.33325C3.33464 7.41278 4.08083 6.66659 5.0013 6.66659Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Agent Framework</div><p class="MobileMenu_ListItemText__n_MHY">Orchestrate and deploy multi-agent applications over your data with the #1 agent framework.</p></a></li></ul></details></li><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Solutions<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/finance"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 6.66675H8.33073C7.8887 6.66675 7.46478 6.84234 7.15222 7.1549C6.83966 7.46746 6.66406 7.89139 6.66406 8.33342C6.66406 8.77544 6.83966 9.19937 7.15222 9.51193C7.46478 9.82449 7.8887 10.0001 8.33073 10.0001H11.6641C12.1061 10.0001 12.53 10.1757 12.8426 10.4882C13.1551 10.8008 13.3307 11.2247 13.3307 11.6667C13.3307 12.1088 13.1551 12.5327 12.8426 12.8453C12.53 13.1578 12.1061 13.3334 11.6641 13.3334H6.66406M9.9974 15.0001V5.00008M18.3307 10.0001C18.3307 14.6025 14.5998 18.3334 9.9974 18.3334C5.39502 18.3334 1.66406 14.6025 1.66406 10.0001C1.66406 5.39771 5.39502 1.66675 9.9974 1.66675C14.5998 1.66675 18.3307 5.39771 18.3307 10.0001Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Financial Analysts</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/administrative-operations"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1.66406 6.66659V15.8333C1.66406 16.2753 1.83966 16.6992 2.15222 17.0118C2.46478 17.3243 2.8887 17.4999 3.33073 17.4999H14.9974M16.6641 14.1666C17.1061 14.1666 17.53 13.991 17.8426 13.6784C18.1551 13.3659 18.3307 12.9419 18.3307 12.4999V7.49992C18.3307 7.05789 18.1551 6.63397 17.8426 6.32141C17.53 6.00885 17.1061 5.83325 16.6641 5.83325H13.4141C13.1353 5.83598 12.8604 5.76876 12.6143 5.63774C12.3683 5.50671 12.159 5.31606 12.0057 5.08325L11.3307 4.08325C11.179 3.85281 10.9724 3.66365 10.7295 3.53275C10.4866 3.40185 10.215 3.3333 9.93906 3.33325H6.66406C6.22204 3.33325 5.79811 3.50885 5.48555 3.82141C5.17299 4.13397 4.9974 4.55789 4.9974 4.99992V12.4999C4.9974 12.9419 5.17299 13.3659 5.48555 13.6784C5.79811 13.991 6.22204 14.1666 6.66406 14.1666H16.6641Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Administrative Operations</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/engineering"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 15L18.3307 10L13.3307 5M6.66406 5L1.66406 10L6.66406 15" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Engineering &amp; R&amp;D</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/customer-support"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.9974 7.50008H16.6641C17.1061 7.50008 17.53 7.67568 17.8426 7.98824C18.1551 8.3008 18.3307 8.72472 18.3307 9.16675V18.3334L14.9974 15.0001H9.9974C9.55537 15.0001 9.13145 14.8245 8.81888 14.5119C8.50632 14.1994 8.33073 13.7754 8.33073 13.3334V12.5001M11.6641 7.50008C11.6641 7.94211 11.4885 8.36603 11.1759 8.67859C10.8633 8.99115 10.4394 9.16675 9.9974 9.16675H4.9974L1.66406 12.5001V3.33341C1.66406 2.41675 2.41406 1.66675 3.33073 1.66675H9.9974C10.4394 1.66675 10.8633 1.84234 11.1759 2.1549C11.4885 2.46746 11.6641 2.89139 11.6641 3.33341V7.50008Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Customer Support</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/healthcare-pharma"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M17.0128 3.81671C16.5948 3.39719 16.098 3.06433 15.551 2.8372C15.004 2.61008 14.4176 2.49316 13.8253 2.49316C13.2331 2.49316 12.6466 2.61008 12.0996 2.8372C11.5527 3.06433 11.0559 3.39719 10.6378 3.81671L9.99617 4.46671L9.3545 3.81671C8.93643 3.39719 8.43967 3.06433 7.89268 2.8372C7.3457 2.61008 6.75926 2.49316 6.167 2.49316C5.57474 2.49316 4.9883 2.61008 4.44132 2.8372C3.89433 3.06433 3.39756 3.39719 2.9795 3.81671C1.21283 5.58338 1.1045 8.56671 3.3295 10.8334L9.99617 17.5L16.6628 10.8334C18.8878 8.56671 18.7795 5.58338 17.0128 3.81671Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M2.91406 9.99992H7.91406L8.33073 9.16659L9.9974 12.9166L11.6641 7.08325L12.9141 9.99992H17.0807" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Healthcare / Pharma</div></a></li></ul></details></li><li><a class="MobileMenu_Link__5frcx" href="/community">Community</a></li><li><a class="MobileMenu_Link__5frcx" href="/pricing">Pricing</a></li><li><a class="MobileMenu_Link__5frcx" href="/blog">Blog</a></li><li><a class="MobileMenu_Link__5frcx" href="/customers">Customer stories</a></li><li><a class="MobileMenu_Link__5frcx" href="/careers">Careers</a></li></ul></nav><a href="/contact" class="Button_button-variant-ghost__o2AbG Button_button__aJ0V6" data-tracking-variant="ghost"> <!-- -->Talk to us</a><ul class="Socials_socials__8Y_s5 Socials_socials-theme-dark__Hq8lc MobileMenu_socials__JykCO"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu MobileMenu_copyright__nKVOs">© <!-- -->2025<!-- --> LlamaIndex</p></div></header><main><section class="BlogPost_post__JHNzd"><img alt="" loading="lazy" width="800" height="314" decoding="async" data-nimg="1" class="BlogPost_featuredImage__KGxwX" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fd9d35d832985fa8837a7cd34d87f3a5f5431f7f8-1429x628.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fd9d35d832985fa8837a7cd34d87f3a5f5431f7f8-1429x628.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fd9d35d832985fa8837a7cd34d87f3a5f5431f7f8-1429x628.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><p class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-600__fKYth BlogPost_date__6uxQw"><a class="BlogPost_author__mesdl" href="/blog/author/llamaindex">LlamaIndex</a> <!-- -->•<!-- --> <!-- -->2024-11-07</p><h1 class="Text_text__zPO0D Text_text-size-32__koGps BlogPost_title__b2lqJ">RAG Context Refinement Agent</h1><ul class="BlogPost_tags__13pBH"><li><a class="Badge_badge___1ssn" href="/blog/tag/hackathon"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Hackathon</span></a></li></ul><div class="BlogPost_htmlPost__Z5oDL"><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><em>This is a guest post from one of the winners of our <a href="https://www.llamaindex.ai/blog/agentic-rag-a-thon-2-winners-and-recap" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">recent hackathon</a>.</em></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The promise of agent architectures is that AI can become more capable not by relying on clever prompting, fine-tuning, and scaling of individual LLMs to solve a problem in one autoregressive gulp, but by coordinating simpler tasks that collectively marshal resources and incrementally work toward solutions. The recent Agentic RAG-A-Thon offered incentives, resources, and community for participants to build prototypes and demos doing exactly that.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Problem: RAG for Code Repositories</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Our team&#x27;s problem scenario starts with a real-world application of RAG in technical support. Users have questions, support engineers respond with answers. Sometimes, the answer is based on documentation that may be more or less accessible to average users. For example, manufacturers of semiconductors host community forums listing thousands of how-to and troubleshooting questions. Many questions and answers draw from the hundreds of git repos a company might maintain containing APIs, example code, firmware, and documentation. AI should help the support engineers find the right documents, and synthesize useful answers for customers&#x27; problems.</p><figure><img alt="" loading="lazy" width="715" height="395.5" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Ff907b15fb40619fd882414cd04766dfd37355a7c-1430x791.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=750&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Ff907b15fb40619fd882414cd04766dfd37355a7c-1430x791.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Ff907b15fb40619fd882414cd04766dfd37355a7c-1430x791.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/></figure><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Retrieval Augmented Generation (RAG) can work well when context chunks are derived from well-structured segments of natural language source documents. But some knowledge sources, such as code repositories, tend to produce chunks that lack context and meaning necessary for effective indexing, and that lack significance toward a useful question+context prompt for LLM response synthesis.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">One solution operates at knowledge source preparation time, to build smarter chunks. For example, along with function-level chunks identified in software files, include imports and class membership annotations. Or include a narrative summary for each chunk. Already, IDEs such as VS Code and Cursor reach beyond code completion by bridging software expressions with narrative explanations of purpose and function.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Naturally, up-front knowledge preparation for RAG is general-purpose---it cannot be tuned to surfacing knowledge for any particular user question.</p><figure><img alt="" loading="lazy" width="714.5" height="301.5" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Ff2715dccbf48d30ab7799fa86f3197891fb13400-1429x603.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=750&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Ff2715dccbf48d30ab7799fa86f3197891fb13400-1429x603.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Ff2715dccbf48d30ab7799fa86f3197891fb13400-1429x603.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/></figure><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Proposal: Revisit the source docs</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">An alternative approach more closely resembles what a human expert would do. Over multiple rounds of iteration, they will search and follow leads in the documentation until a satisfactory answer is found or pieced together.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Our idea is to emulate this strategy by deploying an AI Agent at question-answering time. Instead of relying solely on chunks retrieved via index search and re-ranking, we propose for the agent to revisit the source documentation itself, to refine the context portion of the LLM prompt until it contains sufficient information to answer the user&#x27;s question.</p><figure><img alt="" loading="lazy" width="714.5" height="314" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fd9d35d832985fa8837a7cd34d87f3a5f5431f7f8-1429x628.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=750&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fd9d35d832985fa8837a7cd34d87f3a5f5431f7f8-1429x628.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fd9d35d832985fa8837a7cd34d87f3a5f5431f7f8-1429x628.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/></figure><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Our design centers around a scratchpad containing the question-specific context information. After refinement, this context is included in the LLM call that generates a final answer, along with the initial user question, plus instruction prompt.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The content of the scratchpad starts off with the initial set of retrieval chunks pulled from the RAG vector store.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">But crucially, an Evaluator step decides whether the scratchpad context is sufficient to answer the question, or not. If, for example, the initial chunks are merely assorted snippets of code that appear to be relevant to the question, but offer no coherent explanation of how they fit together, then the Evaluator passes control to other steps within the agent.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The Context Refinement Agent includes an open-ended library of tools that can be applied to refine the scratchpad. Tools can include:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Selection and filtering of useful repos versus distractors, based on chunk scores and voting.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Application of summarization to files and directories.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Inclusion of entire code files (subject to size), based on chunks matched to fragments.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Removal of chunks deemed irrelevant to the question.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Selection of explanatory documentation associated with functions, files, and repos.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Following of links found to documentation located elsewhere on the company&#x27;s site, or third party sites.</li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">A Tool Selector step decides which tool to apply next. This decision may be a pre-determined sequence, a rule-like policy, or an open-ended judgement.</p><figure><img alt="" loading="lazy" width="714.5" height="395" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F7a5d9d92d47520c4f017f1ab0dbc395f766ea83c-1429x790.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=750&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F7a5d9d92d47520c4f017f1ab0dbc395f766ea83c-1429x790.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F7a5d9d92d47520c4f017f1ab0dbc395f766ea83c-1429x790.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/></figure><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Learning from Classical AI</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Students of Artificial Intelligence will recognize this architecture as a classic Production System. In AI parlance, &quot;<a href="https://en.wikipedia.org/wiki/Production_system_(computer_science)" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Production System</a>&quot; does not mean a &quot;system ready for production deployment.&quot; Instead, a Production System establishes a collection of incremental computational steps that compete to modify the contents of a central &quot;blackboard.&quot; Control flow is not pre-defined, but depends on the data. In contrast to traditional declarative programs, this approach affords asynchronous, distributed, and parallel modes of computation. The idea dates to Selfridge&#x27;s 1959 &quot;Pandemonium&quot; architecture for feature matching in visual perception; other significant Production Systems include <a href="https://en.wikipedia.org/wiki/Soar_(cognitive_architecture)" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Soar</a>, <a href="https://en.wikipedia.org/wiki/ACT-R" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Act-R</a>, and <a href="https://en.wikipedia.org/wiki/OpenCog" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">OpenCog</a>.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Traditional Production Systems based in symbolic representations have fallen short of the spectacular results delivered by Large Language Models trained and run on deep neural networks. Among the challenges is weighing context in decisions about what productions to fire and how their outputs should modify the blackboard workspace.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">LLMs offer several breakthrough capabilities that hold promise for an agent architecture organized around a cycle of evaluation, tool selection, and tool application:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">A large amount of loosely structured context can be brought to bear on decisions.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Interface representations are human natural language and comprehensible artificial languages.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Vector embeddings afford &quot;fuzzy&quot; pattern matching.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Effective abstraction of concepts by LLMs negates the need for explicit programming of intricate logic rules.</li></ul><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Proof of Concept</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Over the Hack-A-Thon weekend, we built a minimal proof-of-concept RAG Context Refinement Agent. Sample questions were selected from the public Community Forum site of the semiconductor company, Infineon. We chose questions whose peer and expert answers included references to Infineon&#x27;s public GitHub site. Then, we built and indexed knowledge chunks from these repos using the LlamaIndex and Pinecone tool chain. For baseline testing, we ran the questions against ChatGPT and standard RAG that used top-K retrievals as context.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The figure below shows how AI context refinement improves the response to a sample question over baseline RAG. The user&#x27;s question is about sleep state of a microcontroller. Our Evaluator step asks an LLM to provide a numerical score assessing how well the scratchpad context answers the question. The initial retrieved chunks offer no helpful answer; they were scored as 0.3 by the Evaluator, which sent control to the Tool Selector. In this case, the relevant tool was one that identified high-scoring chunks from the same file, and fetched the entire file into the scratchpad. The evaluator rated the improved context 0.7. With this context refinement, information was retrieved that addresses HOST_WAKE, DEV_WAKE, and other aspects of the question.</p><figure><img alt="" loading="lazy" width="631" height="351.5" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F8cb333cead11d8bc503c914253729c5f348bfb7c-1262x703.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F8cb333cead11d8bc503c914253729c5f348bfb7c-1262x703.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F8cb333cead11d8bc503c914253729c5f348bfb7c-1262x703.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/></figure><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We built the Context Refinement Agent in the LlamaIndex Workflow framework. In fact, we built the entire RAG question/response-generation pipeline in the event-driven Workflow framework. Custom <em>Events</em> of the developer&#x27;s design trigger operational <em>Steps</em> in asynchronous, dataflow fashion. Workflow steps can be purely programmatic, or they can invoke LLM calls, or they can invite human interaction. We found this framework to be elegant and intuitive---although in Python it can be tricky to get the handoffs right between synchronous and asynchronous code.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The Workflow framework supports a global <em>Context </em>object that naturally maps onto our scratchpad, or blackboard. Within the Context Refinement Agent, context state consists of the user question and question elaborations, plus the current contents of source knowledge context to be supplied in the final LLM answer-generation call.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We found it drop dead easy to run our demo in a web browser using Reflex&#x27;s tools for building a web GUI in Python.<br/></p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Outlook: RAG Context Refinement</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">With a proof-of-concept and working implementation in hand (at least in prototype, outline form), this idea is a candidate for further refinement. A significant amount of development and testing with real-world question-against-repo cases will be required to solidify and improve it. Specifically, any degree of agentic autonomy is subject to unpredictable behavior so requires careful instrumentation, monitoring, and evaluation. For example, some tools might explore the open web to pull in relevant information such as references to third party libraries, but these sources must be constrained and vetted.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The Agentic RAG-A-Thon offered an exhilarating opportunity to exchange ideas with other developers, to learn about the growing array of tools and services, and to learn how Agentic RAG technology can meet real world problems. We are gratified to have received the Global 500 Award recognizing our efforts, and we congratulate all of the sponsors and participants for creating a fantastic event.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><br/><a href="https://www.linkedin.com/in/eric-saund/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Eric Saund</a>, Ph.D., is Chief AI Officer, <a href="https://www.ept.ai/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">ept.ai</a>.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><a href="https://www.linkedin.com/in/ballagas/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Tico Ballagas</a> is VP Software Engineering, <a href="https://www.penumbrainc.com/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Penumbra</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><a href="https://www.linkedin.com/in/mohitsv/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Mohit Shankar Velu</a> is recently graduated from UMass Amherst and works at <a href="https://prosimo.io/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Prosimo</a>.<br/></p></div><div class="BlogPost_relatedPosts__0z6SN"><h2 class="Text_text__zPO0D Text_text-align-center__HhKqo Text_text-size-16__PkjFu Text_text-weight-400__5ENkK Text_text-family-spaceGrotesk__E4zcE BlogPost_relatedPostsTitle___JIrW">Related articles</h2><ul class="BlogPost_relatedPostsList__uOKzB"><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fb4d9037565b2f80a1cda4284955fa82aac5fa370-1024x632.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fb4d9037565b2f80a1cda4284955fa82aac5fa370-1024x632.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fb4d9037565b2f80a1cda4284955fa82aac5fa370-1024x632.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/automatically-generating-cloud-configurations-introducing-ragformation">Automatically generating cloud configurations: Introducing RAGformation</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-11-14</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F613ddcf4ef038c8e492bc2424dbb2108908152a5-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F613ddcf4ef038c8e492bc2424dbb2108908152a5-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F613ddcf4ef038c8e492bc2424dbb2108908152a5-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/oilyrags-building-a-rag-powered-mechanic-assistant-with-ai">OilyRAGs: Building a RAG-powered mechanic&#x27;s assistant with AI</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-11-01</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fdbc69a3737a2a808237abf5c40c2f8b8b1d790f6-1935x1451.jpg%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fdbc69a3737a2a808237abf5c40c2f8b8b1d790f6-1935x1451.jpg%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fdbc69a3737a2a808237abf5c40c2f8b8b1d790f6-1935x1451.jpg%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/agentic-rag-a-thon-2-winners-and-recap">Agentic RAG-a-thon 2: winners and recap</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-10-17</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4419e1afaa5eab8c15eb7b3ba750166298158a67-853x480.gif%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4419e1afaa5eab8c15eb7b3ba750166298158a67-853x480.gif%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4419e1afaa5eab8c15eb7b3ba750166298158a67-853x480.gif%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/pii-detector-hacking-privacy-in-rag">PII Detector: hacking privacy in RAG</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-03-13</p></div></li></ul></div></section></main><footer class="Footer_footer__eNA9m"><div class="Footer_navContainer__7bvx4"><div class="Footer_logoContainer__3EpzI"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" style="color:transparent" src="/llamaindex.svg"/><div class="Footer_socialContainer__GdOgk"><ul class="Socials_socials__8Y_s5"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul></div></div><div class="Footer_nav__BLEuE"><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/">LlamaIndex</a></h3><ul><li><a href="/blog"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Blog</span></a></li><li><a href="/partners"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Partners</span></a></li><li><a href="/careers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Careers</span></a></li><li><a href="/contact"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Contact</span></a></li><li><a href="/brand"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Brand</span></a></li><li><a href="https://llamaindex.statuspage.io" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Status</span></a></li><li><a href="https://app.vanta.com/runllama.ai/trust/pkcgbjf8b3ihxjpqdx17nu" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Trust Center</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/enterprise">Enterprise</a></h3><ul><li><a href="https://cloud.llamaindex.ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaCloud</span></a></li><li><a href="https://cloud.llamaindex.ai/parse" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaParse</span></a></li><li><a href="/customers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Customers</span></a></li><li><a href="/llamacloud-sharepoint-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SharePoint</span></a></li><li><a href="/llamacloud-aws-s3-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">AWS S3</span></a></li><li><a href="/llamacloud-azure-blob-storage-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure Blob Storage</span></a></li><li><a href="/llamacloud-google-drive-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Google Drive</span></a></li> </ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/framework">Framework</a></h3><ul><li><a href="https://pypi.org/project/llama-index/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python package</span></a></li><li><a href="https://docs.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python docs</span></a></li><li><a href="https://www.npmjs.com/package/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript package</span></a></li><li><a href="https://ts.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript docs</span></a></li><li><a href="https://llamahub.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaHub</span></a></li><li><a href="https://github.com/run-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">GitHub</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/community">Community</a></h3><ul><li><a href="/community#newsletter"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Newsletter</span></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Discord</span></a></li><li><a href="https://www.linkedin.com/company/91154103/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LinkedIn</span></a></li><li><a href="https://twitter.com/llama_index"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Twitter/X</span></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">YouTube</span></a></li><li><a href="https://bsky.app/profile/llamaindex.bsky.social"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">BlueSky</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e">Starter projects</h3><ul><li><a href="https://www.npmjs.com/package/create-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">create-llama</span></a></li><li><a href="https://secinsights.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SEC Insights</span></a></li><li><a href="https://github.com/run-llama/llamabot"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaBot</span></a></li><li><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/rag_cli.html"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">RAG CLI</span></a></li></ul></div></div></div><div class="Footer_copyrightContainer__mBKsT"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA">© <!-- -->2025<!-- --> LlamaIndex</p><div class="Footer_legalNav__O1yJA"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/privacy-notice.pdf">Privacy Notice</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/terms-of-service.pdf">Terms of Service</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="https://bit.ly/llamaindexdpa">Data Processing Addendum</a></p></div></div></footer></div><svg xmlns="http://www.w3.org/2000/svg" class="flt_svg" style="display:none"><defs><filter id="flt_tag"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="2"></feGaussianBlur><feColorMatrix in="blur" result="flt_tag" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="flt_tag" operator="atop"></feComposite></filter><filter id="svg_blur_large"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="8"></feGaussianBlur><feColorMatrix in="blur" result="svg_blur_large" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="svg_blur_large" operator="atop"></feComposite></filter></defs></svg></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"page":{"announcement":{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"},"post":{"_createdAt":"2024-11-07T19:46:24Z","_id":"2ca2cc7a-fc3b-4f0e-858c-dfba330c1f11","_rev":"Ys5IzmCaJ2UnW2RAX7U7Uw","_type":"blogPost","_updatedAt":"2025-05-21T20:37:00Z","announcement":[{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"}],"authors":[{"_createdAt":"2024-02-20T20:23:12Z","_id":"363ec4e9-0b8f-48d2-ba6a-567a9c527c3d","_rev":"rGZ2nN6K5mjOGJOoWaUhNb","_type":"people","_updatedAt":"2024-02-25T00:45:24Z","image":{"_type":"image","asset":{"_ref":"image-89523511cf20d73e3f10077add50128d077ed520-176x176-png","_type":"reference"}},"name":"LlamaIndex","slug":{"_type":"slug","current":"llamaindex"}}],"featured":false,"image":{"_type":"image","asset":{"_ref":"image-d9d35d832985fa8837a7cd34d87f3a5f5431f7f8-1429x628-png","_type":"reference"}},"mainImage":"https://cdn.sanity.io/images/7m9jw85w/production/d9d35d832985fa8837a7cd34d87f3a5f5431f7f8-1429x628.png","publishedDate":"2024-11-07","relatedPosts":[{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-b4d9037565b2f80a1cda4284955fa82aac5fa370-1024x632-png","_type":"reference"}},"publishedDate":"2024-11-14","slug":"automatically-generating-cloud-configurations-introducing-ragformation","title":"Automatically generating cloud configurations: Introducing RAGformation"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-613ddcf4ef038c8e492bc2424dbb2108908152a5-1024x1024-png","_type":"reference"}},"publishedDate":"2024-11-01","slug":"oilyrags-building-a-rag-powered-mechanic-assistant-with-ai","title":"OilyRAGs: Building a RAG-powered mechanic's assistant with AI"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-dbc69a3737a2a808237abf5c40c2f8b8b1d790f6-1935x1451-jpg","_type":"reference"}},"publishedDate":"2024-10-17","slug":"agentic-rag-a-thon-2-winners-and-recap","title":"Agentic RAG-a-thon 2: winners and recap"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-4419e1afaa5eab8c15eb7b3ba750166298158a67-853x480-gif","_type":"reference"}},"publishedDate":"2024-03-13","slug":"pii-detector-hacking-privacy-in-rag","title":"PII Detector: hacking privacy in RAG"}],"slug":{"_type":"slug","current":"rag-context-refinement-agent"},"tags":[{"_createdAt":"2024-02-22T20:19:12Z","_id":"9c0e4590-0706-49f2-ac4a-29827474db8f","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:12Z","slug":{"_type":"slug","current":"hackathon"},"title":"Hackathon"}],"text":[{"_key":"b87e655f6730","_type":"block","children":[{"_key":"21f1ae89c306","_type":"span","marks":["em"],"text":"This is a guest post from one of the winners of our "},{"_key":"0b49ad09e774","_type":"span","marks":["em","80dbcd573d9b"],"text":"recent hackathon"},{"_key":"a201b1fa6c88","_type":"span","marks":["em"],"text":"."}],"markDefs":[{"_key":"80dbcd573d9b","_type":"link","href":"https://www.llamaindex.ai/blog/agentic-rag-a-thon-2-winners-and-recap"}],"style":"normal"},{"_key":"a809f8b74864","_type":"block","children":[{"_key":"a51a5912048e","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"d3ab53834361","_type":"block","children":[{"_key":"f38df54166bc0","_type":"span","marks":[],"text":"The promise of agent architectures is that AI can become more capable not by relying on clever prompting, fine-tuning, and scaling of individual LLMs to solve a problem in one autoregressive gulp, but by coordinating simpler tasks that collectively marshal resources and incrementally work toward solutions. The recent Agentic RAG-A-Thon offered incentives, resources, and community for participants to build prototypes and demos doing exactly that."}],"markDefs":[],"style":"normal"},{"_key":"fe945fda9304","_type":"block","children":[{"_key":"c2155abb18e6","_type":"span","marks":[],"text":"Problem: RAG for Code Repositories"}],"markDefs":[],"style":"h2"},{"_key":"c4a5e460f5e4","_type":"block","children":[{"_key":"6b9eb5fb74960","_type":"span","marks":[],"text":"Our team's problem scenario starts with a real-world application of RAG in technical support. Users have questions, support engineers respond with answers. Sometimes, the answer is based on documentation that may be more or less accessible to average users. For example, manufacturers of semiconductors host community forums listing thousands of how-to and troubleshooting questions. Many questions and answers draw from the hundreds of git repos a company might maintain containing APIs, example code, firmware, and documentation. AI should help the support engineers find the right documents, and synthesize useful answers for customers' problems."}],"markDefs":[],"style":"normal"},{"_key":"65802da55bde","_type":"image","asset":{"_ref":"image-f907b15fb40619fd882414cd04766dfd37355a7c-1430x791-png","_type":"reference"}},{"_key":"e81bc5cdbcf0","_type":"block","children":[{"_key":"b34041ff3bc80","_type":"span","marks":[],"text":"Retrieval Augmented Generation (RAG) can work well when context chunks are derived from well-structured segments of natural language source documents. But some knowledge sources, such as code repositories, tend to produce chunks that lack context and meaning necessary for effective indexing, and that lack significance toward a useful question+context prompt for LLM response synthesis."}],"markDefs":[],"style":"normal"},{"_key":"e415a43c61f2","_type":"block","children":[{"_key":"2defeedf77bd0","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"1ed782584119","_type":"block","children":[{"_key":"8fbb32c283340","_type":"span","marks":[],"text":"One solution operates at knowledge source preparation time, to build smarter chunks. For example, along with function-level chunks identified in software files, include imports and class membership annotations. Or include a narrative summary for each chunk. Already, IDEs such as VS Code and Cursor reach beyond code completion by bridging software expressions with narrative explanations of purpose and function."}],"markDefs":[],"style":"normal"},{"_key":"294ee3eec267","_type":"block","children":[{"_key":"95addff947330","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"f7b72e3748d2","_type":"block","children":[{"_key":"d84635de08a40","_type":"span","marks":[],"text":"Naturally, up-front knowledge preparation for RAG is general-purpose---it cannot be tuned to surfacing knowledge for any particular user question."}],"markDefs":[],"style":"normal"},{"_key":"1d42cf360adc","_type":"image","asset":{"_ref":"image-f2715dccbf48d30ab7799fa86f3197891fb13400-1429x603-png","_type":"reference"}},{"_key":"442f54d8ee6e","_type":"block","children":[{"_key":"ea359732550f0","_type":"span","marks":[],"text":"Proposal: Revisit the source docs"}],"markDefs":[],"style":"h2"},{"_key":"b61bb64cc73d","_type":"block","children":[{"_key":"6dd0d6ae2e970","_type":"span","marks":[],"text":"An alternative approach more closely resembles what a human expert would do. Over multiple rounds of iteration, they will search and follow leads in the documentation until a satisfactory answer is found or pieced together."}],"markDefs":[],"style":"normal"},{"_key":"e70f3cf797c0","_type":"block","children":[{"_key":"2b164aa07ff00","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"66449deffb20","_type":"block","children":[{"_key":"ec8ea485a19c0","_type":"span","marks":[],"text":"Our idea is to emulate this strategy by deploying an AI Agent at question-answering time. Instead of relying solely on chunks retrieved via index search and re-ranking, we propose for the agent to revisit the source documentation itself, to refine the context portion of the LLM prompt until it contains sufficient information to answer the user's question."}],"markDefs":[],"style":"normal"},{"_key":"89ed4c47238e","_type":"image","asset":{"_ref":"image-d9d35d832985fa8837a7cd34d87f3a5f5431f7f8-1429x628-png","_type":"reference"}},{"_key":"a2bcd902e654","_type":"block","children":[{"_key":"69c4b52fc4350","_type":"span","marks":[],"text":"Our design centers around a scratchpad containing the question-specific context information. After refinement, this context is included in the LLM call that generates a final answer, along with the initial user question, plus instruction prompt."}],"markDefs":[],"style":"normal"},{"_key":"6e65e673f510","_type":"block","children":[{"_key":"bb3822bd502c0","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"0abcfdc90df6","_type":"block","children":[{"_key":"0f698532ba0c0","_type":"span","marks":[],"text":"The content of the scratchpad starts off with the initial set of retrieval chunks pulled from the RAG vector store."}],"markDefs":[],"style":"normal"},{"_key":"6a0b8fd7c0c4","_type":"block","children":[{"_key":"b434469f4e540","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"6ff129e89836","_type":"block","children":[{"_key":"9a2d801ae3560","_type":"span","marks":[],"text":"But crucially, an Evaluator step decides whether the scratchpad context is sufficient to answer the question, or not. If, for example, the initial chunks are merely assorted snippets of code that appear to be relevant to the question, but offer no coherent explanation of how they fit together, then the Evaluator passes control to other steps within the agent."}],"markDefs":[],"style":"normal"},{"_key":"3279e1133ac6","_type":"block","children":[{"_key":"c26eac2d915d0","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"5b5154a50525","_type":"block","children":[{"_key":"a8626033fd920","_type":"span","marks":[],"text":"The Context Refinement Agent includes an open-ended library of tools that can be applied to refine the scratchpad. Tools can include:"}],"markDefs":[],"style":"normal"},{"_key":"0e24ab8c1674","_type":"block","children":[{"_key":"d3c4707fb7970","_type":"span","marks":[],"text":"Selection and filtering of useful repos versus distractors, based on chunk scores and voting."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"b46db855994f","_type":"block","children":[{"_key":"02aa020f2f110","_type":"span","marks":[],"text":"Application of summarization to files and directories."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"eb646767deef","_type":"block","children":[{"_key":"fb27b8fdca780","_type":"span","marks":[],"text":"Inclusion of entire code files (subject to size), based on chunks matched to fragments."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"85a4da52ddad","_type":"block","children":[{"_key":"861ea2a9d08a0","_type":"span","marks":[],"text":"Removal of chunks deemed irrelevant to the question."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"da2064933675","_type":"block","children":[{"_key":"5740c098b2320","_type":"span","marks":[],"text":"Selection of explanatory documentation associated with functions, files, and repos."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"0d626e22d5aa","_type":"block","children":[{"_key":"9dd6cab7a3380","_type":"span","marks":[],"text":"Following of links found to documentation located elsewhere on the company's site, or third party sites."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"808cc5ba7add","_type":"block","children":[{"_key":"f57774a45d780","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"c06ac8054fa6","_type":"block","children":[{"_key":"9d9c6c5ac6e60","_type":"span","marks":[],"text":"A Tool Selector step decides which tool to apply next. This decision may be a pre-determined sequence, a rule-like policy, or an open-ended judgement."}],"markDefs":[],"style":"normal"},{"_key":"2b0ed37e30d0","_type":"image","asset":{"_ref":"image-7a5d9d92d47520c4f017f1ab0dbc395f766ea83c-1429x790-png","_type":"reference"}},{"_key":"3fe75026d164","_type":"block","children":[{"_key":"70fdaf72d0040","_type":"span","marks":[],"text":"Learning from Classical AI"}],"markDefs":[],"style":"h2"},{"_key":"83e7cfb869f2","_type":"block","children":[{"_key":"440efaa21ff50","_type":"span","marks":[],"text":"Students of Artificial Intelligence will recognize this architecture as a classic Production System. In AI parlance, \""},{"_key":"440efaa21ff51","_type":"span","marks":["615201fa0e31"],"text":"Production System"},{"_key":"440efaa21ff52","_type":"span","marks":[],"text":"\" does not mean a \"system ready for production deployment.\" Instead, a Production System establishes a collection of incremental computational steps that compete to modify the contents of a central \"blackboard.\" Control flow is not pre-defined, but depends on the data. In contrast to traditional declarative programs, this approach affords asynchronous, distributed, and parallel modes of computation. The idea dates to Selfridge's 1959 \"Pandemonium\" architecture for feature matching in visual perception; other significant Production Systems include "},{"_key":"440efaa21ff53","_type":"span","marks":["b0af20b9faf9"],"text":"Soar"},{"_key":"440efaa21ff54","_type":"span","marks":[],"text":", "},{"_key":"440efaa21ff55","_type":"span","marks":["dea36bf68a96"],"text":"Act-R"},{"_key":"440efaa21ff56","_type":"span","marks":[],"text":", and "},{"_key":"440efaa21ff57","_type":"span","marks":["9a757aae5184"],"text":"OpenCog"},{"_key":"440efaa21ff58","_type":"span","marks":[],"text":"."}],"markDefs":[{"_key":"615201fa0e31","_type":"link","href":"https://en.wikipedia.org/wiki/Production_system_(computer_science)"},{"_key":"b0af20b9faf9","_type":"link","href":"https://en.wikipedia.org/wiki/Soar_(cognitive_architecture)"},{"_key":"dea36bf68a96","_type":"link","href":"https://en.wikipedia.org/wiki/ACT-R"},{"_key":"9a757aae5184","_type":"link","href":"https://en.wikipedia.org/wiki/OpenCog"}],"style":"normal"},{"_key":"94baf854e493","_type":"block","children":[{"_key":"69c9f7a571300","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"9a621529d662","_type":"block","children":[{"_key":"e82fd162da200","_type":"span","marks":[],"text":"Traditional Production Systems based in symbolic representations have fallen short of the spectacular results delivered by Large Language Models trained and run on deep neural networks. Among the challenges is weighing context in decisions about what productions to fire and how their outputs should modify the blackboard workspace."}],"markDefs":[],"style":"normal"},{"_key":"051073a2602c","_type":"block","children":[{"_key":"a6934c4ff1200","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"3d025f4669e0","_type":"block","children":[{"_key":"8bcafc9684980","_type":"span","marks":[],"text":"LLMs offer several breakthrough capabilities that hold promise for an agent architecture organized around a cycle of evaluation, tool selection, and tool application:"}],"markDefs":[],"style":"normal"},{"_key":"019ab017b9d4","_type":"block","children":[{"_key":"1ec0c6c758880","_type":"span","marks":[],"text":"A large amount of loosely structured context can be brought to bear on decisions."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"20c0c60ddf70","_type":"block","children":[{"_key":"4552123313da0","_type":"span","marks":[],"text":"Interface representations are human natural language and comprehensible artificial languages."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"a06c8bb0561a","_type":"block","children":[{"_key":"5464985fc0740","_type":"span","marks":[],"text":"Vector embeddings afford \"fuzzy\" pattern matching."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"8b74abb0fece","_type":"block","children":[{"_key":"5c5f503bdc0f0","_type":"span","marks":[],"text":"Effective abstraction of concepts by LLMs negates the need for explicit programming of intricate logic rules."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"c28e6be05625","_type":"block","children":[{"_key":"8a45c90d9e1a0","_type":"span","marks":[],"text":"Proof of Concept"}],"markDefs":[],"style":"h2"},{"_key":"b6363a450e79","_type":"block","children":[{"_key":"4e90e1f5b7750","_type":"span","marks":[],"text":"Over the Hack-A-Thon weekend, we built a minimal proof-of-concept RAG Context Refinement Agent. Sample questions were selected from the public Community Forum site of the semiconductor company, Infineon. We chose questions whose peer and expert answers included references to Infineon's public GitHub site. Then, we built and indexed knowledge chunks from these repos using the LlamaIndex and Pinecone tool chain. For baseline testing, we ran the questions against ChatGPT and standard RAG that used top-K retrievals as context."}],"markDefs":[],"style":"normal"},{"_key":"1e9567c03fb5","_type":"block","children":[{"_key":"dd9a748c10ea0","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"5c17d79b9f6d","_type":"block","children":[{"_key":"2a9156d8382d0","_type":"span","marks":[],"text":"The figure below shows how AI context refinement improves the response to a sample question over baseline RAG. The user's question is about sleep state of a microcontroller. Our Evaluator step asks an LLM to provide a numerical score assessing how well the scratchpad context answers the question. The initial retrieved chunks offer no helpful answer; they were scored as 0.3 by the Evaluator, which sent control to the Tool Selector. In this case, the relevant tool was one that identified high-scoring chunks from the same file, and fetched the entire file into the scratchpad. The evaluator rated the improved context 0.7. With this context refinement, information was retrieved that addresses HOST_WAKE, DEV_WAKE, and other aspects of the question."}],"markDefs":[],"style":"normal"},{"_key":"2b8416b34c36","_type":"image","asset":{"_ref":"image-8cb333cead11d8bc503c914253729c5f348bfb7c-1262x703-png","_type":"reference"}},{"_key":"5d24feca65e1","_type":"block","children":[{"_key":"aea38c43b3670","_type":"span","marks":[],"text":"We built the Context Refinement Agent in the LlamaIndex Workflow framework. In fact, we built the entire RAG question/response-generation pipeline in the event-driven Workflow framework. Custom "},{"_key":"aea38c43b3671","_type":"span","marks":["em"],"text":"Events"},{"_key":"aea38c43b3672","_type":"span","marks":[],"text":" of the developer's design trigger operational "},{"_key":"aea38c43b3673","_type":"span","marks":["em"],"text":"Steps"},{"_key":"aea38c43b3674","_type":"span","marks":[],"text":" in asynchronous, dataflow fashion. Workflow steps can be purely programmatic, or they can invoke LLM calls, or they can invite human interaction. We found this framework to be elegant and intuitive---although in Python it can be tricky to get the handoffs right between synchronous and asynchronous code."}],"markDefs":[],"style":"normal"},{"_key":"98c63e0ef758","_type":"block","children":[{"_key":"f11993a831a50","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"0b441938dd3d","_type":"block","children":[{"_key":"da9b3bde4ad90","_type":"span","marks":[],"text":"The Workflow framework supports a global "},{"_key":"da9b3bde4ad91","_type":"span","marks":["em"],"text":"Context "},{"_key":"da9b3bde4ad92","_type":"span","marks":[],"text":"object that naturally maps onto our scratchpad, or blackboard. Within the Context Refinement Agent, context state consists of the user question and question elaborations, plus the current contents of source knowledge context to be supplied in the final LLM answer-generation call."}],"markDefs":[],"style":"normal"},{"_key":"86708b445a32","_type":"block","children":[{"_key":"f36ba294e35f0","_type":"span","marks":[],"text":"We found it drop dead easy to run our demo in a web browser using Reflex's tools for building a web GUI in Python.\n"}],"markDefs":[],"style":"normal"},{"_key":"43ccfbfcbb3b","_type":"block","children":[{"_key":"8233b5dbf216","_type":"span","marks":[],"text":"Outlook: RAG Context Refinement"}],"markDefs":[],"style":"h2"},{"_key":"a5aec5d67e8b","_type":"block","children":[{"_key":"a6caa7f25d450","_type":"span","marks":[],"text":"With a proof-of-concept and working implementation in hand (at least in prototype, outline form), this idea is a candidate for further refinement. A significant amount of development and testing with real-world question-against-repo cases will be required to solidify and improve it. Specifically, any degree of agentic autonomy is subject to unpredictable behavior so requires careful instrumentation, monitoring, and evaluation. For example, some tools might explore the open web to pull in relevant information such as references to third party libraries, but these sources must be constrained and vetted."}],"markDefs":[],"style":"normal"},{"_key":"9977e83ab1b0","_type":"block","children":[{"_key":"ad29318219290","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"3d8756c6caa1","_type":"block","children":[{"_key":"f598543287ce0","_type":"span","marks":[],"text":"The Agentic RAG-A-Thon offered an exhilarating opportunity to exchange ideas with other developers, to learn about the growing array of tools and services, and to learn how Agentic RAG technology can meet real world problems. We are gratified to have received the Global 500 Award recognizing our efforts, and we congratulate all of the sponsors and participants for creating a fantastic event."}],"markDefs":[],"style":"normal"},{"_key":"1e3482254a35","_type":"block","children":[{"_key":"9509bc612200","_type":"span","marks":[],"text":"\n"},{"_key":"8279625ce199","_type":"span","marks":["6ff447f08240"],"text":"Eric Saund"},{"_key":"334d34c18807","_type":"span","marks":[],"text":", Ph.D., is Chief AI Officer, "},{"_key":"e358aa225ad9","_type":"span","marks":["acbde6ed2473"],"text":"ept.ai"},{"_key":"11d4f5ae22eb","_type":"span","marks":[],"text":"."}],"markDefs":[{"_key":"acbde6ed2473","_type":"link","href":"https://www.ept.ai/"},{"_key":"6ff447f08240","_type":"link","href":"https://www.linkedin.com/in/eric-saund/"}],"style":"normal"},{"_key":"586313496fdb","_type":"block","children":[{"_key":"4cefb1f80c2e0","_type":"span","marks":["7d62e539931b"],"text":"Tico Ballagas"},{"_key":"c4e24235ba38","_type":"span","marks":[],"text":" is VP Software Engineering, "},{"_key":"4cefb1f80c2e1","_type":"span","marks":["b3963bac7bcc"],"text":"Penumbra"}],"markDefs":[{"_key":"b3963bac7bcc","_type":"link","href":"https://www.penumbrainc.com/"},{"_key":"7d62e539931b","_type":"link","href":"https://www.linkedin.com/in/ballagas/"}],"style":"normal"},{"_key":"13e583c23019","_type":"block","children":[{"_key":"f9b6693eb4b80","_type":"span","marks":["8d87aad64228"],"text":"Mohit Shankar Velu"},{"_key":"c1bcf36e158d","_type":"span","marks":[],"text":" is recently graduated from UMass Amherst and works at "},{"_key":"f9b6693eb4b81","_type":"span","marks":["b979a4517868"],"text":"Prosimo"},{"_key":"f9b6693eb4b82","_type":"span","marks":[],"text":".\n"}],"markDefs":[{"_key":"b979a4517868","_type":"link","href":"https://prosimo.io/"},{"_key":"8d87aad64228","_type":"link","href":"https://www.linkedin.com/in/mohitsv/"}],"style":"normal"}],"title":"RAG Context Refinement Agent"},"publishedDate":"Invalid Date"},"params":{"slug":"rag-context-refinement-agent"},"draftMode":false,"token":""},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"rag-context-refinement-agent"},"buildId":"C8J-EMc_4OCN1ch65l4fl","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>