<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>Introducing LlamaCloud and LlamaParse — LlamaIndex - Build Knowledge Assistants over your Enterprise Data</title><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><meta name="title" content="Introducing LlamaCloud and LlamaParse — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta name="description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:title" content="Introducing LlamaCloud and LlamaParse — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="og:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:image" content="https://cdn.sanity.io/images/7m9jw85w/production/65e2a4a5037cc464566a13e7828fbb905fd33b38-960x863.png"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="Introducing LlamaCloud and LlamaParse — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="twitter:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="twitter:image" content="https://cdn.sanity.io/images/7m9jw85w/production/65e2a4a5037cc464566a13e7828fbb905fd33b38-960x863.png"/><link rel="alternate" type="application/rss+xml" href="https://www.llamaindex.ai/blog/feed"/><meta name="next-head-count" content="20"/><script>
            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WWRFB36R');
            </script><link rel="preload" href="/_next/static/css/41c9222e47d080c9.css" as="style"/><link rel="stylesheet" href="/_next/static/css/41c9222e47d080c9.css" data-n-g=""/><link rel="preload" href="/_next/static/css/97c33c8d95f1230e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/97c33c8d95f1230e.css" data-n-p=""/><link rel="preload" href="/_next/static/css/e009059e80bf60c5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e009059e80bf60c5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-1b629d9c8fb16f34.js" defer=""></script><script src="/_next/static/chunks/framework-df1f68dff096b68a.js" defer=""></script><script src="/_next/static/chunks/main-eca7952a704663f8.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c7c49437be49d2ad.js" defer=""></script><script src="/_next/static/chunks/d9067523-4985945b21298365.js" defer=""></script><script src="/_next/static/chunks/41155975-60c12da9ce9fa0b2.js" defer=""></script><script src="/_next/static/chunks/cb355538-cee2ea45674d9de3.js" defer=""></script><script src="/_next/static/chunks/9494-dff62cb53535dd7d.js" defer=""></script><script src="/_next/static/chunks/4063-39a391a51171ff87.js" defer=""></script><script src="/_next/static/chunks/6889-edfa85b69b88a372.js" defer=""></script><script src="/_next/static/chunks/5575-11ee0a29eaffae61.js" defer=""></script><script src="/_next/static/chunks/3444-95c636af25a42734.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-82c8e764e69afd2c.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_buildManifest.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_ssgManifest.js" defer=""></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WWRFB36R" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div class="__variable_d65c78 __variable_b1ea77 __variable_eb7534"><a class="Announcement_announcement__2ohK8" href="http://48755185.hs-sites.com/llamaindex-0">Meet LlamaIndex at the Databricks Data + AI Summit!<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M8.293 5.293a1 1 0 0 1 1.414 0l6 6a1 1 0 0 1 0 1.414l-6 6a1 1 0 0 1-1.414-1.414L13.586 12 8.293 6.707a1 1 0 0 1 0-1.414Z" clip-rule="evenodd"></path></svg></a><header class="Header_header__hO3lJ"><button class="Hamburger_hamburger__17auO Header_hamburger__lUulX"><svg width="28" height="28" viewBox="0 0 28 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.5 14H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" id="hamburger-stroke-top" class="Hamburger_hamburgerStrokeMiddle__I7VpD"></path><path d="M3.5 7H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeTop__oOhFM"></path><path d="M3.5 21H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeBottom__GIQR2"></path></svg></button><a aria-label="Homepage" href="/"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" class="Header_logo__e5KhT" style="color:transparent" src="/llamaindex.svg"/></a><nav aria-label="Main" data-orientation="horizontal" dir="ltr" style="--content-position:0px"><div style="position:relative"><ul data-orientation="horizontal" class="Nav_MenuList__PrCDJ" dir="ltr"><li><button id="radix-:R6tm:-trigger-radix-:R5mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R5mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Products</button></li><li><button id="radix-:R6tm:-trigger-radix-:R9mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R9mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Solutions</button></li><li><a class="Nav_Link__ZrzFc" href="/community" data-radix-collection-item="">Community</a></li><li><a class="Nav_Link__ZrzFc" href="/pricing" data-radix-collection-item="">Pricing</a></li><li><a class="Nav_Link__ZrzFc" href="/blog" data-radix-collection-item="">Blog</a></li><li><a class="Nav_Link__ZrzFc" href="/customers" data-radix-collection-item="">Customer stories</a></li><li><a class="Nav_Link__ZrzFc" href="/careers" data-radix-collection-item="">Careers</a></li></ul></div><div class="Nav_ViewportPosition__jmyHM"></div></nav><div class="Header_secondNav__YJvm8"><nav><a href="/contact" class="Link_link__71cl8 Link_link-variant-tertiary__BYxn_ Header_bookADemo__qCuxV">Book a demo</a></nav><a href="https://cloud.llamaindex.ai/" class="Button_button-variant-default__Oi__n Button_button__aJ0V6 Header_button__1HFhY" data-tracking-variant="default"> <!-- -->Get started</a></div><div class="MobileMenu_mobileMenu__g5Fa6"><nav class="MobileMenu_nav__EmtTw"><ul><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Products<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaparse"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.6654 1.66675V6.66675H16.6654M8.33203 10.8334L6.66536 12.5001L8.33203 14.1667M11.6654 14.1667L13.332 12.5001L11.6654 10.8334M12.082 1.66675H4.9987C4.55667 1.66675 4.13275 1.84234 3.82019 2.1549C3.50763 2.46746 3.33203 2.89139 3.33203 3.33341V16.6667C3.33203 17.1088 3.50763 17.5327 3.82019 17.8453C4.13275 18.1578 4.55667 18.3334 4.9987 18.3334H14.9987C15.4407 18.3334 15.8646 18.1578 16.1772 17.8453C16.4898 17.5327 16.6654 17.1088 16.6654 16.6667V6.25008L12.082 1.66675Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Document parsing</div><p class="MobileMenu_ListItemText__n_MHY">The first and leading GenAI-native parser over your most complex data.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaextract"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.668 1.66675V5.00008C11.668 5.44211 11.8436 5.86603 12.1561 6.17859C12.4687 6.49115 12.8926 6.66675 13.3346 6.66675H16.668M3.33464 5.83341V3.33341C3.33464 2.89139 3.51023 2.46746 3.82279 2.1549C4.13535 1.84234 4.55927 1.66675 5.0013 1.66675H12.5013L16.668 5.83341V16.6667C16.668 17.1088 16.4924 17.5327 16.1798 17.8453C15.8672 18.1578 15.4433 18.3334 15.0013 18.3334L5.05379 18.3326C4.72458 18.3755 4.39006 18.3191 4.09312 18.1706C3.79618 18.0221 3.55034 17.7884 3.38713 17.4992M4.16797 9.16675L1.66797 11.6667M1.66797 11.6667L4.16797 14.1667M1.66797 11.6667H10.0013" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Data extraction</div><p class="MobileMenu_ListItemText__n_MHY">Extract structured data from documents using a schema-driven engine.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/enterprise"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.16667 15.8333C12.8486 15.8333 15.8333 12.8486 15.8333 9.16667C15.8333 5.48477 12.8486 2.5 9.16667 2.5C5.48477 2.5 2.5 5.48477 2.5 9.16667C2.5 12.8486 5.48477 15.8333 9.16667 15.8333Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M17.5 17.5L13.875 13.875" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Knowledge Management</div><p class="MobileMenu_ListItemText__n_MHY">Connect, transform, and index your enterprise data into an agent-accessible knowledge base</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/framework"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.0013 6.66659V3.33325H6.66797M1.66797 11.6666H3.33464M16.668 11.6666H18.3346M12.5013 10.8333V12.4999M7.5013 10.8333V12.4999M5.0013 6.66659H15.0013C15.9218 6.66659 16.668 7.41278 16.668 8.33325V14.9999C16.668 15.9204 15.9218 16.6666 15.0013 16.6666H5.0013C4.08083 16.6666 3.33464 15.9204 3.33464 14.9999V8.33325C3.33464 7.41278 4.08083 6.66659 5.0013 6.66659Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Agent Framework</div><p class="MobileMenu_ListItemText__n_MHY">Orchestrate and deploy multi-agent applications over your data with the #1 agent framework.</p></a></li></ul></details></li><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Solutions<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/finance"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 6.66675H8.33073C7.8887 6.66675 7.46478 6.84234 7.15222 7.1549C6.83966 7.46746 6.66406 7.89139 6.66406 8.33342C6.66406 8.77544 6.83966 9.19937 7.15222 9.51193C7.46478 9.82449 7.8887 10.0001 8.33073 10.0001H11.6641C12.1061 10.0001 12.53 10.1757 12.8426 10.4882C13.1551 10.8008 13.3307 11.2247 13.3307 11.6667C13.3307 12.1088 13.1551 12.5327 12.8426 12.8453C12.53 13.1578 12.1061 13.3334 11.6641 13.3334H6.66406M9.9974 15.0001V5.00008M18.3307 10.0001C18.3307 14.6025 14.5998 18.3334 9.9974 18.3334C5.39502 18.3334 1.66406 14.6025 1.66406 10.0001C1.66406 5.39771 5.39502 1.66675 9.9974 1.66675C14.5998 1.66675 18.3307 5.39771 18.3307 10.0001Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Financial Analysts</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/administrative-operations"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1.66406 6.66659V15.8333C1.66406 16.2753 1.83966 16.6992 2.15222 17.0118C2.46478 17.3243 2.8887 17.4999 3.33073 17.4999H14.9974M16.6641 14.1666C17.1061 14.1666 17.53 13.991 17.8426 13.6784C18.1551 13.3659 18.3307 12.9419 18.3307 12.4999V7.49992C18.3307 7.05789 18.1551 6.63397 17.8426 6.32141C17.53 6.00885 17.1061 5.83325 16.6641 5.83325H13.4141C13.1353 5.83598 12.8604 5.76876 12.6143 5.63774C12.3683 5.50671 12.159 5.31606 12.0057 5.08325L11.3307 4.08325C11.179 3.85281 10.9724 3.66365 10.7295 3.53275C10.4866 3.40185 10.215 3.3333 9.93906 3.33325H6.66406C6.22204 3.33325 5.79811 3.50885 5.48555 3.82141C5.17299 4.13397 4.9974 4.55789 4.9974 4.99992V12.4999C4.9974 12.9419 5.17299 13.3659 5.48555 13.6784C5.79811 13.991 6.22204 14.1666 6.66406 14.1666H16.6641Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Administrative Operations</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/engineering"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 15L18.3307 10L13.3307 5M6.66406 5L1.66406 10L6.66406 15" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Engineering &amp; R&amp;D</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/customer-support"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.9974 7.50008H16.6641C17.1061 7.50008 17.53 7.67568 17.8426 7.98824C18.1551 8.3008 18.3307 8.72472 18.3307 9.16675V18.3334L14.9974 15.0001H9.9974C9.55537 15.0001 9.13145 14.8245 8.81888 14.5119C8.50632 14.1994 8.33073 13.7754 8.33073 13.3334V12.5001M11.6641 7.50008C11.6641 7.94211 11.4885 8.36603 11.1759 8.67859C10.8633 8.99115 10.4394 9.16675 9.9974 9.16675H4.9974L1.66406 12.5001V3.33341C1.66406 2.41675 2.41406 1.66675 3.33073 1.66675H9.9974C10.4394 1.66675 10.8633 1.84234 11.1759 2.1549C11.4885 2.46746 11.6641 2.89139 11.6641 3.33341V7.50008Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Customer Support</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/healthcare-pharma"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M17.0128 3.81671C16.5948 3.39719 16.098 3.06433 15.551 2.8372C15.004 2.61008 14.4176 2.49316 13.8253 2.49316C13.2331 2.49316 12.6466 2.61008 12.0996 2.8372C11.5527 3.06433 11.0559 3.39719 10.6378 3.81671L9.99617 4.46671L9.3545 3.81671C8.93643 3.39719 8.43967 3.06433 7.89268 2.8372C7.3457 2.61008 6.75926 2.49316 6.167 2.49316C5.57474 2.49316 4.9883 2.61008 4.44132 2.8372C3.89433 3.06433 3.39756 3.39719 2.9795 3.81671C1.21283 5.58338 1.1045 8.56671 3.3295 10.8334L9.99617 17.5L16.6628 10.8334C18.8878 8.56671 18.7795 5.58338 17.0128 3.81671Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M2.91406 9.99992H7.91406L8.33073 9.16659L9.9974 12.9166L11.6641 7.08325L12.9141 9.99992H17.0807" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Healthcare / Pharma</div></a></li></ul></details></li><li><a class="MobileMenu_Link__5frcx" href="/community">Community</a></li><li><a class="MobileMenu_Link__5frcx" href="/pricing">Pricing</a></li><li><a class="MobileMenu_Link__5frcx" href="/blog">Blog</a></li><li><a class="MobileMenu_Link__5frcx" href="/customers">Customer stories</a></li><li><a class="MobileMenu_Link__5frcx" href="/careers">Careers</a></li></ul></nav><a href="/contact" class="Button_button-variant-ghost__o2AbG Button_button__aJ0V6" data-tracking-variant="ghost"> <!-- -->Talk to us</a><ul class="Socials_socials__8Y_s5 Socials_socials-theme-dark__Hq8lc MobileMenu_socials__JykCO"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu MobileMenu_copyright__nKVOs">© <!-- -->2025<!-- --> LlamaIndex</p></div></header><main><section class="BlogPost_post__JHNzd"><img alt="" loading="lazy" width="800" height="431.5" decoding="async" data-nimg="1" class="BlogPost_featuredImage__KGxwX" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F65e2a4a5037cc464566a13e7828fbb905fd33b38-960x863.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F65e2a4a5037cc464566a13e7828fbb905fd33b38-960x863.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F65e2a4a5037cc464566a13e7828fbb905fd33b38-960x863.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><p class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-600__fKYth BlogPost_date__6uxQw"><a class="BlogPost_author__mesdl" href="/blog/author/jerry-liu">Jerry Liu</a> <!-- -->•<!-- --> <!-- -->2024-02-20</p><h1 class="Text_text__zPO0D Text_text-size-32__koGps BlogPost_title__b2lqJ">Introducing LlamaCloud and LlamaParse</h1><ul class="BlogPost_tags__13pBH"><li><a class="Badge_badge___1ssn" href="/blog/tag/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Llamaindex</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/llm"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">LLM</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">AI</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/retrieval-augmented"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Retrieval Augmented</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/data"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Data</span></a></li></ul><div class="BlogPost_htmlPost__Z5oDL"><p>Today is a big day for the LlamaIndex ecosystem: we are announcing LlamaCloud, a new generation of managed parsing, ingestion, and retrieval services, designed to bring <strong>production-grade</strong> <strong>context-augmentation</strong> to your LLM and RAG applications.</p><p>Using LlamaCloud as an enterprise AI engineer, you can focus on writing the business logic and not on data wrangling. Process large volumes of production data, immediately leading to better response quality. LlamaCloud launches with the following key components:</p><ol><li><strong>LlamaParse:</strong> Proprietary parsing for complex documents with embedded objects such as tables and figures. LlamaParse directly integrates with LlamaIndex ingestion and retrieval to let you build retrieval over complex, semi-structured documents. You’ll be able to answer complex questions that simply weren’t possible previously.</li><li><strong>Managed Ingestion and Retrieval API:</strong> An API which allows you to easily load, process, and store data for your RAG app and consume it in any language. Backed by data sources in <a href="https://llamahub.ai/" rel="noopener ugc nofollow" target="_blank">LlamaHub</a>, including LlamaParse, and our data storage integrations.</li></ol><p>LlamaParse is available in a public preview setting starting today. It can currently handle PDFs and usage is capped for public use; <a href="https://llamaindex.ai/contact" rel="noopener ugc nofollow" target="_blank">contact us</a> for commercial terms. The managed ingestion and retrieval API is available as a private preview; we are offering access to a limited set of enterprise design partners. If you’re interested, <a href="https://llamaindex.ai/contact" rel="noopener ugc nofollow" target="_blank">get in touch</a>. (We’ve also launched a <a href="https://www.llamaindex.ai/" rel="noopener ugc nofollow" target="_blank">new version of our website</a> 🦙!)</p><h1>RAG is Only as Good as your Data</h1><p>A core promise of LLMs is the ability to automate knowledge search, synthesis, extraction, and planning over any source of unstructured data. Over the past year a new data stack has emerged to power these context-augmented LLM applications, popularly referred to as Retrieval-Augmented Generation (RAG). This stack includes loading data, processing it, embedding it, and loading into a vector database. This enables downstream orchestration of retrieval and prompting to provide context within an LLM app.</p><p>This stack is different from any ETL stack before it, because unlike traditional software, every decision in the data stack directly <strong>affects the accuracy</strong> of the full LLM-powered system. Every decision like chunk size and embedding model affects LLM outputs, and since LLMs are black boxes, you can’t unit test your way to correct behavior.</p><p>We’ve spent the past year hard at work at the forefront of providing tooling and educating users on how to build high-performing, advanced RAG for various use cases. We crossed the 2M monthly download mark, and are used by large enterprises to startups, including Adyen, T-Systems, Jasper.ai, Weights and Biases, DataStax, and many more.</p><p>But while getting started with our famous 5-line starter example is easy, building production-grade RAG remains a complex and subtle problem. In our hundreds of user conversations, we learned the biggest pain points:</p><ul><li><strong>Results aren’t accurate enough:</strong> The application was not able to produce satisfactory results for a long-tail of input tasks/queries.</li><li><strong>The number of parameters to tune is overwhelming:</strong> It’s not clear which parameters across the data parsing, ingestion, retrieval.</li><li><strong>PDFs are specifically a problem:</strong> I have complex docs with lots of messy formatting. How do I represent this in the right way so the LLM can understand it?</li><li><strong>Data syncing is a challenge:</strong> Production data often updates regularly, and continuously syncing new data brings a new set of challenges.</li></ul><p>These are the problems we set out to solve with LlamaCloud.</p><h1>Data Pipelines to Bring you to Production</h1><p>We built LlamaCloud and LlamaParse as the data pipelines to get your RAG application to production more quickly.</p><h1>LlamaParse</h1><p>LlamaParse is a state-of-the-art parser designed to specifically unlock RAG over complex PDFs with embedded tables and charts. This simply wasn’t possible before with other approaches, and we’re incredibly excited about this technology.</p><figure><figcaption class="pz fe qa pl pm qb qc be b bf z dt">LlamaParse Demo. Given a PDF file, returns a parsed markdown file that maintains semantic structure within the document.</figcaption><img src="/blog/images/1*MKmgF62Blz45SCpzzCm58g.png" alt="" width="700" height="630"></figure><p>For the past few months we’ve been obsessed with this problem. This is a surprisingly prevalent use case across a variety of data types and verticals, from ArXiv papers to 10K filings to medical reports.</p><p>Naive chunking and retrieval algorithms do terribly. We were the first to propose a <a href="https://docs.llamaindex.ai/en/stable/examples/query_engine/pdf_tables/recursive_retriever.html" rel="noopener ugc nofollow" target="_blank">novel recursive retrieval RAG technique</a> for being able to hierarchically index and query over tables and text in a document. The only challenge that remained was how to properly parse out tables and text in the first place.</p><figure><figcaption class="pz fe qa pl pm qb qc be b bf z dt">Comparison of LlamaParse vs. PyPDF over the Apple 10K filing. <a href="https://drive.google.com/file/d/1fyQAg7nOtChQzhF2Ai7HEeKYYqdeWsdt/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">Full comparisons are here</a>. A green highlight in a cell means that the RAG pipeline correctly returned the cell value as the answer to a question over that cell. A red highlight means that the question was answered incorrectly.</figcaption><img src="/blog/images/1*y5XbR-mfluMxkEo9G_6EFg.png" alt="" width="700" height="460"></figure><p>This is where LlamaParse comes in. We’ve developed a proprietary parsing service that is incredibly good at parsing PDFs with complex tables into a well-structured markdown format. This representation directly plugs into the advanced Markdown parsing and recursive retrieval algorithms available in the open-source library. The end result is that you are able to build RAG over complex documents that can answer questions over both tabular and unstructured data. Check out the results below for a comparison:</p><figure><figcaption class="pz fe qa pl pm qb qc be b bf z dt">Comparison of baseline PDF approach (top) vs. LlamaParse + advanced retrieval (bottom)</figcaption><img src="/blog/images/1*v_kwUZaZ765SpuJPp37_Qw.png" alt="" width="700" height="298"></figure><figure><figcaption class="pz fe qa pl pm qb qc be b bf z dt">Results over the <a href="https://github.com/run-llama/llama-hub/tree/main/llama_hub/llama_datasets/10k/uber_2021" rel="noopener ugc nofollow" target="_blank">Uber 10K Dataset</a>. For more information on our evaluation metrics check out our <a href="https://docs.llamaindex.ai/en/stable/module_guides/evaluating/root.html" rel="noopener ugc nofollow" target="_blank">evaluation page</a> here.</figcaption><img src="/blog/images/1*9g72gSs3lVwzkYZHfkG1aw.png" alt="" width="700" height="152"></figure><p>This service is available in a <strong>public preview mode:</strong> available to everyone, but with a usage limit (1k pages per day). It operates as a standalone service that also plugs into our managed ingestion and retrieval API (see below). Check out our <a href="https://docs.cloud.llamaindex.ai/llamaparse/" target="_blank">LlamaParse onboarding here</a> for more details.</p><pre><span id="e50b" class="qk oi gt qh b bf ql qm l qn qo"><span class="hljs-keyword">from</span> llama_parse <span class="hljs-keyword">import</span> LlamaParse

parser = LlamaParse(
    api_key=<span class="hljs-string">"llx-..."</span>,  <span class="hljs-comment"># can also be set in your env as LLAMA_CLOUD_API_KEY</span>
    result_type=<span class="hljs-string">"markdown"</span>,  <span class="hljs-comment"># "markdown" and "text" are available</span>
    verbose=<span class="hljs-literal">True</span>
)</span></pre><p>For unlimited commercial use of LlamaParse, <a href="https://llamaindex.ai/contact" rel="noopener ugc nofollow" target="_blank">get in touch</a> with us.</p><p><strong>Next Steps</strong></p><p>Our early users have already given us important feedback on what they’d like to see next. Currently we primarily support PDFs with tables, but we are also building out better support for figures, and and an expanded set of the most popular document types: .docx, .pptx, .html.</p><h1>Managed Ingestion and Retrieval</h1><p>Our other main offering in LlamaCloud is a managed ingestion and retrieval API which allows you to easily declare performant data pipelines for any context-augmented LLM application.</p><p>Get clean data for your LLM application, so you can spend less time wrangling data and more time writing core application logic. LlamaCloud empowers enterprise developers with the following benefits:</p><ul><li><strong>Engineering Time Savings:</strong> Instead of having to write custom connectors and parsing logic in Python, our APIs allow you to directly connect to different data sources.</li><li><strong>Performance:</strong> we provide good out-of-the-box performance for different data types, while offering an intuitive path for experimentation, evaluation, and improvement.</li><li><strong>Ease Systems Complexity:</strong> Handle a large number of data sources with incremental updates.</li></ul><p>Let’s do a brief tour through the core components!</p><ol><li><strong>Ingestion:</strong> Declare a managed pipeline to process and transform/chunk/embed data backed by our 150+ data sources in LlamaHub and our 40+ storage integrations as destinations. Automatically handle syncing and load balancing. Define through the UI or our open-source library.</li><li><strong>Retrieval:</strong> Get access to state-of-the-art, advanced retrieval backed by our open-source library and your data storage. Wrap it in an easy-to-use REST API that you can consume from any language.</li><li><strong>Playground:</strong> Interactive UI to test and refine your ingestion/retrieval strategies pre-deployment, with evaluations in the loop.</li></ol><figure><figcaption class="pz fe qa pl pm qb qc be b bf z dt">LlamaCloud Playground: configure, evaluate, and optimize your ingestion/retrieval pipeline before deployment.</figcaption><img src="/blog/images/1*GyTHgPBTZwQW-k_gmKdxwA.png" alt="" width="700" height="402"></figure><figure><figcaption class="pz fe qa pl pm qb qc be b bf z dt">LlamaCloud Retrieval: Access advanced retrieval over your storage system via an API.</figcaption><img src="/blog/images/1*xMLXXokE_cJt0cmM9gDdpw.png" alt="" width="700" height="430"></figure><p>We are opening up a private beta to a limited set of enterprise partners for the managed ingestion and retrieval API. If you’re interested in centralizing your data pipelines and spending more time working on your actual RAG use cases, come <a href="https://llamaindex.ai/contact" rel="noopener ugc nofollow" target="_blank">talk to us</a>.</p><h1>Launch Partners and Collaborators</h1><p>We opened up access to LlamaParse at <a href="https://rag-a-thon.devpost.com/" rel="noopener ugc nofollow" target="_blank">our hackathon</a> we co-hosted with <a href="https://www.futureproofsv.com/" rel="noopener ugc nofollow" target="_blank">Futureproof Labs</a> and <a href="https://www.datastax.com/" rel="noopener ugc nofollow" target="_blank">Datastax</a> at the beginning of February. We saw some incredible applications of LlamaParse in action, <a rel="noopener ugc nofollow" target="_blank" href="/pioneering-the-future-of-housing-introducing-genai-driven-adu-planning-ea950be71e2f">including parsing building codes for Accessory Dwelling Unit (ADU) planning</a>, <a href="https://devpost.com/software/home-ai" rel="noopener ugc nofollow" target="_blank">parsing real-estate disclosures for home buying</a>, and dozens more.</p><p>Eric Ciarla, co-founder at Mendable AI, incorporated LlamaParse into Mendable’s data stack: “We integrated LlamaParse into our <a href="https://github.com/mendableai/data-connectors" rel="noopener ugc nofollow" target="_blank">open source data connector repo</a> which powers our production ingestion suite. It was easy to integrate and more powerful than any of the alternatives we tried.”</p><p>We’re also excited to be joined by initial launch partners and collaborators in the LLM and AI ecosystem, from storage to compute.</p><p><strong>DataStax</strong></p><p>Datastax has incorporated LlamaParse into their RAGStack to bring a privacy-preserving out-of-the-box RAG solution for enterprises: "Last week one of our customers Imprompt has launched a pioneering 'Chat-to-Everything' platform leveraging RAGStack powered by LlamaIndex to enhance their enterprise offerings while prioritizing privacy." said Davor Bonaci, CTO and executive vice president, DataStax. "We're thrilled to partner with LlamaIndex to bring a streamlined solution to market. By incorporating LlamaIndex into RAGStack, we are providing enterprise developers with a comprehensive Gen AI stack that simplifies the complexities of RAG implementation, while offering long-term support and compatibility assurance.”</p><p><strong>MongoDB</strong></p><p>“MongoDB’s partnership with LlamaIndex allows for the ingestion of data into the MongoDB Atlas Vector database, and the retrieval of the index from Atlas via LlamaParse and LlamaCloud, enabling the development of RAG systems and other AI applications,” said Greg Maxson, Global Lead, AI Ecosystems at MongoDB. “Now, developers can abstract complexities associated with data ingestion, simplify RAG pipeline implementations, and more cost effectively develop large language model applications, ultimately accelerating generative AI app development and more quickly bringing apps to market.”</p><p><strong>Qdrant</strong></p><p>André Zayarni, CEO of Qdrant, says “The Qdrant team is excited to partner with LlamaIndex to combine the power of optimal data preprocessing, vectorization, and ingestion with Qdrant for a powerful fullstack RAG solution.”</p><p><strong>NVIDIA</strong></p><p>We are also excited to collaborate with NVIDIA to integrate LlamaIndex with the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" rel="noopener ugc nofollow" target="_blank">NVIDIA AI Enterprise</a> software platform for production AI: “LlamaCloud will help enterprises get generative AI applications from development into production with connectors that link proprietary data to the power of large language models,” said Justin Boitano, vice president, Enterprise and Edge Computing, NVIDIA. “Pairing LlamaCloud with NVIDIA AI Enterprise can accelerate the end-to-end LLM pipeline — including data processing, embedding creation, indexing, and model inference on accelerated computing across clouds, data centers and out to the edge.”</p><h1>FAQ</h1><p><strong>Is this competitive with vector databases?</strong></p><p>No. LlamaCloud is focused primarily on data parsing and ingestion, which is a complementary layer to any vector storage provider. The retrieval layer is orchestration on top of an existing storage system. LlamaIndex open-source integrates with 40+ of the most popular vector databases, and we are working hard to do the following:</p><ol><li>Integrate LlamaCloud with storage providers of existing design partners</li><li>Make LlamaCloud available in a more “self-serve” manner.</li></ol><h1>Next Steps</h1><p>As mentioned in the above sections, LlamaParse is available for public preview starting today with a usage cap. LlamaCloud is in a private preview mode; we are offering access to a limited set of enterprise design partners. If you’re interested come talk to us!</p><p>LlamaParse: <a href="https://github.com/run-llama/llama_parse" rel="noopener ugc nofollow" target="_blank">Repo</a>, <a href="https://github.com/run-llama/llama_parse/blob/main/examples/demo_advanced.ipynb" rel="noopener ugc nofollow" target="_blank">Cookbook</a>, <a href="https://www.llamaindex.ai/contact" rel="noopener ugc nofollow" target="_blank">Contact Us</a></p><p>LlamaCloud: <a href="https://www.llamaindex.ai/contact" rel="noopener ugc nofollow" target="_blank">Contact Us</a></p></div><div class="BlogPost_relatedPosts__0z6SN"><h2 class="Text_text__zPO0D Text_text-align-center__HhKqo Text_text-size-16__PkjFu Text_text-weight-400__5ENkK Text_text-family-spaceGrotesk__E4zcE BlogPost_relatedPostsTitle___JIrW">Related articles</h2><ul class="BlogPost_relatedPostsList__uOKzB"><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Faa21c9d353919277d4fce16f174e54280bda8660-1920x832.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Faa21c9d353919277d4fce16f174e54280bda8660-1920x832.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Faa21c9d353919277d4fce16f174e54280bda8660-1920x832.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/jamba-instruct-s-256k-context-window-on-llamaindex">Jamba-Instruct&#x27;s 256k context window on LlamaIndex</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-07-31</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F31290fcec6832b337689a39c17adf5d995ff46b6-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F31290fcec6832b337689a39c17adf5d995ff46b6-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F31290fcec6832b337689a39c17adf5d995ff46b6-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/llamaindex-newsletter-2024-04-02">LlamaIndex Newsletter 2024-04-02</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-04-02</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F67e9da6888edfa6119225413068198422f1eaf77-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F67e9da6888edfa6119225413068198422f1eaf77-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F67e9da6888edfa6119225413068198422f1eaf77-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/llamaindex-newsletter-2024-03-26">LlamaIndex Newsletter 2024-03-26</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-03-26</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F23819f5bd086643f28ca7d2746a9e400f28cdbee-1023x561.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F23819f5bd086643f28ca7d2746a9e400f28cdbee-1023x561.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F23819f5bd086643f28ca7d2746a9e400f28cdbee-1023x561.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations">Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-03-19</p></div></li></ul></div></section></main><footer class="Footer_footer__eNA9m"><div class="Footer_navContainer__7bvx4"><div class="Footer_logoContainer__3EpzI"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" style="color:transparent" src="/llamaindex.svg"/><div class="Footer_socialContainer__GdOgk"><ul class="Socials_socials__8Y_s5"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul></div></div><div class="Footer_nav__BLEuE"><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/">LlamaIndex</a></h3><ul><li><a href="/blog"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Blog</span></a></li><li><a href="/partners"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Partners</span></a></li><li><a href="/careers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Careers</span></a></li><li><a href="/contact"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Contact</span></a></li><li><a href="/brand"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Brand</span></a></li><li><a href="https://llamaindex.statuspage.io" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Status</span></a></li><li><a href="https://app.vanta.com/runllama.ai/trust/pkcgbjf8b3ihxjpqdx17nu" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Trust Center</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/enterprise">Enterprise</a></h3><ul><li><a href="https://cloud.llamaindex.ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaCloud</span></a></li><li><a href="https://cloud.llamaindex.ai/parse" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaParse</span></a></li><li><a href="/customers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Customers</span></a></li><li><a href="/llamacloud-sharepoint-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SharePoint</span></a></li><li><a href="/llamacloud-aws-s3-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">AWS S3</span></a></li><li><a href="/llamacloud-azure-blob-storage-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure Blob Storage</span></a></li><li><a href="/llamacloud-google-drive-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Google Drive</span></a></li> </ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/framework">Framework</a></h3><ul><li><a href="https://pypi.org/project/llama-index/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python package</span></a></li><li><a href="https://docs.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python docs</span></a></li><li><a href="https://www.npmjs.com/package/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript package</span></a></li><li><a href="https://ts.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript docs</span></a></li><li><a href="https://llamahub.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaHub</span></a></li><li><a href="https://github.com/run-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">GitHub</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/community">Community</a></h3><ul><li><a href="/community#newsletter"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Newsletter</span></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Discord</span></a></li><li><a href="https://www.linkedin.com/company/91154103/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LinkedIn</span></a></li><li><a href="https://twitter.com/llama_index"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Twitter/X</span></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">YouTube</span></a></li><li><a href="https://bsky.app/profile/llamaindex.bsky.social"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">BlueSky</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e">Starter projects</h3><ul><li><a href="https://www.npmjs.com/package/create-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">create-llama</span></a></li><li><a href="https://secinsights.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SEC Insights</span></a></li><li><a href="https://github.com/run-llama/llamabot"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaBot</span></a></li><li><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/rag_cli.html"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">RAG CLI</span></a></li></ul></div></div></div><div class="Footer_copyrightContainer__mBKsT"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA">© <!-- -->2025<!-- --> LlamaIndex</p><div class="Footer_legalNav__O1yJA"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/privacy-notice.pdf">Privacy Notice</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/terms-of-service.pdf">Terms of Service</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="https://bit.ly/llamaindexdpa">Data Processing Addendum</a></p></div></div></footer></div><svg xmlns="http://www.w3.org/2000/svg" class="flt_svg" style="display:none"><defs><filter id="flt_tag"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="2"></feGaussianBlur><feColorMatrix in="blur" result="flt_tag" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="flt_tag" operator="atop"></feComposite></filter><filter id="svg_blur_large"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="8"></feGaussianBlur><feColorMatrix in="blur" result="svg_blur_large" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="svg_blur_large" operator="atop"></feComposite></filter></defs></svg></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"page":{"announcement":{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"},"post":{"_createdAt":"2024-02-22T21:47:07Z","_id":"439e2065-5f29-4111-839d-d44af1c8c818","_rev":"Ys5IzmCaJ2UnW2RAX7UAxT","_type":"blogPost","_updatedAt":"2025-05-21T20:37:20Z","announcement":[{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"}],"authors":[{"_createdAt":"2024-02-22T19:59:39Z","_id":"26898661-ce74-4e56-a3bb-21000059ea8d","_rev":"1yZmiycp7gyBYGbmM40Ock","_type":"people","_updatedAt":"2025-05-07T15:41:41Z","image":{"_type":"image","asset":{"_ref":"image-e4426ff6862cbb8bec81b8407730e6e1e9383c8f-2176x2176-jpg","_type":"reference"}},"name":"Jerry Liu","position":"CEO","slug":{"_type":"slug","current":"jerry-liu"}}],"featured":false,"htmlContent":"\u003cp\u003eToday is a big day for the LlamaIndex ecosystem: we are announcing LlamaCloud, a new generation of managed parsing, ingestion, and retrieval services, designed to bring \u003cstrong\u003eproduction-grade\u003c/strong\u003e \u003cstrong\u003econtext-augmentation\u003c/strong\u003e to your LLM and RAG applications.\u003c/p\u003e\u003cp\u003eUsing LlamaCloud as an enterprise AI engineer, you can focus on writing the business logic and not on data wrangling. Process large volumes of production data, immediately leading to better response quality. LlamaCloud launches with the following key components:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eLlamaParse:\u003c/strong\u003e Proprietary parsing for complex documents with embedded objects such as tables and figures. LlamaParse directly integrates with LlamaIndex ingestion and retrieval to let you build retrieval over complex, semi-structured documents. You’ll be able to answer complex questions that simply weren’t possible previously.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eManaged Ingestion and Retrieval API:\u003c/strong\u003e An API which allows you to easily load, process, and store data for your RAG app and consume it in any language. Backed by data sources in \u003ca href=\"https://llamahub.ai/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eLlamaHub\u003c/a\u003e, including LlamaParse, and our data storage integrations.\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eLlamaParse is available in a public preview setting starting today. It can currently handle PDFs and usage is capped for public use; \u003ca href=\"https://llamaindex.ai/contact\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003econtact us\u003c/a\u003e for commercial terms. The managed ingestion and retrieval API is available as a private preview; we are offering access to a limited set of enterprise design partners. If you’re interested, \u003ca href=\"https://llamaindex.ai/contact\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eget in touch\u003c/a\u003e. (We’ve also launched a \u003ca href=\"https://www.llamaindex.ai/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003enew version of our website\u003c/a\u003e 🦙!)\u003c/p\u003e\u003ch1\u003eRAG is Only as Good as your Data\u003c/h1\u003e\u003cp\u003eA core promise of LLMs is the ability to automate knowledge search, synthesis, extraction, and planning over any source of unstructured data. Over the past year a new data stack has emerged to power these context-augmented LLM applications, popularly referred to as Retrieval-Augmented Generation (RAG). This stack includes loading data, processing it, embedding it, and loading into a vector database. This enables downstream orchestration of retrieval and prompting to provide context within an LLM app.\u003c/p\u003e\u003cp\u003eThis stack is different from any ETL stack before it, because unlike traditional software, every decision in the data stack directly \u003cstrong\u003eaffects the accuracy\u003c/strong\u003e of the full LLM-powered system. Every decision like chunk size and embedding model affects LLM outputs, and since LLMs are black boxes, you can’t unit test your way to correct behavior.\u003c/p\u003e\u003cp\u003eWe’ve spent the past year hard at work at the forefront of providing tooling and educating users on how to build high-performing, advanced RAG for various use cases. We crossed the 2M monthly download mark, and are used by large enterprises to startups, including Adyen, T-Systems, Jasper.ai, Weights and Biases, DataStax, and many more.\u003c/p\u003e\u003cp\u003eBut while getting started with our famous 5-line starter example is easy, building production-grade RAG remains a complex and subtle problem. In our hundreds of user conversations, we learned the biggest pain points:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eResults aren’t accurate enough:\u003c/strong\u003e The application was not able to produce satisfactory results for a long-tail of input tasks/queries.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eThe number of parameters to tune is overwhelming:\u003c/strong\u003e It’s not clear which parameters across the data parsing, ingestion, retrieval.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003ePDFs are specifically a problem:\u003c/strong\u003e I have complex docs with lots of messy formatting. How do I represent this in the right way so the LLM can understand it?\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eData syncing is a challenge:\u003c/strong\u003e Production data often updates regularly, and continuously syncing new data brings a new set of challenges.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThese are the problems we set out to solve with LlamaCloud.\u003c/p\u003e\u003ch1\u003eData Pipelines to Bring you to Production\u003c/h1\u003e\u003cp\u003eWe built LlamaCloud and LlamaParse as the data pipelines to get your RAG application to production more quickly.\u003c/p\u003e\u003ch1\u003eLlamaParse\u003c/h1\u003e\u003cp\u003eLlamaParse is a state-of-the-art parser designed to specifically unlock RAG over complex PDFs with embedded tables and charts. This simply wasn’t possible before with other approaches, and we’re incredibly excited about this technology.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption class=\"pz fe qa pl pm qb qc be b bf z dt\"\u003eLlamaParse Demo. Given a PDF file, returns a parsed markdown file that maintains semantic structure within the document.\u003c/figcaption\u003e\u003cimg src=\"/blog/images/1*MKmgF62Blz45SCpzzCm58g.png\" alt=\"\" width=\"700\" height=\"630\"\u003e\u003c/figure\u003e\u003cp\u003eFor the past few months we’ve been obsessed with this problem. This is a surprisingly prevalent use case across a variety of data types and verticals, from ArXiv papers to 10K filings to medical reports.\u003c/p\u003e\u003cp\u003eNaive chunking and retrieval algorithms do terribly. We were the first to propose a \u003ca href=\"https://docs.llamaindex.ai/en/stable/examples/query_engine/pdf_tables/recursive_retriever.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003enovel recursive retrieval RAG technique\u003c/a\u003e for being able to hierarchically index and query over tables and text in a document. The only challenge that remained was how to properly parse out tables and text in the first place.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption class=\"pz fe qa pl pm qb qc be b bf z dt\"\u003eComparison of LlamaParse vs. PyPDF over the Apple 10K filing. \u003ca href=\"https://drive.google.com/file/d/1fyQAg7nOtChQzhF2Ai7HEeKYYqdeWsdt/view?usp=sharing\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eFull comparisons are here\u003c/a\u003e. A green highlight in a cell means that the RAG pipeline correctly returned the cell value as the answer to a question over that cell. A red highlight means that the question was answered incorrectly.\u003c/figcaption\u003e\u003cimg src=\"/blog/images/1*y5XbR-mfluMxkEo9G_6EFg.png\" alt=\"\" width=\"700\" height=\"460\"\u003e\u003c/figure\u003e\u003cp\u003eThis is where LlamaParse comes in. We’ve developed a proprietary parsing service that is incredibly good at parsing PDFs with complex tables into a well-structured markdown format. This representation directly plugs into the advanced Markdown parsing and recursive retrieval algorithms available in the open-source library. The end result is that you are able to build RAG over complex documents that can answer questions over both tabular and unstructured data. Check out the results below for a comparison:\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption class=\"pz fe qa pl pm qb qc be b bf z dt\"\u003eComparison of baseline PDF approach (top) vs. LlamaParse + advanced retrieval (bottom)\u003c/figcaption\u003e\u003cimg src=\"/blog/images/1*v_kwUZaZ765SpuJPp37_Qw.png\" alt=\"\" width=\"700\" height=\"298\"\u003e\u003c/figure\u003e\u003cfigure\u003e\u003cfigcaption class=\"pz fe qa pl pm qb qc be b bf z dt\"\u003eResults over the \u003ca href=\"https://github.com/run-llama/llama-hub/tree/main/llama_hub/llama_datasets/10k/uber_2021\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eUber 10K Dataset\u003c/a\u003e. For more information on our evaluation metrics check out our \u003ca href=\"https://docs.llamaindex.ai/en/stable/module_guides/evaluating/root.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eevaluation page\u003c/a\u003e here.\u003c/figcaption\u003e\u003cimg src=\"/blog/images/1*9g72gSs3lVwzkYZHfkG1aw.png\" alt=\"\" width=\"700\" height=\"152\"\u003e\u003c/figure\u003e\u003cp\u003eThis service is available in a \u003cstrong\u003epublic preview mode:\u003c/strong\u003e available to everyone, but with a usage limit (1k pages per day). It operates as a standalone service that also plugs into our managed ingestion and retrieval API (see below). Check out our \u003ca href=\"https://docs.cloud.llamaindex.ai/llamaparse/\" target=\"_blank\"\u003eLlamaParse onboarding here\u003c/a\u003e for more details.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"e50b\" class=\"qk oi gt qh b bf ql qm l qn qo\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_parse \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e LlamaParse\n\nparser = LlamaParse(\n    api_key=\u003cspan class=\"hljs-string\"\u003e\"llx-...\"\u003c/span\u003e,  \u003cspan class=\"hljs-comment\"\u003e# can also be set in your env as LLAMA_CLOUD_API_KEY\u003c/span\u003e\n    result_type=\u003cspan class=\"hljs-string\"\u003e\"markdown\"\u003c/span\u003e,  \u003cspan class=\"hljs-comment\"\u003e# \"markdown\" and \"text\" are available\u003c/span\u003e\n    verbose=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e\n)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003eFor unlimited commercial use of LlamaParse, \u003ca href=\"https://llamaindex.ai/contact\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eget in touch\u003c/a\u003e with us.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eNext Steps\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eOur early users have already given us important feedback on what they’d like to see next. Currently we primarily support PDFs with tables, but we are also building out better support for figures, and and an expanded set of the most popular document types: .docx, .pptx, .html.\u003c/p\u003e\u003ch1\u003eManaged Ingestion and Retrieval\u003c/h1\u003e\u003cp\u003eOur other main offering in LlamaCloud is a managed ingestion and retrieval API which allows you to easily declare performant data pipelines for any context-augmented LLM application.\u003c/p\u003e\u003cp\u003eGet clean data for your LLM application, so you can spend less time wrangling data and more time writing core application logic. LlamaCloud empowers enterprise developers with the following benefits:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eEngineering Time Savings:\u003c/strong\u003e Instead of having to write custom connectors and parsing logic in Python, our APIs allow you to directly connect to different data sources.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003ePerformance:\u003c/strong\u003e we provide good out-of-the-box performance for different data types, while offering an intuitive path for experimentation, evaluation, and improvement.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eEase Systems Complexity:\u003c/strong\u003e Handle a large number of data sources with incremental updates.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eLet’s do a brief tour through the core components!\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eIngestion:\u003c/strong\u003e Declare a managed pipeline to process and transform/chunk/embed data backed by our 150+ data sources in LlamaHub and our 40+ storage integrations as destinations. Automatically handle syncing and load balancing. Define through the UI or our open-source library.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eRetrieval:\u003c/strong\u003e Get access to state-of-the-art, advanced retrieval backed by our open-source library and your data storage. Wrap it in an easy-to-use REST API that you can consume from any language.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003ePlayground:\u003c/strong\u003e Interactive UI to test and refine your ingestion/retrieval strategies pre-deployment, with evaluations in the loop.\u003c/li\u003e\u003c/ol\u003e\u003cfigure\u003e\u003cfigcaption class=\"pz fe qa pl pm qb qc be b bf z dt\"\u003eLlamaCloud Playground: configure, evaluate, and optimize your ingestion/retrieval pipeline before deployment.\u003c/figcaption\u003e\u003cimg src=\"/blog/images/1*GyTHgPBTZwQW-k_gmKdxwA.png\" alt=\"\" width=\"700\" height=\"402\"\u003e\u003c/figure\u003e\u003cfigure\u003e\u003cfigcaption class=\"pz fe qa pl pm qb qc be b bf z dt\"\u003eLlamaCloud Retrieval: Access advanced retrieval over your storage system via an API.\u003c/figcaption\u003e\u003cimg src=\"/blog/images/1*xMLXXokE_cJt0cmM9gDdpw.png\" alt=\"\" width=\"700\" height=\"430\"\u003e\u003c/figure\u003e\u003cp\u003eWe are opening up a private beta to a limited set of enterprise partners for the managed ingestion and retrieval API. If you’re interested in centralizing your data pipelines and spending more time working on your actual RAG use cases, come \u003ca href=\"https://llamaindex.ai/contact\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003etalk to us\u003c/a\u003e.\u003c/p\u003e\u003ch1\u003eLaunch Partners and Collaborators\u003c/h1\u003e\u003cp\u003eWe opened up access to LlamaParse at \u003ca href=\"https://rag-a-thon.devpost.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eour hackathon\u003c/a\u003e we co-hosted with \u003ca href=\"https://www.futureproofsv.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eFutureproof Labs\u003c/a\u003e and \u003ca href=\"https://www.datastax.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDatastax\u003c/a\u003e at the beginning of February. We saw some incredible applications of LlamaParse in action, \u003ca rel=\"noopener ugc nofollow\" target=\"_blank\" href=\"/pioneering-the-future-of-housing-introducing-genai-driven-adu-planning-ea950be71e2f\"\u003eincluding parsing building codes for Accessory Dwelling Unit (ADU) planning\u003c/a\u003e, \u003ca href=\"https://devpost.com/software/home-ai\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eparsing real-estate disclosures for home buying\u003c/a\u003e, and dozens more.\u003c/p\u003e\u003cp\u003eEric Ciarla, co-founder at Mendable AI, incorporated LlamaParse into Mendable’s data stack: “We integrated LlamaParse into our \u003ca href=\"https://github.com/mendableai/data-connectors\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eopen source data connector repo\u003c/a\u003e which powers our production ingestion suite. It was easy to integrate and more powerful than any of the alternatives we tried.”\u003c/p\u003e\u003cp\u003eWe’re also excited to be joined by initial launch partners and collaborators in the LLM and AI ecosystem, from storage to compute.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eDataStax\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eDatastax has incorporated LlamaParse into their RAGStack to bring a privacy-preserving out-of-the-box RAG solution for enterprises: \"Last week one of our customers Imprompt has launched a pioneering 'Chat-to-Everything' platform leveraging RAGStack powered by LlamaIndex to enhance their enterprise offerings while prioritizing privacy.\" said Davor Bonaci, CTO and executive vice president, DataStax. \"We're thrilled to partner with LlamaIndex to bring a streamlined solution to market. By incorporating LlamaIndex into RAGStack, we are providing enterprise developers with a comprehensive Gen AI stack that simplifies the complexities of RAG implementation, while offering long-term support and compatibility assurance.”\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eMongoDB\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e“MongoDB’s partnership with LlamaIndex allows for the ingestion of data into the MongoDB Atlas Vector database, and the retrieval of the index from Atlas via LlamaParse and LlamaCloud, enabling the development of RAG systems and other AI applications,” said Greg Maxson, Global Lead, AI Ecosystems at MongoDB. “Now, developers can abstract complexities associated with data ingestion, simplify RAG pipeline implementations, and more cost effectively develop large language model applications, ultimately accelerating generative AI app development and more quickly bringing apps to market.”\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eQdrant\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAndré Zayarni, CEO of Qdrant, says “The Qdrant team is excited to partner with LlamaIndex to combine the power of optimal data preprocessing, vectorization, and ingestion with Qdrant for a powerful fullstack RAG solution.”\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eNVIDIA\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWe are also excited to collaborate with NVIDIA to integrate LlamaIndex with the \u003ca href=\"https://www.nvidia.com/en-us/data-center/products/ai-enterprise/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eNVIDIA AI Enterprise\u003c/a\u003e software platform for production AI: “LlamaCloud will help enterprises get generative AI applications from development into production with connectors that link proprietary data to the power of large language models,” said Justin Boitano, vice president, Enterprise and Edge Computing, NVIDIA. “Pairing LlamaCloud with NVIDIA AI Enterprise can accelerate the end-to-end LLM pipeline — including data processing, embedding creation, indexing, and model inference on accelerated computing across clouds, data centers and out to the edge.”\u003c/p\u003e\u003ch1\u003eFAQ\u003c/h1\u003e\u003cp\u003e\u003cstrong\u003eIs this competitive with vector databases?\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eNo. LlamaCloud is focused primarily on data parsing and ingestion, which is a complementary layer to any vector storage provider. The retrieval layer is orchestration on top of an existing storage system. LlamaIndex open-source integrates with 40+ of the most popular vector databases, and we are working hard to do the following:\u003c/p\u003e\u003col\u003e\u003cli\u003eIntegrate LlamaCloud with storage providers of existing design partners\u003c/li\u003e\u003cli\u003eMake LlamaCloud available in a more “self-serve” manner.\u003c/li\u003e\u003c/ol\u003e\u003ch1\u003eNext Steps\u003c/h1\u003e\u003cp\u003eAs mentioned in the above sections, LlamaParse is available for public preview starting today with a usage cap. LlamaCloud is in a private preview mode; we are offering access to a limited set of enterprise design partners. If you’re interested come talk to us!\u003c/p\u003e\u003cp\u003eLlamaParse: \u003ca href=\"https://github.com/run-llama/llama_parse\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eRepo\u003c/a\u003e, \u003ca href=\"https://github.com/run-llama/llama_parse/blob/main/examples/demo_advanced.ipynb\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCookbook\u003c/a\u003e, \u003ca href=\"https://www.llamaindex.ai/contact\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eContact Us\u003c/a\u003e\u003c/p\u003e\u003cp\u003eLlamaCloud: \u003ca href=\"https://www.llamaindex.ai/contact\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eContact Us\u003c/a\u003e\u003c/p\u003e","image":{"_type":"image","asset":{"_ref":"image-65e2a4a5037cc464566a13e7828fbb905fd33b38-960x863-png","_type":"reference"}},"mainImage":"https://cdn.sanity.io/images/7m9jw85w/production/65e2a4a5037cc464566a13e7828fbb905fd33b38-960x863.png","publishedDate":"2024-02-20","relatedPosts":[{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-aa21c9d353919277d4fce16f174e54280bda8660-1920x832-png","_type":"reference"}},"publishedDate":"2024-07-31","slug":"jamba-instruct-s-256k-context-window-on-llamaindex","title":"Jamba-Instruct's 256k context window on LlamaIndex"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-31290fcec6832b337689a39c17adf5d995ff46b6-1024x1024-webp","_type":"reference"}},"publishedDate":"2024-04-02","slug":"llamaindex-newsletter-2024-04-02","title":"LlamaIndex Newsletter 2024-04-02"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-67e9da6888edfa6119225413068198422f1eaf77-1024x1024-png","_type":"reference"}},"publishedDate":"2024-03-26","slug":"llamaindex-newsletter-2024-03-26","title":"LlamaIndex Newsletter 2024-03-26"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-23819f5bd086643f28ca7d2746a9e400f28cdbee-1023x561-png","_type":"reference"}},"publishedDate":"2024-03-19","slug":"supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations","title":"Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations"}],"slug":{"_type":"slug","current":"introducing-llamacloud-and-llamaparse-af8cedf9006b"},"tags":[{"_createdAt":"2024-02-22T20:19:11Z","_id":"17d4fc95-517c-4f4a-95ce-bf753e802ac4","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"llamaindex"},"title":"Llamaindex"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"aa7d304e-787e-4a6c-80cb-8911afd4c788","_rev":"jbUo4a8sS9GhVRG46mMVHT","_type":"blogTag","_updatedAt":"2024-03-13T16:00:26Z","slug":{"_type":"slug","current":"llm"},"title":"LLM"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"d0a79109-34ab-41fa-a8f4-0b3522970c7d","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"ai"},"title":"AI"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"ab1559f4-5cbd-47f4-ac89-7b293fc14f4b","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"retrieval-augmented"},"title":"Retrieval Augmented"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"d05727dc-d53f-4ac2-b076-f4af681ec188","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"data"},"title":"Data"}],"title":"Introducing LlamaCloud and LlamaParse"},"publishedDate":"Invalid Date"},"params":{"slug":"introducing-llamacloud-and-llamaparse-af8cedf9006b"},"draftMode":false,"token":""},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"introducing-llamacloud-and-llamaparse-af8cedf9006b"},"buildId":"C8J-EMc_4OCN1ch65l4fl","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>