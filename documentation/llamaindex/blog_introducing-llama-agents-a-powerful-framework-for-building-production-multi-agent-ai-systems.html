<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>Introducing llama-agents: A Powerful Framework for Building Production Multi-Agent AI Systems — LlamaIndex - Build Knowledge Assistants over your Enterprise Data</title><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><meta name="title" content="Introducing llama-agents: A Powerful Framework for Building Production Multi-Agent AI Systems — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta name="description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:title" content="Introducing llama-agents: A Powerful Framework for Building Production Multi-Agent AI Systems — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="og:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:image" content="https://cdn.sanity.io/images/7m9jw85w/production/8de93915700c90d8442f4342edb3d9cdb5ef0266-720x402.png"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="Introducing llama-agents: A Powerful Framework for Building Production Multi-Agent AI Systems — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="twitter:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="twitter:image" content="https://cdn.sanity.io/images/7m9jw85w/production/8de93915700c90d8442f4342edb3d9cdb5ef0266-720x402.png"/><link rel="alternate" type="application/rss+xml" href="https://www.llamaindex.ai/blog/feed"/><meta name="next-head-count" content="20"/><script>
            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WWRFB36R');
            </script><link rel="preload" href="/_next/static/css/41c9222e47d080c9.css" as="style"/><link rel="stylesheet" href="/_next/static/css/41c9222e47d080c9.css" data-n-g=""/><link rel="preload" href="/_next/static/css/97c33c8d95f1230e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/97c33c8d95f1230e.css" data-n-p=""/><link rel="preload" href="/_next/static/css/e009059e80bf60c5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e009059e80bf60c5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-1b629d9c8fb16f34.js" defer=""></script><script src="/_next/static/chunks/framework-df1f68dff096b68a.js" defer=""></script><script src="/_next/static/chunks/main-eca7952a704663f8.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c7c49437be49d2ad.js" defer=""></script><script src="/_next/static/chunks/d9067523-4985945b21298365.js" defer=""></script><script src="/_next/static/chunks/41155975-60c12da9ce9fa0b2.js" defer=""></script><script src="/_next/static/chunks/cb355538-cee2ea45674d9de3.js" defer=""></script><script src="/_next/static/chunks/9494-dff62cb53535dd7d.js" defer=""></script><script src="/_next/static/chunks/4063-39a391a51171ff87.js" defer=""></script><script src="/_next/static/chunks/6889-edfa85b69b88a372.js" defer=""></script><script src="/_next/static/chunks/5575-11ee0a29eaffae61.js" defer=""></script><script src="/_next/static/chunks/3444-95c636af25a42734.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-82c8e764e69afd2c.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_buildManifest.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_ssgManifest.js" defer=""></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WWRFB36R" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div class="__variable_d65c78 __variable_b1ea77 __variable_eb7534"><a class="Announcement_announcement__2ohK8" href="http://48755185.hs-sites.com/llamaindex-0">Meet LlamaIndex at the Databricks Data + AI Summit!<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M8.293 5.293a1 1 0 0 1 1.414 0l6 6a1 1 0 0 1 0 1.414l-6 6a1 1 0 0 1-1.414-1.414L13.586 12 8.293 6.707a1 1 0 0 1 0-1.414Z" clip-rule="evenodd"></path></svg></a><header class="Header_header__hO3lJ"><button class="Hamburger_hamburger__17auO Header_hamburger__lUulX"><svg width="28" height="28" viewBox="0 0 28 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.5 14H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" id="hamburger-stroke-top" class="Hamburger_hamburgerStrokeMiddle__I7VpD"></path><path d="M3.5 7H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeTop__oOhFM"></path><path d="M3.5 21H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeBottom__GIQR2"></path></svg></button><a aria-label="Homepage" href="/"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" class="Header_logo__e5KhT" style="color:transparent" src="/llamaindex.svg"/></a><nav aria-label="Main" data-orientation="horizontal" dir="ltr" style="--content-position:0px"><div style="position:relative"><ul data-orientation="horizontal" class="Nav_MenuList__PrCDJ" dir="ltr"><li><button id="radix-:R6tm:-trigger-radix-:R5mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R5mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Products</button></li><li><button id="radix-:R6tm:-trigger-radix-:R9mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R9mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Solutions</button></li><li><a class="Nav_Link__ZrzFc" href="/community" data-radix-collection-item="">Community</a></li><li><a class="Nav_Link__ZrzFc" href="/pricing" data-radix-collection-item="">Pricing</a></li><li><a class="Nav_Link__ZrzFc" href="/blog" data-radix-collection-item="">Blog</a></li><li><a class="Nav_Link__ZrzFc" href="/customers" data-radix-collection-item="">Customer stories</a></li><li><a class="Nav_Link__ZrzFc" href="/careers" data-radix-collection-item="">Careers</a></li></ul></div><div class="Nav_ViewportPosition__jmyHM"></div></nav><div class="Header_secondNav__YJvm8"><nav><a href="/contact" class="Link_link__71cl8 Link_link-variant-tertiary__BYxn_ Header_bookADemo__qCuxV">Book a demo</a></nav><a href="https://cloud.llamaindex.ai/" class="Button_button-variant-default__Oi__n Button_button__aJ0V6 Header_button__1HFhY" data-tracking-variant="default"> <!-- -->Get started</a></div><div class="MobileMenu_mobileMenu__g5Fa6"><nav class="MobileMenu_nav__EmtTw"><ul><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Products<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaparse"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.6654 1.66675V6.66675H16.6654M8.33203 10.8334L6.66536 12.5001L8.33203 14.1667M11.6654 14.1667L13.332 12.5001L11.6654 10.8334M12.082 1.66675H4.9987C4.55667 1.66675 4.13275 1.84234 3.82019 2.1549C3.50763 2.46746 3.33203 2.89139 3.33203 3.33341V16.6667C3.33203 17.1088 3.50763 17.5327 3.82019 17.8453C4.13275 18.1578 4.55667 18.3334 4.9987 18.3334H14.9987C15.4407 18.3334 15.8646 18.1578 16.1772 17.8453C16.4898 17.5327 16.6654 17.1088 16.6654 16.6667V6.25008L12.082 1.66675Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Document parsing</div><p class="MobileMenu_ListItemText__n_MHY">The first and leading GenAI-native parser over your most complex data.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaextract"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.668 1.66675V5.00008C11.668 5.44211 11.8436 5.86603 12.1561 6.17859C12.4687 6.49115 12.8926 6.66675 13.3346 6.66675H16.668M3.33464 5.83341V3.33341C3.33464 2.89139 3.51023 2.46746 3.82279 2.1549C4.13535 1.84234 4.55927 1.66675 5.0013 1.66675H12.5013L16.668 5.83341V16.6667C16.668 17.1088 16.4924 17.5327 16.1798 17.8453C15.8672 18.1578 15.4433 18.3334 15.0013 18.3334L5.05379 18.3326C4.72458 18.3755 4.39006 18.3191 4.09312 18.1706C3.79618 18.0221 3.55034 17.7884 3.38713 17.4992M4.16797 9.16675L1.66797 11.6667M1.66797 11.6667L4.16797 14.1667M1.66797 11.6667H10.0013" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Data extraction</div><p class="MobileMenu_ListItemText__n_MHY">Extract structured data from documents using a schema-driven engine.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/enterprise"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.16667 15.8333C12.8486 15.8333 15.8333 12.8486 15.8333 9.16667C15.8333 5.48477 12.8486 2.5 9.16667 2.5C5.48477 2.5 2.5 5.48477 2.5 9.16667C2.5 12.8486 5.48477 15.8333 9.16667 15.8333Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M17.5 17.5L13.875 13.875" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Knowledge Management</div><p class="MobileMenu_ListItemText__n_MHY">Connect, transform, and index your enterprise data into an agent-accessible knowledge base</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/framework"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.0013 6.66659V3.33325H6.66797M1.66797 11.6666H3.33464M16.668 11.6666H18.3346M12.5013 10.8333V12.4999M7.5013 10.8333V12.4999M5.0013 6.66659H15.0013C15.9218 6.66659 16.668 7.41278 16.668 8.33325V14.9999C16.668 15.9204 15.9218 16.6666 15.0013 16.6666H5.0013C4.08083 16.6666 3.33464 15.9204 3.33464 14.9999V8.33325C3.33464 7.41278 4.08083 6.66659 5.0013 6.66659Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Agent Framework</div><p class="MobileMenu_ListItemText__n_MHY">Orchestrate and deploy multi-agent applications over your data with the #1 agent framework.</p></a></li></ul></details></li><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Solutions<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/finance"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 6.66675H8.33073C7.8887 6.66675 7.46478 6.84234 7.15222 7.1549C6.83966 7.46746 6.66406 7.89139 6.66406 8.33342C6.66406 8.77544 6.83966 9.19937 7.15222 9.51193C7.46478 9.82449 7.8887 10.0001 8.33073 10.0001H11.6641C12.1061 10.0001 12.53 10.1757 12.8426 10.4882C13.1551 10.8008 13.3307 11.2247 13.3307 11.6667C13.3307 12.1088 13.1551 12.5327 12.8426 12.8453C12.53 13.1578 12.1061 13.3334 11.6641 13.3334H6.66406M9.9974 15.0001V5.00008M18.3307 10.0001C18.3307 14.6025 14.5998 18.3334 9.9974 18.3334C5.39502 18.3334 1.66406 14.6025 1.66406 10.0001C1.66406 5.39771 5.39502 1.66675 9.9974 1.66675C14.5998 1.66675 18.3307 5.39771 18.3307 10.0001Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Financial Analysts</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/administrative-operations"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1.66406 6.66659V15.8333C1.66406 16.2753 1.83966 16.6992 2.15222 17.0118C2.46478 17.3243 2.8887 17.4999 3.33073 17.4999H14.9974M16.6641 14.1666C17.1061 14.1666 17.53 13.991 17.8426 13.6784C18.1551 13.3659 18.3307 12.9419 18.3307 12.4999V7.49992C18.3307 7.05789 18.1551 6.63397 17.8426 6.32141C17.53 6.00885 17.1061 5.83325 16.6641 5.83325H13.4141C13.1353 5.83598 12.8604 5.76876 12.6143 5.63774C12.3683 5.50671 12.159 5.31606 12.0057 5.08325L11.3307 4.08325C11.179 3.85281 10.9724 3.66365 10.7295 3.53275C10.4866 3.40185 10.215 3.3333 9.93906 3.33325H6.66406C6.22204 3.33325 5.79811 3.50885 5.48555 3.82141C5.17299 4.13397 4.9974 4.55789 4.9974 4.99992V12.4999C4.9974 12.9419 5.17299 13.3659 5.48555 13.6784C5.79811 13.991 6.22204 14.1666 6.66406 14.1666H16.6641Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Administrative Operations</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/engineering"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 15L18.3307 10L13.3307 5M6.66406 5L1.66406 10L6.66406 15" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Engineering &amp; R&amp;D</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/customer-support"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.9974 7.50008H16.6641C17.1061 7.50008 17.53 7.67568 17.8426 7.98824C18.1551 8.3008 18.3307 8.72472 18.3307 9.16675V18.3334L14.9974 15.0001H9.9974C9.55537 15.0001 9.13145 14.8245 8.81888 14.5119C8.50632 14.1994 8.33073 13.7754 8.33073 13.3334V12.5001M11.6641 7.50008C11.6641 7.94211 11.4885 8.36603 11.1759 8.67859C10.8633 8.99115 10.4394 9.16675 9.9974 9.16675H4.9974L1.66406 12.5001V3.33341C1.66406 2.41675 2.41406 1.66675 3.33073 1.66675H9.9974C10.4394 1.66675 10.8633 1.84234 11.1759 2.1549C11.4885 2.46746 11.6641 2.89139 11.6641 3.33341V7.50008Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Customer Support</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/healthcare-pharma"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M17.0128 3.81671C16.5948 3.39719 16.098 3.06433 15.551 2.8372C15.004 2.61008 14.4176 2.49316 13.8253 2.49316C13.2331 2.49316 12.6466 2.61008 12.0996 2.8372C11.5527 3.06433 11.0559 3.39719 10.6378 3.81671L9.99617 4.46671L9.3545 3.81671C8.93643 3.39719 8.43967 3.06433 7.89268 2.8372C7.3457 2.61008 6.75926 2.49316 6.167 2.49316C5.57474 2.49316 4.9883 2.61008 4.44132 2.8372C3.89433 3.06433 3.39756 3.39719 2.9795 3.81671C1.21283 5.58338 1.1045 8.56671 3.3295 10.8334L9.99617 17.5L16.6628 10.8334C18.8878 8.56671 18.7795 5.58338 17.0128 3.81671Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M2.91406 9.99992H7.91406L8.33073 9.16659L9.9974 12.9166L11.6641 7.08325L12.9141 9.99992H17.0807" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Healthcare / Pharma</div></a></li></ul></details></li><li><a class="MobileMenu_Link__5frcx" href="/community">Community</a></li><li><a class="MobileMenu_Link__5frcx" href="/pricing">Pricing</a></li><li><a class="MobileMenu_Link__5frcx" href="/blog">Blog</a></li><li><a class="MobileMenu_Link__5frcx" href="/customers">Customer stories</a></li><li><a class="MobileMenu_Link__5frcx" href="/careers">Careers</a></li></ul></nav><a href="/contact" class="Button_button-variant-ghost__o2AbG Button_button__aJ0V6" data-tracking-variant="ghost"> <!-- -->Talk to us</a><ul class="Socials_socials__8Y_s5 Socials_socials-theme-dark__Hq8lc MobileMenu_socials__JykCO"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu MobileMenu_copyright__nKVOs">© <!-- -->2025<!-- --> LlamaIndex</p></div></header><main><section class="BlogPost_post__JHNzd"><img alt="" loading="lazy" width="800" height="201" decoding="async" data-nimg="1" class="BlogPost_featuredImage__KGxwX" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F8de93915700c90d8442f4342edb3d9cdb5ef0266-720x402.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F8de93915700c90d8442f4342edb3d9cdb5ef0266-720x402.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F8de93915700c90d8442f4342edb3d9cdb5ef0266-720x402.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><p class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-600__fKYth BlogPost_date__6uxQw"><a class="BlogPost_author__mesdl" href="/blog/author/llamaindex">LlamaIndex</a> <!-- -->•<!-- --> <!-- -->2024-06-26</p><h1 class="Text_text__zPO0D Text_text-size-32__koGps BlogPost_title__b2lqJ">Introducing llama-agents: A Powerful Framework for Building Production Multi-Agent AI Systems</h1><ul class="BlogPost_tags__13pBH"><li><a class="Badge_badge___1ssn" href="/blog/tag/agents"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Agents</span></a></li></ul><div class="BlogPost_htmlPost__Z5oDL"><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We&#x27;re excited to announce the alpha release of <code class="SanityPortableText_inlineCode__cI85z">llama-agents</code>, a new open-source framework designed to simplify the process of building, iterating, and deploying multi-agent AI systems and turn your agents into production microservices. Whether you&#x27;re working on complex question-answering systems, collaborative AI assistants, or distributed AI workflows, llama-agents provides the tools and structure you need to bring your ideas to life.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Key Features of llama-agents</h2><ol><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>Distributed Service Oriented Architecture:</strong> every agent in LlamaIndex can be its own independently running microservice, orchestrated by a fully customizable LLM-powered control plane that routes and distributes tasks.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>Communication via standardized API interfaces:</strong> interface between agents using a central control plane orchestrator. Pass messages between agents using a message queue.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>Define agentic and explicit orchestration flows:</strong> developers have the flexibility to directly define the sequence of interactions between agents, or leave it up to an “agentic orchestrator” that decides which agents are relevant to the task.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>Ease of deployment:</strong> launch, scale and monitor each agent and your control plane independently.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>Scalability and resource management:</strong> use our built-in observability tools to monitor the quality and performance of the system and each individual agent service</li></ol><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Let&#x27;s dive into how you can start using llama-agents to build your own multi-agent systems.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Getting Started with llama-agents</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">First, install the framework using pip:</p><pre><code>pip install llama-agents llama-index-agent-openai</code></pre><h3 class="Text_text__zPO0D Text_text-size-40__fIyvA">Basic System Setup</h3><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Here&#x27;s a simple example of how to set up a basic multi-agent system using llama-agents. First we’ll bring in our dependencies and set up our control plane, which contains our LLM-powered orchestrator</p><pre><code><span class="hljs-keyword">import</span> dotenv
dotenv.load_dotenv() <span class="hljs-comment"># our .env file defines OPENAI_API_KEY</span>
<span class="hljs-keyword">from</span> llama_agents <span class="hljs-keyword">import</span> (
    AgentService,
    ControlPlaneServer,
    SimpleMessageQueue,
    AgentOrchestrator,
)
<span class="hljs-keyword">from</span> llama_index.core.agent <span class="hljs-keyword">import</span> FunctionCallingAgentWorker
<span class="hljs-keyword">from</span> llama_index.core.tools <span class="hljs-keyword">import</span> FunctionTool
<span class="hljs-keyword">from</span> llama_index.llms.openai <span class="hljs-keyword">import</span> OpenAI
<span class="hljs-keyword">import</span> logging

<span class="hljs-comment"># turn on logging so we can see the system working</span>
logging.getLogger(<span class="hljs-string">&quot;llama_agents&quot;</span>).setLevel(logging.INFO)

<span class="hljs-comment"># Set up the message queue and control plane</span>
message_queue = SimpleMessageQueue()
control_plane = ControlPlaneServer(
    message_queue=message_queue,
    orchestrator=AgentOrchestrator(llm=OpenAI()),
)</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Next we create our tools using LlamaIndex’s existing abstractions, provide those tools to an agent, and turn that agent into an independent microservice:</p><pre><code><span class="hljs-comment"># create a tool</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_the_secret_fact</span>() -&gt; <span class="hljs-built_in">str</span>:
    <span class="hljs-string">&quot;&quot;&quot;Returns the secret fact.&quot;&quot;&quot;</span>
    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;The secret fact is: A baby llama is called a &#x27;Cria&#x27;.&quot;</span>

tool = FunctionTool.from_defaults(fn=get_the_secret_fact)

<span class="hljs-comment"># Define an agent</span>
worker = FunctionCallingAgentWorker.from_tools([tool], llm=OpenAI())
agent = worker.as_agent()

<span class="hljs-comment"># Create an agent service</span>
agent_service = AgentService(
    agent=agent,
    message_queue=message_queue,
    description=<span class="hljs-string">&quot;General purpose assistant&quot;</span>,
    service_name=<span class="hljs-string">&quot;assistant&quot;</span>,
)</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Finally we launch the service and the control plane. Note that here we’re using a helper function to run a single query through the system and then exit; next we’ll show how to deploy this to production.</p><pre><code><span class="hljs-comment"># Set up the launcher for local testing</span>
<span class="hljs-keyword">from</span> llama_agents <span class="hljs-keyword">import</span> LocalLauncher

launcher = LocalLauncher(
    [agent_service],
    control_plane,
    message_queue,
)

<span class="hljs-comment"># Run a single query through the system</span>
result = launcher.launch_single(<span class="hljs-string">&quot;What&#x27;s the secret fact?&quot;</span>)
<span class="hljs-built_in">print</span>(result)</code></pre><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Deploying Your Multi-Agent System</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Once you&#x27;ve tested your system locally, you can deploy it as a set of services for real production use. Here&#x27;s how you might set that up. This is similar to the previous example, but we’ve added a second agent service and we’re using a different launcher. Let’s bring in our dependencies and set up our control plane again:</p><pre><code><span class="hljs-keyword">import</span> dotenv
dotenv.load_dotenv()
<span class="hljs-keyword">from</span> llama_agents <span class="hljs-keyword">import</span> (
    AgentService,
    AgentOrchestrator,
    ControlPlaneServer,
    SimpleMessageQueue,
)

<span class="hljs-keyword">from</span> llama_index.core.agent <span class="hljs-keyword">import</span> FunctionCallingAgentWorker
<span class="hljs-keyword">from</span> llama_index.core.tools <span class="hljs-keyword">import</span> FunctionTool
<span class="hljs-keyword">from</span> llama_index.llms.openai <span class="hljs-keyword">import</span> OpenAI
<span class="hljs-keyword">import</span> logging

<span class="hljs-comment"># change logging level to enable or disable more verbose logging</span>
logging.getLogger(<span class="hljs-string">&quot;llama_agents&quot;</span>).setLevel(logging.INFO)

<span class="hljs-comment"># create our multi-agent framework components</span>
message_queue = SimpleMessageQueue()
control_plane = ControlPlaneServer(
    message_queue=message_queue,
    orchestrator=AgentOrchestrator(llm=OpenAI()),
)</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Then as before we create a tool and an agent, though this time we’ll add a second agent:</p><pre><code><span class="hljs-comment"># create a tool</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_the_secret_fact</span>() -&gt; <span class="hljs-built_in">str</span>:
    <span class="hljs-string">&quot;&quot;&quot;Returns the secret fact.&quot;&quot;&quot;</span>
    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;The secret fact is: A baby llama is called a &#x27;Cria&#x27;.&quot;</span>

tool = FunctionTool.from_defaults(fn=get_the_secret_fact)

<span class="hljs-comment"># create our agents</span>
worker1 = FunctionCallingAgentWorker.from_tools([tool], llm=OpenAI())
worker2 = FunctionCallingAgentWorker.from_tools([], llm=OpenAI())
agent1 = worker1.as_agent()
agent2 = worker2.as_agent()</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We turn those agents into services:</p><pre><code>agent_server_1 = AgentService(
    agent=agent1,
    message_queue=message_queue,
    description=<span class="hljs-string">&quot;Useful for getting the secret fact.&quot;</span>,
    service_name=<span class="hljs-string">&quot;secret_fact_agent&quot;</span>,
    host=<span class="hljs-string">&quot;localhost&quot;</span>,
    port=<span class="hljs-number">8003</span>
)
agent_server_2 = AgentService(
    agent=agent2,
    message_queue=message_queue,
    description=<span class="hljs-string">&quot;Useful for getting random dumb facts.&quot;</span>,
    service_name=<span class="hljs-string">&quot;dumb_fact_agent&quot;</span>,
    host=<span class="hljs-string">&quot;localhost&quot;</span>,
    port=<span class="hljs-number">8004</span>
)</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">And finally we launch each service as an independent agent. Here we’re doing them all from a single script, but each of these could be a totally separate service, launched and scaled independently:</p><pre><code><span class="hljs-keyword">from</span> llama_agents <span class="hljs-keyword">import</span> ServerLauncher, CallableMessageConsumer

<span class="hljs-comment"># Additional human consumer</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">handle_result</span>(<span class="hljs-params">message</span>) -&gt; <span class="hljs-literal">None</span>:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Got result:&quot;</span>, message.data)


<span class="hljs-comment"># the final result is published to a &quot;human&quot; consumer</span>
<span class="hljs-comment"># so we define one to handle it!</span>
human_consumer = CallableMessageConsumer(
    handler=handle_result, message_type=<span class="hljs-string">&quot;human&quot;</span>
)

<span class="hljs-comment"># Define Launcher</span>
launcher = ServerLauncher(
    [agent_server_1, agent_server_2],
    control_plane,
    message_queue,
    additional_consumers=[human_consumer]
)

launcher.launch_servers()</code></pre><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Real-time monitoring</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">One of the coolest debugging features of our multi-agent system is our agent monitor, which is built right in. You launch it like this:</p><pre><code>llama-agents monitor --control-plane-url http://127.0.0.1:8000</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Once launched, you get an intuitive, point-and-click terminal application. You can see both of the agents running, and at the bottom you can inject a task like the query “What is the secret fact?” You’ll get a job ID which you can then click on to see your results:</p><figure><img alt="" loading="lazy" width="549" height="307.5" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F077894fcf1dc8b2cd0ee5999ed58e252479783c4-1098x615.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F077894fcf1dc8b2cd0ee5999ed58e252479783c4-1098x615.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1200&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F077894fcf1dc8b2cd0ee5999ed58e252479783c4-1098x615.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1200&amp;q=75"/></figure><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Building a Query Rewriting RAG System</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Let&#x27;s look at a more complex example: a Query Rewriting RAG system. This system will rewrite user queries to improve retrieval, then use the rewritten query to perform RAG over a document.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">This example demonstrates how to create a more sophisticated system that combines query rewriting with RAG to improve question-answering capabilities. See <a href="https://github.com/run-llama/llama-agents/blob/main/examples/query_rewrite_rag.ipynb" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">this notebook</a> for a fuller explanation of what’s going on.</p><pre><code><span class="hljs-keyword">import</span> dotenv
dotenv.load_dotenv() <span class="hljs-comment"># our .env defines OPENAI_API_KEY</span>
<span class="hljs-keyword">from</span> llama_index.core <span class="hljs-keyword">import</span> VectorStoreIndex, Document
<span class="hljs-keyword">from</span> llama_index.core.agent <span class="hljs-keyword">import</span> FnAgentWorker
<span class="hljs-keyword">from</span> llama_index.core <span class="hljs-keyword">import</span> PromptTemplate
<span class="hljs-keyword">from</span> llama_index.core.query_pipeline <span class="hljs-keyword">import</span> QueryPipeline
<span class="hljs-keyword">from</span> llama_index.core.query_engine <span class="hljs-keyword">import</span> RetrieverQueryEngine
<span class="hljs-keyword">from</span> llama_agents <span class="hljs-keyword">import</span> (
    AgentService,
    ControlPlaneServer,
    SimpleMessageQueue,
    PipelineOrchestrator,
    ServiceComponent,
)
<span class="hljs-keyword">from</span> llama_agents.launchers <span class="hljs-keyword">import</span> LocalLauncher
<span class="hljs-keyword">from</span> llama_index.llms.openai <span class="hljs-keyword">import</span> OpenAI
<span class="hljs-keyword">import</span> logging

<span class="hljs-comment"># change logging level to enable or disable more verbose logging</span>
logging.getLogger(<span class="hljs-string">&quot;llama_agents&quot;</span>).setLevel(logging.INFO)

<span class="hljs-comment"># Load and index your document</span>
docs = [Document(text=<span class="hljs-string">&quot;The rabbit is a small mammal with long ears and a fluffy tail. His name is Peter.&quot;</span>)]
index = VectorStoreIndex.from_documents(docs)

<span class="hljs-comment"># Define a query rewrite agent</span>
HYDE_PROMPT_STR = (
    <span class="hljs-string">&quot;Please rewrite the following query to include more detail:\n{query_str}\n&quot;</span>
)
HYDE_PROMPT_TMPL = PromptTemplate(HYDE_PROMPT_STR)

<span class="hljs-keyword">def</span> <span class="hljs-title function_">run_hyde_fn</span>(<span class="hljs-params">state</span>):
    prompt_tmpl, llm, input_str = (
        state[<span class="hljs-string">&quot;prompt_tmpl&quot;</span>],
        state[<span class="hljs-string">&quot;llm&quot;</span>],
        state[<span class="hljs-string">&quot;__task__&quot;</span>].<span class="hljs-built_in">input</span>,
    )
    qp = QueryPipeline(chain=[prompt_tmpl, llm])
    output = qp.run(query_str=input_str)
    state[<span class="hljs-string">&quot;__output__&quot;</span>] = <span class="hljs-built_in">str</span>(output)
    <span class="hljs-keyword">return</span> state, <span class="hljs-literal">True</span>

hyde_agent = FnAgentWorker(
    fn=run_hyde_fn,
    initial_state={<span class="hljs-string">&quot;prompt_tmpl&quot;</span>: HYDE_PROMPT_TMPL, <span class="hljs-string">&quot;llm&quot;</span>: OpenAI()}
).as_agent()

<span class="hljs-comment"># Define a RAG agent</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">run_rag_fn</span>(<span class="hljs-params">state</span>):
    retriever, llm, input_str = (
        state[<span class="hljs-string">&quot;retriever&quot;</span>],
        state[<span class="hljs-string">&quot;llm&quot;</span>],
        state[<span class="hljs-string">&quot;__task__&quot;</span>].<span class="hljs-built_in">input</span>,
    )
    query_engine = RetrieverQueryEngine.from_args(retriever, llm=llm)
    response = query_engine.query(input_str)
    state[<span class="hljs-string">&quot;__output__&quot;</span>] = <span class="hljs-built_in">str</span>(response)
    <span class="hljs-keyword">return</span> state, <span class="hljs-literal">True</span>

rag_agent = FnAgentWorker(
    fn=run_rag_fn,
    initial_state={<span class="hljs-string">&quot;retriever&quot;</span>: index.as_retriever(), <span class="hljs-string">&quot;llm&quot;</span>: OpenAI()}
).as_agent()

<span class="hljs-comment"># Set up the multi-agent system</span>
message_queue = SimpleMessageQueue()

query_rewrite_service = AgentService(
    agent=hyde_agent,
    message_queue=message_queue,
    description=<span class="hljs-string">&quot;Query rewriting service&quot;</span>,
    service_name=<span class="hljs-string">&quot;query_rewrite&quot;</span>,
)

rag_service = AgentService(
    agent=rag_agent,
    message_queue=message_queue,
    description=<span class="hljs-string">&quot;RAG service&quot;</span>,
    service_name=<span class="hljs-string">&quot;rag&quot;</span>,
)

<span class="hljs-comment"># Create the pipeline</span>
pipeline = QueryPipeline(chain=[
    ServiceComponent.from_service_definition(query_rewrite_service),
    ServiceComponent.from_service_definition(rag_service),
])
orchestrator = PipelineOrchestrator(pipeline)

control_plane = ControlPlaneServer(
    message_queue=message_queue,
    orchestrator=orchestrator,
)

<span class="hljs-comment"># Set up the launcher</span>
launcher = LocalLauncher(
    [query_rewrite_service, rag_service],
    control_plane,
    message_queue,
)

<span class="hljs-comment"># Run a query</span>
result = launcher.launch_single(<span class="hljs-string">&quot;Tell me about rabbits&quot;</span>)
<span class="hljs-built_in">print</span>(result)</code></pre><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Public roadmap</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">This is an alpha release, meaning that we’d love your feedback on features to better help you build multi-agent systems in production! We’ve created a <a href="https://github.com/run-llama/llama-agents/discussions/49" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">public roadmap</a> showing where we plan to go from here. We’re actively seeking public feedback on what works for you and what doesn’t.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Dive in!</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><code class="SanityPortableText_inlineCode__cI85z">llama-agents</code> provides a powerful, flexible framework for building complex multi-agent AI systems. Whether you&#x27;re prototyping a new idea or scaling to production, <code class="SanityPortableText_inlineCode__cI85z">llama-agents</code> offers the tools you need to bring your AI vision to life. Check out <a href="https://github.com/run-llama/llama-agents" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">the repo</a> to learn more, especially our library of <a href="https://github.com/run-llama/llama-agents/tree/main/examples" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">examples</a>.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We&#x27;re excited to see what the community builds with <code class="SanityPortableText_inlineCode__cI85z">llama-agents</code>. Happy coding!</p></div><div class="BlogPost_relatedPosts__0z6SN"><h2 class="Text_text__zPO0D Text_text-align-center__HhKqo Text_text-size-16__PkjFu Text_text-weight-400__5ENkK Text_text-family-spaceGrotesk__E4zcE BlogPost_relatedPostsTitle___JIrW">Related articles</h2><ul class="BlogPost_relatedPostsList__uOKzB"><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F89380b5946452462d6c4a91f8109f705dc044c82-1080x1080.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F89380b5946452462d6c4a91f8109f705dc044c82-1080x1080.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F89380b5946452462d6c4a91f8109f705dc044c82-1080x1080.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/introducing-the-spreadsheet-agent-in-private-preview">Introducing the Spreadsheet Agent, in private preview</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2025-06-05</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9fdb15bafdf8c0921f36c6cd8cdac43c8ca87e27-2232x1562.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9fdb15bafdf8c0921f36c6cd8cdac43c8ca87e27-2232x1562.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9fdb15bafdf8c0921f36c6cd8cdac43c8ca87e27-2232x1562.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/rag-is-dead-long-live-agentic-retrieval">RAG is dead, long live agentic retrieval</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2025-05-29</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fadd5d90d8aa67ca128a834e2b8fcbb7746c585cd-734x379.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fadd5d90d8aa67ca128a834e2b8fcbb7746c585cd-734x379.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fadd5d90d8aa67ca128a834e2b8fcbb7746c585cd-734x379.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/improved-long-and-short-term-memory-for-llamaindex-agents">Improved Long &amp; Short-Term Memory for LlamaIndex Agents</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2025-05-13</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fdde8a9c277605647a344c6f4cd83d1ad192e1a09-1024x1536.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fdde8a9c277605647a344c6f4cd83d1ad192e1a09-1024x1536.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fdde8a9c277605647a344c6f4cd83d1ad192e1a09-1024x1536.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/bending-without-breaking-optimal-design-patterns-for-effective-agents">Bending without breaking: optimal design patterns for effective agents</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2025-04-25</p></div></li></ul></div></section></main><footer class="Footer_footer__eNA9m"><div class="Footer_navContainer__7bvx4"><div class="Footer_logoContainer__3EpzI"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" style="color:transparent" src="/llamaindex.svg"/><div class="Footer_socialContainer__GdOgk"><ul class="Socials_socials__8Y_s5"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul></div></div><div class="Footer_nav__BLEuE"><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/">LlamaIndex</a></h3><ul><li><a href="/blog"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Blog</span></a></li><li><a href="/partners"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Partners</span></a></li><li><a href="/careers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Careers</span></a></li><li><a href="/contact"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Contact</span></a></li><li><a href="/brand"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Brand</span></a></li><li><a href="https://llamaindex.statuspage.io" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Status</span></a></li><li><a href="https://app.vanta.com/runllama.ai/trust/pkcgbjf8b3ihxjpqdx17nu" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Trust Center</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/enterprise">Enterprise</a></h3><ul><li><a href="https://cloud.llamaindex.ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaCloud</span></a></li><li><a href="https://cloud.llamaindex.ai/parse" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaParse</span></a></li><li><a href="/customers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Customers</span></a></li><li><a href="/llamacloud-sharepoint-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SharePoint</span></a></li><li><a href="/llamacloud-aws-s3-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">AWS S3</span></a></li><li><a href="/llamacloud-azure-blob-storage-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure Blob Storage</span></a></li><li><a href="/llamacloud-google-drive-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Google Drive</span></a></li> </ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/framework">Framework</a></h3><ul><li><a href="https://pypi.org/project/llama-index/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python package</span></a></li><li><a href="https://docs.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python docs</span></a></li><li><a href="https://www.npmjs.com/package/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript package</span></a></li><li><a href="https://ts.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript docs</span></a></li><li><a href="https://llamahub.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaHub</span></a></li><li><a href="https://github.com/run-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">GitHub</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/community">Community</a></h3><ul><li><a href="/community#newsletter"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Newsletter</span></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Discord</span></a></li><li><a href="https://www.linkedin.com/company/91154103/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LinkedIn</span></a></li><li><a href="https://twitter.com/llama_index"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Twitter/X</span></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">YouTube</span></a></li><li><a href="https://bsky.app/profile/llamaindex.bsky.social"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">BlueSky</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e">Starter projects</h3><ul><li><a href="https://www.npmjs.com/package/create-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">create-llama</span></a></li><li><a href="https://secinsights.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SEC Insights</span></a></li><li><a href="https://github.com/run-llama/llamabot"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaBot</span></a></li><li><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/rag_cli.html"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">RAG CLI</span></a></li></ul></div></div></div><div class="Footer_copyrightContainer__mBKsT"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA">© <!-- -->2025<!-- --> LlamaIndex</p><div class="Footer_legalNav__O1yJA"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/privacy-notice.pdf">Privacy Notice</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/terms-of-service.pdf">Terms of Service</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="https://bit.ly/llamaindexdpa">Data Processing Addendum</a></p></div></div></footer></div><svg xmlns="http://www.w3.org/2000/svg" class="flt_svg" style="display:none"><defs><filter id="flt_tag"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="2"></feGaussianBlur><feColorMatrix in="blur" result="flt_tag" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="flt_tag" operator="atop"></feComposite></filter><filter id="svg_blur_large"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="8"></feGaussianBlur><feColorMatrix in="blur" result="svg_blur_large" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="svg_blur_large" operator="atop"></feComposite></filter></defs></svg></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"page":{"announcement":{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"},"post":{"_createdAt":"2024-06-26T21:50:37Z","_id":"33e63b95-99a7-45d7-bd80-ca570e4b8547","_rev":"Ys5IzmCaJ2UnW2RAX7U8Ea","_type":"blogPost","_updatedAt":"2025-05-21T20:37:05Z","announcement":[{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"}],"authors":[{"_createdAt":"2024-02-20T20:23:12Z","_id":"363ec4e9-0b8f-48d2-ba6a-567a9c527c3d","_rev":"rGZ2nN6K5mjOGJOoWaUhNb","_type":"people","_updatedAt":"2024-02-25T00:45:24Z","image":{"_type":"image","asset":{"_ref":"image-89523511cf20d73e3f10077add50128d077ed520-176x176-png","_type":"reference"}},"name":"LlamaIndex","slug":{"_type":"slug","current":"llamaindex"}}],"featured":false,"image":{"_type":"image","asset":{"_ref":"image-8de93915700c90d8442f4342edb3d9cdb5ef0266-720x402-png","_type":"reference"}},"mainImage":"https://cdn.sanity.io/images/7m9jw85w/production/8de93915700c90d8442f4342edb3d9cdb5ef0266-720x402.png","publishedDate":"2024-06-26","relatedPosts":[{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-89380b5946452462d6c4a91f8109f705dc044c82-1080x1080-png","_type":"reference"}},"publishedDate":"2025-06-05","slug":"introducing-the-spreadsheet-agent-in-private-preview","title":"Introducing the Spreadsheet Agent, in private preview"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-9fdb15bafdf8c0921f36c6cd8cdac43c8ca87e27-2232x1562-png","_type":"reference"}},"publishedDate":"2025-05-29","slug":"rag-is-dead-long-live-agentic-retrieval","title":"RAG is dead, long live agentic retrieval"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-add5d90d8aa67ca128a834e2b8fcbb7746c585cd-734x379-png","_type":"reference"}},"publishedDate":"2025-05-13","slug":"improved-long-and-short-term-memory-for-llamaindex-agents","title":"Improved Long \u0026 Short-Term Memory for LlamaIndex Agents"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-dde8a9c277605647a344c6f4cd83d1ad192e1a09-1024x1536-png","_type":"reference"}},"publishedDate":"2025-04-25","slug":"bending-without-breaking-optimal-design-patterns-for-effective-agents","title":"Bending without breaking: optimal design patterns for effective agents"}],"slug":{"_type":"slug","current":"introducing-llama-agents-a-powerful-framework-for-building-production-multi-agent-ai-systems"},"tags":[{"_createdAt":"2024-02-22T20:19:11Z","_id":"248fed26-a405-4fa0-ba99-8f1af0df185c","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"agents"},"title":"Agents"}],"text":[{"_key":"4f3ffdb90d79","_type":"block","children":[{"_key":"7c3f84e7f3e90","_type":"span","marks":[],"text":"We're excited to announce the alpha release of "},{"_key":"7c3f84e7f3e91","_type":"span","marks":["code"],"text":"llama-agents"},{"_key":"7c3f84e7f3e92","_type":"span","marks":[],"text":", a new open-source framework designed to simplify the process of building, iterating, and deploying multi-agent AI systems and turn your agents into production microservices. Whether you're working on complex question-answering systems, collaborative AI assistants, or distributed AI workflows, llama-agents provides the tools and structure you need to bring your ideas to life."}],"markDefs":[],"style":"normal"},{"_key":"2a540f88ac6a","_type":"block","children":[{"_key":"7d1727b5e38a0","_type":"span","marks":[],"text":"Key Features of llama-agents"}],"markDefs":[],"style":"h2"},{"_key":"d4883970aa04","_type":"block","children":[{"_key":"9ad2cbbb165f0","_type":"span","marks":["strong"],"text":"Distributed Service Oriented Architecture:"},{"_key":"9ad2cbbb165f1","_type":"span","marks":[],"text":" every agent in LlamaIndex can be its own independently running microservice, orchestrated by a fully customizable LLM-powered control plane that routes and distributes tasks."}],"level":1,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"e24cd25dc6c2","_type":"block","children":[{"_key":"7e26f61d5d380","_type":"span","marks":["strong"],"text":"Communication via standardized API interfaces:"},{"_key":"7e26f61d5d381","_type":"span","marks":[],"text":" interface between agents using a central control plane orchestrator. Pass messages between agents using a message queue."}],"level":1,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"d1790fbb3d43","_type":"block","children":[{"_key":"b67ef37d03990","_type":"span","marks":["strong"],"text":"Define agentic and explicit orchestration flows:"},{"_key":"b67ef37d03991","_type":"span","marks":[],"text":" developers have the flexibility to directly define the sequence of interactions between agents, or leave it up to an “agentic orchestrator” that decides which agents are relevant to the task."}],"level":1,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"f476524c96ba","_type":"block","children":[{"_key":"5cc664b2fddb0","_type":"span","marks":["strong"],"text":"Ease of deployment:"},{"_key":"5cc664b2fddb1","_type":"span","marks":[],"text":" launch, scale and monitor each agent and your control plane independently."}],"level":1,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"b705e58ca778","_type":"block","children":[{"_key":"f6bdb23895080","_type":"span","marks":["strong"],"text":"Scalability and resource management:"},{"_key":"f6bdb23895081","_type":"span","marks":[],"text":" use our built-in observability tools to monitor the quality and performance of the system and each individual agent service"}],"level":1,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"787bd77c829f","_type":"block","children":[{"_key":"6d3b8e8d7dd20","_type":"span","marks":[],"text":"Let's dive into how you can start using llama-agents to build your own multi-agent systems."}],"markDefs":[],"style":"normal"},{"_key":"127b5273af47","_type":"block","children":[{"_key":"44bce39b0d460","_type":"span","marks":[],"text":"Getting Started with llama-agents"}],"markDefs":[],"style":"h2"},{"_key":"80cdbad30082","_type":"block","children":[{"_key":"614391a64fee0","_type":"span","marks":[],"text":"First, install the framework using pip:"}],"markDefs":[],"style":"normal"},{"_key":"49ca77c7a81b","_type":"codeBlock","code":"pip install llama-agents llama-index-agent-openai","language":"sh"},{"_key":"c189ee5f22c3","_type":"block","children":[{"_key":"504dbbf8f15e0","_type":"span","marks":[],"text":"Basic System Setup"}],"markDefs":[],"style":"h3"},{"_key":"d698431d84b5","_type":"block","children":[{"_key":"6dcd9baef2750","_type":"span","marks":[],"text":"Here's a simple example of how to set up a basic multi-agent system using llama-agents. First we’ll bring in our dependencies and set up our control plane, which contains our LLM-powered orchestrator"}],"markDefs":[],"style":"normal"},{"_key":"c8b4b2aa4d8e","_type":"codeBlock","code":"import dotenv\ndotenv.load_dotenv() # our .env file defines OPENAI_API_KEY\nfrom llama_agents import (\n    AgentService,\n    ControlPlaneServer,\n    SimpleMessageQueue,\n    AgentOrchestrator,\n)\nfrom llama_index.core.agent import FunctionCallingAgentWorker\nfrom llama_index.core.tools import FunctionTool\nfrom llama_index.llms.openai import OpenAI\nimport logging\n\n# turn on logging so we can see the system working\nlogging.getLogger(\"llama_agents\").setLevel(logging.INFO)\n\n# Set up the message queue and control plane\nmessage_queue = SimpleMessageQueue()\ncontrol_plane = ControlPlaneServer(\n    message_queue=message_queue,\n    orchestrator=AgentOrchestrator(llm=OpenAI()),\n)","language":"python"},{"_key":"0ccaa5d8174d","_type":"block","children":[{"_key":"7d169aa0baa40","_type":"span","marks":[],"text":"Next we create our tools using LlamaIndex’s existing abstractions, provide those tools to an agent, and turn that agent into an independent microservice:"}],"markDefs":[],"style":"normal"},{"_key":"ab249e47bd80","_type":"codeBlock","code":"# create a tool\ndef get_the_secret_fact() -\u003e str:\n    \"\"\"Returns the secret fact.\"\"\"\n    return \"The secret fact is: A baby llama is called a 'Cria'.\"\n\ntool = FunctionTool.from_defaults(fn=get_the_secret_fact)\n\n# Define an agent\nworker = FunctionCallingAgentWorker.from_tools([tool], llm=OpenAI())\nagent = worker.as_agent()\n\n# Create an agent service\nagent_service = AgentService(\n    agent=agent,\n    message_queue=message_queue,\n    description=\"General purpose assistant\",\n    service_name=\"assistant\",\n)","language":"python"},{"_key":"ebc809c9d64f","_type":"block","children":[{"_key":"3883c3c3031a0","_type":"span","marks":[],"text":"Finally we launch the service and the control plane. Note that here we’re using a helper function to run a single query through the system and then exit; next we’ll show how to deploy this to production."}],"markDefs":[],"style":"normal"},{"_key":"8e6b04bcacbd","_type":"codeBlock","code":"# Set up the launcher for local testing\nfrom llama_agents import LocalLauncher\n\nlauncher = LocalLauncher(\n    [agent_service],\n    control_plane,\n    message_queue,\n)\n\n# Run a single query through the system\nresult = launcher.launch_single(\"What's the secret fact?\")\nprint(result)","language":"python"},{"_key":"fda77c66a66a","_type":"block","children":[{"_key":"2715d661e69d0","_type":"span","marks":[],"text":"Deploying Your Multi-Agent System"}],"markDefs":[],"style":"h2"},{"_key":"8a70dbba0080","_type":"block","children":[{"_key":"3c30e1fa38330","_type":"span","marks":[],"text":"Once you've tested your system locally, you can deploy it as a set of services for real production use. Here's how you might set that up. This is similar to the previous example, but we’ve added a second agent service and we’re using a different launcher. Let’s bring in our dependencies and set up our control plane again:"}],"markDefs":[],"style":"normal"},{"_key":"84d5e4d6a7ef","_type":"codeBlock","code":"import dotenv\ndotenv.load_dotenv()\nfrom llama_agents import (\n    AgentService,\n    AgentOrchestrator,\n    ControlPlaneServer,\n    SimpleMessageQueue,\n)\n\nfrom llama_index.core.agent import FunctionCallingAgentWorker\nfrom llama_index.core.tools import FunctionTool\nfrom llama_index.llms.openai import OpenAI\nimport logging\n\n# change logging level to enable or disable more verbose logging\nlogging.getLogger(\"llama_agents\").setLevel(logging.INFO)\n\n# create our multi-agent framework components\nmessage_queue = SimpleMessageQueue()\ncontrol_plane = ControlPlaneServer(\n    message_queue=message_queue,\n    orchestrator=AgentOrchestrator(llm=OpenAI()),\n)","language":"python"},{"_key":"10e2157a6902","_type":"block","children":[{"_key":"70aaf4ee630a0","_type":"span","marks":[],"text":"Then as before we create a tool and an agent, though this time we’ll add a second agent:"}],"markDefs":[],"style":"normal"},{"_key":"32470eacbaf4","_type":"codeBlock","code":"# create a tool\ndef get_the_secret_fact() -\u003e str:\n    \"\"\"Returns the secret fact.\"\"\"\n    return \"The secret fact is: A baby llama is called a 'Cria'.\"\n\ntool = FunctionTool.from_defaults(fn=get_the_secret_fact)\n\n# create our agents\nworker1 = FunctionCallingAgentWorker.from_tools([tool], llm=OpenAI())\nworker2 = FunctionCallingAgentWorker.from_tools([], llm=OpenAI())\nagent1 = worker1.as_agent()\nagent2 = worker2.as_agent()","language":"python"},{"_key":"ff04860788b8","_type":"block","children":[{"_key":"df62ce9525c00","_type":"span","marks":[],"text":"We turn those agents into services:"}],"markDefs":[],"style":"normal"},{"_key":"2b72aa78ec9d","_type":"codeBlock","code":"agent_server_1 = AgentService(\n    agent=agent1,\n    message_queue=message_queue,\n    description=\"Useful for getting the secret fact.\",\n    service_name=\"secret_fact_agent\",\n    host=\"localhost\",\n    port=8003\n)\nagent_server_2 = AgentService(\n    agent=agent2,\n    message_queue=message_queue,\n    description=\"Useful for getting random dumb facts.\",\n    service_name=\"dumb_fact_agent\",\n    host=\"localhost\",\n    port=8004\n)","language":"python"},{"_key":"f539772b0228","_type":"block","children":[{"_key":"434ed73f33cf0","_type":"span","marks":[],"text":"And finally we launch each service as an independent agent. Here we’re doing them all from a single script, but each of these could be a totally separate service, launched and scaled independently:"}],"markDefs":[],"style":"normal"},{"_key":"3d3c6889bdb1","_type":"codeBlock","code":"from llama_agents import ServerLauncher, CallableMessageConsumer\n\n# Additional human consumer\ndef handle_result(message) -\u003e None:\n    print(f\"Got result:\", message.data)\n\n\n# the final result is published to a \"human\" consumer\n# so we define one to handle it!\nhuman_consumer = CallableMessageConsumer(\n    handler=handle_result, message_type=\"human\"\n)\n\n# Define Launcher\nlauncher = ServerLauncher(\n    [agent_server_1, agent_server_2],\n    control_plane,\n    message_queue,\n    additional_consumers=[human_consumer]\n)\n\nlauncher.launch_servers()","language":"python"},{"_key":"b271888166fd","_type":"block","children":[{"_key":"df65771e0cc70","_type":"span","marks":[],"text":"Real-time monitoring"}],"markDefs":[],"style":"h2"},{"_key":"1ef65dc63385","_type":"block","children":[{"_key":"3ae7c8ec2de50","_type":"span","marks":[],"text":"One of the coolest debugging features of our multi-agent system is our agent monitor, which is built right in. You launch it like this:"}],"markDefs":[],"style":"normal"},{"_key":"b5b5c1030649","_type":"codeBlock","code":"llama-agents monitor --control-plane-url http://127.0.0.1:8000","language":"sh"},{"_key":"a59c40dcc846","_type":"block","children":[{"_key":"a65f97447f8f0","_type":"span","marks":[],"text":"Once launched, you get an intuitive, point-and-click terminal application. You can see both of the agents running, and at the bottom you can inject a task like the query “What is the secret fact?” You’ll get a job ID which you can then click on to see your results:"}],"markDefs":[],"style":"normal"},{"_key":"8090d0d183d6","_type":"image","asset":{"_ref":"image-077894fcf1dc8b2cd0ee5999ed58e252479783c4-1098x615-png","_type":"reference"}},{"_key":"1a9038670b61","_type":"block","children":[{"_key":"9cec6413b4100","_type":"span","marks":[],"text":"Building a Query Rewriting RAG System"}],"markDefs":[],"style":"h2"},{"_key":"8236fc451c8e","_type":"block","children":[{"_key":"f77337185e6c0","_type":"span","marks":[],"text":"Let's look at a more complex example: a Query Rewriting RAG system. This system will rewrite user queries to improve retrieval, then use the rewritten query to perform RAG over a document."}],"markDefs":[],"style":"normal"},{"_key":"5a62e1e411ef","_type":"block","children":[{"_key":"60a1e40231c10","_type":"span","marks":[],"text":"This example demonstrates how to create a more sophisticated system that combines query rewriting with RAG to improve question-answering capabilities. See "},{"_key":"60a1e40231c11","_type":"span","marks":["b965ba60ffa5"],"text":"this notebook"},{"_key":"60a1e40231c12","_type":"span","marks":[],"text":" for a fuller explanation of what’s going on."}],"markDefs":[{"_key":"b965ba60ffa5","_type":"link","href":"https://github.com/run-llama/llama-agents/blob/main/examples/query_rewrite_rag.ipynb"}],"style":"normal"},{"_key":"c3be25335540","_type":"codeBlock","code":"import dotenv\ndotenv.load_dotenv() # our .env defines OPENAI_API_KEY\nfrom llama_index.core import VectorStoreIndex, Document\nfrom llama_index.core.agent import FnAgentWorker\nfrom llama_index.core import PromptTemplate\nfrom llama_index.core.query_pipeline import QueryPipeline\nfrom llama_index.core.query_engine import RetrieverQueryEngine\nfrom llama_agents import (\n    AgentService,\n    ControlPlaneServer,\n    SimpleMessageQueue,\n    PipelineOrchestrator,\n    ServiceComponent,\n)\nfrom llama_agents.launchers import LocalLauncher\nfrom llama_index.llms.openai import OpenAI\nimport logging\n\n# change logging level to enable or disable more verbose logging\nlogging.getLogger(\"llama_agents\").setLevel(logging.INFO)\n\n# Load and index your document\ndocs = [Document(text=\"The rabbit is a small mammal with long ears and a fluffy tail. His name is Peter.\")]\nindex = VectorStoreIndex.from_documents(docs)\n\n# Define a query rewrite agent\nHYDE_PROMPT_STR = (\n    \"Please rewrite the following query to include more detail:\\n{query_str}\\n\"\n)\nHYDE_PROMPT_TMPL = PromptTemplate(HYDE_PROMPT_STR)\n\ndef run_hyde_fn(state):\n    prompt_tmpl, llm, input_str = (\n        state[\"prompt_tmpl\"],\n        state[\"llm\"],\n        state[\"__task__\"].input,\n    )\n    qp = QueryPipeline(chain=[prompt_tmpl, llm])\n    output = qp.run(query_str=input_str)\n    state[\"__output__\"] = str(output)\n    return state, True\n\nhyde_agent = FnAgentWorker(\n    fn=run_hyde_fn,\n    initial_state={\"prompt_tmpl\": HYDE_PROMPT_TMPL, \"llm\": OpenAI()}\n).as_agent()\n\n# Define a RAG agent\ndef run_rag_fn(state):\n    retriever, llm, input_str = (\n        state[\"retriever\"],\n        state[\"llm\"],\n        state[\"__task__\"].input,\n    )\n    query_engine = RetrieverQueryEngine.from_args(retriever, llm=llm)\n    response = query_engine.query(input_str)\n    state[\"__output__\"] = str(response)\n    return state, True\n\nrag_agent = FnAgentWorker(\n    fn=run_rag_fn,\n    initial_state={\"retriever\": index.as_retriever(), \"llm\": OpenAI()}\n).as_agent()\n\n# Set up the multi-agent system\nmessage_queue = SimpleMessageQueue()\n\nquery_rewrite_service = AgentService(\n    agent=hyde_agent,\n    message_queue=message_queue,\n    description=\"Query rewriting service\",\n    service_name=\"query_rewrite\",\n)\n\nrag_service = AgentService(\n    agent=rag_agent,\n    message_queue=message_queue,\n    description=\"RAG service\",\n    service_name=\"rag\",\n)\n\n# Create the pipeline\npipeline = QueryPipeline(chain=[\n    ServiceComponent.from_service_definition(query_rewrite_service),\n    ServiceComponent.from_service_definition(rag_service),\n])\norchestrator = PipelineOrchestrator(pipeline)\n\ncontrol_plane = ControlPlaneServer(\n    message_queue=message_queue,\n    orchestrator=orchestrator,\n)\n\n# Set up the launcher\nlauncher = LocalLauncher(\n    [query_rewrite_service, rag_service],\n    control_plane,\n    message_queue,\n)\n\n# Run a query\nresult = launcher.launch_single(\"Tell me about rabbits\")\nprint(result)","language":"python"},{"_key":"8f2cac930954","_type":"block","children":[{"_key":"4b5d79a7237f0","_type":"span","marks":[],"text":"Public roadmap"}],"markDefs":[],"style":"h2"},{"_key":"62d1317d03ea","_type":"block","children":[{"_key":"57121da4fe2f0","_type":"span","marks":[],"text":"This is an alpha release, meaning that we’d love your feedback on features to better help you build multi-agent systems in production! We’ve created a "},{"_key":"57121da4fe2f1","_type":"span","marks":["b92cea2644d0"],"text":"public roadmap"},{"_key":"57121da4fe2f2","_type":"span","marks":[],"text":" showing where we plan to go from here. We’re actively seeking public feedback on what works for you and what doesn’t."}],"markDefs":[{"_key":"b92cea2644d0","_type":"link","href":"https://github.com/run-llama/llama-agents/discussions/49"}],"style":"normal"},{"_key":"7f9e8fb37950","_type":"block","children":[{"_key":"e4f1113d3a090","_type":"span","marks":[],"text":"Dive in!"}],"markDefs":[],"style":"h2"},{"_key":"fbd423f2f9c4","_type":"block","children":[{"_key":"45d51b8a1c160","_type":"span","marks":["code"],"text":"llama-agents"},{"_key":"45d51b8a1c161","_type":"span","marks":[],"text":" provides a powerful, flexible framework for building complex multi-agent AI systems. Whether you're prototyping a new idea or scaling to production, "},{"_key":"45d51b8a1c162","_type":"span","marks":["code"],"text":"llama-agents"},{"_key":"45d51b8a1c163","_type":"span","marks":[],"text":" offers the tools you need to bring your AI vision to life. Check out "},{"_key":"45d51b8a1c164","_type":"span","marks":["f47110df76e3"],"text":"the repo"},{"_key":"45d51b8a1c165","_type":"span","marks":[],"text":" to learn more, especially our library of "},{"_key":"45d51b8a1c166","_type":"span","marks":["66fc5f29cacd"],"text":"examples"},{"_key":"45d51b8a1c167","_type":"span","marks":[],"text":"."}],"markDefs":[{"_key":"f47110df76e3","_type":"link","href":"https://github.com/run-llama/llama-agents"},{"_key":"66fc5f29cacd","_type":"link","href":"https://github.com/run-llama/llama-agents/tree/main/examples"}],"style":"normal"},{"_key":"1bfff36feee0","_type":"block","children":[{"_key":"3df5c8f473910","_type":"span","marks":[],"text":"We're excited to see what the community builds with "},{"_key":"3df5c8f473911","_type":"span","marks":["code"],"text":"llama-agents"},{"_key":"3df5c8f473912","_type":"span","marks":[],"text":". Happy coding!"}],"markDefs":[],"style":"normal"}],"title":"Introducing llama-agents: A Powerful Framework for Building Production Multi-Agent AI Systems"},"publishedDate":"Invalid Date"},"params":{"slug":"introducing-llama-agents-a-powerful-framework-for-building-production-multi-agent-ai-systems"},"draftMode":false,"token":""},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"introducing-llama-agents-a-powerful-framework-for-building-production-multi-agent-ai-systems"},"buildId":"C8J-EMc_4OCN1ch65l4fl","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>