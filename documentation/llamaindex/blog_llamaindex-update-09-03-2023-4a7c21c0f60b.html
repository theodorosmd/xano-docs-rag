<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>LlamaIndex Update — 09/03/2023 — LlamaIndex - Build Knowledge Assistants over your Enterprise Data</title><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><meta name="title" content="LlamaIndex Update — 09/03/2023 — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta name="description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:title" content="LlamaIndex Update — 09/03/2023 — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="og:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:image" content="https://cdn.sanity.io/images/7m9jw85w/production/28384ae80423c0137b96553186cde99b4569c144-1024x1024.jpg"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="LlamaIndex Update — 09/03/2023 — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="twitter:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="twitter:image" content="https://cdn.sanity.io/images/7m9jw85w/production/28384ae80423c0137b96553186cde99b4569c144-1024x1024.jpg"/><link rel="alternate" type="application/rss+xml" href="https://www.llamaindex.ai/blog/feed"/><meta name="next-head-count" content="20"/><script>
            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WWRFB36R');
            </script><link rel="preload" href="/_next/static/css/41c9222e47d080c9.css" as="style"/><link rel="stylesheet" href="/_next/static/css/41c9222e47d080c9.css" data-n-g=""/><link rel="preload" href="/_next/static/css/97c33c8d95f1230e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/97c33c8d95f1230e.css" data-n-p=""/><link rel="preload" href="/_next/static/css/e009059e80bf60c5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e009059e80bf60c5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-1b629d9c8fb16f34.js" defer=""></script><script src="/_next/static/chunks/framework-df1f68dff096b68a.js" defer=""></script><script src="/_next/static/chunks/main-eca7952a704663f8.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c7c49437be49d2ad.js" defer=""></script><script src="/_next/static/chunks/d9067523-4985945b21298365.js" defer=""></script><script src="/_next/static/chunks/41155975-60c12da9ce9fa0b2.js" defer=""></script><script src="/_next/static/chunks/cb355538-cee2ea45674d9de3.js" defer=""></script><script src="/_next/static/chunks/9494-dff62cb53535dd7d.js" defer=""></script><script src="/_next/static/chunks/4063-39a391a51171ff87.js" defer=""></script><script src="/_next/static/chunks/6889-edfa85b69b88a372.js" defer=""></script><script src="/_next/static/chunks/5575-11ee0a29eaffae61.js" defer=""></script><script src="/_next/static/chunks/3444-95c636af25a42734.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-82c8e764e69afd2c.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_buildManifest.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_ssgManifest.js" defer=""></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WWRFB36R" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div class="__variable_d65c78 __variable_b1ea77 __variable_eb7534"><a class="Announcement_announcement__2ohK8" href="http://48755185.hs-sites.com/llamaindex-0">Meet LlamaIndex at the Databricks Data + AI Summit!<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M8.293 5.293a1 1 0 0 1 1.414 0l6 6a1 1 0 0 1 0 1.414l-6 6a1 1 0 0 1-1.414-1.414L13.586 12 8.293 6.707a1 1 0 0 1 0-1.414Z" clip-rule="evenodd"></path></svg></a><header class="Header_header__hO3lJ"><button class="Hamburger_hamburger__17auO Header_hamburger__lUulX"><svg width="28" height="28" viewBox="0 0 28 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.5 14H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" id="hamburger-stroke-top" class="Hamburger_hamburgerStrokeMiddle__I7VpD"></path><path d="M3.5 7H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeTop__oOhFM"></path><path d="M3.5 21H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeBottom__GIQR2"></path></svg></button><a aria-label="Homepage" href="/"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" class="Header_logo__e5KhT" style="color:transparent" src="/llamaindex.svg"/></a><nav aria-label="Main" data-orientation="horizontal" dir="ltr" style="--content-position:0px"><div style="position:relative"><ul data-orientation="horizontal" class="Nav_MenuList__PrCDJ" dir="ltr"><li><button id="radix-:R6tm:-trigger-radix-:R5mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R5mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Products</button></li><li><button id="radix-:R6tm:-trigger-radix-:R9mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R9mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Solutions</button></li><li><a class="Nav_Link__ZrzFc" href="/community" data-radix-collection-item="">Community</a></li><li><a class="Nav_Link__ZrzFc" href="/pricing" data-radix-collection-item="">Pricing</a></li><li><a class="Nav_Link__ZrzFc" href="/blog" data-radix-collection-item="">Blog</a></li><li><a class="Nav_Link__ZrzFc" href="/customers" data-radix-collection-item="">Customer stories</a></li><li><a class="Nav_Link__ZrzFc" href="/careers" data-radix-collection-item="">Careers</a></li></ul></div><div class="Nav_ViewportPosition__jmyHM"></div></nav><div class="Header_secondNav__YJvm8"><nav><a href="/contact" class="Link_link__71cl8 Link_link-variant-tertiary__BYxn_ Header_bookADemo__qCuxV">Book a demo</a></nav><a href="https://cloud.llamaindex.ai/" class="Button_button-variant-default__Oi__n Button_button__aJ0V6 Header_button__1HFhY" data-tracking-variant="default"> <!-- -->Get started</a></div><div class="MobileMenu_mobileMenu__g5Fa6"><nav class="MobileMenu_nav__EmtTw"><ul><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Products<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaparse"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.6654 1.66675V6.66675H16.6654M8.33203 10.8334L6.66536 12.5001L8.33203 14.1667M11.6654 14.1667L13.332 12.5001L11.6654 10.8334M12.082 1.66675H4.9987C4.55667 1.66675 4.13275 1.84234 3.82019 2.1549C3.50763 2.46746 3.33203 2.89139 3.33203 3.33341V16.6667C3.33203 17.1088 3.50763 17.5327 3.82019 17.8453C4.13275 18.1578 4.55667 18.3334 4.9987 18.3334H14.9987C15.4407 18.3334 15.8646 18.1578 16.1772 17.8453C16.4898 17.5327 16.6654 17.1088 16.6654 16.6667V6.25008L12.082 1.66675Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Document parsing</div><p class="MobileMenu_ListItemText__n_MHY">The first and leading GenAI-native parser over your most complex data.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaextract"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.668 1.66675V5.00008C11.668 5.44211 11.8436 5.86603 12.1561 6.17859C12.4687 6.49115 12.8926 6.66675 13.3346 6.66675H16.668M3.33464 5.83341V3.33341C3.33464 2.89139 3.51023 2.46746 3.82279 2.1549C4.13535 1.84234 4.55927 1.66675 5.0013 1.66675H12.5013L16.668 5.83341V16.6667C16.668 17.1088 16.4924 17.5327 16.1798 17.8453C15.8672 18.1578 15.4433 18.3334 15.0013 18.3334L5.05379 18.3326C4.72458 18.3755 4.39006 18.3191 4.09312 18.1706C3.79618 18.0221 3.55034 17.7884 3.38713 17.4992M4.16797 9.16675L1.66797 11.6667M1.66797 11.6667L4.16797 14.1667M1.66797 11.6667H10.0013" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Data extraction</div><p class="MobileMenu_ListItemText__n_MHY">Extract structured data from documents using a schema-driven engine.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/enterprise"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.16667 15.8333C12.8486 15.8333 15.8333 12.8486 15.8333 9.16667C15.8333 5.48477 12.8486 2.5 9.16667 2.5C5.48477 2.5 2.5 5.48477 2.5 9.16667C2.5 12.8486 5.48477 15.8333 9.16667 15.8333Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M17.5 17.5L13.875 13.875" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Knowledge Management</div><p class="MobileMenu_ListItemText__n_MHY">Connect, transform, and index your enterprise data into an agent-accessible knowledge base</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/framework"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.0013 6.66659V3.33325H6.66797M1.66797 11.6666H3.33464M16.668 11.6666H18.3346M12.5013 10.8333V12.4999M7.5013 10.8333V12.4999M5.0013 6.66659H15.0013C15.9218 6.66659 16.668 7.41278 16.668 8.33325V14.9999C16.668 15.9204 15.9218 16.6666 15.0013 16.6666H5.0013C4.08083 16.6666 3.33464 15.9204 3.33464 14.9999V8.33325C3.33464 7.41278 4.08083 6.66659 5.0013 6.66659Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Agent Framework</div><p class="MobileMenu_ListItemText__n_MHY">Orchestrate and deploy multi-agent applications over your data with the #1 agent framework.</p></a></li></ul></details></li><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Solutions<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/finance"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 6.66675H8.33073C7.8887 6.66675 7.46478 6.84234 7.15222 7.1549C6.83966 7.46746 6.66406 7.89139 6.66406 8.33342C6.66406 8.77544 6.83966 9.19937 7.15222 9.51193C7.46478 9.82449 7.8887 10.0001 8.33073 10.0001H11.6641C12.1061 10.0001 12.53 10.1757 12.8426 10.4882C13.1551 10.8008 13.3307 11.2247 13.3307 11.6667C13.3307 12.1088 13.1551 12.5327 12.8426 12.8453C12.53 13.1578 12.1061 13.3334 11.6641 13.3334H6.66406M9.9974 15.0001V5.00008M18.3307 10.0001C18.3307 14.6025 14.5998 18.3334 9.9974 18.3334C5.39502 18.3334 1.66406 14.6025 1.66406 10.0001C1.66406 5.39771 5.39502 1.66675 9.9974 1.66675C14.5998 1.66675 18.3307 5.39771 18.3307 10.0001Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Financial Analysts</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/administrative-operations"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1.66406 6.66659V15.8333C1.66406 16.2753 1.83966 16.6992 2.15222 17.0118C2.46478 17.3243 2.8887 17.4999 3.33073 17.4999H14.9974M16.6641 14.1666C17.1061 14.1666 17.53 13.991 17.8426 13.6784C18.1551 13.3659 18.3307 12.9419 18.3307 12.4999V7.49992C18.3307 7.05789 18.1551 6.63397 17.8426 6.32141C17.53 6.00885 17.1061 5.83325 16.6641 5.83325H13.4141C13.1353 5.83598 12.8604 5.76876 12.6143 5.63774C12.3683 5.50671 12.159 5.31606 12.0057 5.08325L11.3307 4.08325C11.179 3.85281 10.9724 3.66365 10.7295 3.53275C10.4866 3.40185 10.215 3.3333 9.93906 3.33325H6.66406C6.22204 3.33325 5.79811 3.50885 5.48555 3.82141C5.17299 4.13397 4.9974 4.55789 4.9974 4.99992V12.4999C4.9974 12.9419 5.17299 13.3659 5.48555 13.6784C5.79811 13.991 6.22204 14.1666 6.66406 14.1666H16.6641Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Administrative Operations</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/engineering"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 15L18.3307 10L13.3307 5M6.66406 5L1.66406 10L6.66406 15" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Engineering &amp; R&amp;D</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/customer-support"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.9974 7.50008H16.6641C17.1061 7.50008 17.53 7.67568 17.8426 7.98824C18.1551 8.3008 18.3307 8.72472 18.3307 9.16675V18.3334L14.9974 15.0001H9.9974C9.55537 15.0001 9.13145 14.8245 8.81888 14.5119C8.50632 14.1994 8.33073 13.7754 8.33073 13.3334V12.5001M11.6641 7.50008C11.6641 7.94211 11.4885 8.36603 11.1759 8.67859C10.8633 8.99115 10.4394 9.16675 9.9974 9.16675H4.9974L1.66406 12.5001V3.33341C1.66406 2.41675 2.41406 1.66675 3.33073 1.66675H9.9974C10.4394 1.66675 10.8633 1.84234 11.1759 2.1549C11.4885 2.46746 11.6641 2.89139 11.6641 3.33341V7.50008Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Customer Support</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/healthcare-pharma"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M17.0128 3.81671C16.5948 3.39719 16.098 3.06433 15.551 2.8372C15.004 2.61008 14.4176 2.49316 13.8253 2.49316C13.2331 2.49316 12.6466 2.61008 12.0996 2.8372C11.5527 3.06433 11.0559 3.39719 10.6378 3.81671L9.99617 4.46671L9.3545 3.81671C8.93643 3.39719 8.43967 3.06433 7.89268 2.8372C7.3457 2.61008 6.75926 2.49316 6.167 2.49316C5.57474 2.49316 4.9883 2.61008 4.44132 2.8372C3.89433 3.06433 3.39756 3.39719 2.9795 3.81671C1.21283 5.58338 1.1045 8.56671 3.3295 10.8334L9.99617 17.5L16.6628 10.8334C18.8878 8.56671 18.7795 5.58338 17.0128 3.81671Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M2.91406 9.99992H7.91406L8.33073 9.16659L9.9974 12.9166L11.6641 7.08325L12.9141 9.99992H17.0807" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Healthcare / Pharma</div></a></li></ul></details></li><li><a class="MobileMenu_Link__5frcx" href="/community">Community</a></li><li><a class="MobileMenu_Link__5frcx" href="/pricing">Pricing</a></li><li><a class="MobileMenu_Link__5frcx" href="/blog">Blog</a></li><li><a class="MobileMenu_Link__5frcx" href="/customers">Customer stories</a></li><li><a class="MobileMenu_Link__5frcx" href="/careers">Careers</a></li></ul></nav><a href="/contact" class="Button_button-variant-ghost__o2AbG Button_button__aJ0V6" data-tracking-variant="ghost"> <!-- -->Talk to us</a><ul class="Socials_socials__8Y_s5 Socials_socials-theme-dark__Hq8lc MobileMenu_socials__JykCO"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu MobileMenu_copyright__nKVOs">© <!-- -->2025<!-- --> LlamaIndex</p></div></header><main><section class="BlogPost_post__JHNzd"><img alt="" loading="lazy" width="800" height="512" decoding="async" data-nimg="1" class="BlogPost_featuredImage__KGxwX" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F28384ae80423c0137b96553186cde99b4569c144-1024x1024.jpg%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F28384ae80423c0137b96553186cde99b4569c144-1024x1024.jpg%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F28384ae80423c0137b96553186cde99b4569c144-1024x1024.jpg%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><p class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-600__fKYth BlogPost_date__6uxQw"><a class="BlogPost_author__mesdl" href="/blog/author/ravi-theja">Ravi Theja</a> <!-- -->•<!-- --> <!-- -->2023-09-06</p><h1 class="Text_text__zPO0D Text_text-size-32__koGps BlogPost_title__b2lqJ">LlamaIndex Update — 09/03/2023</h1><ul class="BlogPost_tags__13pBH"><li><a class="Badge_badge___1ssn" href="/blog/tag/large-language-models"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Large Language Models</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Llamaindex</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/openai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">OpenAI</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">AI</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/nlp"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">NLP</span></a></li></ul><div class="BlogPost_htmlPost__Z5oDL"><p>Hello LlamaIndex Community!</p><p>We’re thrilled to bring you the latest edition of our LlamaIndex Update series. Whether you’ve been a part of our journey from the start or have just recently joined us, your engagement and input are invaluable to us.</p><p>In this update, we’re excited to unveil some significant advancements. We’ve got comprehensive updates on new features for both the Python and TypeScript versions of LlamaIndex. In addition, we’re offering some expert insights on RAG tips that you won’t want to miss. To keep you ahead of the curve, we’ve also curated a selection of webinars, tutorials, events, and demos.</p><p>So without further ado, let’s delve into the latest developments.</p><h1><strong>New Features:</strong></h1><h2>LlamaIndex</h2><ol><li>LlamaIndex introduces the Sweep AI code splitter for RAG apps, addressing the challenges of traditional code splitting. This tool features recursive splitting combined with CSTs across 100+ languages, enhancing the LlamaIndex experience. <a href="https://docs.sweep.dev/blogs/chunking-2m-files" rel="noopener ugc nofollow" target="_blank">BlogPost</a>, <a href="https://twitter.com/jerryjliu0/status/1686413452988878849?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex now supports streaming data ETL, enhancing structured data extraction with the OpenAI Function API. By inputting a Pydantic object class in LlamaIndex, users can receive streamed data objects from OpenAI individually. <a href="https://gpt-index.readthedocs.io/en/latest/examples/output_parsing/openai_pydantic_program.html#extraction-into-album-streaming" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/jerryjliu0/status/1686752090197008387?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex has teamed up with Neo4j to amplify knowledge graph capabilities with LLM’s. This integration not only allows for storing any knowledge graph created in LlamaIndex directly in Neo4j but also introduces a specialized text-to-cypher prompt for Neo4j users. <a href="https://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/Neo4jKGIndexDemo.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/llama_index/status/1687224679340064768?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex, in collaboration with Mendable AI and Nomic AI, unveils a Nomic Atlas visual map detailing user questions from the Mendable AI bot. This innovative tool groups similar questions, providing insights for improved app deployment, prompt control, language support, and documentation. New users can find the helpful Mendable AI bot on LlamaIndex’s documentation site. <a href="https://twitter.com/llama_index/status/1687485785228906496?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex, in collaboration with Predibase, offers an optimal way to operationalize LLMs. Experience top-tier RAG by privately hosting open-source LLMs on managed infrastructure right within your VPC. <a href="https://gpt-index.readthedocs.io/en/latest/examples/llm/predibase.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/predibase/status/1687493843619598336?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>The LlamaIndex playground <a href="https://llama-playground.vercel.app/" rel="noopener ugc nofollow" target="_blank">app</a> enhances the RAG experience. Updates include new Temperature and Top P options, along with intuitive tooltips offering plain language explanations.</li><li>LlamaIndex Tip💡: Boost your RAG systems by adding structured data to raw text. This allows for easier metadata filtering and optimal embedding biases. Dive into our guide on harnessing the HuggingFace span marker for targeted entity extraction. <a href="https://gpt-index.readthedocs.io/en/latest/examples/metadata_extraction/EntityExtractionClimate.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/llama_index/status/1688711638537682944?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex now has the Semantic Scholar Loader. With it, users can swiftly set up citation-based Q&amp;A systems. <a href="https://llamahub.ai/l/semanticscholar" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/shauryr/status/1687858252481236993?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex highlights the significance of text chunk size in LLM QA systems. To determine the best chunk size without human intervention, we suggest ensembling different sizes and using a reranker for context relevance during queries. This method involves simultaneous queries across retrievers of various sizes and consolidating results for reranking. Though experimental, this approach aims to discern the optimal chunk size strategy. <a href="https://gpt-index.readthedocs.io/en/stable/examples/retrievers/ensemble_retrieval.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/jerryjliu0/status/1688948298781249536?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex’s customer support bot seamlessly interfaces with Shopify’s 50k-line GraphQL API Spec. Through smart tools and LlamaIndex features, it offers quick insights like <code class="cw qm qn qo qp b">refunded orders</code> despite the vast spec size. Efficient indexing ensures precise user query responses. <a href="https://llamahub.ai/l/tools-shopify" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/jerryjliu0/status/1689295239822069760?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex’s integration with Xinference enables users to effortlessly expand models like llama 2, chatglm, and vicuna to incorporate RAG and agents. <a href="https://gpt-index.readthedocs.io/en/latest/examples/llm/XinferenceLocalDeployment.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/llama_index/status/1689426281015005184?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex introduces <code class="cw qm qn qo qp b">One-click Observability</code>. With just a single code line, integrate LlamaIndex with advanced observability tools from partners like Weights &amp; Biases, ArizeAI, and TruEra, simplifying LLM app debugging for production. <a href="https://gpt-index.readthedocs.io/en/latest/end_to_end_tutorials/one_click_observability.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/llama_index/status/1689659395465191424?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex has updated the LLM default temperature value to 0.1. <a href="https://twitter.com/yi_ding/status/1689692197871042561?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex integration with Zep, enhancing the memory layer of LLM apps. It’s not just about storage but also enriching data with summaries, metadata, and more. <a href="https://medium.com/llamaindex-blog/zep-and-llamaindex-a-vector-store-walkthrough-564edb8c22dc" rel="noopener">BlogPost</a>, <a href="https://twitter.com/jerryjliu0/status/1690018390059225088?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex has revamped its defaults! Now, gpt-3.5-turbo is the go-to LLM, with enhanced prompts and a superior text splitter. Additionally, if OpenAI’s key isn’t set, it has backup options with llama.cpp. New embedding features have also been added. <a href="https://twitter.com/llama_index/status/1690081661453803520?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex now seamlessly integrates with FastChat by <a href="https://twitter.com/lmsysorg" rel="noopener ugc nofollow" target="_blank">lmsysorg</a>. Elevate your LLM deployments like Vicuna and Llama 2, serving as an alternative to OpenAI. <a href="https://twitter.com/jerryjliu0/status/1691114369705533440?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex provides a seamless integration with Azure AI Services. Dive into a richer ecosystem of AI tools from Computer Vision, Translation, and speech enhancing your multi-modal AI interactions. <a href="https://llamahub.ai/l/tools-azure_translate" rel="noopener ugc nofollow" target="_blank">Docs1</a>, <a href="https://llamahub.ai/l/tools-azure_speech" rel="noopener ugc nofollow" target="_blank">Docs2</a>, <a href="https://llamahub.ai/l/tools-azure_cv" rel="noopener ugc nofollow" target="_blank">Docs3</a>, <a href="https://twitter.com/llama_index/status/1691605500079800674?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex unveils <code class="cw qm qn qo qp b">Graph RAG</code> — an approach to enhance LLMs with context from graph databases. Extract valuable subgraphs from any knowledge graph for superior question-answering capabilities. <a href="https://gpt-index.readthedocs.io/en/latest/examples/query_engine/knowledge_graph_rag_query_engine.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/jerryjliu0/status/1691835187519459338?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex has expanded native async support, enhancing the scalability of full-stack LLM apps. We now offer async agents, tool execution, and callback support, and have introduced async methods in vector stores. <a href="https://twitter.com/llama_index/status/1691965149840908642?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex enhances debugging with data agent trace observability. Additionally, system prompts can now be added to any query engine and we have begun the transition of LLM and embedding modules to Pydantic. <a href="https://twitter.com/llama_index/status/1692696993900974399?s=20" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://gpt-index.readthedocs.io/en/latest/examples/callbacks/LlamaDebugHandler.html#see-traces-events-for-agents" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex’s <code class="cw qm qn qo qp b">Recursive Document Agents</code> enhance RAG by retrieving based on summaries and adjusting chunk retrieval per need. This boosts querying across varied documents, offering both question-answering and summarization within a document. <a href="https://gpt-index.readthedocs.io/en/latest/examples/query_engine/recursive_retriever_agents.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/jerryjliu0/status/1693421308674289822?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex integrates with Metaphor to supercharge data agents. This integration offers a specialized search engine tailored for LLMs, allowing dynamic data lookup beyond just RAG, and answering a broader range of questions. <a href="https://medium.com/llamaindex-blog/llamaindex-metaphor-towards-automating-knowledge-work-with-llms-5520a32efa2f" rel="noopener">BlogPost</a>, <a href="https://twitter.com/llama_index/status/1693649115983618278?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex now supports integration with OpenAI’s fine-tuned models via their new endpoint. Seamlessly integrate these models into your RAG pipeline. <a href="https://gpt-index.readthedocs.io/en/latest/core_modules/model_modules/llms/usage_custom.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/llama_index/status/1694116968008401201?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex introduces the <code class="cw qm qn qo qp b">OpenAIFineTuningHandler</code> to streamline data collection for fine-tuning gpt-3.5-turbo with GPT-4 outputs. Run RAG with GPT-4 and effortlessly generate a dataset to train a more cost-effective model. <a href="https://github.com/jerryjliu/llama_index/blob/main/experimental/openai_fine_tuning/openai_fine_tuning.ipynb" rel="noopener ugc nofollow" target="_blank">Notebook</a>, <a href="https://twitter.com/llama_index/status/1694395355725746397?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex presents the <code class="cw qm qn qo qp b">Principled Development Practices</code> guide, detailing best practices for LLM app development Observability, Evaluation, and Monitoring. <a href="https://gpt-index.readthedocs.io/en/latest/end_to_end_tutorials/principled_dev_practices.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/llama_index/status/1694736328276271248?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex introduces a refined Prompt system. With just three core classes: <code class="cw qm qn qo qp b">PromptTemplate</code>, <code class="cw qm qn qo qp b">ChatPromptTemplate</code>, and <code class="cw qm qn qo qp b">SelectorPromptTemplate</code>, users can effortlessly format as chat messages or text and tailor prompts based on model conditions. <a href="https://gpt-index.readthedocs.io/en/latest/core_modules/model_modules/prompts.html#" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/llama_index/status/1695093392378880324?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex delves into <code class="cw qm qn qo qp b">chunk dreaming</code> a concept inspired by <a href="https://twitter.com/tomchapin" rel="noopener ugc nofollow" target="_blank">Thomas H. Chapin IV</a>. By auto-extracting metadata from a text chunk, it can identify potential questions and provide summaries over neighboring nodes. This enriched context boosts RAG’s performance. <a href="https://gpt-index.readthedocs.io/en/latest/examples/metadata_extraction/MetadataExtraction_LLMSurvey.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/llama_index/status/1695233836983144764?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex is integrated with BagelDB, enabling developers to effortlessly tap into vector data stored on BagelDB. <a href="https://twitter.com/BagelDB_ai/status/1695158701387059319?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex now lets the LLM choose between vector search for semantic queries or our BM25 retriever for keyword-specific ones. <a href="https://gpt-index.readthedocs.io/en/latest/examples/retrievers/bm25_retriever.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/llama_index/status/1695590257054630149?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex introduces the <code class="cw qm qn qo qp b">AutoMergingRetriever</code>, crafted with insights from <a href="https://twitter.com/jxnlco" rel="noopener ugc nofollow" target="_blank">Jason</a> and ChatGPT. This technique fetches precise context chunks and seamlessly merges them, optimizing LLM responses. Using the HierarchicalNodeParser, we ensure interconnected chunks for enhanced context clarity. <a href="https://gpt-index.readthedocs.io/en/latest/examples/retrievers/auto_merging_retriever.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/llama_index/status/1695832757560356871?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex introduces embedding finetuning for optimized retrieval performance. Beyond enhancing RAG, we’ve simplified retrieval evaluations with automatic QA dataset generation from text, streamlining both finetuning and evaluation processes. <a href="https://gpt-index.readthedocs.io/en/latest/examples/finetuning/embeddings/finetune_embedding.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/llama_index/status/1696583119539966070?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex now integrates directly with Airbyte sources including Gong, Hubspot, Salesforce, Shopify, Stripe, Typeform, and Zendesk Support. Easily enhance your LlamaIndex application with these platforms implemented as data loaders. <a href="https://airbyte.com/blog/introducing-airbyte-sources-within-llamaindex" rel="noopener ugc nofollow" target="_blank">BlogPost</a>, <a href="https://twitter.com/AirbyteHQ/status/1696633858316243046?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex integrates with DeepEval, a comprehensive library to evaluate LLM and RAG apps. Assess on four key metrics: Relevance, Factual Consistency, Answer Similarity, and Bias/Toxicity. <a href="https://gpt-index.readthedocs.io/en/latest/community/integrations/deepeval.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/llama_index/status/1696674470566764846?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex recommends evaluating LLM + RAG step-by-step, especially retrieval. Create synthetic retrieval datasets from text chunks using LLMs. This method not only evaluates retrieval but also fine-tunes embeddings. <a href="https://gpt-index.readthedocs.io/en/latest/examples/finetuning/embeddings/finetune_embedding.html#generate-corpus" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/jerryjliu0/status/1696675525442609166?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex unveils a managed index abstraction simplifying RAG’s ingestion and storage processes with Vectara. <a href="https://gpt-index.readthedocs.io/en/latest/community/integrations/managed_indices.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/llama_index/status/1696919525151899671?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex has significantly enhanced its callback handling support, encompassing features like tracebacks, LLM token counts, templates, and detailed agent tool information. These advancements pave the way for smoother integrations with evaluation and observability applications. <a href="https://twitter.com/llama_index/status/1697407787154997754?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex has integrated with AskMarvinAI, enabling automated metadata extraction from text corpora. Just annotate a Pydantic model and effortlessly log metadata from all associated text chunks. <a href="https://gpt-index.readthedocs.io/en/latest/examples/metadata_extraction/MarvinMetadataExtractorDemo.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/llama_index/status/1697632035186372745?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LlamaIndex is integrated with RunGPT by JinaAI, an outstanding framework for one-click deployment of various open-source models such as Llama, Vicuna, Pythia, and more. Coupled with LlamaIndex’s innate chat/streaming capabilities, users can now deploy and utilize powerhouse models like Llama-7B seamlessly. <a href="https://gpt-index.readthedocs.io/en/latest/examples/llm/rungpt.html" rel="noopener ugc nofollow" target="_blank">Docs</a>, <a href="https://twitter.com/llama_index/status/1698001332563837165?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li></ol><h2>LlamaIndex.TS</h2><ol><li>LITS has Full Azure OpenAI integration. <a href="https://twitter.com/yi_ding/status/1688564790007087104" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LITS Enhanced Llama2 support, new default temperature (0.1), and GPT chat integration. <a href="https://twitter.com/llama_index/status/1689086106036547584?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LITS helps to use <code class="cw qm qn qo qp b">fromDocuments</code> without repeat checks; auto SHA256 comparison. <a href="https://twitter.com/llama_index/status/1691502243286228993?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LITS now supports OpenAI v4, Anthropic 0.6, &amp; Replicate 0.16.1., CSV loader, Merged NodeWithEmbeddings &amp; BaseNode. <a href="https://twitter.com/llama_index/status/1691984600506257462?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LITS now supports PapaCSVLoader for math. <a href="https://twitter.com/yi_ding/status/1691991221974217104?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LITS is now integrated with LiteLLM. <a href="https://twitter.com/yi_ding/status/1692408213340340328" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LITS now has additional session options for proxy server support, Default timeout reset to 60 seconds for OpenAI. <a href="https://twitter.com/llama_index/status/1693072438404276460?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LITS now has Pinecone integration. <a href="https://twitter.com/yi_ding/status/1693275444848840745?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LITS has Optimized ChatGPT prompts, fixed metadata rehydration issues, and OpenAI Node v4.1.0 with fine-tuned model support. <a href="https://twitter.com/llama_index/status/1694382741218005153?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LITS has introduced enhanced text-splitting features, including a specialized tokenizer for Chinese, Japanese, and Korean, and refinements to the SentenceSplitter for handling decimal numbers. <a href="https://twitter.com/llama_index/status/1694719208217588070?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LITS has a Markdown loader and metadata support in the response synthesizer. <a href="https://twitter.com/llama_index/status/1695156772783395255?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LITS revamped usability: <code class="cw qm qn qo qp b">ListIndex</code> is now <code class="cw qm qn qo qp b">SummaryIndex</code> for clarity, and prompts have been made typed and customizable to enhance user control and experience. <a href="https://twitter.com/llama_index/status/1696626780277481491?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li><li>LITS has Notion Reader. Now, users can effortlessly import their documents directly into their RAG or Data Agent application in LITS. <a href="https://twitter.com/llama_index/status/1698053712521146389?s=20" rel="noopener ugc nofollow" target="_blank">Tweet</a>.</li></ol><h1>RAG Tips:</h1><p>LlamaIndex shares <a href="https://gpt-index.readthedocs.io/en/latest/end_to_end_tutorials/dev_practices/production_rag.html" rel="noopener ugc nofollow" target="_blank">four tactics</a> to boost your RAG pipeline:</p><p>1️⃣ Use summaries for retrieval, and a broader context for synthesis.</p><p>2️⃣ Use metadata for structured retrieval over large docs.</p><p>3️⃣ Deploy LLMs for dynamic retrieval based on tasks.</p><p>4️⃣ Fine-tune embeddings for better retrieval.</p><h1>Tutorials:</h1><ol><li><a href="https://twitter.com/jasonzhou1993" rel="noopener ugc nofollow" target="_blank">Jason's</a> <a href="https://www.youtube.com/watch?v=qKtM2AlDTs8&amp;t=475s" rel="noopener ugc nofollow" target="_blank">tutorial</a> on adding Image Responses to GPT knowledge retrieval apps.</li><li><a href="https://twitter.com/wenqi_glantz" rel="noopener ugc nofollow" target="_blank">Wenqi Glantz</a> <a href="https://betterprogramming.pub/building-production-ready-llm-apps-with-llamaindex-document-metadata-for-higher-accuracy-retrieval-a8ceca641fb5" rel="noopener ugc nofollow" target="_blank">tutorial</a> on Building Production-Ready LLM Apps with LlamaIndex: Document Metadata for Higher Accuracy Retrieval</li><li>Streamlit <a href="https://blog.streamlit.io/build-a-chatbot-with-custom-data-sources-powered-by-llamaindex/" rel="noopener ugc nofollow" target="_blank">tutorial</a> on Building a chatbot with custom data sources, powered by LlamaIndex.</li><li><a href="https://twitter.com/wenqi_glantz" rel="noopener ugc nofollow" target="_blank">Wenqi Glantz</a> <a href="https://betterprogramming.pub/building-production-ready-llm-apps-with-llamaindex-recursive-document-agents-for-dynamic-retrieval-1f4b25287918" rel="noopener ugc nofollow" target="_blank">tutorial</a> on Building Production-Ready LLM Apps With LlamaIndex: Recursive Document Agents for Dynamic Retrieval.</li><li><a href="https://twitter.com/ecardenas300" rel="noopener ugc nofollow" target="_blank">Erika Cardenas</a> covers the usage of <a href="https://twitter.com/ecardenas300/status/1695816617207153016?s=20" rel="noopener ugc nofollow" target="_blank">LlamaIndex in building an RAG app</a>.</li><li><a href="https://argilla.io/" rel="noopener ugc nofollow" target="_blank">Argilla</a> blog post on <a href="https://docs.argilla.io/en/latest/guides/llms/examples/fine-tuning-openai-rag-feedback.html#Evaluating-base-vs-fine-tuned-with-human-preference-data" rel="noopener ugc nofollow" target="_blank">Fine-tuning and evaluating GPT-3.5 with human feedback for RAG using LlamaIndex</a>.</li><li><a href="https://www.kdnuggets.com/" rel="noopener ugc nofollow" target="_blank">KDNuggests</a> blog post on <a href="https://www.kdnuggets.com/build-your-own-pandasai-with-llamaindex" rel="noopener ugc nofollow" target="_blank">Build Your Own PandasAI with LlamaIndex</a>.</li></ol><p>From the LlamaIndex team:</p><ol><li><a href="https://twitter.com/jerryjliu0" rel="noopener ugc nofollow" target="_blank">Jerry Liu</a>’s <a href="https://medium.com/llamaindex-blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d" rel="noopener">tutorial</a> on fine-tuning Llama 2 for Text-to-SQL Applications.</li><li><a href="https://twitter.com/jerryjliu0" rel="noopener ugc nofollow" target="_blank">Jerry Liu's</a> <a href="https://medium.com/llamaindex-blog/fine-tuning-embeddings-for-rag-with-synthetic-data-e534409a3971" rel="noopener">tutorial</a> on Fine-Tuning Embeddings for RAG with Synthetic Data.</li><li><a href="https://twitter.com/ravithejads" rel="noopener ugc nofollow" target="_blank">Ravi Theja’s</a> <a href="https://medium.com/llamaindex-blog/llamaindex-harnessing-the-power-of-text2sql-and-rag-to-analyze-product-reviews-204feabdf25b" rel="noopener">tutorial</a> on combining Text2SQL and RAG with LlamaIndex to analyze product reviews.</li><li><a href="https://twitter.com/ravithejads" rel="noopener ugc nofollow" target="_blank">Ravi Theja’s</a> tutorial on different <a href="https://www.youtube.com/watch?v=gQXXeLHTxkI" rel="noopener ugc nofollow" target="_blank">Indicies, Storage Context, and Service Context of LlamaIndex.</a></li><li><a href="https://twitter.com/ravithejads" rel="noopener ugc nofollow" target="_blank">Ravi Theja’s</a> tutorial on <a href="https://www.youtube.com/watch?v=hsEWohYtg0I" rel="noopener ugc nofollow" target="_blank">Custom Retrievers and Hybrid Search in LlamaIndex.</a></li><li><a href="https://twitter.com/ajhofmann18" rel="noopener ugc nofollow" target="_blank">Adam's</a> tutorial on <a href="https://www.youtube.com/watch?v=GkIEEdIErm8" rel="noopener ugc nofollow" target="_blank">Introduction to Data Agents for Developers</a>.</li><li><a href="https://twitter.com/ravithejads" rel="noopener ugc nofollow" target="_blank">Ravi Theja’s</a> tutorial on creating <a href="https://medium.com/llamaindex-blog/llamaindex-automatic-knowledge-transfer-kt-generation-for-code-bases-f3d91f21b7af" rel="noopener">Automatic Knowledge Transfer (KT) Generation for Code Bases using LlamaIndex.</a></li></ol><h1>Webinars:</h1><ol><li><a href="https://www.youtube.com/watch?v=njzB6fm0U8g" rel="noopener ugc nofollow" target="_blank">Webinar</a> with members from Docugami on Document Metadata and Local Models for Better, Faster Retrieval.</li><li><a href="https://www.youtube.com/watch?v=CwdAi1tts9c" rel="noopener ugc nofollow" target="_blank">Webinar</a> with Shaun and Piaoyang on building Personalized AI Characters with RealChar.</li><li><a href="https://www.youtube.com/watch?v=Zj5RCweUHIk" rel="noopener ugc nofollow" target="_blank">Webinar</a> with Bob (Weaviet), Max (sid.ai), and Tuana (HayStack) on making RAG Production-Ready.</li><li><a href="https://www.youtube.com/watch?v=hb8uT-VBEwQ" rel="noopener ugc nofollow" target="_blank">Workshop</a> by Wey Gu on Building RAG with Knowledge Graphs.</li><li><a href="https://www.youtube.com/watch?v=mndiDJ5k26A" rel="noopener ugc nofollow" target="_blank">Webinar</a> with Jo Bergum and Shishir Patil on fine-tuning and RAG.</li></ol><h1>Events:</h1><ol><li><a href="https://twitter.com/jerryjliu0" rel="noopener ugc nofollow" target="_blank">Jerry Liu</a> spoke about LlamaIndex at the <a href="https://www.youtube.com/watch?v=QtYL4Cm-pjE" rel="noopener ugc nofollow" target="_blank">NYSE Floor Talk</a>.</li><li><a href="https://twitter.com/ravithejads" rel="noopener ugc nofollow" target="_blank">Ravi Theja</a> spoke about LlamaIndex at the <a href="https://twitter.com/ravithejads/status/1689491855543599104?s=20" rel="noopener ugc nofollow" target="_blank">Fifth Elephant conference</a> in Bengaluru, India.</li><li><a href="https://twitter.com/ravithejads" rel="noopener ugc nofollow" target="_blank">Ravi Theja</a> conducted a <a href="https://twitter.com/fifthel/status/1692785973283656052?s=20" rel="noopener ugc nofollow" target="_blank">workshop</a> on LlamaIndex in Bengaluru, India.</li></ol><h1>Demos And Papers:</h1><ol><li>The paper titled <a href="https://www.nature.com/articles/s41598-023-41512-8" rel="noopener ugc nofollow" target="_blank">Performance of ChatGPT, human radiologists, and context-aware ChatGPT in identifying AO codes from radiology reports</a> is an intriguing medical research. It leverages both LlamaIndex and ChatGPT to pinpoint AO codes within radiology reports, enhancing fracture classification. A fantastic fusion of tech and medicine!</li><li><a href="https://www.secinsights.ai/" rel="noopener ugc nofollow" target="_blank">SEC Insights AI</a> does SEC document analysis using LlamaIndex is on Product Hunt as the 5th product of the day.</li><li><a href="https://lablab.ai/event/autonomous-agents-hackathon/kbve/atlas" rel="noopener ugc nofollow" target="_blank">RentEarth</a>: an agent to build your own startup with an amazing 3D interface and LlamaIndex.</li></ol><p>In wrapping up this edition of our LlamaIndex Update series, we’re reminded of the power of collaboration and innovation. From new features to integrations and tutorials, our mission to revolutionize the AI realm marches forward. To every member of our community, thank you for your unwavering support and enthusiasm. Let’s continue to elevate the world of AI together!</p></div><div class="BlogPost_relatedPosts__0z6SN"><h2 class="Text_text__zPO0D Text_text-align-center__HhKqo Text_text-size-16__PkjFu Text_text-weight-400__5ENkK Text_text-family-spaceGrotesk__E4zcE BlogPost_relatedPostsTitle___JIrW">Related articles</h2><ul class="BlogPost_relatedPostsList__uOKzB"><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F23819f5bd086643f28ca7d2746a9e400f28cdbee-1023x561.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F23819f5bd086643f28ca7d2746a9e400f28cdbee-1023x561.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F23819f5bd086643f28ca7d2746a9e400f28cdbee-1023x561.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations">Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-03-19</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fe1c4d777a0138dbccbbc909ab66184688ab914fc-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fe1c4d777a0138dbccbbc909ab66184688ab914fc-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fe1c4d777a0138dbccbbc909ab66184688ab914fc-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/llamaindex-newsletter-2024-03-19">LlamaIndex Newsletter 2024-03-19</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-03-19</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fbf9b74d4436b1204f7567421bf0421e9319655a6-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fbf9b74d4436b1204f7567421bf0421e9319655a6-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fbf9b74d4436b1204f7567421bf0421e9319655a6-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/llamaindex-newsletter-2024-03-05">LlamaIndex Newsletter 2024-03-05</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-03-05</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fa195d5cbe68a6c2cb0847c985ead93111909f0bf-3378x3265.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fa195d5cbe68a6c2cb0847c985ead93111909f0bf-3378x3265.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fa195d5cbe68a6c2cb0847c985ead93111909f0bf-3378x3265.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/querying-a-network-of-knowledge-with-llama-index-networks-d784b4c3006f">Querying a network of knowledge with llama-index-networks</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-02-27</p></div></li></ul></div></section></main><footer class="Footer_footer__eNA9m"><div class="Footer_navContainer__7bvx4"><div class="Footer_logoContainer__3EpzI"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" style="color:transparent" src="/llamaindex.svg"/><div class="Footer_socialContainer__GdOgk"><ul class="Socials_socials__8Y_s5"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul></div></div><div class="Footer_nav__BLEuE"><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/">LlamaIndex</a></h3><ul><li><a href="/blog"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Blog</span></a></li><li><a href="/partners"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Partners</span></a></li><li><a href="/careers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Careers</span></a></li><li><a href="/contact"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Contact</span></a></li><li><a href="/brand"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Brand</span></a></li><li><a href="https://llamaindex.statuspage.io" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Status</span></a></li><li><a href="https://app.vanta.com/runllama.ai/trust/pkcgbjf8b3ihxjpqdx17nu" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Trust Center</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/enterprise">Enterprise</a></h3><ul><li><a href="https://cloud.llamaindex.ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaCloud</span></a></li><li><a href="https://cloud.llamaindex.ai/parse" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaParse</span></a></li><li><a href="/customers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Customers</span></a></li><li><a href="/llamacloud-sharepoint-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SharePoint</span></a></li><li><a href="/llamacloud-aws-s3-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">AWS S3</span></a></li><li><a href="/llamacloud-azure-blob-storage-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure Blob Storage</span></a></li><li><a href="/llamacloud-google-drive-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Google Drive</span></a></li> </ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/framework">Framework</a></h3><ul><li><a href="https://pypi.org/project/llama-index/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python package</span></a></li><li><a href="https://docs.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python docs</span></a></li><li><a href="https://www.npmjs.com/package/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript package</span></a></li><li><a href="https://ts.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript docs</span></a></li><li><a href="https://llamahub.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaHub</span></a></li><li><a href="https://github.com/run-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">GitHub</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/community">Community</a></h3><ul><li><a href="/community#newsletter"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Newsletter</span></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Discord</span></a></li><li><a href="https://www.linkedin.com/company/91154103/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LinkedIn</span></a></li><li><a href="https://twitter.com/llama_index"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Twitter/X</span></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">YouTube</span></a></li><li><a href="https://bsky.app/profile/llamaindex.bsky.social"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">BlueSky</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e">Starter projects</h3><ul><li><a href="https://www.npmjs.com/package/create-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">create-llama</span></a></li><li><a href="https://secinsights.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SEC Insights</span></a></li><li><a href="https://github.com/run-llama/llamabot"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaBot</span></a></li><li><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/rag_cli.html"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">RAG CLI</span></a></li></ul></div></div></div><div class="Footer_copyrightContainer__mBKsT"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA">© <!-- -->2025<!-- --> LlamaIndex</p><div class="Footer_legalNav__O1yJA"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/privacy-notice.pdf">Privacy Notice</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/terms-of-service.pdf">Terms of Service</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="https://bit.ly/llamaindexdpa">Data Processing Addendum</a></p></div></div></footer></div><svg xmlns="http://www.w3.org/2000/svg" class="flt_svg" style="display:none"><defs><filter id="flt_tag"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="2"></feGaussianBlur><feColorMatrix in="blur" result="flt_tag" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="flt_tag" operator="atop"></feComposite></filter><filter id="svg_blur_large"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="8"></feGaussianBlur><feColorMatrix in="blur" result="svg_blur_large" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="svg_blur_large" operator="atop"></feComposite></filter></defs></svg></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"page":{"announcement":{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"},"post":{"_createdAt":"2024-02-22T21:47:07Z","_id":"1b6fe510-fc22-4366-a46b-fbd0dad72f36","_rev":"05dtDS0H5iRVsxYMarZ1cL","_type":"blogPost","_updatedAt":"2025-05-21T20:36:43Z","announcement":[{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"}],"authors":[{"_createdAt":"2024-02-22T19:58:55Z","_id":"60575af5-a5c2-40f6-9aab-d5e02da9c000","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"people","_updatedAt":"2024-02-24T20:08:04Z","name":"Ravi Theja","slug":{"_type":"slug","current":"ravi-theja"}}],"featured":false,"htmlContent":"\u003cp\u003eHello LlamaIndex Community!\u003c/p\u003e\u003cp\u003eWe’re thrilled to bring you the latest edition of our LlamaIndex Update series. Whether you’ve been a part of our journey from the start or have just recently joined us, your engagement and input are invaluable to us.\u003c/p\u003e\u003cp\u003eIn this update, we’re excited to unveil some significant advancements. We’ve got comprehensive updates on new features for both the Python and TypeScript versions of LlamaIndex. In addition, we’re offering some expert insights on RAG tips that you won’t want to miss. To keep you ahead of the curve, we’ve also curated a selection of webinars, tutorials, events, and demos.\u003c/p\u003e\u003cp\u003eSo without further ado, let’s delve into the latest developments.\u003c/p\u003e\u003ch1\u003e\u003cstrong\u003eNew Features:\u003c/strong\u003e\u003c/h1\u003e\u003ch2\u003eLlamaIndex\u003c/h2\u003e\u003col\u003e\u003cli\u003eLlamaIndex introduces the Sweep AI code splitter for RAG apps, addressing the challenges of traditional code splitting. This tool features recursive splitting combined with CSTs across 100+ languages, enhancing the LlamaIndex experience. \u003ca href=\"https://docs.sweep.dev/blogs/chunking-2m-files\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBlogPost\u003c/a\u003e, \u003ca href=\"https://twitter.com/jerryjliu0/status/1686413452988878849?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex now supports streaming data ETL, enhancing structured data extraction with the OpenAI Function API. By inputting a Pydantic object class in LlamaIndex, users can receive streamed data objects from OpenAI individually. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/examples/output_parsing/openai_pydantic_program.html#extraction-into-album-streaming\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/jerryjliu0/status/1686752090197008387?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex has teamed up with Neo4j to amplify knowledge graph capabilities with LLM’s. This integration not only allows for storing any knowledge graph created in LlamaIndex directly in Neo4j but also introduces a specialized text-to-cypher prompt for Neo4j users. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/Neo4jKGIndexDemo.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1687224679340064768?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex, in collaboration with Mendable AI and Nomic AI, unveils a Nomic Atlas visual map detailing user questions from the Mendable AI bot. This innovative tool groups similar questions, providing insights for improved app deployment, prompt control, language support, and documentation. New users can find the helpful Mendable AI bot on LlamaIndex’s documentation site. \u003ca href=\"https://twitter.com/llama_index/status/1687485785228906496?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex, in collaboration with Predibase, offers an optimal way to operationalize LLMs. Experience top-tier RAG by privately hosting open-source LLMs on managed infrastructure right within your VPC. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/examples/llm/predibase.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/predibase/status/1687493843619598336?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eThe LlamaIndex playground \u003ca href=\"https://llama-playground.vercel.app/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eapp\u003c/a\u003e enhances the RAG experience. Updates include new Temperature and Top P options, along with intuitive tooltips offering plain language explanations.\u003c/li\u003e\u003cli\u003eLlamaIndex Tip💡: Boost your RAG systems by adding structured data to raw text. This allows for easier metadata filtering and optimal embedding biases. Dive into our guide on harnessing the HuggingFace span marker for targeted entity extraction. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/examples/metadata_extraction/EntityExtractionClimate.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1688711638537682944?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex now has the Semantic Scholar Loader. With it, users can swiftly set up citation-based Q\u0026amp;A systems. \u003ca href=\"https://llamahub.ai/l/semanticscholar\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/shauryr/status/1687858252481236993?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex highlights the significance of text chunk size in LLM QA systems. To determine the best chunk size without human intervention, we suggest ensembling different sizes and using a reranker for context relevance during queries. This method involves simultaneous queries across retrievers of various sizes and consolidating results for reranking. Though experimental, this approach aims to discern the optimal chunk size strategy. \u003ca href=\"https://gpt-index.readthedocs.io/en/stable/examples/retrievers/ensemble_retrieval.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/jerryjliu0/status/1688948298781249536?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex’s customer support bot seamlessly interfaces with Shopify’s 50k-line GraphQL API Spec. Through smart tools and LlamaIndex features, it offers quick insights like \u003ccode class=\"cw qm qn qo qp b\"\u003erefunded orders\u003c/code\u003e despite the vast spec size. Efficient indexing ensures precise user query responses. \u003ca href=\"https://llamahub.ai/l/tools-shopify\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/jerryjliu0/status/1689295239822069760?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex’s integration with Xinference enables users to effortlessly expand models like llama 2, chatglm, and vicuna to incorporate RAG and agents. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/examples/llm/XinferenceLocalDeployment.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1689426281015005184?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex introduces \u003ccode class=\"cw qm qn qo qp b\"\u003eOne-click Observability\u003c/code\u003e. With just a single code line, integrate LlamaIndex with advanced observability tools from partners like Weights \u0026amp; Biases, ArizeAI, and TruEra, simplifying LLM app debugging for production. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/end_to_end_tutorials/one_click_observability.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1689659395465191424?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex has updated the LLM default temperature value to 0.1. \u003ca href=\"https://twitter.com/yi_ding/status/1689692197871042561?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex integration with Zep, enhancing the memory layer of LLM apps. It’s not just about storage but also enriching data with summaries, metadata, and more. \u003ca href=\"https://medium.com/llamaindex-blog/zep-and-llamaindex-a-vector-store-walkthrough-564edb8c22dc\" rel=\"noopener\"\u003eBlogPost\u003c/a\u003e, \u003ca href=\"https://twitter.com/jerryjliu0/status/1690018390059225088?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex has revamped its defaults! Now, gpt-3.5-turbo is the go-to LLM, with enhanced prompts and a superior text splitter. Additionally, if OpenAI’s key isn’t set, it has backup options with llama.cpp. New embedding features have also been added. \u003ca href=\"https://twitter.com/llama_index/status/1690081661453803520?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex now seamlessly integrates with FastChat by \u003ca href=\"https://twitter.com/lmsysorg\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003elmsysorg\u003c/a\u003e. Elevate your LLM deployments like Vicuna and Llama 2, serving as an alternative to OpenAI. \u003ca href=\"https://twitter.com/jerryjliu0/status/1691114369705533440?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex provides a seamless integration with Azure AI Services. Dive into a richer ecosystem of AI tools from Computer Vision, Translation, and speech enhancing your multi-modal AI interactions. \u003ca href=\"https://llamahub.ai/l/tools-azure_translate\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs1\u003c/a\u003e, \u003ca href=\"https://llamahub.ai/l/tools-azure_speech\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs2\u003c/a\u003e, \u003ca href=\"https://llamahub.ai/l/tools-azure_cv\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs3\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1691605500079800674?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex unveils \u003ccode class=\"cw qm qn qo qp b\"\u003eGraph RAG\u003c/code\u003e — an approach to enhance LLMs with context from graph databases. Extract valuable subgraphs from any knowledge graph for superior question-answering capabilities. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/examples/query_engine/knowledge_graph_rag_query_engine.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/jerryjliu0/status/1691835187519459338?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex has expanded native async support, enhancing the scalability of full-stack LLM apps. We now offer async agents, tool execution, and callback support, and have introduced async methods in vector stores. \u003ca href=\"https://twitter.com/llama_index/status/1691965149840908642?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex enhances debugging with data agent trace observability. Additionally, system prompts can now be added to any query engine and we have begun the transition of LLM and embedding modules to Pydantic. \u003ca href=\"https://twitter.com/llama_index/status/1692696993900974399?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/examples/callbacks/LlamaDebugHandler.html#see-traces-events-for-agents\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex’s \u003ccode class=\"cw qm qn qo qp b\"\u003eRecursive Document Agents\u003c/code\u003e enhance RAG by retrieving based on summaries and adjusting chunk retrieval per need. This boosts querying across varied documents, offering both question-answering and summarization within a document. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/examples/query_engine/recursive_retriever_agents.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/jerryjliu0/status/1693421308674289822?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex integrates with Metaphor to supercharge data agents. This integration offers a specialized search engine tailored for LLMs, allowing dynamic data lookup beyond just RAG, and answering a broader range of questions. \u003ca href=\"https://medium.com/llamaindex-blog/llamaindex-metaphor-towards-automating-knowledge-work-with-llms-5520a32efa2f\" rel=\"noopener\"\u003eBlogPost\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1693649115983618278?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex now supports integration with OpenAI’s fine-tuned models via their new endpoint. Seamlessly integrate these models into your RAG pipeline. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/core_modules/model_modules/llms/usage_custom.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1694116968008401201?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex introduces the \u003ccode class=\"cw qm qn qo qp b\"\u003eOpenAIFineTuningHandler\u003c/code\u003e to streamline data collection for fine-tuning gpt-3.5-turbo with GPT-4 outputs. Run RAG with GPT-4 and effortlessly generate a dataset to train a more cost-effective model. \u003ca href=\"https://github.com/jerryjliu/llama_index/blob/main/experimental/openai_fine_tuning/openai_fine_tuning.ipynb\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eNotebook\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1694395355725746397?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex presents the \u003ccode class=\"cw qm qn qo qp b\"\u003ePrincipled Development Practices\u003c/code\u003e guide, detailing best practices for LLM app development Observability, Evaluation, and Monitoring. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/end_to_end_tutorials/principled_dev_practices.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1694736328276271248?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex introduces a refined Prompt system. With just three core classes: \u003ccode class=\"cw qm qn qo qp b\"\u003ePromptTemplate\u003c/code\u003e, \u003ccode class=\"cw qm qn qo qp b\"\u003eChatPromptTemplate\u003c/code\u003e, and \u003ccode class=\"cw qm qn qo qp b\"\u003eSelectorPromptTemplate\u003c/code\u003e, users can effortlessly format as chat messages or text and tailor prompts based on model conditions. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/core_modules/model_modules/prompts.html#\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1695093392378880324?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex delves into \u003ccode class=\"cw qm qn qo qp b\"\u003echunk dreaming\u003c/code\u003e a concept inspired by \u003ca href=\"https://twitter.com/tomchapin\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eThomas H. Chapin IV\u003c/a\u003e. By auto-extracting metadata from a text chunk, it can identify potential questions and provide summaries over neighboring nodes. This enriched context boosts RAG’s performance. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/examples/metadata_extraction/MetadataExtraction_LLMSurvey.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1695233836983144764?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex is integrated with BagelDB, enabling developers to effortlessly tap into vector data stored on BagelDB. \u003ca href=\"https://twitter.com/BagelDB_ai/status/1695158701387059319?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex now lets the LLM choose between vector search for semantic queries or our BM25 retriever for keyword-specific ones. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/examples/retrievers/bm25_retriever.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1695590257054630149?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex introduces the \u003ccode class=\"cw qm qn qo qp b\"\u003eAutoMergingRetriever\u003c/code\u003e, crafted with insights from \u003ca href=\"https://twitter.com/jxnlco\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eJason\u003c/a\u003e and ChatGPT. This technique fetches precise context chunks and seamlessly merges them, optimizing LLM responses. Using the HierarchicalNodeParser, we ensure interconnected chunks for enhanced context clarity. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/examples/retrievers/auto_merging_retriever.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1695832757560356871?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex introduces embedding finetuning for optimized retrieval performance. Beyond enhancing RAG, we’ve simplified retrieval evaluations with automatic QA dataset generation from text, streamlining both finetuning and evaluation processes. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/examples/finetuning/embeddings/finetune_embedding.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1696583119539966070?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex now integrates directly with Airbyte sources including Gong, Hubspot, Salesforce, Shopify, Stripe, Typeform, and Zendesk Support. Easily enhance your LlamaIndex application with these platforms implemented as data loaders. \u003ca href=\"https://airbyte.com/blog/introducing-airbyte-sources-within-llamaindex\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBlogPost\u003c/a\u003e, \u003ca href=\"https://twitter.com/AirbyteHQ/status/1696633858316243046?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex integrates with DeepEval, a comprehensive library to evaluate LLM and RAG apps. Assess on four key metrics: Relevance, Factual Consistency, Answer Similarity, and Bias/Toxicity. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/community/integrations/deepeval.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1696674470566764846?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex recommends evaluating LLM + RAG step-by-step, especially retrieval. Create synthetic retrieval datasets from text chunks using LLMs. This method not only evaluates retrieval but also fine-tunes embeddings. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/examples/finetuning/embeddings/finetune_embedding.html#generate-corpus\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/jerryjliu0/status/1696675525442609166?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex unveils a managed index abstraction simplifying RAG’s ingestion and storage processes with Vectara. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/community/integrations/managed_indices.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1696919525151899671?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex has significantly enhanced its callback handling support, encompassing features like tracebacks, LLM token counts, templates, and detailed agent tool information. These advancements pave the way for smoother integrations with evaluation and observability applications. \u003ca href=\"https://twitter.com/llama_index/status/1697407787154997754?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex has integrated with AskMarvinAI, enabling automated metadata extraction from text corpora. Just annotate a Pydantic model and effortlessly log metadata from all associated text chunks. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/examples/metadata_extraction/MarvinMetadataExtractorDemo.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1697632035186372745?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLlamaIndex is integrated with RunGPT by JinaAI, an outstanding framework for one-click deployment of various open-source models such as Llama, Vicuna, Pythia, and more. Coupled with LlamaIndex’s innate chat/streaming capabilities, users can now deploy and utilize powerhouse models like Llama-7B seamlessly. \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/examples/llm/rungpt.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDocs\u003c/a\u003e, \u003ca href=\"https://twitter.com/llama_index/status/1698001332563837165?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003c/ol\u003e\u003ch2\u003eLlamaIndex.TS\u003c/h2\u003e\u003col\u003e\u003cli\u003eLITS has Full Azure OpenAI integration. \u003ca href=\"https://twitter.com/yi_ding/status/1688564790007087104\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLITS Enhanced Llama2 support, new default temperature (0.1), and GPT chat integration. \u003ca href=\"https://twitter.com/llama_index/status/1689086106036547584?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLITS helps to use \u003ccode class=\"cw qm qn qo qp b\"\u003efromDocuments\u003c/code\u003e without repeat checks; auto SHA256 comparison. \u003ca href=\"https://twitter.com/llama_index/status/1691502243286228993?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLITS now supports OpenAI v4, Anthropic 0.6, \u0026amp; Replicate 0.16.1., CSV loader, Merged NodeWithEmbeddings \u0026amp; BaseNode. \u003ca href=\"https://twitter.com/llama_index/status/1691984600506257462?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLITS now supports PapaCSVLoader for math. \u003ca href=\"https://twitter.com/yi_ding/status/1691991221974217104?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLITS is now integrated with LiteLLM. \u003ca href=\"https://twitter.com/yi_ding/status/1692408213340340328\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLITS now has additional session options for proxy server support, Default timeout reset to 60 seconds for OpenAI. \u003ca href=\"https://twitter.com/llama_index/status/1693072438404276460?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLITS now has Pinecone integration. \u003ca href=\"https://twitter.com/yi_ding/status/1693275444848840745?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLITS has Optimized ChatGPT prompts, fixed metadata rehydration issues, and OpenAI Node v4.1.0 with fine-tuned model support. \u003ca href=\"https://twitter.com/llama_index/status/1694382741218005153?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLITS has introduced enhanced text-splitting features, including a specialized tokenizer for Chinese, Japanese, and Korean, and refinements to the SentenceSplitter for handling decimal numbers. \u003ca href=\"https://twitter.com/llama_index/status/1694719208217588070?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLITS has a Markdown loader and metadata support in the response synthesizer. \u003ca href=\"https://twitter.com/llama_index/status/1695156772783395255?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLITS revamped usability: \u003ccode class=\"cw qm qn qo qp b\"\u003eListIndex\u003c/code\u003e is now \u003ccode class=\"cw qm qn qo qp b\"\u003eSummaryIndex\u003c/code\u003e for clarity, and prompts have been made typed and customizable to enhance user control and experience. \u003ca href=\"https://twitter.com/llama_index/status/1696626780277481491?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eLITS has Notion Reader. Now, users can effortlessly import their documents directly into their RAG or Data Agent application in LITS. \u003ca href=\"https://twitter.com/llama_index/status/1698053712521146389?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTweet\u003c/a\u003e.\u003c/li\u003e\u003c/ol\u003e\u003ch1\u003eRAG Tips:\u003c/h1\u003e\u003cp\u003eLlamaIndex shares \u003ca href=\"https://gpt-index.readthedocs.io/en/latest/end_to_end_tutorials/dev_practices/production_rag.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003efour tactics\u003c/a\u003e to boost your RAG pipeline:\u003c/p\u003e\u003cp\u003e1️⃣ Use summaries for retrieval, and a broader context for synthesis.\u003c/p\u003e\u003cp\u003e2️⃣ Use metadata for structured retrieval over large docs.\u003c/p\u003e\u003cp\u003e3️⃣ Deploy LLMs for dynamic retrieval based on tasks.\u003c/p\u003e\u003cp\u003e4️⃣ Fine-tune embeddings for better retrieval.\u003c/p\u003e\u003ch1\u003eTutorials:\u003c/h1\u003e\u003col\u003e\u003cli\u003e\u003ca href=\"https://twitter.com/jasonzhou1993\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eJason's\u003c/a\u003e \u003ca href=\"https://www.youtube.com/watch?v=qKtM2AlDTs8\u0026amp;t=475s\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003etutorial\u003c/a\u003e on adding Image Responses to GPT knowledge retrieval apps.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://twitter.com/wenqi_glantz\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWenqi Glantz\u003c/a\u003e \u003ca href=\"https://betterprogramming.pub/building-production-ready-llm-apps-with-llamaindex-document-metadata-for-higher-accuracy-retrieval-a8ceca641fb5\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003etutorial\u003c/a\u003e on Building Production-Ready LLM Apps with LlamaIndex: Document Metadata for Higher Accuracy Retrieval\u003c/li\u003e\u003cli\u003eStreamlit \u003ca href=\"https://blog.streamlit.io/build-a-chatbot-with-custom-data-sources-powered-by-llamaindex/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003etutorial\u003c/a\u003e on Building a chatbot with custom data sources, powered by LlamaIndex.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://twitter.com/wenqi_glantz\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWenqi Glantz\u003c/a\u003e \u003ca href=\"https://betterprogramming.pub/building-production-ready-llm-apps-with-llamaindex-recursive-document-agents-for-dynamic-retrieval-1f4b25287918\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003etutorial\u003c/a\u003e on Building Production-Ready LLM Apps With LlamaIndex: Recursive Document Agents for Dynamic Retrieval.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://twitter.com/ecardenas300\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eErika Cardenas\u003c/a\u003e covers the usage of \u003ca href=\"https://twitter.com/ecardenas300/status/1695816617207153016?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eLlamaIndex in building an RAG app\u003c/a\u003e.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://argilla.io/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eArgilla\u003c/a\u003e blog post on \u003ca href=\"https://docs.argilla.io/en/latest/guides/llms/examples/fine-tuning-openai-rag-feedback.html#Evaluating-base-vs-fine-tuned-with-human-preference-data\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eFine-tuning and evaluating GPT-3.5 with human feedback for RAG using LlamaIndex\u003c/a\u003e.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.kdnuggets.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eKDNuggests\u003c/a\u003e blog post on \u003ca href=\"https://www.kdnuggets.com/build-your-own-pandasai-with-llamaindex\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBuild Your Own PandasAI with LlamaIndex\u003c/a\u003e.\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eFrom the LlamaIndex team:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003ca href=\"https://twitter.com/jerryjliu0\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eJerry Liu\u003c/a\u003e’s \u003ca href=\"https://medium.com/llamaindex-blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d\" rel=\"noopener\"\u003etutorial\u003c/a\u003e on fine-tuning Llama 2 for Text-to-SQL Applications.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://twitter.com/jerryjliu0\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eJerry Liu's\u003c/a\u003e \u003ca href=\"https://medium.com/llamaindex-blog/fine-tuning-embeddings-for-rag-with-synthetic-data-e534409a3971\" rel=\"noopener\"\u003etutorial\u003c/a\u003e on Fine-Tuning Embeddings for RAG with Synthetic Data.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://twitter.com/ravithejads\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eRavi Theja’s\u003c/a\u003e \u003ca href=\"https://medium.com/llamaindex-blog/llamaindex-harnessing-the-power-of-text2sql-and-rag-to-analyze-product-reviews-204feabdf25b\" rel=\"noopener\"\u003etutorial\u003c/a\u003e on combining Text2SQL and RAG with LlamaIndex to analyze product reviews.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://twitter.com/ravithejads\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eRavi Theja’s\u003c/a\u003e tutorial on different \u003ca href=\"https://www.youtube.com/watch?v=gQXXeLHTxkI\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eIndicies, Storage Context, and Service Context of LlamaIndex.\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://twitter.com/ravithejads\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eRavi Theja’s\u003c/a\u003e tutorial on \u003ca href=\"https://www.youtube.com/watch?v=hsEWohYtg0I\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCustom Retrievers and Hybrid Search in LlamaIndex.\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://twitter.com/ajhofmann18\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAdam's\u003c/a\u003e tutorial on \u003ca href=\"https://www.youtube.com/watch?v=GkIEEdIErm8\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eIntroduction to Data Agents for Developers\u003c/a\u003e.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://twitter.com/ravithejads\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eRavi Theja’s\u003c/a\u003e tutorial on creating \u003ca href=\"https://medium.com/llamaindex-blog/llamaindex-automatic-knowledge-transfer-kt-generation-for-code-bases-f3d91f21b7af\" rel=\"noopener\"\u003eAutomatic Knowledge Transfer (KT) Generation for Code Bases using LlamaIndex.\u003c/a\u003e\u003c/li\u003e\u003c/ol\u003e\u003ch1\u003eWebinars:\u003c/h1\u003e\u003col\u003e\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=njzB6fm0U8g\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWebinar\u003c/a\u003e with members from Docugami on Document Metadata and Local Models for Better, Faster Retrieval.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=CwdAi1tts9c\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWebinar\u003c/a\u003e with Shaun and Piaoyang on building Personalized AI Characters with RealChar.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=Zj5RCweUHIk\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWebinar\u003c/a\u003e with Bob (Weaviet), Max (sid.ai), and Tuana (HayStack) on making RAG Production-Ready.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=hb8uT-VBEwQ\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWorkshop\u003c/a\u003e by Wey Gu on Building RAG with Knowledge Graphs.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=mndiDJ5k26A\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWebinar\u003c/a\u003e with Jo Bergum and Shishir Patil on fine-tuning and RAG.\u003c/li\u003e\u003c/ol\u003e\u003ch1\u003eEvents:\u003c/h1\u003e\u003col\u003e\u003cli\u003e\u003ca href=\"https://twitter.com/jerryjliu0\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eJerry Liu\u003c/a\u003e spoke about LlamaIndex at the \u003ca href=\"https://www.youtube.com/watch?v=QtYL4Cm-pjE\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eNYSE Floor Talk\u003c/a\u003e.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://twitter.com/ravithejads\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eRavi Theja\u003c/a\u003e spoke about LlamaIndex at the \u003ca href=\"https://twitter.com/ravithejads/status/1689491855543599104?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eFifth Elephant conference\u003c/a\u003e in Bengaluru, India.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://twitter.com/ravithejads\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eRavi Theja\u003c/a\u003e conducted a \u003ca href=\"https://twitter.com/fifthel/status/1692785973283656052?s=20\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eworkshop\u003c/a\u003e on LlamaIndex in Bengaluru, India.\u003c/li\u003e\u003c/ol\u003e\u003ch1\u003eDemos And Papers:\u003c/h1\u003e\u003col\u003e\u003cli\u003eThe paper titled \u003ca href=\"https://www.nature.com/articles/s41598-023-41512-8\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ePerformance of ChatGPT, human radiologists, and context-aware ChatGPT in identifying AO codes from radiology reports\u003c/a\u003e is an intriguing medical research. It leverages both LlamaIndex and ChatGPT to pinpoint AO codes within radiology reports, enhancing fracture classification. A fantastic fusion of tech and medicine!\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.secinsights.ai/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSEC Insights AI\u003c/a\u003e does SEC document analysis using LlamaIndex is on Product Hunt as the 5th product of the day.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://lablab.ai/event/autonomous-agents-hackathon/kbve/atlas\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eRentEarth\u003c/a\u003e: an agent to build your own startup with an amazing 3D interface and LlamaIndex.\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eIn wrapping up this edition of our LlamaIndex Update series, we’re reminded of the power of collaboration and innovation. From new features to integrations and tutorials, our mission to revolutionize the AI realm marches forward. To every member of our community, thank you for your unwavering support and enthusiasm. Let’s continue to elevate the world of AI together!\u003c/p\u003e","image":{"_type":"image","asset":{"_ref":"image-28384ae80423c0137b96553186cde99b4569c144-1024x1024-jpg","_type":"reference"}},"mainImage":"https://cdn.sanity.io/images/7m9jw85w/production/28384ae80423c0137b96553186cde99b4569c144-1024x1024.jpg","publishedDate":"2023-09-06","relatedPosts":[{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-23819f5bd086643f28ca7d2746a9e400f28cdbee-1023x561-png","_type":"reference"}},"publishedDate":"2024-03-19","slug":"supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations","title":"Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-e1c4d777a0138dbccbbc909ab66184688ab914fc-1024x1024-png","_type":"reference"}},"publishedDate":"2024-03-19","slug":"llamaindex-newsletter-2024-03-19","title":"LlamaIndex Newsletter 2024-03-19"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-bf9b74d4436b1204f7567421bf0421e9319655a6-1024x1024-webp","_type":"reference"}},"publishedDate":"2024-03-05","slug":"llamaindex-newsletter-2024-03-05","title":"LlamaIndex Newsletter 2024-03-05"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-a195d5cbe68a6c2cb0847c985ead93111909f0bf-3378x3265-webp","_type":"reference"}},"publishedDate":"2024-02-27","slug":"querying-a-network-of-knowledge-with-llama-index-networks-d784b4c3006f","title":"Querying a network of knowledge with llama-index-networks"}],"slug":{"_type":"slug","current":"llamaindex-update-09-03-2023-4a7c21c0f60b"},"tags":[{"_createdAt":"2024-02-22T20:19:11Z","_id":"412f77ae-efba-466b-abc9-221fc36d252a","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"large-language-models"},"title":"Large Language Models"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"17d4fc95-517c-4f4a-95ce-bf753e802ac4","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"llamaindex"},"title":"Llamaindex"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"e171aa9d-bc85-4645-8a08-eabe04c530c7","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"openai"},"title":"OpenAI"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"d0a79109-34ab-41fa-a8f4-0b3522970c7d","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"ai"},"title":"AI"},{"_createdAt":"2024-02-22T20:19:13Z","_id":"78713226-8bff-400f-bbfe-fd8a3d90be1d","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:13Z","slug":{"_type":"slug","current":"nlp"},"title":"NLP"}],"title":"LlamaIndex Update — 09/03/2023"},"publishedDate":"Invalid Date"},"params":{"slug":"llamaindex-update-09-03-2023-4a7c21c0f60b"},"draftMode":false,"token":""},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"llamaindex-update-09-03-2023-4a7c21c0f60b"},"buildId":"C8J-EMc_4OCN1ch65l4fl","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>