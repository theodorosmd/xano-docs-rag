<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>Document Research Assistant for Blog Creation with NVIDIA NIM microservices — LlamaIndex - Build Knowledge Assistants over your Enterprise Data</title><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><meta name="title" content="Document Research Assistant for Blog Creation with NVIDIA NIM microservices — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta name="description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:title" content="Document Research Assistant for Blog Creation with NVIDIA NIM microservices — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="og:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:image" content="https://cdn.sanity.io/images/7m9jw85w/production/1c22c02db257a629b8cb2760dcef125d75f84d70-1999x907.png"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="Document Research Assistant for Blog Creation with NVIDIA NIM microservices — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="twitter:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="twitter:image" content="https://cdn.sanity.io/images/7m9jw85w/production/1c22c02db257a629b8cb2760dcef125d75f84d70-1999x907.png"/><link rel="alternate" type="application/rss+xml" href="https://www.llamaindex.ai/blog/feed"/><meta name="next-head-count" content="20"/><script>
            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WWRFB36R');
            </script><link rel="preload" href="/_next/static/css/41c9222e47d080c9.css" as="style"/><link rel="stylesheet" href="/_next/static/css/41c9222e47d080c9.css" data-n-g=""/><link rel="preload" href="/_next/static/css/97c33c8d95f1230e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/97c33c8d95f1230e.css" data-n-p=""/><link rel="preload" href="/_next/static/css/e009059e80bf60c5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e009059e80bf60c5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-1b629d9c8fb16f34.js" defer=""></script><script src="/_next/static/chunks/framework-df1f68dff096b68a.js" defer=""></script><script src="/_next/static/chunks/main-eca7952a704663f8.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c7c49437be49d2ad.js" defer=""></script><script src="/_next/static/chunks/d9067523-4985945b21298365.js" defer=""></script><script src="/_next/static/chunks/41155975-60c12da9ce9fa0b2.js" defer=""></script><script src="/_next/static/chunks/cb355538-cee2ea45674d9de3.js" defer=""></script><script src="/_next/static/chunks/9494-dff62cb53535dd7d.js" defer=""></script><script src="/_next/static/chunks/4063-39a391a51171ff87.js" defer=""></script><script src="/_next/static/chunks/6889-edfa85b69b88a372.js" defer=""></script><script src="/_next/static/chunks/5575-11ee0a29eaffae61.js" defer=""></script><script src="/_next/static/chunks/3444-95c636af25a42734.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-82c8e764e69afd2c.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_buildManifest.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_ssgManifest.js" defer=""></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WWRFB36R" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div class="__variable_d65c78 __variable_b1ea77 __variable_eb7534"><a class="Announcement_announcement__2ohK8" href="http://48755185.hs-sites.com/llamaindex-0">Meet LlamaIndex at the Databricks Data + AI Summit!<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M8.293 5.293a1 1 0 0 1 1.414 0l6 6a1 1 0 0 1 0 1.414l-6 6a1 1 0 0 1-1.414-1.414L13.586 12 8.293 6.707a1 1 0 0 1 0-1.414Z" clip-rule="evenodd"></path></svg></a><header class="Header_header__hO3lJ"><button class="Hamburger_hamburger__17auO Header_hamburger__lUulX"><svg width="28" height="28" viewBox="0 0 28 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.5 14H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" id="hamburger-stroke-top" class="Hamburger_hamburgerStrokeMiddle__I7VpD"></path><path d="M3.5 7H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeTop__oOhFM"></path><path d="M3.5 21H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeBottom__GIQR2"></path></svg></button><a aria-label="Homepage" href="/"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" class="Header_logo__e5KhT" style="color:transparent" src="/llamaindex.svg"/></a><nav aria-label="Main" data-orientation="horizontal" dir="ltr" style="--content-position:0px"><div style="position:relative"><ul data-orientation="horizontal" class="Nav_MenuList__PrCDJ" dir="ltr"><li><button id="radix-:R6tm:-trigger-radix-:R5mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R5mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Products</button></li><li><button id="radix-:R6tm:-trigger-radix-:R9mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R9mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Solutions</button></li><li><a class="Nav_Link__ZrzFc" href="/community" data-radix-collection-item="">Community</a></li><li><a class="Nav_Link__ZrzFc" href="/pricing" data-radix-collection-item="">Pricing</a></li><li><a class="Nav_Link__ZrzFc" href="/blog" data-radix-collection-item="">Blog</a></li><li><a class="Nav_Link__ZrzFc" href="/customers" data-radix-collection-item="">Customer stories</a></li><li><a class="Nav_Link__ZrzFc" href="/careers" data-radix-collection-item="">Careers</a></li></ul></div><div class="Nav_ViewportPosition__jmyHM"></div></nav><div class="Header_secondNav__YJvm8"><nav><a href="/contact" class="Link_link__71cl8 Link_link-variant-tertiary__BYxn_ Header_bookADemo__qCuxV">Book a demo</a></nav><a href="https://cloud.llamaindex.ai/" class="Button_button-variant-default__Oi__n Button_button__aJ0V6 Header_button__1HFhY" data-tracking-variant="default"> <!-- -->Get started</a></div><div class="MobileMenu_mobileMenu__g5Fa6"><nav class="MobileMenu_nav__EmtTw"><ul><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Products<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaparse"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.6654 1.66675V6.66675H16.6654M8.33203 10.8334L6.66536 12.5001L8.33203 14.1667M11.6654 14.1667L13.332 12.5001L11.6654 10.8334M12.082 1.66675H4.9987C4.55667 1.66675 4.13275 1.84234 3.82019 2.1549C3.50763 2.46746 3.33203 2.89139 3.33203 3.33341V16.6667C3.33203 17.1088 3.50763 17.5327 3.82019 17.8453C4.13275 18.1578 4.55667 18.3334 4.9987 18.3334H14.9987C15.4407 18.3334 15.8646 18.1578 16.1772 17.8453C16.4898 17.5327 16.6654 17.1088 16.6654 16.6667V6.25008L12.082 1.66675Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Document parsing</div><p class="MobileMenu_ListItemText__n_MHY">The first and leading GenAI-native parser over your most complex data.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaextract"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.668 1.66675V5.00008C11.668 5.44211 11.8436 5.86603 12.1561 6.17859C12.4687 6.49115 12.8926 6.66675 13.3346 6.66675H16.668M3.33464 5.83341V3.33341C3.33464 2.89139 3.51023 2.46746 3.82279 2.1549C4.13535 1.84234 4.55927 1.66675 5.0013 1.66675H12.5013L16.668 5.83341V16.6667C16.668 17.1088 16.4924 17.5327 16.1798 17.8453C15.8672 18.1578 15.4433 18.3334 15.0013 18.3334L5.05379 18.3326C4.72458 18.3755 4.39006 18.3191 4.09312 18.1706C3.79618 18.0221 3.55034 17.7884 3.38713 17.4992M4.16797 9.16675L1.66797 11.6667M1.66797 11.6667L4.16797 14.1667M1.66797 11.6667H10.0013" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Data extraction</div><p class="MobileMenu_ListItemText__n_MHY">Extract structured data from documents using a schema-driven engine.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/enterprise"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.16667 15.8333C12.8486 15.8333 15.8333 12.8486 15.8333 9.16667C15.8333 5.48477 12.8486 2.5 9.16667 2.5C5.48477 2.5 2.5 5.48477 2.5 9.16667C2.5 12.8486 5.48477 15.8333 9.16667 15.8333Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M17.5 17.5L13.875 13.875" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Knowledge Management</div><p class="MobileMenu_ListItemText__n_MHY">Connect, transform, and index your enterprise data into an agent-accessible knowledge base</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/framework"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.0013 6.66659V3.33325H6.66797M1.66797 11.6666H3.33464M16.668 11.6666H18.3346M12.5013 10.8333V12.4999M7.5013 10.8333V12.4999M5.0013 6.66659H15.0013C15.9218 6.66659 16.668 7.41278 16.668 8.33325V14.9999C16.668 15.9204 15.9218 16.6666 15.0013 16.6666H5.0013C4.08083 16.6666 3.33464 15.9204 3.33464 14.9999V8.33325C3.33464 7.41278 4.08083 6.66659 5.0013 6.66659Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Agent Framework</div><p class="MobileMenu_ListItemText__n_MHY">Orchestrate and deploy multi-agent applications over your data with the #1 agent framework.</p></a></li></ul></details></li><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Solutions<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/finance"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 6.66675H8.33073C7.8887 6.66675 7.46478 6.84234 7.15222 7.1549C6.83966 7.46746 6.66406 7.89139 6.66406 8.33342C6.66406 8.77544 6.83966 9.19937 7.15222 9.51193C7.46478 9.82449 7.8887 10.0001 8.33073 10.0001H11.6641C12.1061 10.0001 12.53 10.1757 12.8426 10.4882C13.1551 10.8008 13.3307 11.2247 13.3307 11.6667C13.3307 12.1088 13.1551 12.5327 12.8426 12.8453C12.53 13.1578 12.1061 13.3334 11.6641 13.3334H6.66406M9.9974 15.0001V5.00008M18.3307 10.0001C18.3307 14.6025 14.5998 18.3334 9.9974 18.3334C5.39502 18.3334 1.66406 14.6025 1.66406 10.0001C1.66406 5.39771 5.39502 1.66675 9.9974 1.66675C14.5998 1.66675 18.3307 5.39771 18.3307 10.0001Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Financial Analysts</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/administrative-operations"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1.66406 6.66659V15.8333C1.66406 16.2753 1.83966 16.6992 2.15222 17.0118C2.46478 17.3243 2.8887 17.4999 3.33073 17.4999H14.9974M16.6641 14.1666C17.1061 14.1666 17.53 13.991 17.8426 13.6784C18.1551 13.3659 18.3307 12.9419 18.3307 12.4999V7.49992C18.3307 7.05789 18.1551 6.63397 17.8426 6.32141C17.53 6.00885 17.1061 5.83325 16.6641 5.83325H13.4141C13.1353 5.83598 12.8604 5.76876 12.6143 5.63774C12.3683 5.50671 12.159 5.31606 12.0057 5.08325L11.3307 4.08325C11.179 3.85281 10.9724 3.66365 10.7295 3.53275C10.4866 3.40185 10.215 3.3333 9.93906 3.33325H6.66406C6.22204 3.33325 5.79811 3.50885 5.48555 3.82141C5.17299 4.13397 4.9974 4.55789 4.9974 4.99992V12.4999C4.9974 12.9419 5.17299 13.3659 5.48555 13.6784C5.79811 13.991 6.22204 14.1666 6.66406 14.1666H16.6641Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Administrative Operations</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/engineering"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 15L18.3307 10L13.3307 5M6.66406 5L1.66406 10L6.66406 15" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Engineering &amp; R&amp;D</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/customer-support"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.9974 7.50008H16.6641C17.1061 7.50008 17.53 7.67568 17.8426 7.98824C18.1551 8.3008 18.3307 8.72472 18.3307 9.16675V18.3334L14.9974 15.0001H9.9974C9.55537 15.0001 9.13145 14.8245 8.81888 14.5119C8.50632 14.1994 8.33073 13.7754 8.33073 13.3334V12.5001M11.6641 7.50008C11.6641 7.94211 11.4885 8.36603 11.1759 8.67859C10.8633 8.99115 10.4394 9.16675 9.9974 9.16675H4.9974L1.66406 12.5001V3.33341C1.66406 2.41675 2.41406 1.66675 3.33073 1.66675H9.9974C10.4394 1.66675 10.8633 1.84234 11.1759 2.1549C11.4885 2.46746 11.6641 2.89139 11.6641 3.33341V7.50008Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Customer Support</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/healthcare-pharma"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M17.0128 3.81671C16.5948 3.39719 16.098 3.06433 15.551 2.8372C15.004 2.61008 14.4176 2.49316 13.8253 2.49316C13.2331 2.49316 12.6466 2.61008 12.0996 2.8372C11.5527 3.06433 11.0559 3.39719 10.6378 3.81671L9.99617 4.46671L9.3545 3.81671C8.93643 3.39719 8.43967 3.06433 7.89268 2.8372C7.3457 2.61008 6.75926 2.49316 6.167 2.49316C5.57474 2.49316 4.9883 2.61008 4.44132 2.8372C3.89433 3.06433 3.39756 3.39719 2.9795 3.81671C1.21283 5.58338 1.1045 8.56671 3.3295 10.8334L9.99617 17.5L16.6628 10.8334C18.8878 8.56671 18.7795 5.58338 17.0128 3.81671Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M2.91406 9.99992H7.91406L8.33073 9.16659L9.9974 12.9166L11.6641 7.08325L12.9141 9.99992H17.0807" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Healthcare / Pharma</div></a></li></ul></details></li><li><a class="MobileMenu_Link__5frcx" href="/community">Community</a></li><li><a class="MobileMenu_Link__5frcx" href="/pricing">Pricing</a></li><li><a class="MobileMenu_Link__5frcx" href="/blog">Blog</a></li><li><a class="MobileMenu_Link__5frcx" href="/customers">Customer stories</a></li><li><a class="MobileMenu_Link__5frcx" href="/careers">Careers</a></li></ul></nav><a href="/contact" class="Button_button-variant-ghost__o2AbG Button_button__aJ0V6" data-tracking-variant="ghost"> <!-- -->Talk to us</a><ul class="Socials_socials__8Y_s5 Socials_socials-theme-dark__Hq8lc MobileMenu_socials__JykCO"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu MobileMenu_copyright__nKVOs">© <!-- -->2025<!-- --> LlamaIndex</p></div></header><main><section class="BlogPost_post__JHNzd"><img alt="" loading="lazy" width="800" height="453.5" decoding="async" data-nimg="1" class="BlogPost_featuredImage__KGxwX" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F1c22c02db257a629b8cb2760dcef125d75f84d70-1999x907.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F1c22c02db257a629b8cb2760dcef125d75f84d70-1999x907.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F1c22c02db257a629b8cb2760dcef125d75f84d70-1999x907.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><p class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-600__fKYth BlogPost_date__6uxQw"><a class="BlogPost_author__mesdl" href="/blog/author/llamaindex">LlamaIndex</a> <!-- -->•<!-- --> <!-- -->2025-01-06</p><h1 class="Text_text__zPO0D Text_text-size-32__koGps BlogPost_title__b2lqJ">Document Research Assistant for Blog Creation with NVIDIA NIM microservices</h1><ul class="BlogPost_tags__13pBH"><li><a class="Badge_badge___1ssn" href="/blog/tag/nvidia"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Nvidia</span></a></li></ul><div class="BlogPost_htmlPost__Z5oDL"><p class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaIndex is convinced of the potential and power of LLM-powered agents built with our frameworks, so we are thrilled to have collaborated with NVIDIA on the design and release of an NVIDIA AI Blueprint for a multi-agent system that researches, writes and refines blog posts on any topic using agentic-driven RAG. You can <a href="https://blogs.nvidia.com/blog/agentic-ai-blueprints" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">read the announcement</a> or <a href="https://build.nvidia.com/llamaindex/document-research-assistant-for-blog-creation" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">check out the blueprint</a>. In this blog post, we’ll dive into the architecture of the multi-agent system defined by the blueprint, to explain what’s going on and how you can extend the system for your own purposes. You can also check out our <a href="https://www.youtube.com/watch?v=XdT76bujrXQ" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">video</a><span style="text-decoration:underline">,</span> where we go through the code of the blueprint step by step.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Overview</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The blueprint defines a few things:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">A RAG pipeline that accepts an arbitrary set of documents, and embeds and indexes them for querying</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">An agentic tool based on this pipeline that makes it possible for agents to query the RAG database</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">A LlamaIndex Workflow that accepts an arbitrary set of tools, plus a query</li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The Workflow is designed to take the query and use the tools given to it to write a blog post about that query. The way it does that is shown in the diagram below:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">First, using the query as a topic, an agent outlines what a blog post about that topic might look like</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">A second agent reads the outline and creates a set of simple questions that would provide the facts necessary to write a blog post following that outline</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">A third agent is repeatedly called to query the RAG database with the questions given, fetch relevant context, and generate answers to those questions</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">A fourth agent is given the query, the outline, and the answers, and writes a blog post given all the facts available to it</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">A fifth agent reviews the blog post against the original query and decides whether it is a comprehensive response to the question</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">If the blog post is deemed of sufficient quality, it is output to the user</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">If the blog post needs more work, the agent generates an additional set of questions to further flesh out the blog post</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">These questions and answers are added to the original set and returned to the fourth agent, which will rewrite the blog post with this additional context and try again (a maximum of 3 times)</li></ul><figure><img alt="" loading="lazy" width="197" height="398.5" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4b6f3d968ad31c154344a369bfc1c2134985fd06-394x797.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=256&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4b6f3d968ad31c154344a369bfc1c2134985fd06-394x797.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4b6f3d968ad31c154344a369bfc1c2134985fd06-394x797.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75"/></figure><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Architecture</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">This multi-agent system is designed from the ground up to use the <a href="https://developer.nvidia.com/nemo-retriever/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">NVIDIA NeMo Retriever</a> embedding and Llama3.3-70b-Instruct LLM NVIDIA NIM microservices, which can be deployed on NVIDIA GPUs in workstations, data centers, or cloud environments. In the diagram below, you can see the two distinct phases of the system: set up and querying.</p><figure><img alt="" loading="lazy" width="999.5" height="453.5" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F1c22c02db257a629b8cb2760dcef125d75f84d70-1999x907.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1080&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F1c22c02db257a629b8cb2760dcef125d75f84d70-1999x907.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=2048&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F1c22c02db257a629b8cb2760dcef125d75f84d70-1999x907.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=2048&amp;q=75"/></figure><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Getting set up</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The core of any RAG-based system is data. In the set up phase, the provided documents are parsed by LlamaParse, our world-class document parsing system, which converts complex document formats like PDFs, Word documents, PowerPoints and spreadsheets into Markdown text that LLMs find easy to understand.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The parsed documents are then ingested into a vector store. This first takes the text of the documents and converts them into vectors using the NVIDIA NeMo Retriever embedding NIM microservice, then stores them in a vector store. In the blueprint, the vectors are simply persisted to disk; in production, you would use one of the dozens of vector stores supported by LlamaIndex and available on <a href="https://llamahub.ai/?tab=vector_stores" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">LlamaHub</a> to persist and search these vectors.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">This vector store is then instantiated as a query engine, a LlamaIndex abstraction that allows you to send a query to the vector store, retrieve chunks of data semantically relevant to that query, and then pass the query and the data as context to the LLM to answer the query. The LLM used in this case is Llama 3.3-70b from Meta, and is also available as an NVIDIA NIM microservice.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">By using AI models packaged as NIM microservices, the system can achieve greater model performance and efficiency.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">NIM microservices use pre-optimized inference engines like <a href="https://developer.nvidia.com/tensorrt" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">NVIDIA TensorRT</a> and <a href="https://docs.nvidia.com/tensorrt-llm/index.html" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">NVIDIA TensorRT-LLM</a>, which are specifically tailored for low-latency, high-throughput inferencing on NVIDIA GPU systems.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">NIM microservices help improve throughput. For example, running Meta Llama 3-8B as a NIM microservice produces up to 3x more generative AI tokens on accelerated infrastructure compared to deployment without.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">This query engine is then further wrapped into a QueryEngineTool, an abstraction that allows agents built in LlamaIndex to query the RAG database and retrieve answers.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">The query phase</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">In the query phase, the user passes an array of tools to the Workflow, along with their query. In the blueprint, we are passing only one tool, the query engine we created above. In production, you could pass multiple RAG databases, as well as tools that let you search the wider web for context.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The multi-agent Workflow then unfolds as described earlier:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">An outline is written</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Questions are formulated to satisfy the outline</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">The questions are answered</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">A blog post is written from the outline and the questions</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">The blog post is critiqued for accuracy and thoroughness</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">If it’s adequate it is output</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">If it’s not, additional questions are generated and the process repeats</li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">At each step, the agents are using an LLM NIM microservice. In the blueprint, they are all using the same Llama 3.3 model from Meta, but you could provide a different LLM for every phase, balancing quality with speed, or even fine-tuning a model to specialize at each task.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Enhancing and customizing your blueprint</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">As mentioned earlier, this blueprint is a jumping-off point for you to create your own multi-agent system. You will certainly want to substitute a production-ready vector store for the on-disk version in the blueprint, and you may want to use a variety of different models rather than Llama 3.3-70b for every task.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Other enhancements are possible at the cost of increasing the complexity and time the system takes. The current prompts limit the number of questions originally generated to 8, and the number of follow-up questions to 4. Increasing these limits could potentially improve the quality of the output at some cost in speed.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Another potential improvement is to take the reflection phase back to the outline step: given the facts the agent now knows about the topic, does the outline still make sense, or should it be refactored? You could get the LLM to generate a new outline and attempt to rewrite the blog post based on what it learned in the research phase.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Get started today!</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The full code for the blueprint is available in the <a href="https://docs.llamaindex.ai/en/stable/examples/agent/nvidia_document_research_assistant_for_blog_creation/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">examples section of our documentation</a>. We’re eager to see what use-cases you find for our agentic research system, and what extensions and enhancements you add. Get started with <a href="https://build.nvidia.com/llamaindex/document-research-assistant-for-blog-creation" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">the blueprint on NVIDIA today</a>!</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><br/></p></div><div class="BlogPost_relatedPosts__0z6SN"><h2 class="Text_text__zPO0D Text_text-align-center__HhKqo Text_text-size-16__PkjFu Text_text-weight-400__5ENkK Text_text-family-spaceGrotesk__E4zcE BlogPost_relatedPostsTitle___JIrW">Related articles</h2><ul class="BlogPost_relatedPostsList__uOKzB"><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F51fb30b463a1a40b47d8912225d1fb1f4ea2a56b-1800x980.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F51fb30b463a1a40b47d8912225d1fb1f4ea2a56b-1800x980.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F51fb30b463a1a40b47d8912225d1fb1f4ea2a56b-1800x980.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/llamaindex-accelerates-enterprise-generative-ai-with-nvidia-nim">LlamaIndex Accelerates Enterprise Generative AI with NVIDIA NIM</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-03-18</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9ae77136d1597f079f0204d1dd8fcfee72b50617-1200x440.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9ae77136d1597f079f0204d1dd8fcfee72b50617-1200x440.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9ae77136d1597f079f0204d1dd8fcfee72b50617-1200x440.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/nvidia-research-rag-with-long-context-llms-7d94d40090c4">NVIDIA Research: RAG with Long Context LLMs</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2023-10-22</p></div></li></ul></div></section></main><footer class="Footer_footer__eNA9m"><div class="Footer_navContainer__7bvx4"><div class="Footer_logoContainer__3EpzI"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" style="color:transparent" src="/llamaindex.svg"/><div class="Footer_socialContainer__GdOgk"><ul class="Socials_socials__8Y_s5"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul></div></div><div class="Footer_nav__BLEuE"><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/">LlamaIndex</a></h3><ul><li><a href="/blog"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Blog</span></a></li><li><a href="/partners"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Partners</span></a></li><li><a href="/careers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Careers</span></a></li><li><a href="/contact"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Contact</span></a></li><li><a href="/brand"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Brand</span></a></li><li><a href="https://llamaindex.statuspage.io" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Status</span></a></li><li><a href="https://app.vanta.com/runllama.ai/trust/pkcgbjf8b3ihxjpqdx17nu" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Trust Center</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/enterprise">Enterprise</a></h3><ul><li><a href="https://cloud.llamaindex.ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaCloud</span></a></li><li><a href="https://cloud.llamaindex.ai/parse" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaParse</span></a></li><li><a href="/customers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Customers</span></a></li><li><a href="/llamacloud-sharepoint-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SharePoint</span></a></li><li><a href="/llamacloud-aws-s3-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">AWS S3</span></a></li><li><a href="/llamacloud-azure-blob-storage-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure Blob Storage</span></a></li><li><a href="/llamacloud-google-drive-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Google Drive</span></a></li> </ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/framework">Framework</a></h3><ul><li><a href="https://pypi.org/project/llama-index/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python package</span></a></li><li><a href="https://docs.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python docs</span></a></li><li><a href="https://www.npmjs.com/package/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript package</span></a></li><li><a href="https://ts.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript docs</span></a></li><li><a href="https://llamahub.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaHub</span></a></li><li><a href="https://github.com/run-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">GitHub</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/community">Community</a></h3><ul><li><a href="/community#newsletter"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Newsletter</span></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Discord</span></a></li><li><a href="https://www.linkedin.com/company/91154103/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LinkedIn</span></a></li><li><a href="https://twitter.com/llama_index"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Twitter/X</span></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">YouTube</span></a></li><li><a href="https://bsky.app/profile/llamaindex.bsky.social"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">BlueSky</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e">Starter projects</h3><ul><li><a href="https://www.npmjs.com/package/create-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">create-llama</span></a></li><li><a href="https://secinsights.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SEC Insights</span></a></li><li><a href="https://github.com/run-llama/llamabot"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaBot</span></a></li><li><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/rag_cli.html"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">RAG CLI</span></a></li></ul></div></div></div><div class="Footer_copyrightContainer__mBKsT"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA">© <!-- -->2025<!-- --> LlamaIndex</p><div class="Footer_legalNav__O1yJA"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/privacy-notice.pdf">Privacy Notice</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/terms-of-service.pdf">Terms of Service</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="https://bit.ly/llamaindexdpa">Data Processing Addendum</a></p></div></div></footer></div><svg xmlns="http://www.w3.org/2000/svg" class="flt_svg" style="display:none"><defs><filter id="flt_tag"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="2"></feGaussianBlur><feColorMatrix in="blur" result="flt_tag" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="flt_tag" operator="atop"></feComposite></filter><filter id="svg_blur_large"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="8"></feGaussianBlur><feColorMatrix in="blur" result="svg_blur_large" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="svg_blur_large" operator="atop"></feComposite></filter></defs></svg></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"page":{"announcement":{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"},"post":{"_createdAt":"2024-12-20T17:24:01Z","_id":"0e7003c3-87ca-467d-b9a6-020ca8c84e17","_rev":"05dtDS0H5iRVsxYMarYyhy","_type":"blogPost","_updatedAt":"2025-05-21T20:36:30Z","announcement":[{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"}],"authors":[{"_createdAt":"2024-02-20T20:23:12Z","_id":"363ec4e9-0b8f-48d2-ba6a-567a9c527c3d","_rev":"rGZ2nN6K5mjOGJOoWaUhNb","_type":"people","_updatedAt":"2024-02-25T00:45:24Z","image":{"_type":"image","asset":{"_ref":"image-89523511cf20d73e3f10077add50128d077ed520-176x176-png","_type":"reference"}},"name":"LlamaIndex","slug":{"_type":"slug","current":"llamaindex"}}],"featured":false,"image":{"_type":"image","asset":{"_ref":"image-1c22c02db257a629b8cb2760dcef125d75f84d70-1999x907-png","_type":"reference"}},"mainImage":"https://cdn.sanity.io/images/7m9jw85w/production/1c22c02db257a629b8cb2760dcef125d75f84d70-1999x907.png","publishedDate":"2025-01-06","relatedPosts":[{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-51fb30b463a1a40b47d8912225d1fb1f4ea2a56b-1800x980-png","_type":"reference"}},"publishedDate":"2024-03-18","slug":"llamaindex-accelerates-enterprise-generative-ai-with-nvidia-nim","title":"LlamaIndex Accelerates Enterprise Generative AI with NVIDIA NIM"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-9ae77136d1597f079f0204d1dd8fcfee72b50617-1200x440-png","_type":"reference"}},"publishedDate":"2023-10-22","slug":"nvidia-research-rag-with-long-context-llms-7d94d40090c4","title":"NVIDIA Research: RAG with Long Context LLMs"}],"slug":{"_type":"slug","current":"document-research-assistant-for-blog-creation-with-nvidia-nim-microservices"},"tags":[{"_createdAt":"2024-02-22T20:19:13Z","_id":"797591a5-af8b-4649-917f-60d51184b237","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:13Z","slug":{"_type":"slug","current":"nvidia"},"title":"Nvidia"}],"text":[{"_key":"9792de290102","_type":"block","children":[{"_key":"1cfd8379efc50","_type":"span","marks":[],"text":"LlamaIndex is convinced of the potential and power of LLM-powered agents built with our frameworks, so we are thrilled to have collaborated with NVIDIA on the design and release of an NVIDIA AI Blueprint for a multi-agent system that researches, writes and refines blog posts on any topic using agentic-driven RAG. You can "},{"_key":"1cfd8379efc51","_type":"span","marks":["4726eb11a0d2"],"text":"read the announcement"},{"_key":"1cfd8379efc52","_type":"span","marks":[],"text":" or "},{"_key":"1cfd8379efc53","_type":"span","marks":["079a37e2c659"],"text":"check out the blueprint"},{"_key":"1cfd8379efc54","_type":"span","marks":[],"text":". In this blog post, we’ll dive into the architecture of the multi-agent system defined by the blueprint, to explain what’s going on and how you can extend the system for your own purposes. You can also check out our "},{"_key":"1cfd8379efc55","_type":"span","marks":["978cae6bf1f5"],"text":"video"},{"_key":"1cfd8379efc56","_type":"span","marks":["underline"],"text":","},{"_key":"1cfd8379efc57","_type":"span","marks":[],"text":" where we go through the code of the blueprint step by step."}],"markDefs":[{"_key":"4726eb11a0d2","_type":"link","href":"https://blogs.nvidia.com/blog/agentic-ai-blueprints"},{"_key":"079a37e2c659","_type":"link","href":"https://build.nvidia.com/llamaindex/document-research-assistant-for-blog-creation"},{"_key":"978cae6bf1f5","_type":"link","href":"https://www.youtube.com/watch?v=XdT76bujrXQ"}],"style":"normal"},{"_key":"7084967190f8","_type":"block","children":[{"_key":"8b81e01133880","_type":"span","marks":[],"text":"Overview"}],"markDefs":[],"style":"h2"},{"_key":"e64a737f7e57","_type":"block","children":[{"_key":"a8cf33c848ec0","_type":"span","marks":[],"text":"The blueprint defines a few things:"}],"markDefs":[],"style":"normal"},{"_key":"bf8feaea4acd","_type":"block","children":[{"_key":"8cdc59e739160","_type":"span","marks":[],"text":"A RAG pipeline that accepts an arbitrary set of documents, and embeds and indexes them for querying"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"3a22472c6263","_type":"block","children":[{"_key":"af8bfe5369e80","_type":"span","marks":[],"text":"An agentic tool based on this pipeline that makes it possible for agents to query the RAG database"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"5b0580a2413c","_type":"block","children":[{"_key":"2a871263c5a90","_type":"span","marks":[],"text":"A LlamaIndex Workflow that accepts an arbitrary set of tools, plus a query"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"289f115b49f3","_type":"block","children":[{"_key":"3022c304a2a70","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"414b3cac99fb","_type":"block","children":[{"_key":"1706bec43f1c0","_type":"span","marks":[],"text":"The Workflow is designed to take the query and use the tools given to it to write a blog post about that query. The way it does that is shown in the diagram below:"}],"markDefs":[],"style":"normal"},{"_key":"b1f7146f4bd6","_type":"block","children":[{"_key":"1e5ac76a91ee0","_type":"span","marks":[],"text":"First, using the query as a topic, an agent outlines what a blog post about that topic might look like"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"123bfaaa52d9","_type":"block","children":[{"_key":"2bcb62bdbc360","_type":"span","marks":[],"text":"A second agent reads the outline and creates a set of simple questions that would provide the facts necessary to write a blog post following that outline"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"39efc62e9592","_type":"block","children":[{"_key":"58fe1f98eb1f0","_type":"span","marks":[],"text":"A third agent is repeatedly called to query the RAG database with the questions given, fetch relevant context, and generate answers to those questions"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"6ded273a6525","_type":"block","children":[{"_key":"7df5784e419c0","_type":"span","marks":[],"text":"A fourth agent is given the query, the outline, and the answers, and writes a blog post given all the facts available to it"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"a823d4680b4f","_type":"block","children":[{"_key":"4c7d5ea2e4eb0","_type":"span","marks":[],"text":"A fifth agent reviews the blog post against the original query and decides whether it is a comprehensive response to the question"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"d11ba4e8c5a5","_type":"block","children":[{"_key":"71d70a2d7add0","_type":"span","marks":[],"text":"If the blog post is deemed of sufficient quality, it is output to the user"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"c456263db753","_type":"block","children":[{"_key":"74ed56ca831d0","_type":"span","marks":[],"text":"If the blog post needs more work, the agent generates an additional set of questions to further flesh out the blog post"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"c8254f663176","_type":"block","children":[{"_key":"2cef4152de8c0","_type":"span","marks":[],"text":"These questions and answers are added to the original set and returned to the fourth agent, which will rewrite the blog post with this additional context and try again (a maximum of 3 times)"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"a7bda53e2498","_type":"image","asset":{"_ref":"image-4b6f3d968ad31c154344a369bfc1c2134985fd06-394x797-png","_type":"reference"}},{"_key":"47b2197fc5fc","_type":"block","children":[{"_key":"a4620406112a0","_type":"span","marks":[],"text":"Architecture"}],"markDefs":[],"style":"h2"},{"_key":"283921971a7e","_type":"block","children":[{"_key":"519acffd1f150","_type":"span","marks":[],"text":"This multi-agent system is designed from the ground up to use the "},{"_key":"519acffd1f151","_type":"span","marks":["8bf752e3d5a6"],"text":"NVIDIA NeMo Retriever"},{"_key":"519acffd1f152","_type":"span","marks":[],"text":" embedding and Llama3.3-70b-Instruct LLM NVIDIA NIM microservices, which can be deployed on NVIDIA GPUs in workstations, data centers, or cloud environments. In the diagram below, you can see the two distinct phases of the system: set up and querying."}],"markDefs":[{"_key":"8bf752e3d5a6","_type":"link","href":"https://developer.nvidia.com/nemo-retriever/"}],"style":"normal"},{"_key":"3c8c75d24033","_type":"image","asset":{"_ref":"image-1c22c02db257a629b8cb2760dcef125d75f84d70-1999x907-png","_type":"reference"}},{"_key":"3a6b361a562d","_type":"block","children":[{"_key":"55d316d428950","_type":"span","marks":[],"text":"Getting set up"}],"markDefs":[],"style":"h2"},{"_key":"a03a75c8b4b5","_type":"block","children":[{"_key":"f492ce59cbec0","_type":"span","marks":[],"text":"The core of any RAG-based system is data. In the set up phase, the provided documents are parsed by LlamaParse, our world-class document parsing system, which converts complex document formats like PDFs, Word documents, PowerPoints and spreadsheets into Markdown text that LLMs find easy to understand."}],"markDefs":[],"style":"normal"},{"_key":"61af63dda1e9","_type":"block","children":[{"_key":"2a0a6a2b63bf0","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"20319413f724","_type":"block","children":[{"_key":"f16248aa0d6b0","_type":"span","marks":[],"text":"The parsed documents are then ingested into a vector store. This first takes the text of the documents and converts them into vectors using the NVIDIA NeMo Retriever embedding NIM microservice, then stores them in a vector store. In the blueprint, the vectors are simply persisted to disk; in production, you would use one of the dozens of vector stores supported by LlamaIndex and available on "},{"_key":"f16248aa0d6b1","_type":"span","marks":["8bbc2e4455d3"],"text":"LlamaHub"},{"_key":"f16248aa0d6b2","_type":"span","marks":[],"text":" to persist and search these vectors."}],"markDefs":[{"_key":"8bbc2e4455d3","_type":"link","href":"https://llamahub.ai/?tab=vector_stores"}],"style":"normal"},{"_key":"fc87efe10a5e","_type":"block","children":[{"_key":"2d887cb504e40","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"7362f64db5ec","_type":"block","children":[{"_key":"7edf36ad6d6b0","_type":"span","marks":[],"text":"This vector store is then instantiated as a query engine, a LlamaIndex abstraction that allows you to send a query to the vector store, retrieve chunks of data semantically relevant to that query, and then pass the query and the data as context to the LLM to answer the query. The LLM used in this case is Llama 3.3-70b from Meta, and is also available as an NVIDIA NIM microservice."}],"markDefs":[],"style":"normal"},{"_key":"77281f6cc7a2","_type":"block","children":[{"_key":"d3acb7db6ed40","_type":"span","marks":[],"text":"By using AI models packaged as NIM microservices, the system can achieve greater model performance and efficiency."}],"markDefs":[],"style":"normal"},{"_key":"74e6bc701096","_type":"block","children":[{"_key":"bb9c28d889350","_type":"span","marks":[],"text":"NIM microservices use pre-optimized inference engines like "},{"_key":"bb9c28d889351","_type":"span","marks":["2721c79bb72d"],"text":"NVIDIA TensorRT"},{"_key":"bb9c28d889352","_type":"span","marks":[],"text":" and "},{"_key":"bb9c28d889353","_type":"span","marks":["7e076aedbe5d"],"text":"NVIDIA TensorRT-LLM"},{"_key":"bb9c28d889354","_type":"span","marks":[],"text":", which are specifically tailored for low-latency, high-throughput inferencing on NVIDIA GPU systems."}],"markDefs":[{"_key":"2721c79bb72d","_type":"link","href":"https://developer.nvidia.com/tensorrt"},{"_key":"7e076aedbe5d","_type":"link","href":"https://docs.nvidia.com/tensorrt-llm/index.html"}],"style":"normal"},{"_key":"bd5239df72d7","_type":"block","children":[{"_key":"d6a924ee76890","_type":"span","marks":[],"text":"NIM microservices help improve throughput. For example, running Meta Llama 3-8B as a NIM microservice produces up to 3x more generative AI tokens on accelerated infrastructure compared to deployment without."}],"markDefs":[],"style":"normal"},{"_key":"4b455d8c9992","_type":"block","children":[{"_key":"787123f8ab350","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"dc86743f5c46","_type":"block","children":[{"_key":"fc7d11f33a590","_type":"span","marks":[],"text":"This query engine is then further wrapped into a QueryEngineTool, an abstraction that allows agents built in LlamaIndex to query the RAG database and retrieve answers."}],"markDefs":[],"style":"normal"},{"_key":"14d0f2ace76d","_type":"block","children":[{"_key":"40bcb3b5156b0","_type":"span","marks":[],"text":"The query phase"}],"markDefs":[],"style":"h2"},{"_key":"1573cc8f9c4a","_type":"block","children":[{"_key":"7a7834fa54d70","_type":"span","marks":[],"text":"In the query phase, the user passes an array of tools to the Workflow, along with their query. In the blueprint, we are passing only one tool, the query engine we created above. In production, you could pass multiple RAG databases, as well as tools that let you search the wider web for context."}],"markDefs":[],"style":"normal"},{"_key":"f3ff29a0611b","_type":"block","children":[{"_key":"22a31ff60d300","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"3b59c9e699cc","_type":"block","children":[{"_key":"08fd069a27310","_type":"span","marks":[],"text":"The multi-agent Workflow then unfolds as described earlier:"}],"markDefs":[],"style":"normal"},{"_key":"c541f0ce9350","_type":"block","children":[{"_key":"4e6332422eef0","_type":"span","marks":[],"text":"An outline is written"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"17888f39920e","_type":"block","children":[{"_key":"8f4209de7ccd0","_type":"span","marks":[],"text":"Questions are formulated to satisfy the outline"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"1b61492e0e13","_type":"block","children":[{"_key":"629e141bd64a0","_type":"span","marks":[],"text":"The questions are answered"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"67b62da3ab30","_type":"block","children":[{"_key":"6b83c3859d910","_type":"span","marks":[],"text":"A blog post is written from the outline and the questions"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"b9a74fa183de","_type":"block","children":[{"_key":"95c4dde7060b0","_type":"span","marks":[],"text":"The blog post is critiqued for accuracy and thoroughness"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"9c183c4eadfb","_type":"block","children":[{"_key":"d26d163f283c0","_type":"span","marks":[],"text":"If it’s adequate it is output"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"73458114e133","_type":"block","children":[{"_key":"a3f359b254320","_type":"span","marks":[],"text":"If it’s not, additional questions are generated and the process repeats"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"c92ed68dcd3d","_type":"block","children":[{"_key":"d8e57b2635470","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"f5493ccf72f6","_type":"block","children":[{"_key":"f24d8e7a33fd0","_type":"span","marks":[],"text":"At each step, the agents are using an LLM NIM microservice. In the blueprint, they are all using the same Llama 3.3 model from Meta, but you could provide a different LLM for every phase, balancing quality with speed, or even fine-tuning a model to specialize at each task."}],"markDefs":[],"style":"normal"},{"_key":"2d9cc4cc983a","_type":"block","children":[{"_key":"d10082bcfec70","_type":"span","marks":[],"text":"Enhancing and customizing your blueprint"}],"markDefs":[],"style":"h2"},{"_key":"37cd0f69f305","_type":"block","children":[{"_key":"e8759bc0c91e0","_type":"span","marks":[],"text":"As mentioned earlier, this blueprint is a jumping-off point for you to create your own multi-agent system. You will certainly want to substitute a production-ready vector store for the on-disk version in the blueprint, and you may want to use a variety of different models rather than Llama 3.3-70b for every task."}],"markDefs":[],"style":"normal"},{"_key":"db80a5b786d3","_type":"block","children":[{"_key":"bc60f56aaaf20","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"5ea08d8cf614","_type":"block","children":[{"_key":"4e832d997a0a0","_type":"span","marks":[],"text":"Other enhancements are possible at the cost of increasing the complexity and time the system takes. The current prompts limit the number of questions originally generated to 8, and the number of follow-up questions to 4. Increasing these limits could potentially improve the quality of the output at some cost in speed."}],"markDefs":[],"style":"normal"},{"_key":"7456bed8d9c8","_type":"block","children":[{"_key":"9203490d77910","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"ff42a7087b73","_type":"block","children":[{"_key":"2ac983fe98fa0","_type":"span","marks":[],"text":"Another potential improvement is to take the reflection phase back to the outline step: given the facts the agent now knows about the topic, does the outline still make sense, or should it be refactored? You could get the LLM to generate a new outline and attempt to rewrite the blog post based on what it learned in the research phase."}],"markDefs":[],"style":"normal"},{"_key":"b84c53602491","_type":"block","children":[{"_key":"9faf0703f3bb0","_type":"span","marks":[],"text":"Get started today!"}],"markDefs":[],"style":"h2"},{"_key":"da69fd40f5df","_type":"block","children":[{"_key":"f5156efdac6b0","_type":"span","marks":[],"text":"The full code for the blueprint is available in the "},{"_key":"f5156efdac6b1","_type":"span","marks":["87ff7c504aa9"],"text":"examples section of our documentation"},{"_key":"f5156efdac6b2","_type":"span","marks":[],"text":". We’re eager to see what use-cases you find for our agentic research system, and what extensions and enhancements you add. Get started with "},{"_key":"f5156efdac6b3","_type":"span","marks":["cc2721e41d6e"],"text":"the blueprint on NVIDIA today"},{"_key":"f5156efdac6b4","_type":"span","marks":[],"text":"!"}],"markDefs":[{"_key":"87ff7c504aa9","_type":"link","href":"https://docs.llamaindex.ai/en/stable/examples/agent/nvidia_document_research_assistant_for_blog_creation/"},{"_key":"cc2721e41d6e","_type":"link","href":"https://build.nvidia.com/llamaindex/document-research-assistant-for-blog-creation"}],"style":"normal"},{"_key":"bb1491fd1ae1","_type":"block","children":[{"_key":"9e0363e9f4770","_type":"span","marks":[],"text":"\n"}],"markDefs":[],"style":"normal"}],"title":"Document Research Assistant for Blog Creation with NVIDIA NIM microservices"},"publishedDate":"Invalid Date"},"params":{"slug":"document-research-assistant-for-blog-creation-with-nvidia-nim-microservices"},"draftMode":false,"token":""},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"document-research-assistant-for-blog-creation-with-nvidia-nim-microservices"},"buildId":"C8J-EMc_4OCN1ch65l4fl","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>