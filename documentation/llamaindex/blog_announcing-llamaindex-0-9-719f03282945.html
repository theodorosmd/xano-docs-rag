<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>Announcing LlamaIndex 0.9 — LlamaIndex - Build Knowledge Assistants over your Enterprise Data</title><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><meta name="title" content="Announcing LlamaIndex 0.9 — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta name="description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:title" content="Announcing LlamaIndex 0.9 — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="og:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:image" content="https://cdn.sanity.io/images/7m9jw85w/production/eba569ed6e28e7dd438946ce2c1f45cb44d9ed14-1024x1024.png"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="Announcing LlamaIndex 0.9 — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="twitter:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="twitter:image" content="https://cdn.sanity.io/images/7m9jw85w/production/eba569ed6e28e7dd438946ce2c1f45cb44d9ed14-1024x1024.png"/><link rel="alternate" type="application/rss+xml" href="https://www.llamaindex.ai/blog/feed"/><meta name="next-head-count" content="20"/><script>
            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WWRFB36R');
            </script><link rel="preload" href="/_next/static/css/41c9222e47d080c9.css" as="style"/><link rel="stylesheet" href="/_next/static/css/41c9222e47d080c9.css" data-n-g=""/><link rel="preload" href="/_next/static/css/97c33c8d95f1230e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/97c33c8d95f1230e.css" data-n-p=""/><link rel="preload" href="/_next/static/css/e009059e80bf60c5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e009059e80bf60c5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-1b629d9c8fb16f34.js" defer=""></script><script src="/_next/static/chunks/framework-df1f68dff096b68a.js" defer=""></script><script src="/_next/static/chunks/main-eca7952a704663f8.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c7c49437be49d2ad.js" defer=""></script><script src="/_next/static/chunks/d9067523-4985945b21298365.js" defer=""></script><script src="/_next/static/chunks/41155975-60c12da9ce9fa0b2.js" defer=""></script><script src="/_next/static/chunks/cb355538-cee2ea45674d9de3.js" defer=""></script><script src="/_next/static/chunks/9494-dff62cb53535dd7d.js" defer=""></script><script src="/_next/static/chunks/4063-39a391a51171ff87.js" defer=""></script><script src="/_next/static/chunks/6889-edfa85b69b88a372.js" defer=""></script><script src="/_next/static/chunks/5575-11ee0a29eaffae61.js" defer=""></script><script src="/_next/static/chunks/3444-95c636af25a42734.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-82c8e764e69afd2c.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_buildManifest.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_ssgManifest.js" defer=""></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WWRFB36R" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div class="__variable_d65c78 __variable_b1ea77 __variable_eb7534"><a class="Announcement_announcement__2ohK8" href="http://48755185.hs-sites.com/llamaindex-0">Meet LlamaIndex at the Databricks Data + AI Summit!<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M8.293 5.293a1 1 0 0 1 1.414 0l6 6a1 1 0 0 1 0 1.414l-6 6a1 1 0 0 1-1.414-1.414L13.586 12 8.293 6.707a1 1 0 0 1 0-1.414Z" clip-rule="evenodd"></path></svg></a><header class="Header_header__hO3lJ"><button class="Hamburger_hamburger__17auO Header_hamburger__lUulX"><svg width="28" height="28" viewBox="0 0 28 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.5 14H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" id="hamburger-stroke-top" class="Hamburger_hamburgerStrokeMiddle__I7VpD"></path><path d="M3.5 7H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeTop__oOhFM"></path><path d="M3.5 21H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeBottom__GIQR2"></path></svg></button><a aria-label="Homepage" href="/"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" class="Header_logo__e5KhT" style="color:transparent" src="/llamaindex.svg"/></a><nav aria-label="Main" data-orientation="horizontal" dir="ltr" style="--content-position:0px"><div style="position:relative"><ul data-orientation="horizontal" class="Nav_MenuList__PrCDJ" dir="ltr"><li><button id="radix-:R6tm:-trigger-radix-:R5mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R5mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Products</button></li><li><button id="radix-:R6tm:-trigger-radix-:R9mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R9mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Solutions</button></li><li><a class="Nav_Link__ZrzFc" href="/community" data-radix-collection-item="">Community</a></li><li><a class="Nav_Link__ZrzFc" href="/pricing" data-radix-collection-item="">Pricing</a></li><li><a class="Nav_Link__ZrzFc" href="/blog" data-radix-collection-item="">Blog</a></li><li><a class="Nav_Link__ZrzFc" href="/customers" data-radix-collection-item="">Customer stories</a></li><li><a class="Nav_Link__ZrzFc" href="/careers" data-radix-collection-item="">Careers</a></li></ul></div><div class="Nav_ViewportPosition__jmyHM"></div></nav><div class="Header_secondNav__YJvm8"><nav><a href="/contact" class="Link_link__71cl8 Link_link-variant-tertiary__BYxn_ Header_bookADemo__qCuxV">Book a demo</a></nav><a href="https://cloud.llamaindex.ai/" class="Button_button-variant-default__Oi__n Button_button__aJ0V6 Header_button__1HFhY" data-tracking-variant="default"> <!-- -->Get started</a></div><div class="MobileMenu_mobileMenu__g5Fa6"><nav class="MobileMenu_nav__EmtTw"><ul><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Products<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaparse"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.6654 1.66675V6.66675H16.6654M8.33203 10.8334L6.66536 12.5001L8.33203 14.1667M11.6654 14.1667L13.332 12.5001L11.6654 10.8334M12.082 1.66675H4.9987C4.55667 1.66675 4.13275 1.84234 3.82019 2.1549C3.50763 2.46746 3.33203 2.89139 3.33203 3.33341V16.6667C3.33203 17.1088 3.50763 17.5327 3.82019 17.8453C4.13275 18.1578 4.55667 18.3334 4.9987 18.3334H14.9987C15.4407 18.3334 15.8646 18.1578 16.1772 17.8453C16.4898 17.5327 16.6654 17.1088 16.6654 16.6667V6.25008L12.082 1.66675Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Document parsing</div><p class="MobileMenu_ListItemText__n_MHY">The first and leading GenAI-native parser over your most complex data.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaextract"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.668 1.66675V5.00008C11.668 5.44211 11.8436 5.86603 12.1561 6.17859C12.4687 6.49115 12.8926 6.66675 13.3346 6.66675H16.668M3.33464 5.83341V3.33341C3.33464 2.89139 3.51023 2.46746 3.82279 2.1549C4.13535 1.84234 4.55927 1.66675 5.0013 1.66675H12.5013L16.668 5.83341V16.6667C16.668 17.1088 16.4924 17.5327 16.1798 17.8453C15.8672 18.1578 15.4433 18.3334 15.0013 18.3334L5.05379 18.3326C4.72458 18.3755 4.39006 18.3191 4.09312 18.1706C3.79618 18.0221 3.55034 17.7884 3.38713 17.4992M4.16797 9.16675L1.66797 11.6667M1.66797 11.6667L4.16797 14.1667M1.66797 11.6667H10.0013" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Data extraction</div><p class="MobileMenu_ListItemText__n_MHY">Extract structured data from documents using a schema-driven engine.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/enterprise"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.16667 15.8333C12.8486 15.8333 15.8333 12.8486 15.8333 9.16667C15.8333 5.48477 12.8486 2.5 9.16667 2.5C5.48477 2.5 2.5 5.48477 2.5 9.16667C2.5 12.8486 5.48477 15.8333 9.16667 15.8333Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M17.5 17.5L13.875 13.875" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Knowledge Management</div><p class="MobileMenu_ListItemText__n_MHY">Connect, transform, and index your enterprise data into an agent-accessible knowledge base</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/framework"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.0013 6.66659V3.33325H6.66797M1.66797 11.6666H3.33464M16.668 11.6666H18.3346M12.5013 10.8333V12.4999M7.5013 10.8333V12.4999M5.0013 6.66659H15.0013C15.9218 6.66659 16.668 7.41278 16.668 8.33325V14.9999C16.668 15.9204 15.9218 16.6666 15.0013 16.6666H5.0013C4.08083 16.6666 3.33464 15.9204 3.33464 14.9999V8.33325C3.33464 7.41278 4.08083 6.66659 5.0013 6.66659Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Agent Framework</div><p class="MobileMenu_ListItemText__n_MHY">Orchestrate and deploy multi-agent applications over your data with the #1 agent framework.</p></a></li></ul></details></li><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Solutions<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/finance"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 6.66675H8.33073C7.8887 6.66675 7.46478 6.84234 7.15222 7.1549C6.83966 7.46746 6.66406 7.89139 6.66406 8.33342C6.66406 8.77544 6.83966 9.19937 7.15222 9.51193C7.46478 9.82449 7.8887 10.0001 8.33073 10.0001H11.6641C12.1061 10.0001 12.53 10.1757 12.8426 10.4882C13.1551 10.8008 13.3307 11.2247 13.3307 11.6667C13.3307 12.1088 13.1551 12.5327 12.8426 12.8453C12.53 13.1578 12.1061 13.3334 11.6641 13.3334H6.66406M9.9974 15.0001V5.00008M18.3307 10.0001C18.3307 14.6025 14.5998 18.3334 9.9974 18.3334C5.39502 18.3334 1.66406 14.6025 1.66406 10.0001C1.66406 5.39771 5.39502 1.66675 9.9974 1.66675C14.5998 1.66675 18.3307 5.39771 18.3307 10.0001Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Financial Analysts</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/administrative-operations"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1.66406 6.66659V15.8333C1.66406 16.2753 1.83966 16.6992 2.15222 17.0118C2.46478 17.3243 2.8887 17.4999 3.33073 17.4999H14.9974M16.6641 14.1666C17.1061 14.1666 17.53 13.991 17.8426 13.6784C18.1551 13.3659 18.3307 12.9419 18.3307 12.4999V7.49992C18.3307 7.05789 18.1551 6.63397 17.8426 6.32141C17.53 6.00885 17.1061 5.83325 16.6641 5.83325H13.4141C13.1353 5.83598 12.8604 5.76876 12.6143 5.63774C12.3683 5.50671 12.159 5.31606 12.0057 5.08325L11.3307 4.08325C11.179 3.85281 10.9724 3.66365 10.7295 3.53275C10.4866 3.40185 10.215 3.3333 9.93906 3.33325H6.66406C6.22204 3.33325 5.79811 3.50885 5.48555 3.82141C5.17299 4.13397 4.9974 4.55789 4.9974 4.99992V12.4999C4.9974 12.9419 5.17299 13.3659 5.48555 13.6784C5.79811 13.991 6.22204 14.1666 6.66406 14.1666H16.6641Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Administrative Operations</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/engineering"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 15L18.3307 10L13.3307 5M6.66406 5L1.66406 10L6.66406 15" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Engineering &amp; R&amp;D</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/customer-support"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.9974 7.50008H16.6641C17.1061 7.50008 17.53 7.67568 17.8426 7.98824C18.1551 8.3008 18.3307 8.72472 18.3307 9.16675V18.3334L14.9974 15.0001H9.9974C9.55537 15.0001 9.13145 14.8245 8.81888 14.5119C8.50632 14.1994 8.33073 13.7754 8.33073 13.3334V12.5001M11.6641 7.50008C11.6641 7.94211 11.4885 8.36603 11.1759 8.67859C10.8633 8.99115 10.4394 9.16675 9.9974 9.16675H4.9974L1.66406 12.5001V3.33341C1.66406 2.41675 2.41406 1.66675 3.33073 1.66675H9.9974C10.4394 1.66675 10.8633 1.84234 11.1759 2.1549C11.4885 2.46746 11.6641 2.89139 11.6641 3.33341V7.50008Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Customer Support</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/healthcare-pharma"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M17.0128 3.81671C16.5948 3.39719 16.098 3.06433 15.551 2.8372C15.004 2.61008 14.4176 2.49316 13.8253 2.49316C13.2331 2.49316 12.6466 2.61008 12.0996 2.8372C11.5527 3.06433 11.0559 3.39719 10.6378 3.81671L9.99617 4.46671L9.3545 3.81671C8.93643 3.39719 8.43967 3.06433 7.89268 2.8372C7.3457 2.61008 6.75926 2.49316 6.167 2.49316C5.57474 2.49316 4.9883 2.61008 4.44132 2.8372C3.89433 3.06433 3.39756 3.39719 2.9795 3.81671C1.21283 5.58338 1.1045 8.56671 3.3295 10.8334L9.99617 17.5L16.6628 10.8334C18.8878 8.56671 18.7795 5.58338 17.0128 3.81671Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M2.91406 9.99992H7.91406L8.33073 9.16659L9.9974 12.9166L11.6641 7.08325L12.9141 9.99992H17.0807" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Healthcare / Pharma</div></a></li></ul></details></li><li><a class="MobileMenu_Link__5frcx" href="/community">Community</a></li><li><a class="MobileMenu_Link__5frcx" href="/pricing">Pricing</a></li><li><a class="MobileMenu_Link__5frcx" href="/blog">Blog</a></li><li><a class="MobileMenu_Link__5frcx" href="/customers">Customer stories</a></li><li><a class="MobileMenu_Link__5frcx" href="/careers">Careers</a></li></ul></nav><a href="/contact" class="Button_button-variant-ghost__o2AbG Button_button__aJ0V6" data-tracking-variant="ghost"> <!-- -->Talk to us</a><ul class="Socials_socials__8Y_s5 Socials_socials-theme-dark__Hq8lc MobileMenu_socials__JykCO"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu MobileMenu_copyright__nKVOs">© <!-- -->2025<!-- --> LlamaIndex</p></div></header><main><section class="BlogPost_post__JHNzd"><img alt="" loading="lazy" width="800" height="512" decoding="async" data-nimg="1" class="BlogPost_featuredImage__KGxwX" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Feba569ed6e28e7dd438946ce2c1f45cb44d9ed14-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Feba569ed6e28e7dd438946ce2c1f45cb44d9ed14-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Feba569ed6e28e7dd438946ce2c1f45cb44d9ed14-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><p class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-600__fKYth BlogPost_date__6uxQw"><a class="BlogPost_author__mesdl" href="/blog/author/llamaindex">LlamaIndex</a> <!-- -->•<!-- --> <!-- -->2023-11-15</p><h1 class="Text_text__zPO0D Text_text-size-32__koGps BlogPost_title__b2lqJ">Announcing LlamaIndex 0.9</h1><ul class="BlogPost_tags__13pBH"><li><a class="Badge_badge___1ssn" href="/blog/tag/llm"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">LLM</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">AI</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Llamaindex</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/genai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Genai</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/python"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Python</span></a></li></ul><div class="BlogPost_htmlPost__Z5oDL"><p>Our hard-working team is delighted to announce our latest major release, LlamaIndex 0.9! You can get it right now:</p><p><code class="cw om on oo op b">pip install --upgrade llama_index</code></p><p>In LlamaIndex v0.9, we are taking the time to refine several key aspects of the user experience, including token counting, text splitting, and more!</p><p>As part of this, there are some new features and minor changes to current usage that developers should be aware of:</p><ul><li>New <code class="cw om on oo op b">IngestionPipline</code> concept for ingesting and transforming data</li><li>Data ingestion and transforms are now automatically cached</li><li>Updated interface for node parsing/text splitting/metadata extraction modules</li><li>Changes to the default tokenizer, as well as customizing the tokenizer</li><li>Packaging/Installation changes with PyPi (reduced bloat, new install options)</li><li>More predictable and consistent import paths</li><li>Plus, in beta: MultiModal RAG Modules for handling text and images!</li></ul><p>Have questions or concerns? You can <a href="https://github.com/run-llama/llama_index/issues" rel="noopener ugc nofollow" target="_blank">report an issue</a> on GitHub or <a href="https://discord.com/invite/eN6D2HQ4aX" rel="noopener ugc nofollow" target="_blank">ask a question on our Discord</a>!</p><p>Read on for more details on our new features and changes.</p><h1>IngestionPipeline — New abstraction for purely ingesting data</h1><p>Sometimes, all you want is to ingest and embed nodes from data sources, for instance if your application allows users to upload new data. New in LlamaIndex V0.9 is the concept of an <code class="cw om on oo op b">IngestionPipepline</code> .</p><p>An <code class="cw om on oo op b">IngestionPipeline</code> uses a new concept of <code class="cw om on oo op b">Transformations</code> that are applied to input data.</p><p>What is a <code class="cw om on oo op b">Transformation</code> though? It could be a:</p><ul><li>text splitter</li><li>node parser</li><li>metadata extractor</li><li>embeddings model</li></ul><p>Here’s a quick example of the basic usage pattern:</p><pre><span id="d8ed" class="qk pa gt op b bf ql qm l qn qo"><span class="hljs-keyword">from</span> llama_index <span class="hljs-keyword">import</span> Document
<span class="hljs-keyword">from</span> llama_index.embeddings <span class="hljs-keyword">import</span> OpenAIEmbedding
<span class="hljs-keyword">from</span> llama_index.text_splitter <span class="hljs-keyword">import</span> SentenceSplitter
<span class="hljs-keyword">from</span> llama_index.extractors <span class="hljs-keyword">import</span> TitleExtractor
<span class="hljs-keyword">from</span> llama_index.ingestion <span class="hljs-keyword">import</span> IngestionPipeline, IngestionCache

pipeline = IngestionPipeline(
    transformations=[
        SentenceSplitter(chunk_size=<span class="hljs-number">25</span>, chunk_overlap=<span class="hljs-number">0</span>),
        TitleExtractor(),
        OpenAIEmbedding(),
    ]
)
nodes = pipeline.run(documents=[Document.example()])</span></pre><h1>Transformation Caching</h1><p>Each time you run the same <code class="cw om on oo op b">IngestionPipeline</code> object, it caches a hash of the input nodes + transformations and the output of that transformation for each transformation in the pipeline.</p><p>In subsequent runs, if there is a cache hit, that transformation will be skipped and the cached result will be used instead. The greatly speeds up duplicate runs, and can help improve iteration times when deciding which transformations to use.</p><p>Here’s an example with a saving and loading a local cache:</p><pre><span id="1882" class="qk pa gt op b bf ql qm l qn qo"><span class="hljs-keyword">from</span> llama_index <span class="hljs-keyword">import</span> Document
<span class="hljs-keyword">from</span> llama_index.embeddings <span class="hljs-keyword">import</span> OpenAIEmbedding
<span class="hljs-keyword">from</span> llama_index.text_splitter <span class="hljs-keyword">import</span> SentenceSplitter
<span class="hljs-keyword">from</span> llama_index.extractors <span class="hljs-keyword">import</span> TitleExtractor
<span class="hljs-keyword">from</span> llama_index.ingestion <span class="hljs-keyword">import</span> IngestionPipeline, IngestionCache

pipeline = IngestionPipeline(
    transformations=[
        SentenceSplitter(chunk_size=<span class="hljs-number">25</span>, chunk_overlap=<span class="hljs-number">0</span>),
        TitleExtractor(),
        OpenAIEmbedding(),
    ]
)
<span class="hljs-comment"># will only execute full pipeline once</span>
nodes = pipeline.run(documents=[Document.example()])
nodes = pipeline.run(documents=[Document.example()])
<span class="hljs-comment"># save and load</span>
pipeline.cache.persist(<span class="hljs-string">"./test_cache.json"</span>)
new_cache = IngestionCache.from_persist_path(<span class="hljs-string">"./test_cache.json"</span>)
new_pipeline = IngestionPipeline(
    transformations=[
        SentenceSplitter(chunk_size=<span class="hljs-number">25</span>, chunk_overlap=<span class="hljs-number">0</span>),
        TitleExtractor(),
    ],
    cache=new_cache,
)
<span class="hljs-comment"># will run instantly due to the cache</span>
nodes = pipeline.run(documents=[Document.example()])</span></pre><p>And here’s another example using Redis as a cache and Qdrant as a vector store. Running this will directly insert the nodes into your vector store and cache each transformation step in Redis.</p><pre><span id="14d4" class="qk pa gt op b bf ql qm l qn qo"><span class="hljs-keyword">from</span> llama_index <span class="hljs-keyword">import</span> Document
<span class="hljs-keyword">from</span> llama_index.embeddings <span class="hljs-keyword">import</span> OpenAIEmbedding
<span class="hljs-keyword">from</span> llama_index.text_splitter <span class="hljs-keyword">import</span> SentenceSplitter
<span class="hljs-keyword">from</span> llama_index.extractors <span class="hljs-keyword">import</span> TitleExtractor
<span class="hljs-keyword">from</span> llama_index.ingestion <span class="hljs-keyword">import</span> IngestionPipeline, IngestionCache
<span class="hljs-keyword">from</span> llama_index.ingestion.cache <span class="hljs-keyword">import</span> RedisCache
<span class="hljs-keyword">from</span> llama_index.vector_stores.qdrant <span class="hljs-keyword">import</span> QdrantVectorStore

<span class="hljs-keyword">import</span> qdrant_client
client = qdrant_client.QdrantClient(location=<span class="hljs-string">":memory:"</span>)
vector_store = QdrantVectorStore(client=client, collection_name=<span class="hljs-string">"test_store"</span>)
pipeline = IngestionPipeline(
    transformations=[
        SentenceSplitter(chunk_size=<span class="hljs-number">25</span>, chunk_overlap=<span class="hljs-number">0</span>),
        TitleExtractor(),
        OpenAIEmbedding(),
    ],
    cache=IngestionCache(cache=RedisCache(), collection=<span class="hljs-string">"test_cache"</span>),
    vector_store=vector_store,
)
<span class="hljs-comment"># Ingest directly into a vector db</span>
pipeline.run(documents=[Document.example()])
<span class="hljs-comment"># Create your index</span>
<span class="hljs-keyword">from</span> llama_index <span class="hljs-keyword">import</span> VectorStoreIndex
index = VectorStoreIndex.from_vector_store(vector_store)</span></pre><h1>Custom Transformations</h1><p>Implementing custom transformations is easy! Let’s add a transform to remove special characters from the text before calling embeddings.</p><p>The only real requirement for transformations is that they must accept a list of nodes and return a list of nodes.</p><pre><span id="b3ca" class="qk pa gt op b bf ql qm l qn qo"><span class="hljs-keyword">import</span> re
<span class="hljs-keyword">from</span> llama_index <span class="hljs-keyword">import</span> Document
<span class="hljs-keyword">from</span> llama_index.embeddings <span class="hljs-keyword">import</span> OpenAIEmbedding
<span class="hljs-keyword">from</span> llama_index.text_splitter <span class="hljs-keyword">import</span> SentenceSplitter
<span class="hljs-keyword">from</span> llama_index.ingestion <span class="hljs-keyword">import</span> IngestionPipeline
<span class="hljs-keyword">from</span> llama_index.schema <span class="hljs-keyword">import</span> TransformComponent

<span class="hljs-keyword">class</span> <span class="hljs-title class_">TextCleaner</span>(<span class="hljs-title class_ inherited__">TransformComponent</span>):
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, nodes, **kwargs</span>):
    <span class="hljs-keyword">for</span> node <span class="hljs-keyword">in</span> nodes:
      node.text = re.sub(<span class="hljs-string">r'[^0-9A-Za-z ]'</span>, <span class="hljs-string">""</span>, node.text)
    <span class="hljs-keyword">return</span> nodes
pipeline = IngestionPipeline(
    transformations=[
        SentenceSplitter(chunk_size=<span class="hljs-number">25</span>, chunk_overlap=<span class="hljs-number">0</span>),
        TextCleaner(),
        OpenAIEmbedding(),
    ],
)
nodes = pipeline.run(documents=[Document.example()])</span></pre><h1>Node Parsing/Text Splitting — Flattened and Simplified Interface</h1><p>We’ve made our interface for parsing and splitting text a lot cleaner.</p><h1>Before:</h1><pre><span id="c330" class="qk pa gt op b bf ql qm l qn qo"><span class="hljs-keyword">from</span> llama_index.node_parser <span class="hljs-keyword">import</span> SimpleNodeParser
<span class="hljs-keyword">from</span> llama_index.node_parser.extractors <span class="hljs-keyword">import</span> (
	MetadataExtractor, TitleExtractor
) 
<span class="hljs-keyword">from</span> llama_index.text_splitter <span class="hljs-keyword">import</span> SentenceSplitter

node_parser = SimpleNodeParser(
  text_splitter=SentenceSplitter(chunk_size=<span class="hljs-number">512</span>),
  metadata_extractor=MetadataExtractor(
  extractors=[TitleExtractor()]
 ),
)
nodes = node_parser.get_nodes_from_documents(documents)</span></pre><h1>After:</h1><pre><span id="5692" class="qk pa gt op b bf ql qm l qn qo"><span class="hljs-keyword">from</span> llama_index.text_splitter <span class="hljs-keyword">import</span> SentenceSplitter
<span class="hljs-keyword">from</span> llama_index.extractors <span class="hljs-keyword">import</span> TitleExtractor 

node_parser = SentenceSplitter(chunk_size=<span class="hljs-number">512</span>)
extractor = TitleExtractor()

<span class="hljs-comment"># use transforms directly</span>
nodes = node_parser(documents)
nodes = extractor(nodes)</span></pre><p>Previously, the <code class="cw om on oo op b">NodeParser</code> object in LlamaIndex had become extremely bloated, holding both text splitters and metadata extractors, which caused both pains for users when changing these components, and pains for us trying to maintain and develop them.</p><p>In V0.9, we have <strong>flattened</strong> the entire interface into a single <code class="cw om on oo op b">TransformComponent</code> abstraction, so that these transformations are easier to setup, use, and customize.</p><p>We’ve done our best to minimize the impacts on users, but the main thing to note is that <code class="cw om on oo op b"><strong>SimpleNodeParser</strong></code><strong> has been removed</strong>, and other node parsers and text splitters have been elevated to have the same features, just with different parsing and splitting techniques.</p><p>Any old imports of <code class="cw om on oo op b">SimpleNodeParser</code> will redirect to the most equivalent module, <code class="cw om on oo op b">SentenceSplitter</code>.</p><p>Furthermore, the wrapper object <code class="cw om on oo op b"><strong>MetadataExtractor</strong></code><strong> has been removed</strong>, in favour of using extractors directly.</p><p>Full documentation for all this can be found below:</p><ul><li><a href="https://docs.llamaindex.ai/en/stable/module_guides/loading/node_parsers/modules.html" rel="noopener ugc nofollow" target="_blank">Node Parsers and Text Splitters</a></li><li><a href="https://docs.llamaindex.ai/en/stable/module_guides/indexing/metadata_extraction.html" rel="noopener ugc nofollow" target="_blank">Metadata Extractors</a></li></ul><h1>Tokenization and Token Counting — Improved defaults and Customization</h1><p>A big pain point in LlamaIndex previously was tokenization. Many components used a non-configurable <code class="cw om on oo op b">gpt2</code> tokenizer for token counting, causing headaches for users using non-OpenAI models, or even some hacky fixes <a href="https://github.com/run-llama/llama_index/blob/336a88db4f13cfc598c473f9b5a3bc073b5d7ef4/llama_index/indices/prompt_helper.py#L119" rel="noopener ugc nofollow" target="_blank">like this</a> for OpenAI models too!</p><p>In LlamaIndex V0.9, this <strong>global tokenizer is now configurable and defaults to the CL100K tokenizer</strong> to match our default GPT-3.5 LLM.</p><p>The single requirement for a tokenizer is that it is a callable function, that takes a string, and returns a list.</p><p>Some examples of configuring this are below:</p><pre><span id="5d70" class="qk pa gt op b bf ql qm l qn qo"><span class="hljs-keyword">from</span> llama_index <span class="hljs-keyword">import</span> set_global_tokenizer

<span class="hljs-comment"># tiktoken</span>
<span class="hljs-keyword">import</span> tiktoken
set_global_tokenizer(
  tiktoken.encoding_for_model(<span class="hljs-string">"gpt-3.5-turbo"</span>).encode
)
<span class="hljs-comment"># huggingface</span>
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer
set_global_tokenizer(
  AutoTokenizer.from_pretrained(<span class="hljs-string">"HuggingFaceH4/zephyr-7b-beta"</span>).encode
)</span></pre><p>Furthermore, the <code class="cw om on oo op b">TokenCountingHandler</code> has gotten an upgrade with better token counting, as well as using token counts from API responses directly when available.</p><h1>Packaging — Reduced Bloat</h1><p>In an effort to modernize the packaging of LlamaIndex, V0.9 also comes with changes to installation.</p><p>The biggest change here is that <code class="cw om on oo op b">LangChain</code> is now an optional package, and will not be installed by default.</p><p>To install <code class="cw om on oo op b">LangChain</code> as part of your llama-index installation you can follow the example below. There are also other installation options depending on your needs, and we are welcoming further contributions to the extras in the future.</p><pre><span id="09ee" class="qk pa gt op b bf ql qm l qn qo"># installs langchain
pip install llama-index[langchain]
 
# installs tools needed for running local models
pip install llama-index[local_models]

# installs tools needed for postgres
pip install llama-index[postgres]

# combinations!
pip isntall llama-index[local_models,postgres]</span></pre><p><strong>If you were previously importing </strong><code class="cw om on oo op b"><strong>langchain</strong></code><strong> modules</strong> in your code, please update your project packaging requirements appropriately.</p><h1>Import Paths — More Consistent and Predictable</h1><p>We are making two changes to our import paths:</p><ol><li>We’ve removed uncommonly used imports from the root level to make importing <code class="cw om on oo op b">llama_index</code> faster</li><li>We now have a consistent policy for making “user-facing” concepts import-able at level-1 modules.</li></ol><pre><span id="13d2" class="qk pa gt op b bf ql qm l qn qo"><span class="hljs-keyword">from</span> llama_index.llms <span class="hljs-keyword">import</span> OpenAI, ...
<span class="hljs-keyword">from</span> llama_index.embeddings <span class="hljs-keyword">import</span> OpenAIEmbedding, ...
<span class="hljs-keyword">from</span> llama_index.prompts <span class="hljs-keyword">import</span> PromptTemplate, ...
<span class="hljs-keyword">from</span> llama_index.readers <span class="hljs-keyword">import</span> SimpleDirectoryReader, ...
<span class="hljs-keyword">from</span> llama_index.text_splitter <span class="hljs-keyword">import</span> SentenceSplitter, ...
<span class="hljs-keyword">from</span> llama_index.extractors <span class="hljs-keyword">import</span> TitleExtractor, ...
<span class="hljs-keyword">from</span> llama_index.vector_stores <span class="hljs-keyword">import</span> SimpleVectorStore, ...</span></pre><p>We still expose some of the most commonly used modules at the root level.</p><pre><span id="299d" class="qk pa gt op b bf ql qm l qn qo"><span class="hljs-keyword">from</span> llama_index <span class="hljs-keyword">import</span> SimpleDirectoryReader, VectorStoreIndex, ...</span></pre><h1>MultiModal RAG</h1><p>Given the recent announcements of the GPT-4V API, multi-modal use cases are more accessible than ever before.</p><p>To help users use these features, we’ve started to introduce a number of new modules to help support use-cases for MultiModal RAG:</p><ul><li>MultiModal LLMs (GPT-4V, Llava, Fuyu, etc.)</li><li>MultiModal Embeddings (i.e clip) for join image-text embedding/retrieval</li><li>MultiModal RAG, combining indexes and query engines</li></ul><p>Our documentation has a <a href="https://docs.llamaindex.ai/en/latest/examples/multi_modal/gpt4v_multi_modal_retrieval.html" rel="noopener ugc nofollow" target="_blank">full guide to multi-modal retrieval</a>.</p><h1>Thanks for all your support!</h1><p>As an open-source project we couldn’t exist without our <a href="https://github.com/run-llama/llama_index/graphs/contributors" rel="noopener ugc nofollow" target="_blank">hundreds of contributors</a>. We are so grateful for them and the support of the hundreds of thousands of LlamaIndex users around the world. See you on the Discord!</p></div><div class="BlogPost_relatedPosts__0z6SN"><h2 class="Text_text__zPO0D Text_text-align-center__HhKqo Text_text-size-16__PkjFu Text_text-weight-400__5ENkK Text_text-family-spaceGrotesk__E4zcE BlogPost_relatedPostsTitle___JIrW">Related articles</h2><ul class="BlogPost_relatedPostsList__uOKzB"><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F5072f44cf25db4b603e6a20487d2b46085ef6f05-1536x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F5072f44cf25db4b603e6a20487d2b46085ef6f05-1536x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F5072f44cf25db4b603e6a20487d2b46085ef6f05-1536x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/python-tooling-at-scale-llamaindex-s-monorepo-overhaul">Python Tooling at Scale: LlamaIndex’s Monorepo Overhaul</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2025-05-21</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F075ee1a825a2122c94617e3af09a1a3ae48fc4a2-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F075ee1a825a2122c94617e3af09a1a3ae48fc4a2-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F075ee1a825a2122c94617e3af09a1a3ae48fc4a2-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/introducing-llamaindex-0-11">Introducing LlamaIndex 0.11</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-08-22</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Faa21c9d353919277d4fce16f174e54280bda8660-1920x832.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Faa21c9d353919277d4fce16f174e54280bda8660-1920x832.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Faa21c9d353919277d4fce16f174e54280bda8660-1920x832.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/jamba-instruct-s-256k-context-window-on-llamaindex">Jamba-Instruct&#x27;s 256k context window on LlamaIndex</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-07-31</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F31290fcec6832b337689a39c17adf5d995ff46b6-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F31290fcec6832b337689a39c17adf5d995ff46b6-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F31290fcec6832b337689a39c17adf5d995ff46b6-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/llamaindex-newsletter-2024-04-02">LlamaIndex Newsletter 2024-04-02</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-04-02</p></div></li></ul></div></section></main><footer class="Footer_footer__eNA9m"><div class="Footer_navContainer__7bvx4"><div class="Footer_logoContainer__3EpzI"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" style="color:transparent" src="/llamaindex.svg"/><div class="Footer_socialContainer__GdOgk"><ul class="Socials_socials__8Y_s5"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul></div></div><div class="Footer_nav__BLEuE"><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/">LlamaIndex</a></h3><ul><li><a href="/blog"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Blog</span></a></li><li><a href="/partners"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Partners</span></a></li><li><a href="/careers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Careers</span></a></li><li><a href="/contact"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Contact</span></a></li><li><a href="/brand"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Brand</span></a></li><li><a href="https://llamaindex.statuspage.io" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Status</span></a></li><li><a href="https://app.vanta.com/runllama.ai/trust/pkcgbjf8b3ihxjpqdx17nu" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Trust Center</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/enterprise">Enterprise</a></h3><ul><li><a href="https://cloud.llamaindex.ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaCloud</span></a></li><li><a href="https://cloud.llamaindex.ai/parse" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaParse</span></a></li><li><a href="/customers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Customers</span></a></li><li><a href="/llamacloud-sharepoint-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SharePoint</span></a></li><li><a href="/llamacloud-aws-s3-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">AWS S3</span></a></li><li><a href="/llamacloud-azure-blob-storage-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure Blob Storage</span></a></li><li><a href="/llamacloud-google-drive-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Google Drive</span></a></li> </ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/framework">Framework</a></h3><ul><li><a href="https://pypi.org/project/llama-index/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python package</span></a></li><li><a href="https://docs.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python docs</span></a></li><li><a href="https://www.npmjs.com/package/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript package</span></a></li><li><a href="https://ts.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript docs</span></a></li><li><a href="https://llamahub.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaHub</span></a></li><li><a href="https://github.com/run-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">GitHub</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/community">Community</a></h3><ul><li><a href="/community#newsletter"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Newsletter</span></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Discord</span></a></li><li><a href="https://www.linkedin.com/company/91154103/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LinkedIn</span></a></li><li><a href="https://twitter.com/llama_index"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Twitter/X</span></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">YouTube</span></a></li><li><a href="https://bsky.app/profile/llamaindex.bsky.social"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">BlueSky</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e">Starter projects</h3><ul><li><a href="https://www.npmjs.com/package/create-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">create-llama</span></a></li><li><a href="https://secinsights.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SEC Insights</span></a></li><li><a href="https://github.com/run-llama/llamabot"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaBot</span></a></li><li><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/rag_cli.html"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">RAG CLI</span></a></li></ul></div></div></div><div class="Footer_copyrightContainer__mBKsT"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA">© <!-- -->2025<!-- --> LlamaIndex</p><div class="Footer_legalNav__O1yJA"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/privacy-notice.pdf">Privacy Notice</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/terms-of-service.pdf">Terms of Service</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="https://bit.ly/llamaindexdpa">Data Processing Addendum</a></p></div></div></footer></div><svg xmlns="http://www.w3.org/2000/svg" class="flt_svg" style="display:none"><defs><filter id="flt_tag"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="2"></feGaussianBlur><feColorMatrix in="blur" result="flt_tag" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="flt_tag" operator="atop"></feComposite></filter><filter id="svg_blur_large"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="8"></feGaussianBlur><feColorMatrix in="blur" result="svg_blur_large" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="svg_blur_large" operator="atop"></feComposite></filter></defs></svg></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"page":{"announcement":{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"},"post":{"_createdAt":"2024-02-22T21:47:07Z","_id":"01935efc-1ff9-4c79-bbb7-1fd2cee94dca","_rev":"TLgH6AcXrxoqw75SBDhe1w","_type":"blogPost","_updatedAt":"2025-05-21T20:36:12Z","announcement":[{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"}],"authors":[{"_createdAt":"2024-02-20T20:23:12Z","_id":"363ec4e9-0b8f-48d2-ba6a-567a9c527c3d","_rev":"rGZ2nN6K5mjOGJOoWaUhNb","_type":"people","_updatedAt":"2024-02-25T00:45:24Z","image":{"_type":"image","asset":{"_ref":"image-89523511cf20d73e3f10077add50128d077ed520-176x176-png","_type":"reference"}},"name":"LlamaIndex","slug":{"_type":"slug","current":"llamaindex"}}],"featured":false,"htmlContent":"\u003cp\u003eOur hard-working team is delighted to announce our latest major release, LlamaIndex 0.9! You can get it right now:\u003c/p\u003e\u003cp\u003e\u003ccode class=\"cw om on oo op b\"\u003epip install --upgrade llama_index\u003c/code\u003e\u003c/p\u003e\u003cp\u003eIn LlamaIndex v0.9, we are taking the time to refine several key aspects of the user experience, including token counting, text splitting, and more!\u003c/p\u003e\u003cp\u003eAs part of this, there are some new features and minor changes to current usage that developers should be aware of:\u003c/p\u003e\u003cul\u003e\u003cli\u003eNew \u003ccode class=\"cw om on oo op b\"\u003eIngestionPipline\u003c/code\u003e concept for ingesting and transforming data\u003c/li\u003e\u003cli\u003eData ingestion and transforms are now automatically cached\u003c/li\u003e\u003cli\u003eUpdated interface for node parsing/text splitting/metadata extraction modules\u003c/li\u003e\u003cli\u003eChanges to the default tokenizer, as well as customizing the tokenizer\u003c/li\u003e\u003cli\u003ePackaging/Installation changes with PyPi (reduced bloat, new install options)\u003c/li\u003e\u003cli\u003eMore predictable and consistent import paths\u003c/li\u003e\u003cli\u003ePlus, in beta: MultiModal RAG Modules for handling text and images!\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eHave questions or concerns? You can \u003ca href=\"https://github.com/run-llama/llama_index/issues\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ereport an issue\u003c/a\u003e on GitHub or \u003ca href=\"https://discord.com/invite/eN6D2HQ4aX\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eask a question on our Discord\u003c/a\u003e!\u003c/p\u003e\u003cp\u003eRead on for more details on our new features and changes.\u003c/p\u003e\u003ch1\u003eIngestionPipeline — New abstraction for purely ingesting data\u003c/h1\u003e\u003cp\u003eSometimes, all you want is to ingest and embed nodes from data sources, for instance if your application allows users to upload new data. New in LlamaIndex V0.9 is the concept of an \u003ccode class=\"cw om on oo op b\"\u003eIngestionPipepline\u003c/code\u003e .\u003c/p\u003e\u003cp\u003eAn \u003ccode class=\"cw om on oo op b\"\u003eIngestionPipeline\u003c/code\u003e uses a new concept of \u003ccode class=\"cw om on oo op b\"\u003eTransformations\u003c/code\u003e that are applied to input data.\u003c/p\u003e\u003cp\u003eWhat is a \u003ccode class=\"cw om on oo op b\"\u003eTransformation\u003c/code\u003e though? It could be a:\u003c/p\u003e\u003cul\u003e\u003cli\u003etext splitter\u003c/li\u003e\u003cli\u003enode parser\u003c/li\u003e\u003cli\u003emetadata extractor\u003c/li\u003e\u003cli\u003eembeddings model\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eHere’s a quick example of the basic usage pattern:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"d8ed\" class=\"qk pa gt op b bf ql qm l qn qo\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Document\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.embeddings \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e OpenAIEmbedding\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.text_splitter \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SentenceSplitter\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.extractors \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e TitleExtractor\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.ingestion \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e IngestionPipeline, IngestionCache\n\npipeline = IngestionPipeline(\n    transformations=[\n        SentenceSplitter(chunk_size=\u003cspan class=\"hljs-number\"\u003e25\u003c/span\u003e, chunk_overlap=\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e),\n        TitleExtractor(),\n        OpenAIEmbedding(),\n    ]\n)\nnodes = pipeline.run(documents=[Document.example()])\u003c/span\u003e\u003c/pre\u003e\u003ch1\u003eTransformation Caching\u003c/h1\u003e\u003cp\u003eEach time you run the same \u003ccode class=\"cw om on oo op b\"\u003eIngestionPipeline\u003c/code\u003e object, it caches a hash of the input nodes + transformations and the output of that transformation for each transformation in the pipeline.\u003c/p\u003e\u003cp\u003eIn subsequent runs, if there is a cache hit, that transformation will be skipped and the cached result will be used instead. The greatly speeds up duplicate runs, and can help improve iteration times when deciding which transformations to use.\u003c/p\u003e\u003cp\u003eHere’s an example with a saving and loading a local cache:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"1882\" class=\"qk pa gt op b bf ql qm l qn qo\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Document\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.embeddings \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e OpenAIEmbedding\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.text_splitter \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SentenceSplitter\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.extractors \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e TitleExtractor\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.ingestion \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e IngestionPipeline, IngestionCache\n\npipeline = IngestionPipeline(\n    transformations=[\n        SentenceSplitter(chunk_size=\u003cspan class=\"hljs-number\"\u003e25\u003c/span\u003e, chunk_overlap=\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e),\n        TitleExtractor(),\n        OpenAIEmbedding(),\n    ]\n)\n\u003cspan class=\"hljs-comment\"\u003e# will only execute full pipeline once\u003c/span\u003e\nnodes = pipeline.run(documents=[Document.example()])\nnodes = pipeline.run(documents=[Document.example()])\n\u003cspan class=\"hljs-comment\"\u003e# save and load\u003c/span\u003e\npipeline.cache.persist(\u003cspan class=\"hljs-string\"\u003e\"./test_cache.json\"\u003c/span\u003e)\nnew_cache = IngestionCache.from_persist_path(\u003cspan class=\"hljs-string\"\u003e\"./test_cache.json\"\u003c/span\u003e)\nnew_pipeline = IngestionPipeline(\n    transformations=[\n        SentenceSplitter(chunk_size=\u003cspan class=\"hljs-number\"\u003e25\u003c/span\u003e, chunk_overlap=\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e),\n        TitleExtractor(),\n    ],\n    cache=new_cache,\n)\n\u003cspan class=\"hljs-comment\"\u003e# will run instantly due to the cache\u003c/span\u003e\nnodes = pipeline.run(documents=[Document.example()])\u003c/span\u003e\u003c/pre\u003e\u003cp\u003eAnd here’s another example using Redis as a cache and Qdrant as a vector store. Running this will directly insert the nodes into your vector store and cache each transformation step in Redis.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"14d4\" class=\"qk pa gt op b bf ql qm l qn qo\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Document\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.embeddings \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e OpenAIEmbedding\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.text_splitter \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SentenceSplitter\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.extractors \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e TitleExtractor\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.ingestion \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e IngestionPipeline, IngestionCache\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.ingestion.cache \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e RedisCache\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.vector_stores.qdrant \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e QdrantVectorStore\n\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e qdrant_client\nclient = qdrant_client.QdrantClient(location=\u003cspan class=\"hljs-string\"\u003e\":memory:\"\u003c/span\u003e)\nvector_store = QdrantVectorStore(client=client, collection_name=\u003cspan class=\"hljs-string\"\u003e\"test_store\"\u003c/span\u003e)\npipeline = IngestionPipeline(\n    transformations=[\n        SentenceSplitter(chunk_size=\u003cspan class=\"hljs-number\"\u003e25\u003c/span\u003e, chunk_overlap=\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e),\n        TitleExtractor(),\n        OpenAIEmbedding(),\n    ],\n    cache=IngestionCache(cache=RedisCache(), collection=\u003cspan class=\"hljs-string\"\u003e\"test_cache\"\u003c/span\u003e),\n    vector_store=vector_store,\n)\n\u003cspan class=\"hljs-comment\"\u003e# Ingest directly into a vector db\u003c/span\u003e\npipeline.run(documents=[Document.example()])\n\u003cspan class=\"hljs-comment\"\u003e# Create your index\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e VectorStoreIndex\nindex = VectorStoreIndex.from_vector_store(vector_store)\u003c/span\u003e\u003c/pre\u003e\u003ch1\u003eCustom Transformations\u003c/h1\u003e\u003cp\u003eImplementing custom transformations is easy! Let’s add a transform to remove special characters from the text before calling embeddings.\u003c/p\u003e\u003cp\u003eThe only real requirement for transformations is that they must accept a list of nodes and return a list of nodes.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"b3ca\" class=\"qk pa gt op b bf ql qm l qn qo\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e re\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Document\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.embeddings \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e OpenAIEmbedding\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.text_splitter \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SentenceSplitter\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.ingestion \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e IngestionPipeline\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.schema \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e TransformComponent\n\n\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eTextCleaner\u003c/span\u003e(\u003cspan class=\"hljs-title class_ inherited__\"\u003eTransformComponent\u003c/span\u003e):\n  \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__call__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, nodes, **kwargs\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e node \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e nodes:\n      node.text = re.sub(\u003cspan class=\"hljs-string\"\u003er'[^0-9A-Za-z ]'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e, node.text)\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e nodes\npipeline = IngestionPipeline(\n    transformations=[\n        SentenceSplitter(chunk_size=\u003cspan class=\"hljs-number\"\u003e25\u003c/span\u003e, chunk_overlap=\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e),\n        TextCleaner(),\n        OpenAIEmbedding(),\n    ],\n)\nnodes = pipeline.run(documents=[Document.example()])\u003c/span\u003e\u003c/pre\u003e\u003ch1\u003eNode Parsing/Text Splitting — Flattened and Simplified Interface\u003c/h1\u003e\u003cp\u003eWe’ve made our interface for parsing and splitting text a lot cleaner.\u003c/p\u003e\u003ch1\u003eBefore:\u003c/h1\u003e\u003cpre\u003e\u003cspan id=\"c330\" class=\"qk pa gt op b bf ql qm l qn qo\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.node_parser \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SimpleNodeParser\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.node_parser.extractors \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e (\n\tMetadataExtractor, TitleExtractor\n) \n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.text_splitter \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SentenceSplitter\n\nnode_parser = SimpleNodeParser(\n  text_splitter=SentenceSplitter(chunk_size=\u003cspan class=\"hljs-number\"\u003e512\u003c/span\u003e),\n  metadata_extractor=MetadataExtractor(\n  extractors=[TitleExtractor()]\n ),\n)\nnodes = node_parser.get_nodes_from_documents(documents)\u003c/span\u003e\u003c/pre\u003e\u003ch1\u003eAfter:\u003c/h1\u003e\u003cpre\u003e\u003cspan id=\"5692\" class=\"qk pa gt op b bf ql qm l qn qo\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.text_splitter \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SentenceSplitter\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.extractors \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e TitleExtractor \n\nnode_parser = SentenceSplitter(chunk_size=\u003cspan class=\"hljs-number\"\u003e512\u003c/span\u003e)\nextractor = TitleExtractor()\n\n\u003cspan class=\"hljs-comment\"\u003e# use transforms directly\u003c/span\u003e\nnodes = node_parser(documents)\nnodes = extractor(nodes)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003ePreviously, the \u003ccode class=\"cw om on oo op b\"\u003eNodeParser\u003c/code\u003e object in LlamaIndex had become extremely bloated, holding both text splitters and metadata extractors, which caused both pains for users when changing these components, and pains for us trying to maintain and develop them.\u003c/p\u003e\u003cp\u003eIn V0.9, we have \u003cstrong\u003eflattened\u003c/strong\u003e the entire interface into a single \u003ccode class=\"cw om on oo op b\"\u003eTransformComponent\u003c/code\u003e abstraction, so that these transformations are easier to setup, use, and customize.\u003c/p\u003e\u003cp\u003eWe’ve done our best to minimize the impacts on users, but the main thing to note is that \u003ccode class=\"cw om on oo op b\"\u003e\u003cstrong\u003eSimpleNodeParser\u003c/strong\u003e\u003c/code\u003e\u003cstrong\u003e has been removed\u003c/strong\u003e, and other node parsers and text splitters have been elevated to have the same features, just with different parsing and splitting techniques.\u003c/p\u003e\u003cp\u003eAny old imports of \u003ccode class=\"cw om on oo op b\"\u003eSimpleNodeParser\u003c/code\u003e will redirect to the most equivalent module, \u003ccode class=\"cw om on oo op b\"\u003eSentenceSplitter\u003c/code\u003e.\u003c/p\u003e\u003cp\u003eFurthermore, the wrapper object \u003ccode class=\"cw om on oo op b\"\u003e\u003cstrong\u003eMetadataExtractor\u003c/strong\u003e\u003c/code\u003e\u003cstrong\u003e has been removed\u003c/strong\u003e, in favour of using extractors directly.\u003c/p\u003e\u003cp\u003eFull documentation for all this can be found below:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://docs.llamaindex.ai/en/stable/module_guides/loading/node_parsers/modules.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eNode Parsers and Text Splitters\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://docs.llamaindex.ai/en/stable/module_guides/indexing/metadata_extraction.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMetadata Extractors\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch1\u003eTokenization and Token Counting — Improved defaults and Customization\u003c/h1\u003e\u003cp\u003eA big pain point in LlamaIndex previously was tokenization. Many components used a non-configurable \u003ccode class=\"cw om on oo op b\"\u003egpt2\u003c/code\u003e tokenizer for token counting, causing headaches for users using non-OpenAI models, or even some hacky fixes \u003ca href=\"https://github.com/run-llama/llama_index/blob/336a88db4f13cfc598c473f9b5a3bc073b5d7ef4/llama_index/indices/prompt_helper.py#L119\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003elike this\u003c/a\u003e for OpenAI models too!\u003c/p\u003e\u003cp\u003eIn LlamaIndex V0.9, this \u003cstrong\u003eglobal tokenizer is now configurable and defaults to the CL100K tokenizer\u003c/strong\u003e to match our default GPT-3.5 LLM.\u003c/p\u003e\u003cp\u003eThe single requirement for a tokenizer is that it is a callable function, that takes a string, and returns a list.\u003c/p\u003e\u003cp\u003eSome examples of configuring this are below:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"5d70\" class=\"qk pa gt op b bf ql qm l qn qo\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e set_global_tokenizer\n\n\u003cspan class=\"hljs-comment\"\u003e# tiktoken\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e tiktoken\nset_global_tokenizer(\n  tiktoken.encoding_for_model(\u003cspan class=\"hljs-string\"\u003e\"gpt-3.5-turbo\"\u003c/span\u003e).encode\n)\n\u003cspan class=\"hljs-comment\"\u003e# huggingface\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e transformers \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e AutoTokenizer\nset_global_tokenizer(\n  AutoTokenizer.from_pretrained(\u003cspan class=\"hljs-string\"\u003e\"HuggingFaceH4/zephyr-7b-beta\"\u003c/span\u003e).encode\n)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003eFurthermore, the \u003ccode class=\"cw om on oo op b\"\u003eTokenCountingHandler\u003c/code\u003e has gotten an upgrade with better token counting, as well as using token counts from API responses directly when available.\u003c/p\u003e\u003ch1\u003ePackaging — Reduced Bloat\u003c/h1\u003e\u003cp\u003eIn an effort to modernize the packaging of LlamaIndex, V0.9 also comes with changes to installation.\u003c/p\u003e\u003cp\u003eThe biggest change here is that \u003ccode class=\"cw om on oo op b\"\u003eLangChain\u003c/code\u003e is now an optional package, and will not be installed by default.\u003c/p\u003e\u003cp\u003eTo install \u003ccode class=\"cw om on oo op b\"\u003eLangChain\u003c/code\u003e as part of your llama-index installation you can follow the example below. There are also other installation options depending on your needs, and we are welcoming further contributions to the extras in the future.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"09ee\" class=\"qk pa gt op b bf ql qm l qn qo\"\u003e# installs langchain\npip install llama-index[langchain]\n \n# installs tools needed for running local models\npip install llama-index[local_models]\n\n# installs tools needed for postgres\npip install llama-index[postgres]\n\n# combinations!\npip isntall llama-index[local_models,postgres]\u003c/span\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eIf you were previously importing \u003c/strong\u003e\u003ccode class=\"cw om on oo op b\"\u003e\u003cstrong\u003elangchain\u003c/strong\u003e\u003c/code\u003e\u003cstrong\u003e modules\u003c/strong\u003e in your code, please update your project packaging requirements appropriately.\u003c/p\u003e\u003ch1\u003eImport Paths — More Consistent and Predictable\u003c/h1\u003e\u003cp\u003eWe are making two changes to our import paths:\u003c/p\u003e\u003col\u003e\u003cli\u003eWe’ve removed uncommonly used imports from the root level to make importing \u003ccode class=\"cw om on oo op b\"\u003ellama_index\u003c/code\u003e faster\u003c/li\u003e\u003cli\u003eWe now have a consistent policy for making “user-facing” concepts import-able at level-1 modules.\u003c/li\u003e\u003c/ol\u003e\u003cpre\u003e\u003cspan id=\"13d2\" class=\"qk pa gt op b bf ql qm l qn qo\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.llms \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e OpenAI, ...\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.embeddings \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e OpenAIEmbedding, ...\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.prompts \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e PromptTemplate, ...\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.readers \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SimpleDirectoryReader, ...\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.text_splitter \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SentenceSplitter, ...\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.extractors \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e TitleExtractor, ...\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index.vector_stores \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SimpleVectorStore, ...\u003c/span\u003e\u003c/pre\u003e\u003cp\u003eWe still expose some of the most commonly used modules at the root level.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"299d\" class=\"qk pa gt op b bf ql qm l qn qo\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e llama_index \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SimpleDirectoryReader, VectorStoreIndex, ...\u003c/span\u003e\u003c/pre\u003e\u003ch1\u003eMultiModal RAG\u003c/h1\u003e\u003cp\u003eGiven the recent announcements of the GPT-4V API, multi-modal use cases are more accessible than ever before.\u003c/p\u003e\u003cp\u003eTo help users use these features, we’ve started to introduce a number of new modules to help support use-cases for MultiModal RAG:\u003c/p\u003e\u003cul\u003e\u003cli\u003eMultiModal LLMs (GPT-4V, Llava, Fuyu, etc.)\u003c/li\u003e\u003cli\u003eMultiModal Embeddings (i.e clip) for join image-text embedding/retrieval\u003c/li\u003e\u003cli\u003eMultiModal RAG, combining indexes and query engines\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOur documentation has a \u003ca href=\"https://docs.llamaindex.ai/en/latest/examples/multi_modal/gpt4v_multi_modal_retrieval.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003efull guide to multi-modal retrieval\u003c/a\u003e.\u003c/p\u003e\u003ch1\u003eThanks for all your support!\u003c/h1\u003e\u003cp\u003eAs an open-source project we couldn’t exist without our \u003ca href=\"https://github.com/run-llama/llama_index/graphs/contributors\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ehundreds of contributors\u003c/a\u003e. We are so grateful for them and the support of the hundreds of thousands of LlamaIndex users around the world. See you on the Discord!\u003c/p\u003e","image":{"_type":"image","asset":{"_ref":"image-eba569ed6e28e7dd438946ce2c1f45cb44d9ed14-1024x1024-png","_type":"reference"}},"mainImage":"https://cdn.sanity.io/images/7m9jw85w/production/eba569ed6e28e7dd438946ce2c1f45cb44d9ed14-1024x1024.png","publishedDate":"2023-11-15","relatedPosts":[{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-5072f44cf25db4b603e6a20487d2b46085ef6f05-1536x1024-png","_type":"reference"}},"publishedDate":"2025-05-21","slug":"python-tooling-at-scale-llamaindex-s-monorepo-overhaul","title":"Python Tooling at Scale: LlamaIndex’s Monorepo Overhaul"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-075ee1a825a2122c94617e3af09a1a3ae48fc4a2-1024x1024-webp","_type":"reference"}},"publishedDate":"2024-08-22","slug":"introducing-llamaindex-0-11","title":"Introducing LlamaIndex 0.11"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-aa21c9d353919277d4fce16f174e54280bda8660-1920x832-png","_type":"reference"}},"publishedDate":"2024-07-31","slug":"jamba-instruct-s-256k-context-window-on-llamaindex","title":"Jamba-Instruct's 256k context window on LlamaIndex"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-31290fcec6832b337689a39c17adf5d995ff46b6-1024x1024-webp","_type":"reference"}},"publishedDate":"2024-04-02","slug":"llamaindex-newsletter-2024-04-02","title":"LlamaIndex Newsletter 2024-04-02"}],"slug":{"_type":"slug","current":"announcing-llamaindex-0-9-719f03282945"},"tags":[{"_createdAt":"2024-02-22T20:19:11Z","_id":"aa7d304e-787e-4a6c-80cb-8911afd4c788","_rev":"jbUo4a8sS9GhVRG46mMVHT","_type":"blogTag","_updatedAt":"2024-03-13T16:00:26Z","slug":{"_type":"slug","current":"llm"},"title":"LLM"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"d0a79109-34ab-41fa-a8f4-0b3522970c7d","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"ai"},"title":"AI"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"17d4fc95-517c-4f4a-95ce-bf753e802ac4","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"llamaindex"},"title":"Llamaindex"},{"_createdAt":"2024-02-22T20:19:13Z","_id":"e8f062ea-c886-4c2d-9652-08fbf991fd84","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:13Z","slug":{"_type":"slug","current":"genai"},"title":"Genai"},{"_createdAt":"2024-02-22T20:19:12Z","_id":"e46a1fe5-b185-49a2-96fd-d7edf876e25d","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:12Z","slug":{"_type":"slug","current":"python"},"title":"Python"}],"title":"Announcing LlamaIndex 0.9"},"publishedDate":"Invalid Date"},"params":{"slug":"announcing-llamaindex-0-9-719f03282945"},"draftMode":false,"token":""},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"announcing-llamaindex-0-9-719f03282945"},"buildId":"C8J-EMc_4OCN1ch65l4fl","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>