<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>LlamaIndex: Enhancing Retrieval Performance with Alpha Tuning in Hybrid Search in RAG — LlamaIndex - Build Knowledge Assistants over your Enterprise Data</title><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><meta name="title" content="LlamaIndex: Enhancing Retrieval Performance with Alpha Tuning in Hybrid Search in RAG — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta name="description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:title" content="LlamaIndex: Enhancing Retrieval Performance with Alpha Tuning in Hybrid Search in RAG — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="og:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:image" content="https://cdn.sanity.io/images/7m9jw85w/production/a648cc90b9363a4d64a84cf4505057a0d9ebfa16-3840x2352.png"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="LlamaIndex: Enhancing Retrieval Performance with Alpha Tuning in Hybrid Search in RAG — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="twitter:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="twitter:image" content="https://cdn.sanity.io/images/7m9jw85w/production/a648cc90b9363a4d64a84cf4505057a0d9ebfa16-3840x2352.png"/><link rel="alternate" type="application/rss+xml" href="https://www.llamaindex.ai/blog/feed"/><meta name="next-head-count" content="20"/><script>
            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WWRFB36R');
            </script><link rel="preload" href="/_next/static/css/41c9222e47d080c9.css" as="style"/><link rel="stylesheet" href="/_next/static/css/41c9222e47d080c9.css" data-n-g=""/><link rel="preload" href="/_next/static/css/97c33c8d95f1230e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/97c33c8d95f1230e.css" data-n-p=""/><link rel="preload" href="/_next/static/css/e009059e80bf60c5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e009059e80bf60c5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-1b629d9c8fb16f34.js" defer=""></script><script src="/_next/static/chunks/framework-df1f68dff096b68a.js" defer=""></script><script src="/_next/static/chunks/main-eca7952a704663f8.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c7c49437be49d2ad.js" defer=""></script><script src="/_next/static/chunks/d9067523-4985945b21298365.js" defer=""></script><script src="/_next/static/chunks/41155975-60c12da9ce9fa0b2.js" defer=""></script><script src="/_next/static/chunks/cb355538-cee2ea45674d9de3.js" defer=""></script><script src="/_next/static/chunks/9494-dff62cb53535dd7d.js" defer=""></script><script src="/_next/static/chunks/4063-39a391a51171ff87.js" defer=""></script><script src="/_next/static/chunks/6889-edfa85b69b88a372.js" defer=""></script><script src="/_next/static/chunks/5575-11ee0a29eaffae61.js" defer=""></script><script src="/_next/static/chunks/3444-95c636af25a42734.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-82c8e764e69afd2c.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_buildManifest.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_ssgManifest.js" defer=""></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WWRFB36R" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div class="__variable_d65c78 __variable_b1ea77 __variable_eb7534"><a class="Announcement_announcement__2ohK8" href="http://48755185.hs-sites.com/llamaindex-0">Meet LlamaIndex at the Databricks Data + AI Summit!<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M8.293 5.293a1 1 0 0 1 1.414 0l6 6a1 1 0 0 1 0 1.414l-6 6a1 1 0 0 1-1.414-1.414L13.586 12 8.293 6.707a1 1 0 0 1 0-1.414Z" clip-rule="evenodd"></path></svg></a><header class="Header_header__hO3lJ"><button class="Hamburger_hamburger__17auO Header_hamburger__lUulX"><svg width="28" height="28" viewBox="0 0 28 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.5 14H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" id="hamburger-stroke-top" class="Hamburger_hamburgerStrokeMiddle__I7VpD"></path><path d="M3.5 7H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeTop__oOhFM"></path><path d="M3.5 21H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeBottom__GIQR2"></path></svg></button><a aria-label="Homepage" href="/"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" class="Header_logo__e5KhT" style="color:transparent" src="/llamaindex.svg"/></a><nav aria-label="Main" data-orientation="horizontal" dir="ltr" style="--content-position:0px"><div style="position:relative"><ul data-orientation="horizontal" class="Nav_MenuList__PrCDJ" dir="ltr"><li><button id="radix-:R6tm:-trigger-radix-:R5mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R5mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Products</button></li><li><button id="radix-:R6tm:-trigger-radix-:R9mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R9mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Solutions</button></li><li><a class="Nav_Link__ZrzFc" href="/community" data-radix-collection-item="">Community</a></li><li><a class="Nav_Link__ZrzFc" href="/pricing" data-radix-collection-item="">Pricing</a></li><li><a class="Nav_Link__ZrzFc" href="/blog" data-radix-collection-item="">Blog</a></li><li><a class="Nav_Link__ZrzFc" href="/customers" data-radix-collection-item="">Customer stories</a></li><li><a class="Nav_Link__ZrzFc" href="/careers" data-radix-collection-item="">Careers</a></li></ul></div><div class="Nav_ViewportPosition__jmyHM"></div></nav><div class="Header_secondNav__YJvm8"><nav><a href="/contact" class="Link_link__71cl8 Link_link-variant-tertiary__BYxn_ Header_bookADemo__qCuxV">Book a demo</a></nav><a href="https://cloud.llamaindex.ai/" class="Button_button-variant-default__Oi__n Button_button__aJ0V6 Header_button__1HFhY" data-tracking-variant="default"> <!-- -->Get started</a></div><div class="MobileMenu_mobileMenu__g5Fa6"><nav class="MobileMenu_nav__EmtTw"><ul><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Products<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaparse"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.6654 1.66675V6.66675H16.6654M8.33203 10.8334L6.66536 12.5001L8.33203 14.1667M11.6654 14.1667L13.332 12.5001L11.6654 10.8334M12.082 1.66675H4.9987C4.55667 1.66675 4.13275 1.84234 3.82019 2.1549C3.50763 2.46746 3.33203 2.89139 3.33203 3.33341V16.6667C3.33203 17.1088 3.50763 17.5327 3.82019 17.8453C4.13275 18.1578 4.55667 18.3334 4.9987 18.3334H14.9987C15.4407 18.3334 15.8646 18.1578 16.1772 17.8453C16.4898 17.5327 16.6654 17.1088 16.6654 16.6667V6.25008L12.082 1.66675Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Document parsing</div><p class="MobileMenu_ListItemText__n_MHY">The first and leading GenAI-native parser over your most complex data.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaextract"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.668 1.66675V5.00008C11.668 5.44211 11.8436 5.86603 12.1561 6.17859C12.4687 6.49115 12.8926 6.66675 13.3346 6.66675H16.668M3.33464 5.83341V3.33341C3.33464 2.89139 3.51023 2.46746 3.82279 2.1549C4.13535 1.84234 4.55927 1.66675 5.0013 1.66675H12.5013L16.668 5.83341V16.6667C16.668 17.1088 16.4924 17.5327 16.1798 17.8453C15.8672 18.1578 15.4433 18.3334 15.0013 18.3334L5.05379 18.3326C4.72458 18.3755 4.39006 18.3191 4.09312 18.1706C3.79618 18.0221 3.55034 17.7884 3.38713 17.4992M4.16797 9.16675L1.66797 11.6667M1.66797 11.6667L4.16797 14.1667M1.66797 11.6667H10.0013" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Data extraction</div><p class="MobileMenu_ListItemText__n_MHY">Extract structured data from documents using a schema-driven engine.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/enterprise"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.16667 15.8333C12.8486 15.8333 15.8333 12.8486 15.8333 9.16667C15.8333 5.48477 12.8486 2.5 9.16667 2.5C5.48477 2.5 2.5 5.48477 2.5 9.16667C2.5 12.8486 5.48477 15.8333 9.16667 15.8333Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M17.5 17.5L13.875 13.875" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Knowledge Management</div><p class="MobileMenu_ListItemText__n_MHY">Connect, transform, and index your enterprise data into an agent-accessible knowledge base</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/framework"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.0013 6.66659V3.33325H6.66797M1.66797 11.6666H3.33464M16.668 11.6666H18.3346M12.5013 10.8333V12.4999M7.5013 10.8333V12.4999M5.0013 6.66659H15.0013C15.9218 6.66659 16.668 7.41278 16.668 8.33325V14.9999C16.668 15.9204 15.9218 16.6666 15.0013 16.6666H5.0013C4.08083 16.6666 3.33464 15.9204 3.33464 14.9999V8.33325C3.33464 7.41278 4.08083 6.66659 5.0013 6.66659Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Agent Framework</div><p class="MobileMenu_ListItemText__n_MHY">Orchestrate and deploy multi-agent applications over your data with the #1 agent framework.</p></a></li></ul></details></li><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Solutions<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/finance"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 6.66675H8.33073C7.8887 6.66675 7.46478 6.84234 7.15222 7.1549C6.83966 7.46746 6.66406 7.89139 6.66406 8.33342C6.66406 8.77544 6.83966 9.19937 7.15222 9.51193C7.46478 9.82449 7.8887 10.0001 8.33073 10.0001H11.6641C12.1061 10.0001 12.53 10.1757 12.8426 10.4882C13.1551 10.8008 13.3307 11.2247 13.3307 11.6667C13.3307 12.1088 13.1551 12.5327 12.8426 12.8453C12.53 13.1578 12.1061 13.3334 11.6641 13.3334H6.66406M9.9974 15.0001V5.00008M18.3307 10.0001C18.3307 14.6025 14.5998 18.3334 9.9974 18.3334C5.39502 18.3334 1.66406 14.6025 1.66406 10.0001C1.66406 5.39771 5.39502 1.66675 9.9974 1.66675C14.5998 1.66675 18.3307 5.39771 18.3307 10.0001Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Financial Analysts</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/administrative-operations"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1.66406 6.66659V15.8333C1.66406 16.2753 1.83966 16.6992 2.15222 17.0118C2.46478 17.3243 2.8887 17.4999 3.33073 17.4999H14.9974M16.6641 14.1666C17.1061 14.1666 17.53 13.991 17.8426 13.6784C18.1551 13.3659 18.3307 12.9419 18.3307 12.4999V7.49992C18.3307 7.05789 18.1551 6.63397 17.8426 6.32141C17.53 6.00885 17.1061 5.83325 16.6641 5.83325H13.4141C13.1353 5.83598 12.8604 5.76876 12.6143 5.63774C12.3683 5.50671 12.159 5.31606 12.0057 5.08325L11.3307 4.08325C11.179 3.85281 10.9724 3.66365 10.7295 3.53275C10.4866 3.40185 10.215 3.3333 9.93906 3.33325H6.66406C6.22204 3.33325 5.79811 3.50885 5.48555 3.82141C5.17299 4.13397 4.9974 4.55789 4.9974 4.99992V12.4999C4.9974 12.9419 5.17299 13.3659 5.48555 13.6784C5.79811 13.991 6.22204 14.1666 6.66406 14.1666H16.6641Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Administrative Operations</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/engineering"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 15L18.3307 10L13.3307 5M6.66406 5L1.66406 10L6.66406 15" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Engineering &amp; R&amp;D</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/customer-support"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.9974 7.50008H16.6641C17.1061 7.50008 17.53 7.67568 17.8426 7.98824C18.1551 8.3008 18.3307 8.72472 18.3307 9.16675V18.3334L14.9974 15.0001H9.9974C9.55537 15.0001 9.13145 14.8245 8.81888 14.5119C8.50632 14.1994 8.33073 13.7754 8.33073 13.3334V12.5001M11.6641 7.50008C11.6641 7.94211 11.4885 8.36603 11.1759 8.67859C10.8633 8.99115 10.4394 9.16675 9.9974 9.16675H4.9974L1.66406 12.5001V3.33341C1.66406 2.41675 2.41406 1.66675 3.33073 1.66675H9.9974C10.4394 1.66675 10.8633 1.84234 11.1759 2.1549C11.4885 2.46746 11.6641 2.89139 11.6641 3.33341V7.50008Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Customer Support</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/healthcare-pharma"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M17.0128 3.81671C16.5948 3.39719 16.098 3.06433 15.551 2.8372C15.004 2.61008 14.4176 2.49316 13.8253 2.49316C13.2331 2.49316 12.6466 2.61008 12.0996 2.8372C11.5527 3.06433 11.0559 3.39719 10.6378 3.81671L9.99617 4.46671L9.3545 3.81671C8.93643 3.39719 8.43967 3.06433 7.89268 2.8372C7.3457 2.61008 6.75926 2.49316 6.167 2.49316C5.57474 2.49316 4.9883 2.61008 4.44132 2.8372C3.89433 3.06433 3.39756 3.39719 2.9795 3.81671C1.21283 5.58338 1.1045 8.56671 3.3295 10.8334L9.99617 17.5L16.6628 10.8334C18.8878 8.56671 18.7795 5.58338 17.0128 3.81671Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M2.91406 9.99992H7.91406L8.33073 9.16659L9.9974 12.9166L11.6641 7.08325L12.9141 9.99992H17.0807" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Healthcare / Pharma</div></a></li></ul></details></li><li><a class="MobileMenu_Link__5frcx" href="/community">Community</a></li><li><a class="MobileMenu_Link__5frcx" href="/pricing">Pricing</a></li><li><a class="MobileMenu_Link__5frcx" href="/blog">Blog</a></li><li><a class="MobileMenu_Link__5frcx" href="/customers">Customer stories</a></li><li><a class="MobileMenu_Link__5frcx" href="/careers">Careers</a></li></ul></nav><a href="/contact" class="Button_button-variant-ghost__o2AbG Button_button__aJ0V6" data-tracking-variant="ghost"> <!-- -->Talk to us</a><ul class="Socials_socials__8Y_s5 Socials_socials-theme-dark__Hq8lc MobileMenu_socials__JykCO"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu MobileMenu_copyright__nKVOs">© <!-- -->2025<!-- --> LlamaIndex</p></div></header><main><section class="BlogPost_post__JHNzd"><img alt="" loading="lazy" width="800" height="1176" decoding="async" data-nimg="1" class="BlogPost_featuredImage__KGxwX" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fa648cc90b9363a4d64a84cf4505057a0d9ebfa16-3840x2352.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fa648cc90b9363a4d64a84cf4505057a0d9ebfa16-3840x2352.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fa648cc90b9363a4d64a84cf4505057a0d9ebfa16-3840x2352.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><p class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-600__fKYth BlogPost_date__6uxQw"><a class="BlogPost_author__mesdl" href="/blog/author/ravi-theja">Ravi Theja</a> <!-- -->•<!-- --> <!-- -->2024-01-31</p><h1 class="Text_text__zPO0D Text_text-size-32__koGps BlogPost_title__b2lqJ">LlamaIndex: Enhancing Retrieval Performance with Alpha Tuning in Hybrid Search in RAG</h1><ul class="BlogPost_tags__13pBH"><li><a class="Badge_badge___1ssn" href="/blog/tag/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Llamaindex</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/llm"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">LLM</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/openai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">OpenAI</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/retrieval-augmented"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Retrieval Augmented</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">AI</span></a></li></ul><div class="BlogPost_htmlPost__Z5oDL"><h1>Introduction</h1><p>Retrieving the appropriate chunks, nodes, or context is a critical aspect of building an efficient Retrieval-Augmented Generation (RAG) application. However, a vector or embedding-based search may not be effective for all types of user queries.</p><p>To address this, <a href="https://weaviate.io/blog/hybrid-search-explained" rel="noopener ugc nofollow" target="_blank">Hybrid search</a> combines both keyword-based methods (BM25) and vector (embedding) search techniques. Hybrid search has a specific parameter, <code class="cw pq pr ps pt b">Alpha</code> to balance the weightage between keyword (BM25) and vector search in retrieving the right context for your RAG application. (alpha=0.0 - keyword search (BM25) and alpha=1.0 - vector search)</p><p>But here’s where it gets interesting: fine-tuning Alpha isn’t just a task; it’s an art form. Achieving the ideal balance is crucial for unlocking the full potential of hybrid search. This involves adjusting different Alpha values for various types of user queries in your RAG system.</p><p>In this blog post, we will look into tuning Alpha within the Weaviate vector database using the <code class="cw pq pr ps pt b"><a href="https://docs.llamaindex.ai/en/stable/examples/evaluation/retrieval/retriever_eval.html" rel="noopener ugc nofollow" target="_blank"><strong>Retrieval Evaluation</strong></a></code> module of LlamaIndex with and without rerankers with the help of Hit Rate and MRR metrics.</p><p>Before diving into the implementation, let’s first understand the different query types and metrics we will be using in this article.</p><h1>Different User Query Types:</h1><p>User queries in an RAG application vary based on individual intent. For these diverse query types, it’s essential to fine-tune the <code class="cw pq pr ps pt b"><strong>Alpha</strong></code> parameter. This process involves routing each user query to a specific <code class="cw pq pr ps pt b"><strong>Alpha</strong></code> value for effective retrieval and response synthesis. <a href="https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/azure-ai-search-outperforming-vector-search-with-hybrid/ba-p/3929167" rel="noopener ugc nofollow" target="_blank">Microsoft</a> has identified various user query categories, and we have selected a few for tuning our hybrid search. Below are the different user query types we considered:</p><ol><li><strong>Web Search Queries:</strong> Brief queries similar to those typically inputted into search engines.</li><li><strong>Concept Seeking Queries:</strong> Abstract questions that necessitate detailed, multi-sentence answers.</li><li><strong>Fact Seeking Queries:</strong> Queries that have a single, definitive answer.</li><li><strong>Keyword Queries:</strong> Concise queries composed solely of crucial identifier words.</li><li><strong>Queries With Misspellings:</strong> Queries containing typos, transpositions, and common misspellings.</li><li><strong>Exact Sub-string Searches:</strong> Queries that exactly match sub-strings from the original context.</li></ol><p>Let’s look at sample examples in each of these different user query types:</p><ol><li><strong>Web Search Queries</strong></li></ol><blockquote><p id="2417" class="om on qf oo b op pk or os ot pl ov ow ox pm oz pa pb pn pd pe pf po ph pi pj gm bj"><code class="cw pq pr ps pt b"><em class="gt">Transfer capabilities of LLaMA language model to non-English languages</em></code></p></blockquote><p><strong>2. Concept Seeking Queries</strong></p><blockquote><p id="698f" class="om on qf oo b op pk or os ot pl ov ow ox pm oz pa pb pn pd pe pf po ph pi pj gm bj"><code class="cw pq pr ps pt b"><em class="gt">What is the dual-encoder architecture used in recent works on dense retrievers?</em></code></p></blockquote><p><strong>3. Fact Seeking Queries</strong></p><blockquote><p id="c017" class="om on qf oo b op pk or os ot pl ov ow ox pm oz pa pb pn pd pe pf po ph pi pj gm bj"><code class="cw pq pr ps pt b"><em class="gt">What is the total number of propositions the English Wikipedia dump is segmented into in FACTOID WIKI?</em></code></p></blockquote><p><strong>4. Keyword Queries</strong></p><blockquote><p id="1497" class="om on qf oo b op pk or os ot pl ov ow ox pm oz pa pb pn pd pe pf po ph pi pj gm bj"><code class="cw pq pr ps pt b"><em class="gt">GTR retriever recall rate</em></code></p></blockquote><p><strong>5. Queries With Misspellings</strong></p><blockquote><p id="3608" class="om on qf oo b op pk or os ot pl ov ow ox pm oz pa pb pn pd pe pf po ph pi pj gm bj"><code class="cw pq pr ps pt b"><em class="gt">What is the advntage of prposition retrieval over sentnce or passage retrieval?</em></code></p></blockquote><p><strong>6. Exact Sub-string Searches</strong></p><blockquote><p id="1d9a" class="om on qf oo b op pk or os ot pl ov ow ox pm oz pa pb pn pd pe pf po ph pi pj gm bj"><code class="cw pq pr ps pt b"><em class="gt">first kwords for the GTR retriever. Finer-grained</em></code></p></blockquote><h1>Retrieval Evaluation Metrics:</h1><p>We will utilize Hit Rate and MRR metrics for retrieval evaluation. Let’s get into understanding these metrics.</p><p><strong>Hit Rate:</strong></p><p>Hit Rate measures the proportion of queries for which the correct chunk/ context appears within the top-k results chunks/ contexts. Put simply, it evaluates how frequently our system correctly identifies the chunk within its top-k chunks.</p><p><strong>Mean Reciprocal Rank (MRR):</strong></p><p>MRR assesses a system’s accuracy by taking into account the position of the highest-ranking relevant chunk/ context for each query. It calculates the average of the inverse of these positions across all queries. For instance, if the first relevant chunk/ context is at the top of the list, its reciprocal rank is 1. If it’s the second item, the reciprocal rank becomes 1/2, and this pattern continues accordingly.</p><p>The remainder of this blog post is divided into two main sections:</p><ol><li>Implementing <code class="cw pq pr ps pt b"><strong>Alpha</strong></code> Tuning in Hybrid Search for Various Query Types.</li><li>Analyzing the results of two different document datasets:</li></ol><ul><li><strong>Indexing a Single Document:</strong> The <a href="https://arxiv.org/pdf/2312.04511.pdf" rel="noopener ugc nofollow" target="_blank">LLM Compiler Paper</a>.</li><li><strong>Indexing Three Documents:</strong> The <a href="https://arxiv.org/pdf/2312.04511.pdf" rel="noopener ugc nofollow" target="_blank">LLM Compiler</a>, <a href="https://arxiv.org/abs/2401.01055" rel="noopener ugc nofollow" target="_blank">Llama Beyond English</a>, and <a href="https://arxiv.org/abs/2312.06648" rel="noopener ugc nofollow" target="_blank">Dense X Retrieval</a> Papers.</li></ul><p>You can also continue following along in the <a href="https://colab.research.google.com/drive/1aiXqofZp7hSXuUdv2UGt_QoJa_liJDZ6?usp=sharing" rel="noopener ugc nofollow" target="_blank">Google Colab Notebook</a> from this point forward.</p><h1>Implementation</h1><p>We will adopt a systematic approach to implement the experimental workflow, which involves the following steps:</p><ol><li>Data Download.</li><li>Data Loading.</li><li>Weaviate Client Setup.</li><li>Index Creation and Node Insertion.</li><li>Define LLM (GPT-4)</li><li>Define CohereAI Reranker.</li><li>Generation of Synthetic Queries for Various Query Types.</li><li>Define CustomRetriever.</li><li>Functions for Retrieval Evaluation and Metrics Calculation.</li><li>Conducting Retrieval Evaluation for Different Query Types and Alpha Values.</li></ol><p>Let’s begin by defining some essential functions for our implementation.</p><ol><li><code class="cw pq pr ps pt b">get_weaviate_client</code> - sets up weaviate client.</li><li><code class="cw pq pr ps pt b">load_documents</code> - load the documents from the file path.</li><li><code class="cw pq pr ps pt b">create_nodes</code> - create nodes by chunking the documents using a text splitter.</li><li><code class="cw pq pr ps pt b">connect_index</code> - connect to weaviate index.</li><li><code class="cw pq pr ps pt b">insert_nodes_index</code> - insert nodes into the index.</li></ol><pre><span id="3466" class="qp np gt pt b bf qq qr l qs qt"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_weaviate_client</span>(<span class="hljs-params">api_key, url</span>):
  auth_config = weaviate.AuthApiKey(api_key=api_key)

  client = weaviate.Client(
    url=url,
    auth_client_secret=auth_config
  )
  <span class="hljs-keyword">return</span> client

<span class="hljs-keyword">def</span> <span class="hljs-title function_">load_documents</span>(<span class="hljs-params">file_path, num_pages=<span class="hljs-literal">None</span></span>):
  <span class="hljs-keyword">if</span> num_pages:
    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()[:num_pages]
  <span class="hljs-keyword">else</span>:
    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()
  <span class="hljs-keyword">return</span> documents

<span class="hljs-keyword">def</span> <span class="hljs-title function_">create_nodes</span>(<span class="hljs-params">documents, chunk_size=<span class="hljs-number">512</span>, chunk_overlap=<span class="hljs-number">0</span></span>):
  node_parser = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
  nodes = node_parser.get_nodes_from_documents(documents)
  <span class="hljs-keyword">return</span> nodes

<span class="hljs-keyword">def</span> <span class="hljs-title function_">connect_index</span>(<span class="hljs-params">weaviate_client</span>):
  vector_store = WeaviateVectorStore(weaviate_client=weaviate_client)
  storage_context = StorageContext.from_defaults(vector_store=vector_store)
  index = VectorStoreIndex([], storage_context=storage_context)
  <span class="hljs-keyword">return</span> index

<span class="hljs-keyword">def</span> <span class="hljs-title function_">insert_nodes_index</span>(<span class="hljs-params">index, nodes</span>):
  index.insert_nodes(nodes)</span></pre><ol><li><strong>Download Data</strong></li></ol><pre><span id="c7c7" class="qp np gt pt b bf qq qr l qs qt">!wget --user-agent "Mozilla" "https://arxiv.org/pdf/2312.04511.pdf" -O "llm_compiler.pdf"
!wget --user-agent "Mozilla" "https://arxiv.org/pdf/2401.01055.pdf" -O "llama_beyond_english.pdf"
!wget --user-agent "Mozilla" "https://arxiv.org/pdf/2312.06648.pdf" -O "dense_x_retrieval.pdf"</span></pre><p>2. <strong>Load Data</strong></p><pre><span id="3327" class="qp np gt pt b bf qq qr l qs qt"># load documents, we will skip references and appendices from the papers.
documents1 = load_documents("llm_compiler.pdf", 12)
documents2 = load_documents("dense_x_retrieval.pdf", 9)
documents3 = load_documents("llama_beyond_english.pdf", 7)

# create nodes
nodes1 = create_nodes(documents1)
nodes2 = create_nodes(documents2)
nodes3 = create_nodes(documents3)</span></pre><p>3. <strong>Setup Weaviate Client</strong></p><pre><span id="548f" class="qp np gt pt b bf qq qr l qs qt">url = 'cluster URL'
api_key = 'your api key'

client = get_weaviate_client(api_key, url)</span></pre><p>4. <strong>Create an Index and Insert Nodes.</strong></p><pre><span id="5f1d" class="qp np gt pt b bf qq qr l qs qt">index = connect_index(client)

insert_nodes_index(index, nodes1)</span></pre><p>5. <strong>Define LLM</strong></p><pre><span id="e9f5" class="qp np gt pt b bf qq qr l qs qt"># Deing LLM for query generation
llm = OpenAI(model='gpt-4', temperature=0.1)</span></pre><p>6. <strong>Create Synthetic Queries</strong></p><p>We will create queries as discussed earlier, check prompts for each of the query types in the notebook, and code for each type of query. Showing code snippet for reference.</p><pre><span id="c439" class="qp np gt pt b bf qq qr l qs qt">queries = generate_question_context_pairs(
    nodes, 
  llm=llm, 
  num_questions_per_chunk=<span class="hljs-number">2</span>, 
  qa_generate_prompt_tmpl = qa_template
)</span></pre><p>7. <strong>Define reranker</strong></p><pre><span id="72f4" class="qp np gt pt b bf qq qr l qs qt">reranker = CohereRerank(api_key=os.environ['COHERE_API_KEY'], top_n=4)</span></pre><p>8. <strong>Define CustomRetriever</strong></p><p>We will define <code class="cw pq pr ps pt b">CustomRetriever</code> class to perform retrieval operations with and without a reranker.</p><pre><span id="70a0" class="qp np gt pt b bf qq qr l qs qt"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CustomRetriever</span>(<span class="hljs-title class_ inherited__">BaseRetriever</span>):
    <span class="hljs-string">"""Custom retriever that performs hybrid search with and without reranker"""</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">
        self,
        vector_retriever: VectorIndexRetriever,
        reranker: CohereRerank
    </span>) -&amp;gt; <span class="hljs-literal">None</span>:
        <span class="hljs-string">"""Init params."""</span>

        self._vector_retriever = vector_retriever
        self._reranker = reranker

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_retrieve</span>(<span class="hljs-params">self, query_bundle: QueryBundle</span>) -&amp;gt; <span class="hljs-type">List</span>[NodeWithScore]:
        <span class="hljs-string">"""Retrieve nodes given query."""</span>

        retrieved_nodes = self._vector_retriever.retrieve(query_bundle)

        <span class="hljs-keyword">if</span> self._reranker != <span class="hljs-literal">None</span>:
            retrieved_nodes = self._reranker.postprocess_nodes(retrieved_nodes, query_bundle)
        <span class="hljs-keyword">else</span>:
            retrieved_nodes = retrieved_nodes[:<span class="hljs-number">4</span>]

        <span class="hljs-keyword">return</span> retrieved_nodes

    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">_aretrieve</span>(<span class="hljs-params">self, query_bundle: QueryBundle</span>) -&amp;gt; <span class="hljs-type">List</span>[NodeWithScore]:
        <span class="hljs-string">"""Asynchronously retrieve nodes given query.

        Implemented by the user.

        """</span>
        <span class="hljs-keyword">return</span> self._retrieve(query_bundle)

    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">aretrieve</span>(<span class="hljs-params">self, str_or_query_bundle: QueryType</span>) -&amp;gt; <span class="hljs-type">List</span>[NodeWithScore]:
        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(str_or_query_bundle, <span class="hljs-built_in">str</span>):
            str_or_query_bundle = QueryBundle(str_or_query_bundle)
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">await</span> self._aretrieve(str_or_query_bundle)</span></pre><p>9. <strong>Define functions for retriever evaluation and metrics computation</strong></p><p>We will look into retriever performance for different <code class="cw pq pr ps pt b">alpha</code> values with and without reranker.</p><pre><span id="2955" class="qp np gt pt b bf qq qr l qs qt"><span class="hljs-comment"># Alpha values and datasets to test</span>
alpha_values = [<span class="hljs-number">0.0</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.4</span>, <span class="hljs-number">0.6</span>, <span class="hljs-number">0.8</span>, <span class="hljs-number">1.0</span>]

<span class="hljs-comment"># Function to evaluate retriever and return results</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_retriever</span>(<span class="hljs-params">alpha, dataset, reranker=<span class="hljs-literal">None</span></span>):
    retriever = VectorIndexRetriever(index,
                                     vector_store_query_mode=<span class="hljs-string">"hybrid"</span>,
                                     similarity_top_k=<span class="hljs-number">10</span>,
                                     alpha=alpha)
    custom_retriever = CustomRetriever(retriever,
                                       reranker)

    retriever_evaluator = RetrieverEvaluator.from_metric_names([<span class="hljs-string">"mrr"</span>, <span class="hljs-string">"hit_rate"</span>], retriever=custom_retriever)
    eval_results = <span class="hljs-keyword">await</span> retriever_evaluator.aevaluate_dataset(dataset)
    <span class="hljs-keyword">return</span> eval_results

<span class="hljs-comment"># Function to calculate and store metrics</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_metrics</span>(<span class="hljs-params">eval_results</span>):
    metric_dicts = []
    <span class="hljs-keyword">for</span> eval_result <span class="hljs-keyword">in</span> eval_results:
        metric_dict = eval_result.metric_vals_dict
        metric_dicts.append(metric_dict)

    full_df = pd.DataFrame(metric_dicts)

    hit_rate = full_df[<span class="hljs-string">"hit_rate"</span>].mean()
    mrr = full_df[<span class="hljs-string">"mrr"</span>].mean()
    <span class="hljs-keyword">return</span> hit_rate, mrr</span></pre><p><strong>10. Retrieval Evaluation</strong></p><p>Here we do retrieval evaluation on different query types (datasets) and alpha values to understand which alpha will be suitable for which query type. You need to plug in the reranker accordingly to compute the retrieval evaluation with and without the reranker.</p><pre><span id="4b6f" class="qp np gt pt b bf qq qr l qs qt"><span class="hljs-comment"># Asynchronous function to loop over datasets and alpha values and evaluate</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():
    results_df = pd.DataFrame(columns=[<span class="hljs-string">'Dataset'</span>, <span class="hljs-string">'Alpha'</span>, <span class="hljs-string">'Hit Rate'</span>, <span class="hljs-string">'MRR'</span>])

    <span class="hljs-keyword">for</span> dataset <span class="hljs-keyword">in</span> datasets_single_document.keys():
        <span class="hljs-keyword">for</span> alpha <span class="hljs-keyword">in</span> alpha_values:
            eval_results = <span class="hljs-keyword">await</span> evaluate_retriever(alpha, datasets_single_document[dataset])
            hit_rate, mrr = calculate_metrics(eval_results)
            new_row = pd.DataFrame({<span class="hljs-string">'Dataset'</span>: [dataset], <span class="hljs-string">'Alpha'</span>: [alpha], <span class="hljs-string">'Hit Rate'</span>: [hit_rate], <span class="hljs-string">'MRR'</span>: [mrr]})
            results_df = pd.concat([results_df, new_row], ignore_index=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Determine the grid size for subplots</span>
    num_rows = <span class="hljs-built_in">len</span>(datasets_single_document) // <span class="hljs-number">2</span> + <span class="hljs-built_in">len</span>(datasets_single_document) % <span class="hljs-number">2</span>
    num_cols = <span class="hljs-number">2</span>

    <span class="hljs-comment"># Plotting the results in a grid</span>
    fig, axes = plt.subplots(num_rows, num_cols, figsize=(<span class="hljs-number">12</span>, num_rows * <span class="hljs-number">4</span>), squeeze=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># Ensure axes is always 2D</span>

    <span class="hljs-keyword">for</span> i, dataset <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(datasets_single_document):
        ax = axes[i // num_cols, i % num_cols]
        dataset_df = results_df[results_df[<span class="hljs-string">'Dataset'</span>] == dataset]
        ax.plot(dataset_df[<span class="hljs-string">'Alpha'</span>], dataset_df[<span class="hljs-string">'Hit Rate'</span>], marker=<span class="hljs-string">'o'</span>, label=<span class="hljs-string">'Hit Rate'</span>)
        ax.plot(dataset_df[<span class="hljs-string">'Alpha'</span>], dataset_df[<span class="hljs-string">'MRR'</span>], marker=<span class="hljs-string">'o'</span>, linestyle=<span class="hljs-string">'--'</span>, label=<span class="hljs-string">'MRR'</span>)
        ax.set_xlabel(<span class="hljs-string">'Alpha'</span>)
        ax.set_ylabel(<span class="hljs-string">'Metric Value'</span>)
        ax.set_title(<span class="hljs-string">f'<span class="hljs-subst">{dataset}</span>'</span>)
        ax.legend()
        ax.grid(<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># If the number of datasets is odd, remove the last (empty) subplot</span>
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(datasets_single_document) % num_cols != <span class="hljs-number">0</span>:
        fig.delaxes(axes[-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>])  <span class="hljs-comment"># Remove the last subplot if not needed</span>

    <span class="hljs-comment"># Adjust layout to prevent overlap</span>
    plt.tight_layout()
    plt.show()

<span class="hljs-comment"># Run the main function</span>
asyncio.run(main())</span></pre><h1>Analyze the results:</h1><p>Having completed the implementation phase, we now turn our attention to analyzing the outcomes. We conducted two sets of experiments: one on a single document and another on multiple documents. These experiments varied in alpha values, types of user queries, and the inclusion or exclusion of a reranker. The accompanying graphs display the results, focusing on the Hit Rate and MRR (Mean Reciprocal Rank) as retrieval evaluation metrics.</p><blockquote><p id="492d" class="om on qf oo b op pk or os ot pl ov ow ox pm oz pa pb pn pd pe pf po ph pi pj gm bj">P<!-- -->lease keep in mind that following observations are specific to the datasets used in our study. We encourage you to conduct the experiment with your own documents and draw your relevant observations and conclusions.</p></blockquote><h2><strong>With Single Document:</strong></h2><p><strong>Without Reranker:</strong></p><figure><img src="/blog/images/1*MvCcrI782Hex9AEB51srpA.png" alt="" width="700" height="701"></figure><p><strong>With Reranker:</strong></p><figure><img src="/blog/images/1*iAJP382Gm0I_cDN6CRQNxg.png" alt="" width="700" height="701"></figure><h2>With Multiple Documents:</h2><p><strong>Without Reranker:</strong></p><figure><img src="/blog/images/1*n5GtKtfgi5hI6-uznFgW8Q.png" alt="" width="700" height="701"></figure><p><strong>With Reranker:</strong></p><figure><img src="/blog/images/1*gi7oiwJmZswrgWCE5ttoMg.png" alt="" width="700" height="701"></figure><h1>Observations:</h1><ol><li>There is a boost in Hit Rate and MRR in single and multiple documents indexing with the help of a reranker. Time and again it proves using reranker is pretty useful in your RAG application.</li><li>Though most of the time hybrid search wins over keyword/ vector search, it should be carefully evaluated for different query types based on user queries in the RAG application.</li><li>The behavior is different when you index a single document and multiple documents, which suggests it’s always better to tune alpha as you add documents into the index.</li><li>Let’s look at a deeper analysis of different query types:</li></ol><ul><li><strong>Web Search Queries:</strong></li></ul><p>— MRR is higher with hybrid search with alpha=0.2/0.6 based on with/ without rerankers irrespective of single/ multiple documents indexing.</p><p>— The Hit rate is higher with alpha=1.0 for both single/ multiple documents indexing and with/ without rerankers.</p><ul><li><strong>Concept Seeking Queries:</strong></li></ul><p>— MRR and Hit Rate are higher with hybrid search (with different alpha values) in Multiple documents indexing.</p><p>— MRR and Hit Rate are higher at Alpha=0.0 indicating keyword search works better in Single document indexing. Should be noted that MRR has different behavior with and without reranking.</p><ul><li><strong>Fact Seeking Queries</strong></li></ul><p>— MRR and Hit Rate are higher with Hybrid search with/ without reranker in Multiple documents indexing.</p><p>— MRR and Hit Rate are higher with hybrid search with reranker and keyword search (alpha=0.0) is better without reranker in single documents indexing.</p><ul><li><strong>Keyword Queries</strong></li></ul><p>— MRR and Hit Rate are higher with Hybrid search with/ without reranker in Multiple documents indexing.</p><p>— MRR and Hit Rate are higher with hybrid search with reranker and keyword search is better without reranker in single documents indexing. (though MRR is slightly higher with alpha=0.2)</p><ul><li><strong>Queries With Misspellings</strong></li></ul><p>— MRR and Hit Rate are higher with Hybrid search with/ without reranker in single and multiple documents indexing. (Though in some cases hybrid search with alpha=1.0 wins).</p><p>— This also demonstrates that vector search performs better with misspelled queries, as keyword searches lose effectiveness in such cases.</p><ul><li><strong>Exact Sub-string Searches</strong></li></ul><p>— MRR and Hit Rate are higher with Keyword search with/ without reranker in Single documents indexing and without reranker in multiple documents indexing.</p><p>— MRR and Hit Rate are higher with Hybrid search (alpha=0.4) with reranker in multiple documents indexing.</p><h1>What’s Next?</h1><p>In this blog post, we looked into the tuning of Alpha in a hybrid search system for a range of query types. It was interesting to see how the results varied when indexing either a single document or multiple documents. Going forward, you might consider experimenting with documents from diverse domains, employing different query lengths for various query types. Should you come across any noteworthy observations, we encourage you to share them with us in the comments. It would certainly be interesting to discuss these findings with the wider community.</p><h1>References:</h1><ol><li><a href="https://weaviate.io/blog/hybrid-search-explained" rel="noopener ugc nofollow" target="_blank">Hybrid Search Explained</a></li><li><a href="https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/azure-ai-search-outperforming-vector-search-with-hybrid/ba-p/3929167" rel="noopener ugc nofollow" target="_blank">Azure AI Search: Outperforming vector search with hybrid retrieval and ranking capabilities</a></li></ol></div><div class="BlogPost_relatedPosts__0z6SN"><h2 class="Text_text__zPO0D Text_text-align-center__HhKqo Text_text-size-16__PkjFu Text_text-weight-400__5ENkK Text_text-family-spaceGrotesk__E4zcE BlogPost_relatedPostsTitle___JIrW">Related articles</h2><ul class="BlogPost_relatedPostsList__uOKzB"><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Faa21c9d353919277d4fce16f174e54280bda8660-1920x832.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Faa21c9d353919277d4fce16f174e54280bda8660-1920x832.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Faa21c9d353919277d4fce16f174e54280bda8660-1920x832.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/jamba-instruct-s-256k-context-window-on-llamaindex">Jamba-Instruct&#x27;s 256k context window on LlamaIndex</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-07-31</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F31290fcec6832b337689a39c17adf5d995ff46b6-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F31290fcec6832b337689a39c17adf5d995ff46b6-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F31290fcec6832b337689a39c17adf5d995ff46b6-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/llamaindex-newsletter-2024-04-02">LlamaIndex Newsletter 2024-04-02</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-04-02</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F67e9da6888edfa6119225413068198422f1eaf77-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F67e9da6888edfa6119225413068198422f1eaf77-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F67e9da6888edfa6119225413068198422f1eaf77-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/llamaindex-newsletter-2024-03-26">LlamaIndex Newsletter 2024-03-26</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-03-26</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F23819f5bd086643f28ca7d2746a9e400f28cdbee-1023x561.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F23819f5bd086643f28ca7d2746a9e400f28cdbee-1023x561.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F23819f5bd086643f28ca7d2746a9e400f28cdbee-1023x561.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations">Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-03-19</p></div></li></ul></div></section></main><footer class="Footer_footer__eNA9m"><div class="Footer_navContainer__7bvx4"><div class="Footer_logoContainer__3EpzI"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" style="color:transparent" src="/llamaindex.svg"/><div class="Footer_socialContainer__GdOgk"><ul class="Socials_socials__8Y_s5"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul></div></div><div class="Footer_nav__BLEuE"><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/">LlamaIndex</a></h3><ul><li><a href="/blog"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Blog</span></a></li><li><a href="/partners"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Partners</span></a></li><li><a href="/careers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Careers</span></a></li><li><a href="/contact"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Contact</span></a></li><li><a href="/brand"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Brand</span></a></li><li><a href="https://llamaindex.statuspage.io" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Status</span></a></li><li><a href="https://app.vanta.com/runllama.ai/trust/pkcgbjf8b3ihxjpqdx17nu" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Trust Center</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/enterprise">Enterprise</a></h3><ul><li><a href="https://cloud.llamaindex.ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaCloud</span></a></li><li><a href="https://cloud.llamaindex.ai/parse" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaParse</span></a></li><li><a href="/customers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Customers</span></a></li><li><a href="/llamacloud-sharepoint-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SharePoint</span></a></li><li><a href="/llamacloud-aws-s3-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">AWS S3</span></a></li><li><a href="/llamacloud-azure-blob-storage-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure Blob Storage</span></a></li><li><a href="/llamacloud-google-drive-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Google Drive</span></a></li> </ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/framework">Framework</a></h3><ul><li><a href="https://pypi.org/project/llama-index/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python package</span></a></li><li><a href="https://docs.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python docs</span></a></li><li><a href="https://www.npmjs.com/package/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript package</span></a></li><li><a href="https://ts.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript docs</span></a></li><li><a href="https://llamahub.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaHub</span></a></li><li><a href="https://github.com/run-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">GitHub</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/community">Community</a></h3><ul><li><a href="/community#newsletter"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Newsletter</span></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Discord</span></a></li><li><a href="https://www.linkedin.com/company/91154103/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LinkedIn</span></a></li><li><a href="https://twitter.com/llama_index"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Twitter/X</span></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">YouTube</span></a></li><li><a href="https://bsky.app/profile/llamaindex.bsky.social"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">BlueSky</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e">Starter projects</h3><ul><li><a href="https://www.npmjs.com/package/create-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">create-llama</span></a></li><li><a href="https://secinsights.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SEC Insights</span></a></li><li><a href="https://github.com/run-llama/llamabot"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaBot</span></a></li><li><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/rag_cli.html"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">RAG CLI</span></a></li></ul></div></div></div><div class="Footer_copyrightContainer__mBKsT"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA">© <!-- -->2025<!-- --> LlamaIndex</p><div class="Footer_legalNav__O1yJA"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/privacy-notice.pdf">Privacy Notice</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/terms-of-service.pdf">Terms of Service</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="https://bit.ly/llamaindexdpa">Data Processing Addendum</a></p></div></div></footer></div><svg xmlns="http://www.w3.org/2000/svg" class="flt_svg" style="display:none"><defs><filter id="flt_tag"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="2"></feGaussianBlur><feColorMatrix in="blur" result="flt_tag" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="flt_tag" operator="atop"></feComposite></filter><filter id="svg_blur_large"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="8"></feGaussianBlur><feColorMatrix in="blur" result="svg_blur_large" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="svg_blur_large" operator="atop"></feComposite></filter></defs></svg></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"page":{"announcement":{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"},"post":{"_createdAt":"2024-02-22T21:47:07Z","_id":"dcd3498c-b32b-4778-a1ad-617597fba58e","_rev":"TLgH6AcXrxoqw75SBDhnLT","_type":"blogPost","_updatedAt":"2025-05-21T20:40:05Z","announcement":[{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"}],"authors":[{"_createdAt":"2024-02-22T19:58:55Z","_id":"60575af5-a5c2-40f6-9aab-d5e02da9c000","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"people","_updatedAt":"2024-02-24T20:08:04Z","name":"Ravi Theja","slug":{"_type":"slug","current":"ravi-theja"}}],"featured":false,"htmlContent":"\u003ch1\u003eIntroduction\u003c/h1\u003e\u003cp\u003eRetrieving the appropriate chunks, nodes, or context is a critical aspect of building an efficient Retrieval-Augmented Generation (RAG) application. However, a vector or embedding-based search may not be effective for all types of user queries.\u003c/p\u003e\u003cp\u003eTo address this, \u003ca href=\"https://weaviate.io/blog/hybrid-search-explained\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHybrid search\u003c/a\u003e combines both keyword-based methods (BM25) and vector (embedding) search techniques. Hybrid search has a specific parameter, \u003ccode class=\"cw pq pr ps pt b\"\u003eAlpha\u003c/code\u003e to balance the weightage between keyword (BM25) and vector search in retrieving the right context for your RAG application. (alpha=0.0 - keyword search (BM25) and alpha=1.0 - vector search)\u003c/p\u003e\u003cp\u003eBut here’s where it gets interesting: fine-tuning Alpha isn’t just a task; it’s an art form. Achieving the ideal balance is crucial for unlocking the full potential of hybrid search. This involves adjusting different Alpha values for various types of user queries in your RAG system.\u003c/p\u003e\u003cp\u003eIn this blog post, we will look into tuning Alpha within the Weaviate vector database using the \u003ccode class=\"cw pq pr ps pt b\"\u003e\u003ca href=\"https://docs.llamaindex.ai/en/stable/examples/evaluation/retrieval/retriever_eval.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eRetrieval Evaluation\u003c/strong\u003e\u003c/a\u003e\u003c/code\u003e module of LlamaIndex with and without rerankers with the help of Hit Rate and MRR metrics.\u003c/p\u003e\u003cp\u003eBefore diving into the implementation, let’s first understand the different query types and metrics we will be using in this article.\u003c/p\u003e\u003ch1\u003eDifferent User Query Types:\u003c/h1\u003e\u003cp\u003eUser queries in an RAG application vary based on individual intent. For these diverse query types, it’s essential to fine-tune the \u003ccode class=\"cw pq pr ps pt b\"\u003e\u003cstrong\u003eAlpha\u003c/strong\u003e\u003c/code\u003e parameter. This process involves routing each user query to a specific \u003ccode class=\"cw pq pr ps pt b\"\u003e\u003cstrong\u003eAlpha\u003c/strong\u003e\u003c/code\u003e value for effective retrieval and response synthesis. \u003ca href=\"https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/azure-ai-search-outperforming-vector-search-with-hybrid/ba-p/3929167\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMicrosoft\u003c/a\u003e has identified various user query categories, and we have selected a few for tuning our hybrid search. Below are the different user query types we considered:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eWeb Search Queries:\u003c/strong\u003e Brief queries similar to those typically inputted into search engines.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eConcept Seeking Queries:\u003c/strong\u003e Abstract questions that necessitate detailed, multi-sentence answers.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eFact Seeking Queries:\u003c/strong\u003e Queries that have a single, definitive answer.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eKeyword Queries:\u003c/strong\u003e Concise queries composed solely of crucial identifier words.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eQueries With Misspellings:\u003c/strong\u003e Queries containing typos, transpositions, and common misspellings.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eExact Sub-string Searches:\u003c/strong\u003e Queries that exactly match sub-strings from the original context.\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eLet’s look at sample examples in each of these different user query types:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eWeb Search Queries\u003c/strong\u003e\u003c/li\u003e\u003c/ol\u003e\u003cblockquote\u003e\u003cp id=\"2417\" class=\"om on qf oo b op pk or os ot pl ov ow ox pm oz pa pb pn pd pe pf po ph pi pj gm bj\"\u003e\u003ccode class=\"cw pq pr ps pt b\"\u003e\u003cem class=\"gt\"\u003eTransfer capabilities of LLaMA language model to non-English languages\u003c/em\u003e\u003c/code\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003e\u003cstrong\u003e2. Concept Seeking Queries\u003c/strong\u003e\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"698f\" class=\"om on qf oo b op pk or os ot pl ov ow ox pm oz pa pb pn pd pe pf po ph pi pj gm bj\"\u003e\u003ccode class=\"cw pq pr ps pt b\"\u003e\u003cem class=\"gt\"\u003eWhat is the dual-encoder architecture used in recent works on dense retrievers?\u003c/em\u003e\u003c/code\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003e\u003cstrong\u003e3. Fact Seeking Queries\u003c/strong\u003e\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"c017\" class=\"om on qf oo b op pk or os ot pl ov ow ox pm oz pa pb pn pd pe pf po ph pi pj gm bj\"\u003e\u003ccode class=\"cw pq pr ps pt b\"\u003e\u003cem class=\"gt\"\u003eWhat is the total number of propositions the English Wikipedia dump is segmented into in FACTOID WIKI?\u003c/em\u003e\u003c/code\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003e\u003cstrong\u003e4. Keyword Queries\u003c/strong\u003e\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"1497\" class=\"om on qf oo b op pk or os ot pl ov ow ox pm oz pa pb pn pd pe pf po ph pi pj gm bj\"\u003e\u003ccode class=\"cw pq pr ps pt b\"\u003e\u003cem class=\"gt\"\u003eGTR retriever recall rate\u003c/em\u003e\u003c/code\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003e\u003cstrong\u003e5. Queries With Misspellings\u003c/strong\u003e\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"3608\" class=\"om on qf oo b op pk or os ot pl ov ow ox pm oz pa pb pn pd pe pf po ph pi pj gm bj\"\u003e\u003ccode class=\"cw pq pr ps pt b\"\u003e\u003cem class=\"gt\"\u003eWhat is the advntage of prposition retrieval over sentnce or passage retrieval?\u003c/em\u003e\u003c/code\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003e\u003cstrong\u003e6. Exact Sub-string Searches\u003c/strong\u003e\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"1d9a\" class=\"om on qf oo b op pk or os ot pl ov ow ox pm oz pa pb pn pd pe pf po ph pi pj gm bj\"\u003e\u003ccode class=\"cw pq pr ps pt b\"\u003e\u003cem class=\"gt\"\u003efirst kwords for the GTR retriever. Finer-grained\u003c/em\u003e\u003c/code\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003ch1\u003eRetrieval Evaluation Metrics:\u003c/h1\u003e\u003cp\u003eWe will utilize Hit Rate and MRR metrics for retrieval evaluation. Let’s get into understanding these metrics.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHit Rate:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eHit Rate measures the proportion of queries for which the correct chunk/ context appears within the top-k results chunks/ contexts. Put simply, it evaluates how frequently our system correctly identifies the chunk within its top-k chunks.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eMean Reciprocal Rank (MRR):\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eMRR assesses a system’s accuracy by taking into account the position of the highest-ranking relevant chunk/ context for each query. It calculates the average of the inverse of these positions across all queries. For instance, if the first relevant chunk/ context is at the top of the list, its reciprocal rank is 1. If it’s the second item, the reciprocal rank becomes 1/2, and this pattern continues accordingly.\u003c/p\u003e\u003cp\u003eThe remainder of this blog post is divided into two main sections:\u003c/p\u003e\u003col\u003e\u003cli\u003eImplementing \u003ccode class=\"cw pq pr ps pt b\"\u003e\u003cstrong\u003eAlpha\u003c/strong\u003e\u003c/code\u003e Tuning in Hybrid Search for Various Query Types.\u003c/li\u003e\u003cli\u003eAnalyzing the results of two different document datasets:\u003c/li\u003e\u003c/ol\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eIndexing a Single Document:\u003c/strong\u003e The \u003ca href=\"https://arxiv.org/pdf/2312.04511.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eLLM Compiler Paper\u003c/a\u003e.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eIndexing Three Documents:\u003c/strong\u003e The \u003ca href=\"https://arxiv.org/pdf/2312.04511.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eLLM Compiler\u003c/a\u003e, \u003ca href=\"https://arxiv.org/abs/2401.01055\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eLlama Beyond English\u003c/a\u003e, and \u003ca href=\"https://arxiv.org/abs/2312.06648\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDense X Retrieval\u003c/a\u003e Papers.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eYou can also continue following along in the \u003ca href=\"https://colab.research.google.com/drive/1aiXqofZp7hSXuUdv2UGt_QoJa_liJDZ6?usp=sharing\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGoogle Colab Notebook\u003c/a\u003e from this point forward.\u003c/p\u003e\u003ch1\u003eImplementation\u003c/h1\u003e\u003cp\u003eWe will adopt a systematic approach to implement the experimental workflow, which involves the following steps:\u003c/p\u003e\u003col\u003e\u003cli\u003eData Download.\u003c/li\u003e\u003cli\u003eData Loading.\u003c/li\u003e\u003cli\u003eWeaviate Client Setup.\u003c/li\u003e\u003cli\u003eIndex Creation and Node Insertion.\u003c/li\u003e\u003cli\u003eDefine LLM (GPT-4)\u003c/li\u003e\u003cli\u003eDefine CohereAI Reranker.\u003c/li\u003e\u003cli\u003eGeneration of Synthetic Queries for Various Query Types.\u003c/li\u003e\u003cli\u003eDefine CustomRetriever.\u003c/li\u003e\u003cli\u003eFunctions for Retrieval Evaluation and Metrics Calculation.\u003c/li\u003e\u003cli\u003eConducting Retrieval Evaluation for Different Query Types and Alpha Values.\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eLet’s begin by defining some essential functions for our implementation.\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003ccode class=\"cw pq pr ps pt b\"\u003eget_weaviate_client\u003c/code\u003e - sets up weaviate client.\u003c/li\u003e\u003cli\u003e\u003ccode class=\"cw pq pr ps pt b\"\u003eload_documents\u003c/code\u003e - load the documents from the file path.\u003c/li\u003e\u003cli\u003e\u003ccode class=\"cw pq pr ps pt b\"\u003ecreate_nodes\u003c/code\u003e - create nodes by chunking the documents using a text splitter.\u003c/li\u003e\u003cli\u003e\u003ccode class=\"cw pq pr ps pt b\"\u003econnect_index\u003c/code\u003e - connect to weaviate index.\u003c/li\u003e\u003cli\u003e\u003ccode class=\"cw pq pr ps pt b\"\u003einsert_nodes_index\u003c/code\u003e - insert nodes into the index.\u003c/li\u003e\u003c/ol\u003e\u003cpre\u003e\u003cspan id=\"3466\" class=\"qp np gt pt b bf qq qr l qs qt\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eget_weaviate_client\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eapi_key, url\u003c/span\u003e):\n  auth_config = weaviate.AuthApiKey(api_key=api_key)\n\n  client = weaviate.Client(\n    url=url,\n    auth_client_secret=auth_config\n  )\n  \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e client\n\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eload_documents\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003efile_path, num_pages=\u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e\u003c/span\u003e):\n  \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e num_pages:\n    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()[:num_pages]\n  \u003cspan class=\"hljs-keyword\"\u003eelse\u003c/span\u003e:\n    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n  \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e documents\n\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003ecreate_nodes\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003edocuments, chunk_size=\u003cspan class=\"hljs-number\"\u003e512\u003c/span\u003e, chunk_overlap=\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e\u003c/span\u003e):\n  node_parser = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n  nodes = node_parser.get_nodes_from_documents(documents)\n  \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e nodes\n\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003econnect_index\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eweaviate_client\u003c/span\u003e):\n  vector_store = WeaviateVectorStore(weaviate_client=weaviate_client)\n  storage_context = StorageContext.from_defaults(vector_store=vector_store)\n  index = VectorStoreIndex([], storage_context=storage_context)\n  \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e index\n\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003einsert_nodes_index\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eindex, nodes\u003c/span\u003e):\n  index.insert_nodes(nodes)\u003c/span\u003e\u003c/pre\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eDownload Data\u003c/strong\u003e\u003c/li\u003e\u003c/ol\u003e\u003cpre\u003e\u003cspan id=\"c7c7\" class=\"qp np gt pt b bf qq qr l qs qt\"\u003e!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2312.04511.pdf\" -O \"llm_compiler.pdf\"\n!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2401.01055.pdf\" -O \"llama_beyond_english.pdf\"\n!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2312.06648.pdf\" -O \"dense_x_retrieval.pdf\"\u003c/span\u003e\u003c/pre\u003e\u003cp\u003e2. \u003cstrong\u003eLoad Data\u003c/strong\u003e\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"3327\" class=\"qp np gt pt b bf qq qr l qs qt\"\u003e# load documents, we will skip references and appendices from the papers.\ndocuments1 = load_documents(\"llm_compiler.pdf\", 12)\ndocuments2 = load_documents(\"dense_x_retrieval.pdf\", 9)\ndocuments3 = load_documents(\"llama_beyond_english.pdf\", 7)\n\n# create nodes\nnodes1 = create_nodes(documents1)\nnodes2 = create_nodes(documents2)\nnodes3 = create_nodes(documents3)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003e3. \u003cstrong\u003eSetup Weaviate Client\u003c/strong\u003e\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"548f\" class=\"qp np gt pt b bf qq qr l qs qt\"\u003eurl = 'cluster URL'\napi_key = 'your api key'\n\nclient = get_weaviate_client(api_key, url)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003e4. \u003cstrong\u003eCreate an Index and Insert Nodes.\u003c/strong\u003e\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"5f1d\" class=\"qp np gt pt b bf qq qr l qs qt\"\u003eindex = connect_index(client)\n\ninsert_nodes_index(index, nodes1)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003e5. \u003cstrong\u003eDefine LLM\u003c/strong\u003e\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"e9f5\" class=\"qp np gt pt b bf qq qr l qs qt\"\u003e# Deing LLM for query generation\nllm = OpenAI(model='gpt-4', temperature=0.1)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003e6. \u003cstrong\u003eCreate Synthetic Queries\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWe will create queries as discussed earlier, check prompts for each of the query types in the notebook, and code for each type of query. Showing code snippet for reference.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"c439\" class=\"qp np gt pt b bf qq qr l qs qt\"\u003equeries = generate_question_context_pairs(\n    nodes, \n  llm=llm, \n  num_questions_per_chunk=\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, \n  qa_generate_prompt_tmpl = qa_template\n)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003e7. \u003cstrong\u003eDefine reranker\u003c/strong\u003e\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"72f4\" class=\"qp np gt pt b bf qq qr l qs qt\"\u003ereranker = CohereRerank(api_key=os.environ['COHERE_API_KEY'], top_n=4)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003e8. \u003cstrong\u003eDefine CustomRetriever\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWe will define \u003ccode class=\"cw pq pr ps pt b\"\u003eCustomRetriever\u003c/code\u003e class to perform retrieval operations with and without a reranker.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"70a0\" class=\"qp np gt pt b bf qq qr l qs qt\"\u003e\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eCustomRetriever\u003c/span\u003e(\u003cspan class=\"hljs-title class_ inherited__\"\u003eBaseRetriever\u003c/span\u003e):\n    \u003cspan class=\"hljs-string\"\u003e\"\"\"Custom retriever that performs hybrid search with and without reranker\"\"\"\u003c/span\u003e\n\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003e\n        self,\n        vector_retriever: VectorIndexRetriever,\n        reranker: CohereRerank\n    \u003c/span\u003e) -\u0026amp;gt; \u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e:\n        \u003cspan class=\"hljs-string\"\u003e\"\"\"Init params.\"\"\"\u003c/span\u003e\n\n        self._vector_retriever = vector_retriever\n        self._reranker = reranker\n\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e_retrieve\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, query_bundle: QueryBundle\u003c/span\u003e) -\u0026amp;gt; \u003cspan class=\"hljs-type\"\u003eList\u003c/span\u003e[NodeWithScore]:\n        \u003cspan class=\"hljs-string\"\u003e\"\"\"Retrieve nodes given query.\"\"\"\u003c/span\u003e\n\n        retrieved_nodes = self._vector_retriever.retrieve(query_bundle)\n\n        \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e self._reranker != \u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e:\n            retrieved_nodes = self._reranker.postprocess_nodes(retrieved_nodes, query_bundle)\n        \u003cspan class=\"hljs-keyword\"\u003eelse\u003c/span\u003e:\n            retrieved_nodes = retrieved_nodes[:\u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e]\n\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e retrieved_nodes\n\n    \u003cspan class=\"hljs-keyword\"\u003easync\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e_aretrieve\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, query_bundle: QueryBundle\u003c/span\u003e) -\u0026amp;gt; \u003cspan class=\"hljs-type\"\u003eList\u003c/span\u003e[NodeWithScore]:\n        \u003cspan class=\"hljs-string\"\u003e\"\"\"Asynchronously retrieve nodes given query.\n\n        Implemented by the user.\n\n        \"\"\"\u003c/span\u003e\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e self._retrieve(query_bundle)\n\n    \u003cspan class=\"hljs-keyword\"\u003easync\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003earetrieve\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, str_or_query_bundle: QueryType\u003c/span\u003e) -\u0026amp;gt; \u003cspan class=\"hljs-type\"\u003eList\u003c/span\u003e[NodeWithScore]:\n        \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003eisinstance\u003c/span\u003e(str_or_query_bundle, \u003cspan class=\"hljs-built_in\"\u003estr\u003c/span\u003e):\n            str_or_query_bundle = QueryBundle(str_or_query_bundle)\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eawait\u003c/span\u003e self._aretrieve(str_or_query_bundle)\u003c/span\u003e\u003c/pre\u003e\u003cp\u003e9. \u003cstrong\u003eDefine functions for retriever evaluation and metrics computation\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWe will look into retriever performance for different \u003ccode class=\"cw pq pr ps pt b\"\u003ealpha\u003c/code\u003e values with and without reranker.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"2955\" class=\"qp np gt pt b bf qq qr l qs qt\"\u003e\u003cspan class=\"hljs-comment\"\u003e# Alpha values and datasets to test\u003c/span\u003e\nalpha_values = [\u003cspan class=\"hljs-number\"\u003e0.0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.4\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.6\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1.0\u003c/span\u003e]\n\n\u003cspan class=\"hljs-comment\"\u003e# Function to evaluate retriever and return results\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003easync\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eevaluate_retriever\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003ealpha, dataset, reranker=\u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e\u003c/span\u003e):\n    retriever = VectorIndexRetriever(index,\n                                     vector_store_query_mode=\u003cspan class=\"hljs-string\"\u003e\"hybrid\"\u003c/span\u003e,\n                                     similarity_top_k=\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e,\n                                     alpha=alpha)\n    custom_retriever = CustomRetriever(retriever,\n                                       reranker)\n\n    retriever_evaluator = RetrieverEvaluator.from_metric_names([\u003cspan class=\"hljs-string\"\u003e\"mrr\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"hit_rate\"\u003c/span\u003e], retriever=custom_retriever)\n    eval_results = \u003cspan class=\"hljs-keyword\"\u003eawait\u003c/span\u003e retriever_evaluator.aevaluate_dataset(dataset)\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e eval_results\n\n\u003cspan class=\"hljs-comment\"\u003e# Function to calculate and store metrics\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003ecalculate_metrics\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eeval_results\u003c/span\u003e):\n    metric_dicts = []\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e eval_result \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e eval_results:\n        metric_dict = eval_result.metric_vals_dict\n        metric_dicts.append(metric_dict)\n\n    full_df = pd.DataFrame(metric_dicts)\n\n    hit_rate = full_df[\u003cspan class=\"hljs-string\"\u003e\"hit_rate\"\u003c/span\u003e].mean()\n    mrr = full_df[\u003cspan class=\"hljs-string\"\u003e\"mrr\"\u003c/span\u003e].mean()\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e hit_rate, mrr\u003c/span\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e10. Retrieval Evaluation\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eHere we do retrieval evaluation on different query types (datasets) and alpha values to understand which alpha will be suitable for which query type. You need to plug in the reranker accordingly to compute the retrieval evaluation with and without the reranker.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"4b6f\" class=\"qp np gt pt b bf qq qr l qs qt\"\u003e\u003cspan class=\"hljs-comment\"\u003e# Asynchronous function to loop over datasets and alpha values and evaluate\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003easync\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003emain\u003c/span\u003e():\n    results_df = pd.DataFrame(columns=[\u003cspan class=\"hljs-string\"\u003e'Dataset'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'Alpha'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'Hit Rate'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'MRR'\u003c/span\u003e])\n\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e dataset \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e datasets_single_document.keys():\n        \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e alpha \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e alpha_values:\n            eval_results = \u003cspan class=\"hljs-keyword\"\u003eawait\u003c/span\u003e evaluate_retriever(alpha, datasets_single_document[dataset])\n            hit_rate, mrr = calculate_metrics(eval_results)\n            new_row = pd.DataFrame({\u003cspan class=\"hljs-string\"\u003e'Dataset'\u003c/span\u003e: [dataset], \u003cspan class=\"hljs-string\"\u003e'Alpha'\u003c/span\u003e: [alpha], \u003cspan class=\"hljs-string\"\u003e'Hit Rate'\u003c/span\u003e: [hit_rate], \u003cspan class=\"hljs-string\"\u003e'MRR'\u003c/span\u003e: [mrr]})\n            results_df = pd.concat([results_df, new_row], ignore_index=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e)\n\n    \u003cspan class=\"hljs-comment\"\u003e# Determine the grid size for subplots\u003c/span\u003e\n    num_rows = \u003cspan class=\"hljs-built_in\"\u003elen\u003c/span\u003e(datasets_single_document) // \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e + \u003cspan class=\"hljs-built_in\"\u003elen\u003c/span\u003e(datasets_single_document) % \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e\n    num_cols = \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e\n\n    \u003cspan class=\"hljs-comment\"\u003e# Plotting the results in a grid\u003c/span\u003e\n    fig, axes = plt.subplots(num_rows, num_cols, figsize=(\u003cspan class=\"hljs-number\"\u003e12\u003c/span\u003e, num_rows * \u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e), squeeze=\u003cspan class=\"hljs-literal\"\u003eFalse\u003c/span\u003e)  \u003cspan class=\"hljs-comment\"\u003e# Ensure axes is always 2D\u003c/span\u003e\n\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e i, dataset \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003eenumerate\u003c/span\u003e(datasets_single_document):\n        ax = axes[i // num_cols, i % num_cols]\n        dataset_df = results_df[results_df[\u003cspan class=\"hljs-string\"\u003e'Dataset'\u003c/span\u003e] == dataset]\n        ax.plot(dataset_df[\u003cspan class=\"hljs-string\"\u003e'Alpha'\u003c/span\u003e], dataset_df[\u003cspan class=\"hljs-string\"\u003e'Hit Rate'\u003c/span\u003e], marker=\u003cspan class=\"hljs-string\"\u003e'o'\u003c/span\u003e, label=\u003cspan class=\"hljs-string\"\u003e'Hit Rate'\u003c/span\u003e)\n        ax.plot(dataset_df[\u003cspan class=\"hljs-string\"\u003e'Alpha'\u003c/span\u003e], dataset_df[\u003cspan class=\"hljs-string\"\u003e'MRR'\u003c/span\u003e], marker=\u003cspan class=\"hljs-string\"\u003e'o'\u003c/span\u003e, linestyle=\u003cspan class=\"hljs-string\"\u003e'--'\u003c/span\u003e, label=\u003cspan class=\"hljs-string\"\u003e'MRR'\u003c/span\u003e)\n        ax.set_xlabel(\u003cspan class=\"hljs-string\"\u003e'Alpha'\u003c/span\u003e)\n        ax.set_ylabel(\u003cspan class=\"hljs-string\"\u003e'Metric Value'\u003c/span\u003e)\n        ax.set_title(\u003cspan class=\"hljs-string\"\u003ef'\u003cspan class=\"hljs-subst\"\u003e{dataset}\u003c/span\u003e'\u003c/span\u003e)\n        ax.legend()\n        ax.grid(\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e)\n\n    \u003cspan class=\"hljs-comment\"\u003e# If the number of datasets is odd, remove the last (empty) subplot\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003elen\u003c/span\u003e(datasets_single_document) % num_cols != \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e:\n        fig.delaxes(axes[-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, -\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e])  \u003cspan class=\"hljs-comment\"\u003e# Remove the last subplot if not needed\u003c/span\u003e\n\n    \u003cspan class=\"hljs-comment\"\u003e# Adjust layout to prevent overlap\u003c/span\u003e\n    plt.tight_layout()\n    plt.show()\n\n\u003cspan class=\"hljs-comment\"\u003e# Run the main function\u003c/span\u003e\nasyncio.run(main())\u003c/span\u003e\u003c/pre\u003e\u003ch1\u003eAnalyze the results:\u003c/h1\u003e\u003cp\u003eHaving completed the implementation phase, we now turn our attention to analyzing the outcomes. We conducted two sets of experiments: one on a single document and another on multiple documents. These experiments varied in alpha values, types of user queries, and the inclusion or exclusion of a reranker. The accompanying graphs display the results, focusing on the Hit Rate and MRR (Mean Reciprocal Rank) as retrieval evaluation metrics.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"492d\" class=\"om on qf oo b op pk or os ot pl ov ow ox pm oz pa pb pn pd pe pf po ph pi pj gm bj\"\u003eP\u003c!-- --\u003elease keep in mind that following observations are specific to the datasets used in our study. We encourage you to conduct the experiment with your own documents and draw your relevant observations and conclusions.\u003c/p\u003e\u003c/blockquote\u003e\u003ch2\u003e\u003cstrong\u003eWith Single Document:\u003c/strong\u003e\u003c/h2\u003e\u003cp\u003e\u003cstrong\u003eWithout Reranker:\u003c/strong\u003e\u003c/p\u003e\u003cfigure\u003e\u003cimg src=\"/blog/images/1*MvCcrI782Hex9AEB51srpA.png\" alt=\"\" width=\"700\" height=\"701\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003eWith Reranker:\u003c/strong\u003e\u003c/p\u003e\u003cfigure\u003e\u003cimg src=\"/blog/images/1*iAJP382Gm0I_cDN6CRQNxg.png\" alt=\"\" width=\"700\" height=\"701\"\u003e\u003c/figure\u003e\u003ch2\u003eWith Multiple Documents:\u003c/h2\u003e\u003cp\u003e\u003cstrong\u003eWithout Reranker:\u003c/strong\u003e\u003c/p\u003e\u003cfigure\u003e\u003cimg src=\"/blog/images/1*n5GtKtfgi5hI6-uznFgW8Q.png\" alt=\"\" width=\"700\" height=\"701\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003eWith Reranker:\u003c/strong\u003e\u003c/p\u003e\u003cfigure\u003e\u003cimg src=\"/blog/images/1*gi7oiwJmZswrgWCE5ttoMg.png\" alt=\"\" width=\"700\" height=\"701\"\u003e\u003c/figure\u003e\u003ch1\u003eObservations:\u003c/h1\u003e\u003col\u003e\u003cli\u003eThere is a boost in Hit Rate and MRR in single and multiple documents indexing with the help of a reranker. Time and again it proves using reranker is pretty useful in your RAG application.\u003c/li\u003e\u003cli\u003eThough most of the time hybrid search wins over keyword/ vector search, it should be carefully evaluated for different query types based on user queries in the RAG application.\u003c/li\u003e\u003cli\u003eThe behavior is different when you index a single document and multiple documents, which suggests it’s always better to tune alpha as you add documents into the index.\u003c/li\u003e\u003cli\u003eLet’s look at a deeper analysis of different query types:\u003c/li\u003e\u003c/ol\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eWeb Search Queries:\u003c/strong\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e— MRR is higher with hybrid search with alpha=0.2/0.6 based on with/ without rerankers irrespective of single/ multiple documents indexing.\u003c/p\u003e\u003cp\u003e— The Hit rate is higher with alpha=1.0 for both single/ multiple documents indexing and with/ without rerankers.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eConcept Seeking Queries:\u003c/strong\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e— MRR and Hit Rate are higher with hybrid search (with different alpha values) in Multiple documents indexing.\u003c/p\u003e\u003cp\u003e— MRR and Hit Rate are higher at Alpha=0.0 indicating keyword search works better in Single document indexing. Should be noted that MRR has different behavior with and without reranking.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eFact Seeking Queries\u003c/strong\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e— MRR and Hit Rate are higher with Hybrid search with/ without reranker in Multiple documents indexing.\u003c/p\u003e\u003cp\u003e— MRR and Hit Rate are higher with hybrid search with reranker and keyword search (alpha=0.0) is better without reranker in single documents indexing.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eKeyword Queries\u003c/strong\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e— MRR and Hit Rate are higher with Hybrid search with/ without reranker in Multiple documents indexing.\u003c/p\u003e\u003cp\u003e— MRR and Hit Rate are higher with hybrid search with reranker and keyword search is better without reranker in single documents indexing. (though MRR is slightly higher with alpha=0.2)\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eQueries With Misspellings\u003c/strong\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e— MRR and Hit Rate are higher with Hybrid search with/ without reranker in single and multiple documents indexing. (Though in some cases hybrid search with alpha=1.0 wins).\u003c/p\u003e\u003cp\u003e— This also demonstrates that vector search performs better with misspelled queries, as keyword searches lose effectiveness in such cases.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eExact Sub-string Searches\u003c/strong\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e— MRR and Hit Rate are higher with Keyword search with/ without reranker in Single documents indexing and without reranker in multiple documents indexing.\u003c/p\u003e\u003cp\u003e— MRR and Hit Rate are higher with Hybrid search (alpha=0.4) with reranker in multiple documents indexing.\u003c/p\u003e\u003ch1\u003eWhat’s Next?\u003c/h1\u003e\u003cp\u003eIn this blog post, we looked into the tuning of Alpha in a hybrid search system for a range of query types. It was interesting to see how the results varied when indexing either a single document or multiple documents. Going forward, you might consider experimenting with documents from diverse domains, employing different query lengths for various query types. Should you come across any noteworthy observations, we encourage you to share them with us in the comments. It would certainly be interesting to discuss these findings with the wider community.\u003c/p\u003e\u003ch1\u003eReferences:\u003c/h1\u003e\u003col\u003e\u003cli\u003e\u003ca href=\"https://weaviate.io/blog/hybrid-search-explained\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHybrid Search Explained\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/azure-ai-search-outperforming-vector-search-with-hybrid/ba-p/3929167\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAzure AI Search: Outperforming vector search with hybrid retrieval and ranking capabilities\u003c/a\u003e\u003c/li\u003e\u003c/ol\u003e","image":{"_type":"image","asset":{"_ref":"image-a648cc90b9363a4d64a84cf4505057a0d9ebfa16-3840x2352-png","_type":"reference"}},"mainImage":"https://cdn.sanity.io/images/7m9jw85w/production/a648cc90b9363a4d64a84cf4505057a0d9ebfa16-3840x2352.png","publishedDate":"2024-01-31","relatedPosts":[{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-aa21c9d353919277d4fce16f174e54280bda8660-1920x832-png","_type":"reference"}},"publishedDate":"2024-07-31","slug":"jamba-instruct-s-256k-context-window-on-llamaindex","title":"Jamba-Instruct's 256k context window on LlamaIndex"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-31290fcec6832b337689a39c17adf5d995ff46b6-1024x1024-webp","_type":"reference"}},"publishedDate":"2024-04-02","slug":"llamaindex-newsletter-2024-04-02","title":"LlamaIndex Newsletter 2024-04-02"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-67e9da6888edfa6119225413068198422f1eaf77-1024x1024-png","_type":"reference"}},"publishedDate":"2024-03-26","slug":"llamaindex-newsletter-2024-03-26","title":"LlamaIndex Newsletter 2024-03-26"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-23819f5bd086643f28ca7d2746a9e400f28cdbee-1023x561-png","_type":"reference"}},"publishedDate":"2024-03-19","slug":"supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations","title":"Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations"}],"slug":{"_type":"slug","current":"llamaindex-enhancing-retrieval-performance-with-alpha-tuning-in-hybrid-search-in-rag-135d0c9b8a00"},"tags":[{"_createdAt":"2024-02-22T20:19:11Z","_id":"17d4fc95-517c-4f4a-95ce-bf753e802ac4","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"llamaindex"},"title":"Llamaindex"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"aa7d304e-787e-4a6c-80cb-8911afd4c788","_rev":"jbUo4a8sS9GhVRG46mMVHT","_type":"blogTag","_updatedAt":"2024-03-13T16:00:26Z","slug":{"_type":"slug","current":"llm"},"title":"LLM"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"e171aa9d-bc85-4645-8a08-eabe04c530c7","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"openai"},"title":"OpenAI"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"ab1559f4-5cbd-47f4-ac89-7b293fc14f4b","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"retrieval-augmented"},"title":"Retrieval Augmented"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"d0a79109-34ab-41fa-a8f4-0b3522970c7d","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"ai"},"title":"AI"}],"title":"LlamaIndex: Enhancing Retrieval Performance with Alpha Tuning in Hybrid Search in RAG"},"publishedDate":"Invalid Date"},"params":{"slug":"llamaindex-enhancing-retrieval-performance-with-alpha-tuning-in-hybrid-search-in-rag-135d0c9b8a00"},"draftMode":false,"token":""},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"llamaindex-enhancing-retrieval-performance-with-alpha-tuning-in-hybrid-search-in-rag-135d0c9b8a00"},"buildId":"C8J-EMc_4OCN1ch65l4fl","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>