<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>Introducing workflows beta: a new way to create complex AI applications with LlamaIndex — LlamaIndex - Build Knowledge Assistants over your Enterprise Data</title><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><meta name="title" content="Introducing workflows beta: a new way to create complex AI applications with LlamaIndex — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta name="description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:title" content="Introducing workflows beta: a new way to create complex AI applications with LlamaIndex — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="og:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:image" content="https://cdn.sanity.io/images/7m9jw85w/production/3cf214bf62cde63dddeda80ea71515cd9eb0c42e-2471x2628.png"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="Introducing workflows beta: a new way to create complex AI applications with LlamaIndex — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="twitter:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="twitter:image" content="https://cdn.sanity.io/images/7m9jw85w/production/3cf214bf62cde63dddeda80ea71515cd9eb0c42e-2471x2628.png"/><link rel="alternate" type="application/rss+xml" href="https://www.llamaindex.ai/blog/feed"/><meta name="next-head-count" content="20"/><script>
            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WWRFB36R');
            </script><link rel="preload" href="/_next/static/css/41c9222e47d080c9.css" as="style"/><link rel="stylesheet" href="/_next/static/css/41c9222e47d080c9.css" data-n-g=""/><link rel="preload" href="/_next/static/css/97c33c8d95f1230e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/97c33c8d95f1230e.css" data-n-p=""/><link rel="preload" href="/_next/static/css/e009059e80bf60c5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e009059e80bf60c5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-1b629d9c8fb16f34.js" defer=""></script><script src="/_next/static/chunks/framework-df1f68dff096b68a.js" defer=""></script><script src="/_next/static/chunks/main-eca7952a704663f8.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c7c49437be49d2ad.js" defer=""></script><script src="/_next/static/chunks/d9067523-4985945b21298365.js" defer=""></script><script src="/_next/static/chunks/41155975-60c12da9ce9fa0b2.js" defer=""></script><script src="/_next/static/chunks/cb355538-cee2ea45674d9de3.js" defer=""></script><script src="/_next/static/chunks/9494-dff62cb53535dd7d.js" defer=""></script><script src="/_next/static/chunks/4063-39a391a51171ff87.js" defer=""></script><script src="/_next/static/chunks/6889-edfa85b69b88a372.js" defer=""></script><script src="/_next/static/chunks/5575-11ee0a29eaffae61.js" defer=""></script><script src="/_next/static/chunks/3444-95c636af25a42734.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-82c8e764e69afd2c.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_buildManifest.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_ssgManifest.js" defer=""></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WWRFB36R" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div class="__variable_d65c78 __variable_b1ea77 __variable_eb7534"><a class="Announcement_announcement__2ohK8" href="http://48755185.hs-sites.com/llamaindex-0">Meet LlamaIndex at the Databricks Data + AI Summit!<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M8.293 5.293a1 1 0 0 1 1.414 0l6 6a1 1 0 0 1 0 1.414l-6 6a1 1 0 0 1-1.414-1.414L13.586 12 8.293 6.707a1 1 0 0 1 0-1.414Z" clip-rule="evenodd"></path></svg></a><header class="Header_header__hO3lJ"><button class="Hamburger_hamburger__17auO Header_hamburger__lUulX"><svg width="28" height="28" viewBox="0 0 28 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.5 14H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" id="hamburger-stroke-top" class="Hamburger_hamburgerStrokeMiddle__I7VpD"></path><path d="M3.5 7H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeTop__oOhFM"></path><path d="M3.5 21H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeBottom__GIQR2"></path></svg></button><a aria-label="Homepage" href="/"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" class="Header_logo__e5KhT" style="color:transparent" src="/llamaindex.svg"/></a><nav aria-label="Main" data-orientation="horizontal" dir="ltr" style="--content-position:0px"><div style="position:relative"><ul data-orientation="horizontal" class="Nav_MenuList__PrCDJ" dir="ltr"><li><button id="radix-:R6tm:-trigger-radix-:R5mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R5mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Products</button></li><li><button id="radix-:R6tm:-trigger-radix-:R9mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R9mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Solutions</button></li><li><a class="Nav_Link__ZrzFc" href="/community" data-radix-collection-item="">Community</a></li><li><a class="Nav_Link__ZrzFc" href="/pricing" data-radix-collection-item="">Pricing</a></li><li><a class="Nav_Link__ZrzFc" href="/blog" data-radix-collection-item="">Blog</a></li><li><a class="Nav_Link__ZrzFc" href="/customers" data-radix-collection-item="">Customer stories</a></li><li><a class="Nav_Link__ZrzFc" href="/careers" data-radix-collection-item="">Careers</a></li></ul></div><div class="Nav_ViewportPosition__jmyHM"></div></nav><div class="Header_secondNav__YJvm8"><nav><a href="/contact" class="Link_link__71cl8 Link_link-variant-tertiary__BYxn_ Header_bookADemo__qCuxV">Book a demo</a></nav><a href="https://cloud.llamaindex.ai/" class="Button_button-variant-default__Oi__n Button_button__aJ0V6 Header_button__1HFhY" data-tracking-variant="default"> <!-- -->Get started</a></div><div class="MobileMenu_mobileMenu__g5Fa6"><nav class="MobileMenu_nav__EmtTw"><ul><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Products<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaparse"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.6654 1.66675V6.66675H16.6654M8.33203 10.8334L6.66536 12.5001L8.33203 14.1667M11.6654 14.1667L13.332 12.5001L11.6654 10.8334M12.082 1.66675H4.9987C4.55667 1.66675 4.13275 1.84234 3.82019 2.1549C3.50763 2.46746 3.33203 2.89139 3.33203 3.33341V16.6667C3.33203 17.1088 3.50763 17.5327 3.82019 17.8453C4.13275 18.1578 4.55667 18.3334 4.9987 18.3334H14.9987C15.4407 18.3334 15.8646 18.1578 16.1772 17.8453C16.4898 17.5327 16.6654 17.1088 16.6654 16.6667V6.25008L12.082 1.66675Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Document parsing</div><p class="MobileMenu_ListItemText__n_MHY">The first and leading GenAI-native parser over your most complex data.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaextract"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.668 1.66675V5.00008C11.668 5.44211 11.8436 5.86603 12.1561 6.17859C12.4687 6.49115 12.8926 6.66675 13.3346 6.66675H16.668M3.33464 5.83341V3.33341C3.33464 2.89139 3.51023 2.46746 3.82279 2.1549C4.13535 1.84234 4.55927 1.66675 5.0013 1.66675H12.5013L16.668 5.83341V16.6667C16.668 17.1088 16.4924 17.5327 16.1798 17.8453C15.8672 18.1578 15.4433 18.3334 15.0013 18.3334L5.05379 18.3326C4.72458 18.3755 4.39006 18.3191 4.09312 18.1706C3.79618 18.0221 3.55034 17.7884 3.38713 17.4992M4.16797 9.16675L1.66797 11.6667M1.66797 11.6667L4.16797 14.1667M1.66797 11.6667H10.0013" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Data extraction</div><p class="MobileMenu_ListItemText__n_MHY">Extract structured data from documents using a schema-driven engine.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/enterprise"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.16667 15.8333C12.8486 15.8333 15.8333 12.8486 15.8333 9.16667C15.8333 5.48477 12.8486 2.5 9.16667 2.5C5.48477 2.5 2.5 5.48477 2.5 9.16667C2.5 12.8486 5.48477 15.8333 9.16667 15.8333Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M17.5 17.5L13.875 13.875" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Knowledge Management</div><p class="MobileMenu_ListItemText__n_MHY">Connect, transform, and index your enterprise data into an agent-accessible knowledge base</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/framework"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.0013 6.66659V3.33325H6.66797M1.66797 11.6666H3.33464M16.668 11.6666H18.3346M12.5013 10.8333V12.4999M7.5013 10.8333V12.4999M5.0013 6.66659H15.0013C15.9218 6.66659 16.668 7.41278 16.668 8.33325V14.9999C16.668 15.9204 15.9218 16.6666 15.0013 16.6666H5.0013C4.08083 16.6666 3.33464 15.9204 3.33464 14.9999V8.33325C3.33464 7.41278 4.08083 6.66659 5.0013 6.66659Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Agent Framework</div><p class="MobileMenu_ListItemText__n_MHY">Orchestrate and deploy multi-agent applications over your data with the #1 agent framework.</p></a></li></ul></details></li><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Solutions<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/finance"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 6.66675H8.33073C7.8887 6.66675 7.46478 6.84234 7.15222 7.1549C6.83966 7.46746 6.66406 7.89139 6.66406 8.33342C6.66406 8.77544 6.83966 9.19937 7.15222 9.51193C7.46478 9.82449 7.8887 10.0001 8.33073 10.0001H11.6641C12.1061 10.0001 12.53 10.1757 12.8426 10.4882C13.1551 10.8008 13.3307 11.2247 13.3307 11.6667C13.3307 12.1088 13.1551 12.5327 12.8426 12.8453C12.53 13.1578 12.1061 13.3334 11.6641 13.3334H6.66406M9.9974 15.0001V5.00008M18.3307 10.0001C18.3307 14.6025 14.5998 18.3334 9.9974 18.3334C5.39502 18.3334 1.66406 14.6025 1.66406 10.0001C1.66406 5.39771 5.39502 1.66675 9.9974 1.66675C14.5998 1.66675 18.3307 5.39771 18.3307 10.0001Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Financial Analysts</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/administrative-operations"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1.66406 6.66659V15.8333C1.66406 16.2753 1.83966 16.6992 2.15222 17.0118C2.46478 17.3243 2.8887 17.4999 3.33073 17.4999H14.9974M16.6641 14.1666C17.1061 14.1666 17.53 13.991 17.8426 13.6784C18.1551 13.3659 18.3307 12.9419 18.3307 12.4999V7.49992C18.3307 7.05789 18.1551 6.63397 17.8426 6.32141C17.53 6.00885 17.1061 5.83325 16.6641 5.83325H13.4141C13.1353 5.83598 12.8604 5.76876 12.6143 5.63774C12.3683 5.50671 12.159 5.31606 12.0057 5.08325L11.3307 4.08325C11.179 3.85281 10.9724 3.66365 10.7295 3.53275C10.4866 3.40185 10.215 3.3333 9.93906 3.33325H6.66406C6.22204 3.33325 5.79811 3.50885 5.48555 3.82141C5.17299 4.13397 4.9974 4.55789 4.9974 4.99992V12.4999C4.9974 12.9419 5.17299 13.3659 5.48555 13.6784C5.79811 13.991 6.22204 14.1666 6.66406 14.1666H16.6641Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Administrative Operations</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/engineering"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 15L18.3307 10L13.3307 5M6.66406 5L1.66406 10L6.66406 15" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Engineering &amp; R&amp;D</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/customer-support"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.9974 7.50008H16.6641C17.1061 7.50008 17.53 7.67568 17.8426 7.98824C18.1551 8.3008 18.3307 8.72472 18.3307 9.16675V18.3334L14.9974 15.0001H9.9974C9.55537 15.0001 9.13145 14.8245 8.81888 14.5119C8.50632 14.1994 8.33073 13.7754 8.33073 13.3334V12.5001M11.6641 7.50008C11.6641 7.94211 11.4885 8.36603 11.1759 8.67859C10.8633 8.99115 10.4394 9.16675 9.9974 9.16675H4.9974L1.66406 12.5001V3.33341C1.66406 2.41675 2.41406 1.66675 3.33073 1.66675H9.9974C10.4394 1.66675 10.8633 1.84234 11.1759 2.1549C11.4885 2.46746 11.6641 2.89139 11.6641 3.33341V7.50008Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Customer Support</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/healthcare-pharma"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M17.0128 3.81671C16.5948 3.39719 16.098 3.06433 15.551 2.8372C15.004 2.61008 14.4176 2.49316 13.8253 2.49316C13.2331 2.49316 12.6466 2.61008 12.0996 2.8372C11.5527 3.06433 11.0559 3.39719 10.6378 3.81671L9.99617 4.46671L9.3545 3.81671C8.93643 3.39719 8.43967 3.06433 7.89268 2.8372C7.3457 2.61008 6.75926 2.49316 6.167 2.49316C5.57474 2.49316 4.9883 2.61008 4.44132 2.8372C3.89433 3.06433 3.39756 3.39719 2.9795 3.81671C1.21283 5.58338 1.1045 8.56671 3.3295 10.8334L9.99617 17.5L16.6628 10.8334C18.8878 8.56671 18.7795 5.58338 17.0128 3.81671Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M2.91406 9.99992H7.91406L8.33073 9.16659L9.9974 12.9166L11.6641 7.08325L12.9141 9.99992H17.0807" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Healthcare / Pharma</div></a></li></ul></details></li><li><a class="MobileMenu_Link__5frcx" href="/community">Community</a></li><li><a class="MobileMenu_Link__5frcx" href="/pricing">Pricing</a></li><li><a class="MobileMenu_Link__5frcx" href="/blog">Blog</a></li><li><a class="MobileMenu_Link__5frcx" href="/customers">Customer stories</a></li><li><a class="MobileMenu_Link__5frcx" href="/careers">Careers</a></li></ul></nav><a href="/contact" class="Button_button-variant-ghost__o2AbG Button_button__aJ0V6" data-tracking-variant="ghost"> <!-- -->Talk to us</a><ul class="Socials_socials__8Y_s5 Socials_socials-theme-dark__Hq8lc MobileMenu_socials__JykCO"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu MobileMenu_copyright__nKVOs">© <!-- -->2025<!-- --> LlamaIndex</p></div></header><main><section class="BlogPost_post__JHNzd"><img alt="" loading="lazy" width="800" height="1314" decoding="async" data-nimg="1" class="BlogPost_featuredImage__KGxwX" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F3cf214bf62cde63dddeda80ea71515cd9eb0c42e-2471x2628.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F3cf214bf62cde63dddeda80ea71515cd9eb0c42e-2471x2628.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F3cf214bf62cde63dddeda80ea71515cd9eb0c42e-2471x2628.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><p class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-600__fKYth BlogPost_date__6uxQw"><a class="BlogPost_author__mesdl" href="/blog/author/llamaindex">LlamaIndex</a> <!-- -->•<!-- --> <!-- -->2024-08-01</p><h1 class="Text_text__zPO0D Text_text-size-32__koGps BlogPost_title__b2lqJ">Introducing workflows beta: a new way to create complex AI applications with LlamaIndex</h1><ul class="BlogPost_tags__13pBH"><li><a class="Badge_badge___1ssn" href="/blog/tag/workflows"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Workflows</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/orchestration"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Orchestration</span></a></li></ul><div class="BlogPost_htmlPost__Z5oDL"><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We’re pleased to be introducing a brand-new beta feature of LlamaIndex: workflows, a mechanism for orchestrating actions in the increasingly-complex AI application we see our users building.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">What started as a trend with the advent of LLMs is now a de-facto standard: AI applications are made of multiple tasks implemented by different components. Open source frameworks in the market strive to make the life of AI engineers easier by providing easy-to-use abstractions for foundational components like data loaders, LLMs, vector databases, and rerankers, all the way up to external services. Meanwhile, all of those frameworks are also on a quest to find what’s the best abstraction to orchestrate such components, researching what’s most intuitive and efficient for an AI developer in order to implement the logic that keeps together a compound AI system.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Two of those potential orchestration patterns are chains and pipelines, both of which are implementations of the same Directed Acyclic Graph (DAG) abstraction. We took a stab at this with our <a href="https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Query Pipelines</a> release at the beginning of the year - it was a declarative API that let you orchestrate simple-to-advanced query workflows over your data for different use cases, like QA, structured extraction, and agentic automation. But as we tried to build upon it and experimented with adding cycles to better support more complex workflows, we noticed several issues, causing us to reflect on why a DAG may not be the right fit for an agentic landscape, and what alternatives we could introduce in the framework.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Limitations of a Graph-based UX</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">A fundamental aspect of DAGs is the “A” in DAGs: they are acyclic, meaning there are no loops. But in a world that’s more and more agentic, the inability to perform loops in an AI application’s logic is simply unacceptable. For example, if one component provides bad results, an AI developer should have a way to tell the system to self-correct and try again.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Even without adding cycles and loops to a DAG, the query pipeline suffered from a few noticeable issues:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">hard to debug when things go wrong</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">they obscure how components and modules are being executed</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">our pipeline orchestrator became increasingly extremely complex and had to handle a ton of different edge cases</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">they were hard to read for complex pipelines</li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Once we added cycles to query pipelines, these developer UX issues around graphs were amplified. We experienced first-hand developer pain in areas like:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">A lot of core orchestration logic like <code class="SanityPortableText_inlineCode__cI85z">if-else</code> statements and <code class="SanityPortableText_inlineCode__cI85z">while</code> loops get baked into the edges of the graph. Defining these edges becomes cumbersome and verbose.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">It became hard to handle edge cases around optional and default values. It was hard for us as a framework to figure out whether a parameter would get passed from upstream nodes.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Defining graphs with cycles didn’t always feel as natural to developers building agents. An agent encapsulates a general LLM-powered entity that can take in observations and generate responses. Here the graph UX enforced that “agent” node had the incoming edges and outgoing edges explicitly defined, forcing users to define verbose communication patterns with other nodes.</li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We asked: are graphs really the only abstraction we can use to orchestrate components in a compound AI system?</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">From Graphs to EDA: go event-driven</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">A compound AI system can be implemented with a LlamaIndex <em>workflow</em>. The workflow dispatches events back and forth through a collection of Python functions called <em>steps</em>. Each step can be seen as one component of your system: one to process a query, one to talk with an LLM, one to load data from a vector database and so on. Every step receives one or more events to process and can optionally send back events that will be relayed to other components if needed.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Moving to an event-driven architecture causes a fundamental shift in design. In many graph implementations the graph traversal algorithm is responsible for determining what component should run next and what data should be passed. In an event-driven architecture, the component subscribes to a certain types of events and it’s ultimately responsible for deciding what to do based on the data it received.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">In an event-driven system, concepts like optionality of inputs and default values are sorted out at the component level, dramatically simplifying the orchestration code.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">A workflow primer</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">To help clarify this idea, let’s look at an example. A minimal LlamaIndex workflow looks like this:</p><pre><code><span class="hljs-keyword">from</span> llama_index.core.workflow <span class="hljs-keyword">import</span> (
    StartEvent,
    StopEvent,
    Workflow,
    step,
)

<span class="hljs-keyword">from</span> llama_index.llms.openai <span class="hljs-keyword">import</span> OpenAI

<span class="hljs-keyword">class</span> <span class="hljs-title class_">OpenAIGenerator</span>(<span class="hljs-title class_ inherited__">Workflow</span>):
<span class="hljs-meta">    @step()</span>
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">generate</span>(<span class="hljs-params">self, ev: StartEvent</span>) -&gt; StopEvent:
        query = ev.get(<span class="hljs-string">&quot;query&quot;</span>)
        llm = OpenAI()
        response = <span class="hljs-keyword">await</span> llm.acomplete(query)
        <span class="hljs-keyword">return</span> StopEvent(result=<span class="hljs-built_in">str</span>(response))

w = OpenAIGenerator(timeout=<span class="hljs-number">10</span>, verbose=<span class="hljs-literal">False</span>)
result = <span class="hljs-keyword">await</span> w.run(query=<span class="hljs-string">&quot;What&#x27;s LlamaIndex?&quot;</span>)
<span class="hljs-built_in">print</span>(result)</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The <code class="SanityPortableText_inlineCode__cI85z">generate</code> function is marked as a workflow step using the <code class="SanityPortableText_inlineCode__cI85z">@step</code> decorator and it declares which events it wants to receive and which events it will send back using the method signature with proper typing annotations. In order to run a workflow, we create an instance of the <code class="SanityPortableText_inlineCode__cI85z">OpenAIGenerator</code> class passing some configuration parameters like the desired timeout and we then call the <code class="SanityPortableText_inlineCode__cI85z">run</code> method. Any keyword argument passed to <code class="SanityPortableText_inlineCode__cI85z">run</code> will be packed into a special event of type <code class="SanityPortableText_inlineCode__cI85z">StartEvent</code> that will be relayed to the steps that requested it (in this case, only the <code class="SanityPortableText_inlineCode__cI85z">generate</code> step). The <code class="SanityPortableText_inlineCode__cI85z">generate</code> step returns a special event of type <code class="SanityPortableText_inlineCode__cI85z">StopEvent</code> that will signal the workflow to gracefully halt its execution. A <code class="SanityPortableText_inlineCode__cI85z">StopEvent</code> carries any data that we want to return to the caller as the workflow result, in this case the LLM response.</p><h3 class="Text_text__zPO0D Text_text-size-40__fIyvA">Workflows can loop</h3><p class="Text_text__zPO0D Text_text-size-16__PkjFu">In event-driven architectures, loops have to do with communication rather than topology. Any step can decide to call another step multiple times by crafting and sending the proper event. Let’s see a self-correction loop for example (check the <a href="https://docs.llamaindex.ai/en/latest/examples/workflow/reflection/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">notebook</a> for the full code):</p><pre><code><span class="hljs-keyword">class</span> <span class="hljs-title class_">ExtractionDone</span>(<span class="hljs-title class_ inherited__">Event</span>):
    output: <span class="hljs-built_in">str</span>
    passage: <span class="hljs-built_in">str</span>


<span class="hljs-keyword">class</span> <span class="hljs-title class_">ValidationErrorEvent</span>(<span class="hljs-title class_ inherited__">Event</span>):
    error: <span class="hljs-built_in">str</span>
    wrong_output: <span class="hljs-built_in">str</span>
    passage: <span class="hljs-built_in">str</span>
    
    
<span class="hljs-keyword">class</span> <span class="hljs-title class_">ReflectionWorkflow</span>(<span class="hljs-title class_ inherited__">Workflow</span>):
<span class="hljs-meta">    @step()</span>
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">extract</span>(<span class="hljs-params">
        self, ev: StartEvent | ValidationErrorEvent
    </span>) -&gt; StopEvent | ExtractionDone:
        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(ev, StartEvent):
            passage = ev.get(<span class="hljs-string">&quot;passage&quot;</span>)
            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> passage:
                <span class="hljs-keyword">return</span> StopEvent(result=<span class="hljs-string">&quot;Please provide some text in input&quot;</span>)
            reflection_prompt = <span class="hljs-string">&quot;&quot;</span>
        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(ev, ValidationErrorEvent):
            passage = ev.passage
            reflection_prompt = REFLECTION_PROMPT.<span class="hljs-built_in">format</span>(
                wrong_answer=ev.wrong_output, error=ev.error
            )

        llm = Ollama(model=<span class="hljs-string">&quot;llama3&quot;</span>, request_timeout=<span class="hljs-number">30</span>)
        prompt = EXTRACTION_PROMPT.<span class="hljs-built_in">format</span>(
            passage=passage, schema=CarCollection.schema_json()
        )
        <span class="hljs-keyword">if</span> reflection_prompt:
            prompt += reflection_prompt

        output = <span class="hljs-keyword">await</span> llm.acomplete(prompt)

        <span class="hljs-keyword">return</span> ExtractionDone(output=<span class="hljs-built_in">str</span>(output), passage=passage)

<span class="hljs-meta">    @step()</span>
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">validate</span>(<span class="hljs-params">
        self, ev: ExtractionDone
    </span>) -&gt; StopEvent | ValidationErrorEvent:
        <span class="hljs-keyword">try</span>:
            json.loads(ev.output)
        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Validation failed, retrying...&quot;</span>)
            <span class="hljs-keyword">return</span> ValidationErrorEvent(
                error=<span class="hljs-built_in">str</span>(e), wrong_output=ev.output, passage=ev.passage
            )

        <span class="hljs-keyword">return</span> StopEvent(result=ev.output)

w = ReflectionWorkflow(timeout=<span class="hljs-number">60</span>, verbose=<span class="hljs-literal">True</span>)
result = <span class="hljs-keyword">await</span> w.run(
    passage=<span class="hljs-string">&quot;There are two cars available: a Fiat Panda with 45Hp and a Honda Civic with 330Hp.&quot;</span>
)
<span class="hljs-built_in">print</span>(result)</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">In this example, the <code class="SanityPortableText_inlineCode__cI85z">validate</code> step receives the result of the tentative schema extraction as an event and it can decide to try again by returning a <code class="SanityPortableText_inlineCode__cI85z">ValidationErrorEvent</code> that will be eventually delivered to the <code class="SanityPortableText_inlineCode__cI85z">extract</code> step which will perform another attempt. Note that in this example the workflow might time out if this extract/validate loop keeps providing poor results for too long, but another strategy might be giving up after a precise number of attempts, just to give an example.</p><h3 class="Text_text__zPO0D Text_text-size-40__fIyvA">Workflows keep state</h3><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Workflows keep a global state during the execution, and this state can be shared and propagated to its steps upon request. This shared state is implemented as a <code class="SanityPortableText_inlineCode__cI85z">Context</code> object and can be used by steps to store data in between iterations but also as an alternative form of communication among different steps. Let’s see an excerpt from a more complex RAG example as an example showing how to use the global context (check <a href="https://docs.llamaindex.ai/en/latest/examples/workflow/rag/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">notebook</a> for full code):</p><pre><code><span class="hljs-keyword">class</span> <span class="hljs-title class_">RAGWorkflow</span>(<span class="hljs-title class_ inherited__">Workflow</span>):
<span class="hljs-meta">    @step(<span class="hljs-params">pass_context=<span class="hljs-literal">True</span></span>)</span>
    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">ingest</span>(<span class="hljs-params">self, ctx: Context, ev: StartEvent</span>) -&gt; <span class="hljs-type">Optional</span>[StopEvent]:
        dataset_name = ev.get(<span class="hljs-string">&quot;dataset&quot;</span>)
        _, documents = download_llama_dataset(dsname, <span class="hljs-string">&quot;./data&quot;</span>)
        ctx.data[<span class="hljs-string">&quot;INDEX&quot;</span>] = VectorStoreIndex.from_documents(documents=documents)
        <span class="hljs-keyword">return</span> StopEvent(result=<span class="hljs-string">f&quot;Indexed <span class="hljs-subst">{<span class="hljs-built_in">len</span>(documents)}</span> documents.&quot;</span>)
        
    ...</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">In this case the <code class="SanityPortableText_inlineCode__cI85z">ingest</code> step creates an index, and it wants to make it available to any other step that might needed it later during workflow execution. The idiomatic way of doing that in a LlamaIndex workflow is to declare the step requires an instance of the global context (<code class="SanityPortableText_inlineCode__cI85z">@step(pass_context=True)</code> does the trick) and store the index in the context itself with a predefined key that other steps might access later.</p><h3 class="Text_text__zPO0D Text_text-size-40__fIyvA">Workflows can be customized</h3><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Alongside Workflows, we’ll be releasing a set of predefined workflows so that the most common use cases can be implemented with a single line of code. Using these predefined flows, users still might want to just <em>slightly</em> change a predefined workflow to introduce some custom behavior without having to rewrite a whole workflow from scratch. Let’s say you want to customize a RAG workflow and use a custom re-ranking step, all you would need to do is subclass a hypothetical built-in <code class="SanityPortableText_inlineCode__cI85z">RAGWorkflow</code> class and override the <code class="SanityPortableText_inlineCode__cI85z">rerank</code> step like this:</p><pre><code><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyWorkflow</span>(<span class="hljs-title class_ inherited__">RAGWorkflow</span>):
<span class="hljs-meta">    @step(<span class="hljs-params">pass_context=<span class="hljs-literal">True</span></span>)</span>
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">rerank</span>(<span class="hljs-params">
        self, ctx: Context, ev: <span class="hljs-type">Union</span>[RetrieverEvent, StartEvent]
    </span>) -&gt; <span class="hljs-type">Optional</span>[QueryResult]:
        <span class="hljs-comment"># my custom reranking logic here</span>
        
 
w = MyWorkflow(timeout=<span class="hljs-number">60</span>, verbose=<span class="hljs-literal">True</span>)
result = <span class="hljs-keyword">await</span> w.run(query=<span class="hljs-string">&quot;Who is Paul Graham?&quot;</span>)</code></pre><h3 class="Text_text__zPO0D Text_text-size-40__fIyvA">Workflows can be debugged</h3><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The complexity of your workflows will grow with the complexity of your application logic, and sometimes it can be hard to understand how events will flow during execution by just looking at the Python code. To ease the understanding of complex workflows and to support the debugging of workflow executions, LlamaIndex provides two functions:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><code class="SanityPortableText_inlineCode__cI85z">draw_all_possible_flows</code> produces a picture showing all the steps in a workflow and how events will possibly flow</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><code class="SanityPortableText_inlineCode__cI85z">draw_most_recent_execution</code> produces a similar picture, showing only the events that were actually sent during the last workflow execution</li></ul><figure><img alt="" loading="lazy" width="582" height="379" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4db2cf184b7318891c997552e832638838e67620-1164x758.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4db2cf184b7318891c997552e832638838e67620-1164x758.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1200&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4db2cf184b7318891c997552e832638838e67620-1164x758.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1200&amp;q=75"/></figure><p class="Text_text__zPO0D Text_text-size-16__PkjFu">On top of that, workflows can be executed manually, by calling <code class="SanityPortableText_inlineCode__cI85z">run_step()</code> multiple times until all the steps have completed. After each <code class="SanityPortableText_inlineCode__cI85z">run_step</code> call, the workflow can be inspected, examining any intermediate results or debug logs.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Why you should use workflows today</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Despite being at an early stage of development, LlamaIndex workflows already represent a step forward compared to query pipelines, extending their functionalities and adding more flexibility. On top of that, workflows come with a set of features that you would normally expect from a much more mature software:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Fully async with streaming support</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Instrumented by default, providing one-click observability with the supported integrations</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Step-by-step execution for easier debugging</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Validation and visualization of the event-driven dependencies</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Events are implemented as pydantic models to ease customization and further developments of new features</li></ul><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Resources</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Check out our <a href="https://docs.llamaindex.ai/en/latest/module_guides/workflow/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">workflow documentation</a> and our <a href="https://github.com/run-llama/llama_index/tree/main/docs/docs/examples/workflow" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">examples</a> including:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><a href="https://docs.llamaindex.ai/en/latest/examples/workflow/rag/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">RAG</a></li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><a href="https://docs.llamaindex.ai/en/latest/examples/workflow/reflection/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Reflection</a></li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><a href="https://docs.llamaindex.ai/en/latest/examples/workflow/function_calling_agent/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Function calling</a></li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><a href="https://docs.llamaindex.ai/en/latest/examples/workflow/react_agent/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">ReAct agent</a></li></ul></div><div class="BlogPost_relatedPosts__0z6SN"><h2 class="Text_text__zPO0D Text_text-align-center__HhKqo Text_text-size-16__PkjFu Text_text-weight-400__5ENkK Text_text-family-spaceGrotesk__E4zcE BlogPost_relatedPostsTitle___JIrW">Related articles</h2><ul class="BlogPost_relatedPostsList__uOKzB"><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F5131c90793639ba82a7980d4b2bd944685200871-896x1012.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F5131c90793639ba82a7980d4b2bd944685200871-896x1012.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F5131c90793639ba82a7980d4b2bd944685200871-896x1012.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/using-nvidia-nim-for-agent-enhanced-ai-query-engines-with-llamaindex">Using NVIDIA NIM for Agent-Enhanced AI Query Engines with LlamaIndex</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-11-08</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Ffc2fb39d84bcf6ae0ca2e4130844c076bc9a20a0-2464x1210.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Ffc2fb39d84bcf6ae0ca2e4130844c076bc9a20a0-2464x1210.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Ffc2fb39d84bcf6ae0ca2e4130844c076bc9a20a0-2464x1210.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/introducing-llama-deploy-a-microservice-based-way-to-deploy-llamaindex-workflows">Introducing llama-deploy, a microservice-based way to deploy LlamaIndex Workflows</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-09-05</p></div></li></ul></div></section></main><footer class="Footer_footer__eNA9m"><div class="Footer_navContainer__7bvx4"><div class="Footer_logoContainer__3EpzI"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" style="color:transparent" src="/llamaindex.svg"/><div class="Footer_socialContainer__GdOgk"><ul class="Socials_socials__8Y_s5"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul></div></div><div class="Footer_nav__BLEuE"><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/">LlamaIndex</a></h3><ul><li><a href="/blog"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Blog</span></a></li><li><a href="/partners"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Partners</span></a></li><li><a href="/careers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Careers</span></a></li><li><a href="/contact"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Contact</span></a></li><li><a href="/brand"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Brand</span></a></li><li><a href="https://llamaindex.statuspage.io" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Status</span></a></li><li><a href="https://app.vanta.com/runllama.ai/trust/pkcgbjf8b3ihxjpqdx17nu" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Trust Center</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/enterprise">Enterprise</a></h3><ul><li><a href="https://cloud.llamaindex.ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaCloud</span></a></li><li><a href="https://cloud.llamaindex.ai/parse" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaParse</span></a></li><li><a href="/customers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Customers</span></a></li><li><a href="/llamacloud-sharepoint-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SharePoint</span></a></li><li><a href="/llamacloud-aws-s3-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">AWS S3</span></a></li><li><a href="/llamacloud-azure-blob-storage-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure Blob Storage</span></a></li><li><a href="/llamacloud-google-drive-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Google Drive</span></a></li> </ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/framework">Framework</a></h3><ul><li><a href="https://pypi.org/project/llama-index/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python package</span></a></li><li><a href="https://docs.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python docs</span></a></li><li><a href="https://www.npmjs.com/package/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript package</span></a></li><li><a href="https://ts.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript docs</span></a></li><li><a href="https://llamahub.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaHub</span></a></li><li><a href="https://github.com/run-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">GitHub</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/community">Community</a></h3><ul><li><a href="/community#newsletter"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Newsletter</span></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Discord</span></a></li><li><a href="https://www.linkedin.com/company/91154103/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LinkedIn</span></a></li><li><a href="https://twitter.com/llama_index"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Twitter/X</span></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">YouTube</span></a></li><li><a href="https://bsky.app/profile/llamaindex.bsky.social"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">BlueSky</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e">Starter projects</h3><ul><li><a href="https://www.npmjs.com/package/create-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">create-llama</span></a></li><li><a href="https://secinsights.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SEC Insights</span></a></li><li><a href="https://github.com/run-llama/llamabot"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaBot</span></a></li><li><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/rag_cli.html"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">RAG CLI</span></a></li></ul></div></div></div><div class="Footer_copyrightContainer__mBKsT"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA">© <!-- -->2025<!-- --> LlamaIndex</p><div class="Footer_legalNav__O1yJA"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/privacy-notice.pdf">Privacy Notice</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/terms-of-service.pdf">Terms of Service</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="https://bit.ly/llamaindexdpa">Data Processing Addendum</a></p></div></div></footer></div><svg xmlns="http://www.w3.org/2000/svg" class="flt_svg" style="display:none"><defs><filter id="flt_tag"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="2"></feGaussianBlur><feColorMatrix in="blur" result="flt_tag" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="flt_tag" operator="atop"></feComposite></filter><filter id="svg_blur_large"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="8"></feGaussianBlur><feColorMatrix in="blur" result="svg_blur_large" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="svg_blur_large" operator="atop"></feComposite></filter></defs></svg></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"page":{"announcement":{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"},"post":{"_createdAt":"2024-08-01T16:17:28Z","_id":"3cf26320-a94f-44f7-aab1-188475ea2b51","_rev":"TLgH6AcXrxoqw75SBDhgMZ","_type":"blogPost","_updatedAt":"2025-05-21T20:37:10Z","announcement":[{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"}],"authors":[{"_createdAt":"2024-02-20T20:23:12Z","_id":"363ec4e9-0b8f-48d2-ba6a-567a9c527c3d","_rev":"rGZ2nN6K5mjOGJOoWaUhNb","_type":"people","_updatedAt":"2024-02-25T00:45:24Z","image":{"_type":"image","asset":{"_ref":"image-89523511cf20d73e3f10077add50128d077ed520-176x176-png","_type":"reference"}},"name":"LlamaIndex","slug":{"_type":"slug","current":"llamaindex"}}],"featured":false,"image":{"_type":"image","asset":{"_ref":"image-3cf214bf62cde63dddeda80ea71515cd9eb0c42e-2471x2628-png","_type":"reference"}},"mainImage":"https://cdn.sanity.io/images/7m9jw85w/production/3cf214bf62cde63dddeda80ea71515cd9eb0c42e-2471x2628.png","publishedDate":"2024-08-01","relatedPosts":[{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-5131c90793639ba82a7980d4b2bd944685200871-896x1012-png","_type":"reference"}},"publishedDate":"2024-11-08","slug":"using-nvidia-nim-for-agent-enhanced-ai-query-engines-with-llamaindex","title":"Using NVIDIA NIM for Agent-Enhanced AI Query Engines with LlamaIndex"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-fc2fb39d84bcf6ae0ca2e4130844c076bc9a20a0-2464x1210-png","_type":"reference"}},"publishedDate":"2024-09-05","slug":"introducing-llama-deploy-a-microservice-based-way-to-deploy-llamaindex-workflows","title":"Introducing llama-deploy, a microservice-based way to deploy LlamaIndex Workflows"}],"slug":{"_type":"slug","current":"introducing-workflows-beta-a-new-way-to-create-complex-ai-applications-with-llamaindex"},"tags":[{"_createdAt":"2024-08-01T16:07:34Z","_id":"fb42e2ed-a8a6-4957-a542-104903d0a766","_rev":"M6ETZdzcY6usphylMIwkdv","_type":"blogTag","_updatedAt":"2024-08-01T16:07:34Z","slug":{"_type":"slug","current":"workflows"},"title":"Workflows"},{"_createdAt":"2024-08-01T16:07:48Z","_id":"6614f644-254a-4c03-acf0-1c081021c1f9","_rev":"M6ETZdzcY6usphylMIxb1T","_type":"blogTag","_updatedAt":"2024-08-01T16:07:48Z","slug":{"_type":"slug","current":"orchestration"},"title":"Orchestration"}],"text":[{"_key":"9b2dae029510","_type":"block","children":[{"_key":"eff394b1fe800","_type":"span","marks":[],"text":"We’re pleased to be introducing a brand-new beta feature of LlamaIndex: workflows, a mechanism for orchestrating actions in the increasingly-complex AI application we see our users building."}],"markDefs":[],"style":"normal"},{"_key":"3a526d11dae3","_type":"block","children":[{"_key":"de8178a75c200","_type":"span","marks":[],"text":"What started as a trend with the advent of LLMs is now a de-facto standard: AI applications are made of multiple tasks implemented by different components. Open source frameworks in the market strive to make the life of AI engineers easier by providing easy-to-use abstractions for foundational components like data loaders, LLMs, vector databases, and rerankers, all the way up to external services. Meanwhile, all of those frameworks are also on a quest to find what’s the best abstraction to orchestrate such components, researching what’s most intuitive and efficient for an AI developer in order to implement the logic that keeps together a compound AI system."}],"markDefs":[],"style":"normal"},{"_key":"d9bce4cb600f","_type":"block","children":[{"_key":"786a5a1c709b0","_type":"span","marks":[],"text":"Two of those potential orchestration patterns are chains and pipelines, both of which are implementations of the same Directed Acyclic Graph (DAG) abstraction. We took a stab at this with our "},{"_key":"786a5a1c709b1","_type":"span","marks":["c0207983181c"],"text":"Query Pipelines"},{"_key":"786a5a1c709b2","_type":"span","marks":[],"text":" release at the beginning of the year - it was a declarative API that let you orchestrate simple-to-advanced query workflows over your data for different use cases, like QA, structured extraction, and agentic automation. But as we tried to build upon it and experimented with adding cycles to better support more complex workflows, we noticed several issues, causing us to reflect on why a DAG may not be the right fit for an agentic landscape, and what alternatives we could introduce in the framework."}],"markDefs":[{"_key":"c0207983181c","_type":"link","href":"https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}],"style":"normal"},{"_key":"afce58437025","_type":"block","children":[{"_key":"967436b6372f0","_type":"span","marks":[],"text":"Limitations of a Graph-based UX"}],"markDefs":[],"style":"h2"},{"_key":"bbc48fcdd1e4","_type":"block","children":[{"_key":"ae3e9f7c57230","_type":"span","marks":[],"text":"A fundamental aspect of DAGs is the “A” in DAGs: they are acyclic, meaning there are no loops. But in a world that’s more and more agentic, the inability to perform loops in an AI application’s logic is simply unacceptable. For example, if one component provides bad results, an AI developer should have a way to tell the system to self-correct and try again."}],"markDefs":[],"style":"normal"},{"_key":"40b10e875992","_type":"block","children":[{"_key":"79929b432e8d0","_type":"span","marks":[],"text":"Even without adding cycles and loops to a DAG, the query pipeline suffered from a few noticeable issues:"}],"markDefs":[],"style":"normal"},{"_key":"2a02af7019ef","_type":"block","children":[{"_key":"83b0fe71d4e70","_type":"span","marks":[],"text":"hard to debug when things go wrong"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"3e8f249a0428","_type":"block","children":[{"_key":"0b80dbc3289b0","_type":"span","marks":[],"text":"they obscure how components and modules are being executed"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"f694f288c0e3","_type":"block","children":[{"_key":"abf73c5d81900","_type":"span","marks":[],"text":"our pipeline orchestrator became increasingly extremely complex and had to handle a ton of different edge cases"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"2e7a014a7bc4","_type":"block","children":[{"_key":"01368c81ced10","_type":"span","marks":[],"text":"they were hard to read for complex pipelines"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"fb13a90e4d3c","_type":"block","children":[{"_key":"716f2ebb12150","_type":"span","marks":[],"text":"Once we added cycles to query pipelines, these developer UX issues around graphs were amplified. We experienced first-hand developer pain in areas like:"}],"markDefs":[],"style":"normal"},{"_key":"58471bd2f6e4","_type":"block","children":[{"_key":"50ce05f8d6130","_type":"span","marks":[],"text":"A lot of core orchestration logic like "},{"_key":"50ce05f8d6131","_type":"span","marks":["code"],"text":"if-else"},{"_key":"50ce05f8d6132","_type":"span","marks":[],"text":" statements and "},{"_key":"50ce05f8d6133","_type":"span","marks":["code"],"text":"while"},{"_key":"50ce05f8d6134","_type":"span","marks":[],"text":" loops get baked into the edges of the graph. Defining these edges becomes cumbersome and verbose."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"fece3304ebc2","_type":"block","children":[{"_key":"e43c72d4d3a70","_type":"span","marks":[],"text":"It became hard to handle edge cases around optional and default values. It was hard for us as a framework to figure out whether a parameter would get passed from upstream nodes."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"ca99b2f51298","_type":"block","children":[{"_key":"5212cc97caa50","_type":"span","marks":[],"text":"Defining graphs with cycles didn’t always feel as natural to developers building agents. An agent encapsulates a general LLM-powered entity that can take in observations and generate responses. Here the graph UX enforced that “agent” node had the incoming edges and outgoing edges explicitly defined, forcing users to define verbose communication patterns with other nodes."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"38e3a1541f21","_type":"block","children":[{"_key":"8fe51684fd990","_type":"span","marks":[],"text":"We asked: are graphs really the only abstraction we can use to orchestrate components in a compound AI system?"}],"markDefs":[],"style":"normal"},{"_key":"4cbdc0083756","_type":"block","children":[{"_key":"4d1860cc21d20","_type":"span","marks":[],"text":"From Graphs to EDA: go event-driven"}],"markDefs":[],"style":"h2"},{"_key":"2351576c57c7","_type":"block","children":[{"_key":"3dde43c092840","_type":"span","marks":[],"text":"A compound AI system can be implemented with a LlamaIndex "},{"_key":"3dde43c092841","_type":"span","marks":["em"],"text":"workflow"},{"_key":"3dde43c092842","_type":"span","marks":[],"text":". The workflow dispatches events back and forth through a collection of Python functions called "},{"_key":"3dde43c092843","_type":"span","marks":["em"],"text":"steps"},{"_key":"3dde43c092844","_type":"span","marks":[],"text":". Each step can be seen as one component of your system: one to process a query, one to talk with an LLM, one to load data from a vector database and so on. Every step receives one or more events to process and can optionally send back events that will be relayed to other components if needed."}],"markDefs":[],"style":"normal"},{"_key":"7c0e86346a37","_type":"block","children":[{"_key":"a2e18fbbc8fb0","_type":"span","marks":[],"text":"Moving to an event-driven architecture causes a fundamental shift in design. In many graph implementations the graph traversal algorithm is responsible for determining what component should run next and what data should be passed. In an event-driven architecture, the component subscribes to a certain types of events and it’s ultimately responsible for deciding what to do based on the data it received."}],"markDefs":[],"style":"normal"},{"_key":"7010b0af676c","_type":"block","children":[{"_key":"28193187848f0","_type":"span","marks":[],"text":"In an event-driven system, concepts like optionality of inputs and default values are sorted out at the component level, dramatically simplifying the orchestration code."}],"markDefs":[],"style":"normal"},{"_key":"f8b4efb67f90","_type":"block","children":[{"_key":"527d2a44139b0","_type":"span","marks":[],"text":"A workflow primer"}],"markDefs":[],"style":"h2"},{"_key":"0b5eb3e4b309","_type":"block","children":[{"_key":"898f4f5cb8080","_type":"span","marks":[],"text":"To help clarify this idea, let’s look at an example. A minimal LlamaIndex workflow looks like this:"}],"markDefs":[],"style":"normal"},{"_key":"7551554423a5","_type":"codeBlock","code":"from llama_index.core.workflow import (\n    StartEvent,\n    StopEvent,\n    Workflow,\n    step,\n)\n\nfrom llama_index.llms.openai import OpenAI\n\nclass OpenAIGenerator(Workflow):\n    @step()\n    async def generate(self, ev: StartEvent) -\u003e StopEvent:\n        query = ev.get(\"query\")\n        llm = OpenAI()\n        response = await llm.acomplete(query)\n        return StopEvent(result=str(response))\n\nw = OpenAIGenerator(timeout=10, verbose=False)\nresult = await w.run(query=\"What's LlamaIndex?\")\nprint(result)","language":"python"},{"_key":"296a8124b1f7","_type":"block","children":[{"_key":"7262ad0f8edb0","_type":"span","marks":[],"text":"The "},{"_key":"7262ad0f8edb1","_type":"span","marks":["code"],"text":"generate"},{"_key":"7262ad0f8edb2","_type":"span","marks":[],"text":" function is marked as a workflow step using the "},{"_key":"7262ad0f8edb3","_type":"span","marks":["code"],"text":"@step"},{"_key":"7262ad0f8edb4","_type":"span","marks":[],"text":" decorator and it declares which events it wants to receive and which events it will send back using the method signature with proper typing annotations. In order to run a workflow, we create an instance of the "},{"_key":"7262ad0f8edb5","_type":"span","marks":["code"],"text":"OpenAIGenerator"},{"_key":"7262ad0f8edb6","_type":"span","marks":[],"text":" class passing some configuration parameters like the desired timeout and we then call the "},{"_key":"7262ad0f8edb7","_type":"span","marks":["code"],"text":"run"},{"_key":"7262ad0f8edb8","_type":"span","marks":[],"text":" method. Any keyword argument passed to "},{"_key":"7262ad0f8edb9","_type":"span","marks":["code"],"text":"run"},{"_key":"7262ad0f8edb10","_type":"span","marks":[],"text":" will be packed into a special event of type "},{"_key":"7262ad0f8edb11","_type":"span","marks":["code"],"text":"StartEvent"},{"_key":"7262ad0f8edb12","_type":"span","marks":[],"text":" that will be relayed to the steps that requested it (in this case, only the "},{"_key":"7262ad0f8edb13","_type":"span","marks":["code"],"text":"generate"},{"_key":"7262ad0f8edb14","_type":"span","marks":[],"text":" step). The "},{"_key":"7262ad0f8edb15","_type":"span","marks":["code"],"text":"generate"},{"_key":"7262ad0f8edb16","_type":"span","marks":[],"text":" step returns a special event of type "},{"_key":"7262ad0f8edb17","_type":"span","marks":["code"],"text":"StopEvent"},{"_key":"7262ad0f8edb18","_type":"span","marks":[],"text":" that will signal the workflow to gracefully halt its execution. A "},{"_key":"7262ad0f8edb19","_type":"span","marks":["code"],"text":"StopEvent"},{"_key":"7262ad0f8edb20","_type":"span","marks":[],"text":" carries any data that we want to return to the caller as the workflow result, in this case the LLM response."}],"markDefs":[],"style":"normal"},{"_key":"c6c29189c897","_type":"block","children":[{"_key":"60aa6d24fd990","_type":"span","marks":[],"text":"Workflows can loop"}],"markDefs":[],"style":"h3"},{"_key":"588a3d39ee2d","_type":"block","children":[{"_key":"fa28d6309c620","_type":"span","marks":[],"text":"In event-driven architectures, loops have to do with communication rather than topology. Any step can decide to call another step multiple times by crafting and sending the proper event. Let’s see a self-correction loop for example (check the "},{"_key":"fa28d6309c621","_type":"span","marks":["71554b1d8a52"],"text":"notebook"},{"_key":"fa28d6309c622","_type":"span","marks":[],"text":" for the full code):"}],"markDefs":[{"_key":"71554b1d8a52","_type":"link","href":"https://docs.llamaindex.ai/en/latest/examples/workflow/reflection/"}],"style":"normal"},{"_key":"53d129194518","_type":"codeBlock","code":"class ExtractionDone(Event):\n    output: str\n    passage: str\n\n\nclass ValidationErrorEvent(Event):\n    error: str\n    wrong_output: str\n    passage: str\n    \n    \nclass ReflectionWorkflow(Workflow):\n    @step()\n    async def extract(\n        self, ev: StartEvent | ValidationErrorEvent\n    ) -\u003e StopEvent | ExtractionDone:\n        if isinstance(ev, StartEvent):\n            passage = ev.get(\"passage\")\n            if not passage:\n                return StopEvent(result=\"Please provide some text in input\")\n            reflection_prompt = \"\"\n        elif isinstance(ev, ValidationErrorEvent):\n            passage = ev.passage\n            reflection_prompt = REFLECTION_PROMPT.format(\n                wrong_answer=ev.wrong_output, error=ev.error\n            )\n\n        llm = Ollama(model=\"llama3\", request_timeout=30)\n        prompt = EXTRACTION_PROMPT.format(\n            passage=passage, schema=CarCollection.schema_json()\n        )\n        if reflection_prompt:\n            prompt += reflection_prompt\n\n        output = await llm.acomplete(prompt)\n\n        return ExtractionDone(output=str(output), passage=passage)\n\n    @step()\n    async def validate(\n        self, ev: ExtractionDone\n    ) -\u003e StopEvent | ValidationErrorEvent:\n        try:\n            json.loads(ev.output)\n        except Exception as e:\n            print(\"Validation failed, retrying...\")\n            return ValidationErrorEvent(\n                error=str(e), wrong_output=ev.output, passage=ev.passage\n            )\n\n        return StopEvent(result=ev.output)\n\nw = ReflectionWorkflow(timeout=60, verbose=True)\nresult = await w.run(\n    passage=\"There are two cars available: a Fiat Panda with 45Hp and a Honda Civic with 330Hp.\"\n)\nprint(result)","language":"python"},{"_key":"c000181c85d1","_type":"block","children":[{"_key":"7784d17d153f0","_type":"span","marks":[],"text":"In this example, the "},{"_key":"7784d17d153f1","_type":"span","marks":["code"],"text":"validate"},{"_key":"7784d17d153f2","_type":"span","marks":[],"text":" step receives the result of the tentative schema extraction as an event and it can decide to try again by returning a "},{"_key":"7784d17d153f3","_type":"span","marks":["code"],"text":"ValidationErrorEvent"},{"_key":"7784d17d153f4","_type":"span","marks":[],"text":" that will be eventually delivered to the "},{"_key":"7784d17d153f5","_type":"span","marks":["code"],"text":"extract"},{"_key":"7784d17d153f6","_type":"span","marks":[],"text":" step which will perform another attempt. Note that in this example the workflow might time out if this extract/validate loop keeps providing poor results for too long, but another strategy might be giving up after a precise number of attempts, just to give an example."}],"markDefs":[],"style":"normal"},{"_key":"4bda615f3780","_type":"block","children":[{"_key":"8b21549b7c100","_type":"span","marks":[],"text":"Workflows keep state"}],"markDefs":[],"style":"h3"},{"_key":"4ed54d628301","_type":"block","children":[{"_key":"ab1ff176122b0","_type":"span","marks":[],"text":"Workflows keep a global state during the execution, and this state can be shared and propagated to its steps upon request. This shared state is implemented as a "},{"_key":"ab1ff176122b1","_type":"span","marks":["code"],"text":"Context"},{"_key":"ab1ff176122b2","_type":"span","marks":[],"text":" object and can be used by steps to store data in between iterations but also as an alternative form of communication among different steps. Let’s see an excerpt from a more complex RAG example as an example showing how to use the global context (check "},{"_key":"ab1ff176122b3","_type":"span","marks":["53a0fc508549"],"text":"notebook"},{"_key":"ab1ff176122b4","_type":"span","marks":[],"text":" for full code):"}],"markDefs":[{"_key":"53a0fc508549","_type":"link","href":"https://docs.llamaindex.ai/en/latest/examples/workflow/rag/"}],"style":"normal"},{"_key":"495ef969c75a","_type":"codeBlock","code":"class RAGWorkflow(Workflow):\n    @step(pass_context=True)\n    async def ingest(self, ctx: Context, ev: StartEvent) -\u003e Optional[StopEvent]:\n        dataset_name = ev.get(\"dataset\")\n        _, documents = download_llama_dataset(dsname, \"./data\")\n        ctx.data[\"INDEX\"] = VectorStoreIndex.from_documents(documents=documents)\n        return StopEvent(result=f\"Indexed {len(documents)} documents.\")\n        \n    ...","language":"python"},{"_key":"a748cafa5f4b","_type":"block","children":[{"_key":"f9783288d8ab0","_type":"span","marks":[],"text":"In this case the "},{"_key":"f9783288d8ab1","_type":"span","marks":["code"],"text":"ingest"},{"_key":"f9783288d8ab2","_type":"span","marks":[],"text":" step creates an index, and it wants to make it available to any other step that might needed it later during workflow execution. The idiomatic way of doing that in a LlamaIndex workflow is to declare the step requires an instance of the global context ("},{"_key":"f9783288d8ab3","_type":"span","marks":["code"],"text":"@step(pass_context=True)"},{"_key":"f9783288d8ab4","_type":"span","marks":[],"text":" does the trick) and store the index in the context itself with a predefined key that other steps might access later."}],"markDefs":[],"style":"normal"},{"_key":"e819f38e5068","_type":"block","children":[{"_key":"d79fde673b6f0","_type":"span","marks":[],"text":"Workflows can be customized"}],"markDefs":[],"style":"h3"},{"_key":"7850a97dcebb","_type":"block","children":[{"_key":"648e07bce8b60","_type":"span","marks":[],"text":"Alongside Workflows, we’ll be releasing a set of predefined workflows so that the most common use cases can be implemented with a single line of code. Using these predefined flows, users still might want to just "},{"_key":"648e07bce8b61","_type":"span","marks":["em"],"text":"slightly"},{"_key":"648e07bce8b62","_type":"span","marks":[],"text":" change a predefined workflow to introduce some custom behavior without having to rewrite a whole workflow from scratch. Let’s say you want to customize a RAG workflow and use a custom re-ranking step, all you would need to do is subclass a hypothetical built-in "},{"_key":"648e07bce8b63","_type":"span","marks":["code"],"text":"RAGWorkflow"},{"_key":"648e07bce8b64","_type":"span","marks":[],"text":" class and override the "},{"_key":"648e07bce8b65","_type":"span","marks":["code"],"text":"rerank"},{"_key":"648e07bce8b66","_type":"span","marks":[],"text":" step like this:"}],"markDefs":[],"style":"normal"},{"_key":"5c2317f0d071","_type":"codeBlock","code":"class MyWorkflow(RAGWorkflow):\n    @step(pass_context=True)\n    def rerank(\n        self, ctx: Context, ev: Union[RetrieverEvent, StartEvent]\n    ) -\u003e Optional[QueryResult]:\n        # my custom reranking logic here\n        \n \nw = MyWorkflow(timeout=60, verbose=True)\nresult = await w.run(query=\"Who is Paul Graham?\")","language":"python"},{"_key":"518359a244c8","_type":"block","children":[{"_key":"2d1a3b6bffc20","_type":"span","marks":[],"text":"Workflows can be debugged"}],"markDefs":[],"style":"h3"},{"_key":"2f971f5d6b2d","_type":"block","children":[{"_key":"21c581ae6bfe0","_type":"span","marks":[],"text":"The complexity of your workflows will grow with the complexity of your application logic, and sometimes it can be hard to understand how events will flow during execution by just looking at the Python code. To ease the understanding of complex workflows and to support the debugging of workflow executions, LlamaIndex provides two functions:"}],"markDefs":[],"style":"normal"},{"_key":"1128871f0b5a","_type":"block","children":[{"_key":"e47e78ff5bba0","_type":"span","marks":["code"],"text":"draw_all_possible_flows"},{"_key":"e47e78ff5bba1","_type":"span","marks":[],"text":" produces a picture showing all the steps in a workflow and how events will possibly flow"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"80719579c5bc","_type":"block","children":[{"_key":"8b0ff3027b6d0","_type":"span","marks":["code"],"text":"draw_most_recent_execution"},{"_key":"8b0ff3027b6d1","_type":"span","marks":[],"text":" produces a similar picture, showing only the events that were actually sent during the last workflow execution"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"e9f9c8b93892","_type":"image","asset":{"_ref":"image-4db2cf184b7318891c997552e832638838e67620-1164x758-png","_type":"reference"}},{"_key":"009b8826c8bc","_type":"block","children":[{"_key":"dfd4cae149520","_type":"span","marks":[],"text":"On top of that, workflows can be executed manually, by calling "},{"_key":"dfd4cae149521","_type":"span","marks":["code"],"text":"run_step()"},{"_key":"dfd4cae149522","_type":"span","marks":[],"text":" multiple times until all the steps have completed. After each "},{"_key":"dfd4cae149523","_type":"span","marks":["code"],"text":"run_step"},{"_key":"dfd4cae149524","_type":"span","marks":[],"text":" call, the workflow can be inspected, examining any intermediate results or debug logs."}],"markDefs":[],"style":"normal"},{"_key":"c4dc668941be","_type":"block","children":[{"_key":"8d33408f253d0","_type":"span","marks":[],"text":"Why you should use workflows today"}],"markDefs":[],"style":"h2"},{"_key":"c3ee418f0ffc","_type":"block","children":[{"_key":"5eb9f3771aba0","_type":"span","marks":[],"text":"Despite being at an early stage of development, LlamaIndex workflows already represent a step forward compared to query pipelines, extending their functionalities and adding more flexibility. On top of that, workflows come with a set of features that you would normally expect from a much more mature software:"}],"markDefs":[],"style":"normal"},{"_key":"69d65f6dc99b","_type":"block","children":[{"_key":"48bc6805c6910","_type":"span","marks":[],"text":"Fully async with streaming support"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"021081a61503","_type":"block","children":[{"_key":"5118cd7e1c200","_type":"span","marks":[],"text":"Instrumented by default, providing one-click observability with the supported integrations"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"54dfa7a1f660","_type":"block","children":[{"_key":"8d7763dea38c0","_type":"span","marks":[],"text":"Step-by-step execution for easier debugging"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"b1784276200c","_type":"block","children":[{"_key":"9ef0c30508f10","_type":"span","marks":[],"text":"Validation and visualization of the event-driven dependencies"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"1ee26db05302","_type":"block","children":[{"_key":"0bf621595b420","_type":"span","marks":[],"text":"Events are implemented as pydantic models to ease customization and further developments of new features"}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"99739cfe75e7","_type":"block","children":[{"_key":"f67f11cba5f4","_type":"span","marks":[],"text":"Resources"}],"markDefs":[],"style":"h2"},{"_key":"6bcdcd4942e3","_type":"block","children":[{"_key":"3c598fe3b2ca","_type":"span","marks":[],"text":"Check out our "},{"_key":"880d467f57e6","_type":"span","marks":["9a22e652c969"],"text":"workflow documentation"},{"_key":"3ac51c16ac21","_type":"span","marks":[],"text":" and our "},{"_key":"7db902156caf","_type":"span","marks":["833e305fee0f"],"text":"examples"},{"_key":"0cc7330eb2a4","_type":"span","marks":[],"text":" including:"}],"markDefs":[{"_key":"9a22e652c969","_type":"link","href":"https://docs.llamaindex.ai/en/latest/module_guides/workflow/"},{"_key":"833e305fee0f","_type":"link","href":"https://github.com/run-llama/llama_index/tree/main/docs/docs/examples/workflow"}],"style":"normal"},{"_key":"6791d927ea35","_type":"block","children":[{"_key":"48d63a5b67ab","_type":"span","marks":["e6c86ea3d602"],"text":"RAG"}],"level":1,"listItem":"bullet","markDefs":[{"_key":"e6c86ea3d602","_type":"link","href":"https://docs.llamaindex.ai/en/latest/examples/workflow/rag/"}],"style":"normal"},{"_key":"bd7fde75cf4b","_type":"block","children":[{"_key":"332fef9e2a32","_type":"span","marks":["ca24a17acf93"],"text":"Reflection"}],"level":1,"listItem":"bullet","markDefs":[{"_key":"ca24a17acf93","_type":"link","href":"https://docs.llamaindex.ai/en/latest/examples/workflow/reflection/"}],"style":"normal"},{"_key":"3ce63968c9ea","_type":"block","children":[{"_key":"b0c26056b469","_type":"span","marks":["9f11ce666def"],"text":"Function calling"}],"level":1,"listItem":"bullet","markDefs":[{"_key":"9f11ce666def","_type":"link","href":"https://docs.llamaindex.ai/en/latest/examples/workflow/function_calling_agent/"}],"style":"normal"},{"_key":"529eb0958dc0","_type":"block","children":[{"_key":"b53e320e25b6","_type":"span","marks":["875d01767358"],"text":"ReAct agent"}],"level":1,"listItem":"bullet","markDefs":[{"_key":"875d01767358","_type":"link","href":"https://docs.llamaindex.ai/en/latest/examples/workflow/react_agent/"}],"style":"normal"}],"title":"Introducing workflows beta: a new way to create complex AI applications with LlamaIndex"},"publishedDate":"Invalid Date"},"params":{"slug":"introducing-workflows-beta-a-new-way-to-create-complex-ai-applications-with-llamaindex"},"draftMode":false,"token":""},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"introducing-workflows-beta-a-new-way-to-create-complex-ai-applications-with-llamaindex"},"buildId":"C8J-EMc_4OCN1ch65l4fl","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>