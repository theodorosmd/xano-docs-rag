<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>AI Voice Assistant: Enhancing Accessibility in AI with LlamaIndex and GPT3.5 (Deployed in Prod on Vercel and Render) — LlamaIndex - Build Knowledge Assistants over your Enterprise Data</title><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><meta name="title" content="AI Voice Assistant: Enhancing Accessibility in AI with LlamaIndex and GPT3.5 (Deployed in Prod on Vercel and Render) — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta name="description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:title" content="AI Voice Assistant: Enhancing Accessibility in AI with LlamaIndex and GPT3.5 (Deployed in Prod on Vercel and Render) — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="og:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:image" content="https://cdn.sanity.io/images/7m9jw85w/production/cf25f1a4cbaf20cc6e025ffeefb1a3603a0c74cc-1024x1024.png"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="AI Voice Assistant: Enhancing Accessibility in AI with LlamaIndex and GPT3.5 (Deployed in Prod on Vercel and Render) — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="twitter:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="twitter:image" content="https://cdn.sanity.io/images/7m9jw85w/production/cf25f1a4cbaf20cc6e025ffeefb1a3603a0c74cc-1024x1024.png"/><link rel="alternate" type="application/rss+xml" href="https://www.llamaindex.ai/blog/feed"/><meta name="next-head-count" content="20"/><script>
            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WWRFB36R');
            </script><link rel="preload" href="/_next/static/css/41c9222e47d080c9.css" as="style"/><link rel="stylesheet" href="/_next/static/css/41c9222e47d080c9.css" data-n-g=""/><link rel="preload" href="/_next/static/css/97c33c8d95f1230e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/97c33c8d95f1230e.css" data-n-p=""/><link rel="preload" href="/_next/static/css/e009059e80bf60c5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e009059e80bf60c5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-1b629d9c8fb16f34.js" defer=""></script><script src="/_next/static/chunks/framework-df1f68dff096b68a.js" defer=""></script><script src="/_next/static/chunks/main-eca7952a704663f8.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c7c49437be49d2ad.js" defer=""></script><script src="/_next/static/chunks/d9067523-4985945b21298365.js" defer=""></script><script src="/_next/static/chunks/41155975-60c12da9ce9fa0b2.js" defer=""></script><script src="/_next/static/chunks/cb355538-cee2ea45674d9de3.js" defer=""></script><script src="/_next/static/chunks/9494-dff62cb53535dd7d.js" defer=""></script><script src="/_next/static/chunks/4063-39a391a51171ff87.js" defer=""></script><script src="/_next/static/chunks/6889-edfa85b69b88a372.js" defer=""></script><script src="/_next/static/chunks/5575-11ee0a29eaffae61.js" defer=""></script><script src="/_next/static/chunks/3444-95c636af25a42734.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-82c8e764e69afd2c.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_buildManifest.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_ssgManifest.js" defer=""></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WWRFB36R" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div class="__variable_d65c78 __variable_b1ea77 __variable_eb7534"><a class="Announcement_announcement__2ohK8" href="http://48755185.hs-sites.com/llamaindex-0">Meet LlamaIndex at the Databricks Data + AI Summit!<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M8.293 5.293a1 1 0 0 1 1.414 0l6 6a1 1 0 0 1 0 1.414l-6 6a1 1 0 0 1-1.414-1.414L13.586 12 8.293 6.707a1 1 0 0 1 0-1.414Z" clip-rule="evenodd"></path></svg></a><header class="Header_header__hO3lJ"><button class="Hamburger_hamburger__17auO Header_hamburger__lUulX"><svg width="28" height="28" viewBox="0 0 28 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.5 14H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" id="hamburger-stroke-top" class="Hamburger_hamburgerStrokeMiddle__I7VpD"></path><path d="M3.5 7H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeTop__oOhFM"></path><path d="M3.5 21H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeBottom__GIQR2"></path></svg></button><a aria-label="Homepage" href="/"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" class="Header_logo__e5KhT" style="color:transparent" src="/llamaindex.svg"/></a><nav aria-label="Main" data-orientation="horizontal" dir="ltr" style="--content-position:0px"><div style="position:relative"><ul data-orientation="horizontal" class="Nav_MenuList__PrCDJ" dir="ltr"><li><button id="radix-:R6tm:-trigger-radix-:R5mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R5mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Products</button></li><li><button id="radix-:R6tm:-trigger-radix-:R9mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R9mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Solutions</button></li><li><a class="Nav_Link__ZrzFc" href="/community" data-radix-collection-item="">Community</a></li><li><a class="Nav_Link__ZrzFc" href="/pricing" data-radix-collection-item="">Pricing</a></li><li><a class="Nav_Link__ZrzFc" href="/blog" data-radix-collection-item="">Blog</a></li><li><a class="Nav_Link__ZrzFc" href="/customers" data-radix-collection-item="">Customer stories</a></li><li><a class="Nav_Link__ZrzFc" href="/careers" data-radix-collection-item="">Careers</a></li></ul></div><div class="Nav_ViewportPosition__jmyHM"></div></nav><div class="Header_secondNav__YJvm8"><nav><a href="/contact" class="Link_link__71cl8 Link_link-variant-tertiary__BYxn_ Header_bookADemo__qCuxV">Book a demo</a></nav><a href="https://cloud.llamaindex.ai/" class="Button_button-variant-default__Oi__n Button_button__aJ0V6 Header_button__1HFhY" data-tracking-variant="default"> <!-- -->Get started</a></div><div class="MobileMenu_mobileMenu__g5Fa6"><nav class="MobileMenu_nav__EmtTw"><ul><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Products<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaparse"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.6654 1.66675V6.66675H16.6654M8.33203 10.8334L6.66536 12.5001L8.33203 14.1667M11.6654 14.1667L13.332 12.5001L11.6654 10.8334M12.082 1.66675H4.9987C4.55667 1.66675 4.13275 1.84234 3.82019 2.1549C3.50763 2.46746 3.33203 2.89139 3.33203 3.33341V16.6667C3.33203 17.1088 3.50763 17.5327 3.82019 17.8453C4.13275 18.1578 4.55667 18.3334 4.9987 18.3334H14.9987C15.4407 18.3334 15.8646 18.1578 16.1772 17.8453C16.4898 17.5327 16.6654 17.1088 16.6654 16.6667V6.25008L12.082 1.66675Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Document parsing</div><p class="MobileMenu_ListItemText__n_MHY">The first and leading GenAI-native parser over your most complex data.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaextract"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.668 1.66675V5.00008C11.668 5.44211 11.8436 5.86603 12.1561 6.17859C12.4687 6.49115 12.8926 6.66675 13.3346 6.66675H16.668M3.33464 5.83341V3.33341C3.33464 2.89139 3.51023 2.46746 3.82279 2.1549C4.13535 1.84234 4.55927 1.66675 5.0013 1.66675H12.5013L16.668 5.83341V16.6667C16.668 17.1088 16.4924 17.5327 16.1798 17.8453C15.8672 18.1578 15.4433 18.3334 15.0013 18.3334L5.05379 18.3326C4.72458 18.3755 4.39006 18.3191 4.09312 18.1706C3.79618 18.0221 3.55034 17.7884 3.38713 17.4992M4.16797 9.16675L1.66797 11.6667M1.66797 11.6667L4.16797 14.1667M1.66797 11.6667H10.0013" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Data extraction</div><p class="MobileMenu_ListItemText__n_MHY">Extract structured data from documents using a schema-driven engine.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/enterprise"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.16667 15.8333C12.8486 15.8333 15.8333 12.8486 15.8333 9.16667C15.8333 5.48477 12.8486 2.5 9.16667 2.5C5.48477 2.5 2.5 5.48477 2.5 9.16667C2.5 12.8486 5.48477 15.8333 9.16667 15.8333Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M17.5 17.5L13.875 13.875" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Knowledge Management</div><p class="MobileMenu_ListItemText__n_MHY">Connect, transform, and index your enterprise data into an agent-accessible knowledge base</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/framework"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.0013 6.66659V3.33325H6.66797M1.66797 11.6666H3.33464M16.668 11.6666H18.3346M12.5013 10.8333V12.4999M7.5013 10.8333V12.4999M5.0013 6.66659H15.0013C15.9218 6.66659 16.668 7.41278 16.668 8.33325V14.9999C16.668 15.9204 15.9218 16.6666 15.0013 16.6666H5.0013C4.08083 16.6666 3.33464 15.9204 3.33464 14.9999V8.33325C3.33464 7.41278 4.08083 6.66659 5.0013 6.66659Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Agent Framework</div><p class="MobileMenu_ListItemText__n_MHY">Orchestrate and deploy multi-agent applications over your data with the #1 agent framework.</p></a></li></ul></details></li><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Solutions<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/finance"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 6.66675H8.33073C7.8887 6.66675 7.46478 6.84234 7.15222 7.1549C6.83966 7.46746 6.66406 7.89139 6.66406 8.33342C6.66406 8.77544 6.83966 9.19937 7.15222 9.51193C7.46478 9.82449 7.8887 10.0001 8.33073 10.0001H11.6641C12.1061 10.0001 12.53 10.1757 12.8426 10.4882C13.1551 10.8008 13.3307 11.2247 13.3307 11.6667C13.3307 12.1088 13.1551 12.5327 12.8426 12.8453C12.53 13.1578 12.1061 13.3334 11.6641 13.3334H6.66406M9.9974 15.0001V5.00008M18.3307 10.0001C18.3307 14.6025 14.5998 18.3334 9.9974 18.3334C5.39502 18.3334 1.66406 14.6025 1.66406 10.0001C1.66406 5.39771 5.39502 1.66675 9.9974 1.66675C14.5998 1.66675 18.3307 5.39771 18.3307 10.0001Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Financial Analysts</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/administrative-operations"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1.66406 6.66659V15.8333C1.66406 16.2753 1.83966 16.6992 2.15222 17.0118C2.46478 17.3243 2.8887 17.4999 3.33073 17.4999H14.9974M16.6641 14.1666C17.1061 14.1666 17.53 13.991 17.8426 13.6784C18.1551 13.3659 18.3307 12.9419 18.3307 12.4999V7.49992C18.3307 7.05789 18.1551 6.63397 17.8426 6.32141C17.53 6.00885 17.1061 5.83325 16.6641 5.83325H13.4141C13.1353 5.83598 12.8604 5.76876 12.6143 5.63774C12.3683 5.50671 12.159 5.31606 12.0057 5.08325L11.3307 4.08325C11.179 3.85281 10.9724 3.66365 10.7295 3.53275C10.4866 3.40185 10.215 3.3333 9.93906 3.33325H6.66406C6.22204 3.33325 5.79811 3.50885 5.48555 3.82141C5.17299 4.13397 4.9974 4.55789 4.9974 4.99992V12.4999C4.9974 12.9419 5.17299 13.3659 5.48555 13.6784C5.79811 13.991 6.22204 14.1666 6.66406 14.1666H16.6641Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Administrative Operations</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/engineering"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 15L18.3307 10L13.3307 5M6.66406 5L1.66406 10L6.66406 15" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Engineering &amp; R&amp;D</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/customer-support"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.9974 7.50008H16.6641C17.1061 7.50008 17.53 7.67568 17.8426 7.98824C18.1551 8.3008 18.3307 8.72472 18.3307 9.16675V18.3334L14.9974 15.0001H9.9974C9.55537 15.0001 9.13145 14.8245 8.81888 14.5119C8.50632 14.1994 8.33073 13.7754 8.33073 13.3334V12.5001M11.6641 7.50008C11.6641 7.94211 11.4885 8.36603 11.1759 8.67859C10.8633 8.99115 10.4394 9.16675 9.9974 9.16675H4.9974L1.66406 12.5001V3.33341C1.66406 2.41675 2.41406 1.66675 3.33073 1.66675H9.9974C10.4394 1.66675 10.8633 1.84234 11.1759 2.1549C11.4885 2.46746 11.6641 2.89139 11.6641 3.33341V7.50008Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Customer Support</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/healthcare-pharma"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M17.0128 3.81671C16.5948 3.39719 16.098 3.06433 15.551 2.8372C15.004 2.61008 14.4176 2.49316 13.8253 2.49316C13.2331 2.49316 12.6466 2.61008 12.0996 2.8372C11.5527 3.06433 11.0559 3.39719 10.6378 3.81671L9.99617 4.46671L9.3545 3.81671C8.93643 3.39719 8.43967 3.06433 7.89268 2.8372C7.3457 2.61008 6.75926 2.49316 6.167 2.49316C5.57474 2.49316 4.9883 2.61008 4.44132 2.8372C3.89433 3.06433 3.39756 3.39719 2.9795 3.81671C1.21283 5.58338 1.1045 8.56671 3.3295 10.8334L9.99617 17.5L16.6628 10.8334C18.8878 8.56671 18.7795 5.58338 17.0128 3.81671Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M2.91406 9.99992H7.91406L8.33073 9.16659L9.9974 12.9166L11.6641 7.08325L12.9141 9.99992H17.0807" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Healthcare / Pharma</div></a></li></ul></details></li><li><a class="MobileMenu_Link__5frcx" href="/community">Community</a></li><li><a class="MobileMenu_Link__5frcx" href="/pricing">Pricing</a></li><li><a class="MobileMenu_Link__5frcx" href="/blog">Blog</a></li><li><a class="MobileMenu_Link__5frcx" href="/customers">Customer stories</a></li><li><a class="MobileMenu_Link__5frcx" href="/careers">Careers</a></li></ul></nav><a href="/contact" class="Button_button-variant-ghost__o2AbG Button_button__aJ0V6" data-tracking-variant="ghost"> <!-- -->Talk to us</a><ul class="Socials_socials__8Y_s5 Socials_socials-theme-dark__Hq8lc MobileMenu_socials__JykCO"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu MobileMenu_copyright__nKVOs">© <!-- -->2025<!-- --> LlamaIndex</p></div></header><main><section class="BlogPost_post__JHNzd"><img alt="" loading="lazy" width="800" height="512" decoding="async" data-nimg="1" class="BlogPost_featuredImage__KGxwX" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fcf25f1a4cbaf20cc6e025ffeefb1a3603a0c74cc-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fcf25f1a4cbaf20cc6e025ffeefb1a3603a0c74cc-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fcf25f1a4cbaf20cc6e025ffeefb1a3603a0c74cc-1024x1024.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><p class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-600__fKYth BlogPost_date__6uxQw"><a class="BlogPost_author__mesdl" href="/blog/author/harshad-suryawanshi">Harshad Suryawanshi</a> <!-- -->•<!-- --> <!-- -->2024-01-14</p><h1 class="Text_text__zPO0D Text_text-size-32__koGps BlogPost_title__b2lqJ">AI Voice Assistant: Enhancing Accessibility in AI with LlamaIndex and GPT3.5 (Deployed in Prod on Vercel and Render)</h1><ul class="BlogPost_tags__13pBH"><li><a class="Badge_badge___1ssn" href="/blog/tag/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Llamaindex</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/voice-assistant"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Voice Assistant</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/openai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">OpenAI</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/accessibility"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Accessibility</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/inclusive-ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Inclusive Ai</span></a></li></ul><div class="BlogPost_htmlPost__Z5oDL"><h1>Introduction</h1><p>The C3 Voice Assistant is my latest project aimed at making Large Language Model (LLM) and Retrieval-Augmented Generation (RAG) applications more accessible. This voice-activated assistant caters to a broad audience, including those facing typing challenges or accessibility issues.</p><h1>Features</h1><ul><li><strong>Voice Activation:</strong> Initiated by saying “C3.” Alternatively, users can click the blue ring to activate the listening mode of the app. The wake word “C3” is configurable and you can choose any other word.</li><li><strong>Universal Accessibility:</strong> Ideal for users preferring voice commands or facing typing challenges.</li><li><strong>LLM Integration:</strong> Capable of general queries and document-specific inquiries (e.g., Nvidia’s FY 2023 10K report).</li><li><strong>User-Friendly Interface:</strong> The interface of the AI voice assistant is designed for simplicity and ease of use, focusing on voice chat interactions. It features a minimalistic and user-friendly React.js layout. Additionally, there is a convenient sidebar that displays the entire chat history in text format, allowing users to review and reflect on their interactions with the AI.</li></ul><iframe width="560" height="315" src="https://www.youtube.com/embed/5rqNU8akHb4?si=XhUH3_D568104cF0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe><h1>The Tech Stack</h1><p>The app is built on a robust and flexible tech stack that ensures a smooth, reliable, and efficient user experience. Here’s an overview:</p><ul><li><strong>Frontend: </strong>The user interface is a custom application developed using React.js. It’s designed to be minimalistic yet highly functional, prioritizing ease of use and accessibility.</li><li><strong>Backend:</strong> The server-side operations are powered by Python Flask. I’ve utilized the innovative ‘create-llama’ feature from LlamaIndex, which significantly streamlines the development process.</li><li><strong>Hosting:</strong> For a seamless performance, the frontend of the C3 Voice Assistant is hosted on Vercel. The backend, on the other hand, is deployed on Render, ensuring efficient management and operation of server-side tasks.</li></ul><h1>Building the Frontend</h1><figure><img src="/blog/images/1*VW4FctivpTmaQQjcAqXtzA.png" alt="" width="700" height="505"></figure><p>The frontend, built with React.js, focuses on user interaction and accessibility. The <code class="cw qb qc qd qe b">App.js</code> script incorporates features like wake word recognition, speech-to-text conversion, state management, and dynamic UI elements like speech bubbles and spinners.</p><h2>1. Component and State Initialization</h2><p>This section sets up the React component and initializes various states, such as <code class="cw qb qc qd qe b">appState</code> to track the current state of the app (idle, listening, speaking), and <code class="cw qb qc qd qe b">transcript</code> to store the text transcribed from user speech.</p><pre><span id="0e15" class="qx nb gt qe b bf qy qz l ra rb"><span class="hljs-keyword">import</span> <span class="hljs-title class_">React</span>, { useState, useRef, useEffect } <span class="hljs-keyword">from</span> <span class="hljs-string">"react"</span>;
<span class="hljs-keyword">import</span> <span class="hljs-string">"./App.css"</span>;

<span class="hljs-keyword">const</span> <span class="hljs-title class_">App</span> = () =&amp;gt; {
  <span class="hljs-keyword">const</span> [appState, setAppState] = <span class="hljs-title function_">useState</span>(<span class="hljs-string">"idle"</span>);
  <span class="hljs-keyword">const</span> [transcript, setTranscript] = <span class="hljs-title function_">useState</span>(<span class="hljs-string">""</span>);
  <span class="hljs-comment">// Additional state and ref declarations...</span>
};</span></pre><h2>2. Speech Recognition Setup</h2><p>In this useEffect hook, two speech recognition instances are initialized: one for detecting the wake word “C3” and another for the main speech recognition. This setup ensures that the app starts listening for commands when “C3” is mentioned.</p><p>You can easily swap “C3” with any other wake word of your choice.</p><pre><span id="d657" class="qx nb gt qe b bf qy qz l ra rb">  <span class="hljs-title function_">useEffect</span>(() =&amp;gt; {
    <span class="hljs-comment">// Wake word listener setup</span>
    <span class="hljs-keyword">const</span> <span class="hljs-title class_">WakeWordSpeechRecognition</span> =
      <span class="hljs-variable language_">window</span>.<span class="hljs-property">SpeechRecognition</span> || <span class="hljs-variable language_">window</span>.<span class="hljs-property">webkitSpeechRecognition</span>;
    <span class="hljs-keyword">if</span> (<span class="hljs-title class_">WakeWordSpeechRecognition</span> &amp;amp;&amp;amp; !wakeWordRecognitionRef.<span class="hljs-property">current</span>) {
      wakeWordRecognitionRef.<span class="hljs-property">current</span> = <span class="hljs-keyword">new</span> <span class="hljs-title class_">WakeWordSpeechRecognition</span>();
      wakeWordRecognitionRef.<span class="hljs-property">current</span>.<span class="hljs-property">continuous</span> = <span class="hljs-literal">true</span>;
      wakeWordRecognitionRef.<span class="hljs-property">current</span>.<span class="hljs-property">interimResults</span> = <span class="hljs-literal">false</span>;

      wakeWordRecognitionRef.<span class="hljs-property">current</span>.<span class="hljs-property">onresult</span> = (event) =&amp;gt; {
        <span class="hljs-keyword">const</span> transcript = event.<span class="hljs-property">results</span>[event.<span class="hljs-property">results</span>.<span class="hljs-property">length</span> - <span class="hljs-number">1</span>][<span class="hljs-number">0</span>].<span class="hljs-property">transcript</span>
          .<span class="hljs-title function_">trim</span>()
          .<span class="hljs-title function_">toLowerCase</span>();
        <span class="hljs-keyword">if</span> (transcript.<span class="hljs-title function_">includes</span>(<span class="hljs-string">"c3"</span>)) {
          <span class="hljs-title function_">toggleRecording</span>(); <span class="hljs-comment">// Start the main speech recognition process</span>
        }
      };

      wakeWordRecognitionRef.<span class="hljs-property">current</span>.<span class="hljs-title function_">start</span>();
    }

    <span class="hljs-comment">// Main speech recognition setup</span>
    <span class="hljs-keyword">const</span> <span class="hljs-title class_">SpeechRecognition</span> =
      <span class="hljs-variable language_">window</span>.<span class="hljs-property">SpeechRecognition</span> || <span class="hljs-variable language_">window</span>.<span class="hljs-property">webkitSpeechRecognition</span>;
    <span class="hljs-keyword">if</span> (<span class="hljs-title class_">SpeechRecognition</span> &amp;amp;&amp;amp; !recognitionRef.<span class="hljs-property">current</span>) {
      recognitionRef.<span class="hljs-property">current</span> = <span class="hljs-keyword">new</span> <span class="hljs-title class_">SpeechRecognition</span>();
      recognitionRef.<span class="hljs-property">current</span>.<span class="hljs-property">continuous</span> = <span class="hljs-literal">false</span>;
      recognitionRef.<span class="hljs-property">current</span>.<span class="hljs-property">interimResults</span> = <span class="hljs-literal">false</span>;

      recognitionRef.<span class="hljs-property">current</span>.<span class="hljs-property">onresult</span> = (event) =&amp;gt; {
        <span class="hljs-keyword">const</span> lastResultIndex = event.<span class="hljs-property">results</span>.<span class="hljs-property">length</span> - <span class="hljs-number">1</span>;
        <span class="hljs-keyword">const</span> transcriptResult = event.<span class="hljs-property">results</span>[lastResultIndex][<span class="hljs-number">0</span>].<span class="hljs-property">transcript</span>;
        <span class="hljs-title function_">setTranscript</span>(transcriptResult);
        <span class="hljs-title function_">setAppState</span>(<span class="hljs-string">"playing"</span>);
        <span class="hljs-title function_">setShowSpeechBubble</span>(<span class="hljs-literal">true</span>);
        <span class="hljs-built_in">setTimeout</span>(() =&amp;gt; <span class="hljs-title function_">setShowSpeechBubble</span>(<span class="hljs-literal">false</span>), speechBubbleTimeout);
        <span class="hljs-title function_">fetchResponseFromLLM</span>(transcriptResult);
      };

      recognitionRef.<span class="hljs-property">current</span>.<span class="hljs-property">onend</span> = () =&amp;gt; {
        <span class="hljs-title function_">setShowSpinner</span>(<span class="hljs-literal">true</span>);
      };
    }
  }, []);</span></pre><h2>3. Handling User Speech and Response</h2><p><code class="cw qb qc qd qe b">toggleRecording</code> controls the speech recognition process, while <code class="cw qb qc qd qe b">fetchResponseFromLLM</code> sends the user's speech to the LLM backend and handles the response. This response is then spoken out via speech synthesis and also used to update the chat history displayed on the UI.</p><pre><span id="79b9" class="qx nb gt qe b bf qy qz l ra rb"> <span class="hljs-keyword">const</span> toggleRecording = () =&amp;gt; {
    <span class="hljs-keyword">try</span> {
      <span class="hljs-keyword">if</span> (appState === <span class="hljs-string">"idle"</span>) {
        recognitionRef.<span class="hljs-property">current</span>.<span class="hljs-title function_">start</span>();
        <span class="hljs-title function_">setAppState</span>(<span class="hljs-string">"listening"</span>);
      } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (appState === <span class="hljs-string">"listening"</span>) {
        recognitionRef.<span class="hljs-property">current</span>.<span class="hljs-title function_">stop</span>();
      }
    } <span class="hljs-keyword">catch</span> (error) {
    }
  };</span></pre><pre><span id="05ef" class="qx nb gt qe b bf qy qz l ra rb">  <span class="hljs-keyword">const</span> fetchResponseFromLLM = <span class="hljs-keyword">async</span> (text) =&amp;gt; {
    <span class="hljs-keyword">try</span> {
      <span class="hljs-keyword">const</span> response = <span class="hljs-keyword">await</span> <span class="hljs-title function_">fetch</span>(
        <span class="hljs-string">`https://c3-python-nostream.onrender.com/api/chat`</span>,
        {
          <span class="hljs-attr">method</span>: <span class="hljs-string">"POST"</span>,
          <span class="hljs-attr">headers</span>: { <span class="hljs-string">"Content-Type"</span>: <span class="hljs-string">"application/json"</span> },
          <span class="hljs-attr">body</span>: <span class="hljs-title class_">JSON</span>.<span class="hljs-title function_">stringify</span>({
            <span class="hljs-attr">messages</span>: [
              {
                <span class="hljs-attr">role</span>: <span class="hljs-string">"user"</span>,
                <span class="hljs-attr">content</span>:
                  <span class="hljs-string">"You are an AI voice assistant called C3. You can provide any general information as well as answer basic questions about the Nvidia 10k report for year ended Jan 2023"</span> +
                  text,
              },
            ],
          }),
        }
      );
      <span class="hljs-keyword">const</span> data = <span class="hljs-keyword">await</span> response.<span class="hljs-title function_">json</span>();

      <span class="hljs-title function_">setChatHistory</span>((prevHistory) =&amp;gt; [
        ...prevHistory,
        { <span class="hljs-attr">query</span>: text, <span class="hljs-attr">response</span>: data.<span class="hljs-property">result</span>.<span class="hljs-property">content</span> },
      ]);
      <span class="hljs-title function_">speak</span>(data.<span class="hljs-property">result</span>.<span class="hljs-property">content</span>);
    } <span class="hljs-keyword">catch</span> (error) {
      <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">error</span>(<span class="hljs-string">"Error communicating with LLM:"</span>, error);
    }
  };</span></pre><h2>4. Speech Synthesis</h2><p>The <code class="cw qb qc qd qe b">speak</code> function takes the text response from the LLM and uses the SpeechSynthesis API to read it aloud, providing an interactive experience for the user.</p><pre><span id="e336" class="qx nb gt qe b bf qy qz l ra rb">  <span class="hljs-keyword">const</span> speak = (text) =&amp;gt; {
    <span class="hljs-keyword">if</span> (synthRef.<span class="hljs-property">current</span> &amp;amp;&amp;amp; text) {
      <span class="hljs-keyword">const</span> utterance = <span class="hljs-keyword">new</span> <span class="hljs-title class_">SpeechSynthesisUtterance</span>(text);

      <span class="hljs-keyword">const</span> voices = <span class="hljs-variable language_">window</span>.<span class="hljs-property">speechSynthesis</span>.<span class="hljs-title function_">getVoices</span>();
      <span class="hljs-keyword">if</span> (voices.<span class="hljs-property">length</span> &amp;gt; <span class="hljs-number">0</span>) {
        utterance.<span class="hljs-property">voice</span> = voices[<span class="hljs-number">3</span>]; <span class="hljs-comment">// You can change this to select different voices</span>
      }

      utterance.<span class="hljs-property">onstart</span> = () =&amp;gt; {
        <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(<span class="hljs-string">"TTS starts speaking"</span>);
        <span class="hljs-title function_">setShowSpinner</span>(<span class="hljs-literal">false</span>);
      };

      utterance.<span class="hljs-property">onend</span> = () =&amp;gt; {
        <span class="hljs-title function_">setAppState</span>(<span class="hljs-string">"idle"</span>);
        <span class="hljs-keyword">if</span> (wakeWordRecognitionRef.<span class="hljs-property">current</span>) {
          wakeWordRecognitionRef.<span class="hljs-property">current</span>.<span class="hljs-title function_">start</span>(); <span class="hljs-comment">// Restart wake word listener after speaking</span>
        }
      };
      synthRef.<span class="hljs-property">current</span>.<span class="hljs-title function_">speak</span>(utterance);
    }</span></pre><h2>5. UI Rendering</h2><p>The return statement of the <code class="cw qb qc qd qe b">App</code> function contains the JSX code for rendering the app's UI. This includes buttons for starting/stopping the voice interaction, a display area for the transcript, and a chat sidebar showing the history of interactions.</p><p>By combining voice recognition, LLM integration, and speech synthesis, this frontend component provides a comprehensive and accessible interface for interacting with the C3 Voice Assistant.</p><h1>Backend Server Setup</h1><ol><li>Initialize Create-Llama: Run <code class="cw qb qc qd qe b">npx create-llama@latest</code> in your terminal.</li><li>Follow the prompts to set up a Python FastAPI backend, which we can be integrated with our frontend.</li><li>Use <code class="cw qb qc qd qe b">poetry install</code> and <code class="cw qb qc qd qe b">poetry shell</code> to prepare the environment.</li><li>Create a <code class="cw qb qc qd qe b">.env</code> file with <code class="cw qb qc qd qe b">OPENAI_API_KEY=&lt;openai_api_key&gt;</code>.</li><li>Generate Embeddings (optional): If a <code class="cw qb qc qd qe b">./data</code> directory exists, run <code class="cw qb qc qd qe b">python app/engine/generate.py</code>.</li><li>Execute <code class="cw qb qc qd qe b">python main.py</code>to start the server.</li><li>Test the API: Use <code class="cw qb qc qd qe b">curl --location 'localhost:8000/api/chat' --header 'Content-Type: application/json' --data '{ "messages": [{ "role": "user", "content": "Hello" }] }'</code> to test.</li><li>Modify API behavior in <code class="cw qb qc qd qe b">app/api/routers/chat.py</code>. The server supports CORS for all origins, alterable with the <code class="cw qb qc qd qe b">ENVIRONMENT=prod</code> setting.</li></ol><h1>Integration</h1><p>Once the backend server is set up, integrating it with the frontend is straightforward. Simply update the <code class="cw qb qc qd qe b">fetchResponseFromLLM</code> function in your frontend's <code class="cw qb qc qd qe b">App.js</code> to call the backend server URL. This change ensures that when the frontend makes a request, it communicates with your newly configured backend, thus effectively integrating the two components.</p><h1>Final Thoughts</h1><p>Wrapping up, the C3 Voice Assistant isn’t just a tech showcase; it’s a stride towards democratizing AI. It’s about making powerful AI tools, like LLMs and RAG, accessible and user-friendly. This project is more than lines of code — it’s a push to break down tech barriers and empower everyone.</p><p>Your thoughts and feedback are invaluable — let’s make AI more accessible together!</p><p>Link to Github Repo: <a href="https://github.com/AI-ANK/C3-Voice-Assistant-UI" rel="noopener ugc nofollow" target="_blank">Frontend</a> and <a href="https://github.com/AI-ANK/c3-python-nostream" rel="noopener ugc nofollow" target="_blank">Backend</a></p><p><a href="https://www.linkedin.com/in/harshadsuryawanshi/" rel="noopener ugc nofollow" target="_blank">Connect with Me on LinkedIn</a></p><p><a href="https://www.linkedin.com/posts/harshadsuryawanshi_ai-llamaindex-gpt3-activity-7149796976442740736-1lXj?utm_source=share&amp;utm_medium=member_desktop" rel="noopener ugc nofollow" target="_blank">Linkedin Post</a></p></div><div class="BlogPost_relatedPosts__0z6SN"><h2 class="Text_text__zPO0D Text_text-align-center__HhKqo Text_text-size-16__PkjFu Text_text-weight-400__5ENkK Text_text-family-spaceGrotesk__E4zcE BlogPost_relatedPostsTitle___JIrW">Related articles</h2><ul class="BlogPost_relatedPostsList__uOKzB"><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F39a875fc787fe28f9e44db8769c6fab9c31c7e17-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F39a875fc787fe28f9e44db8769c6fab9c31c7e17-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F39a875fc787fe28f9e44db8769c6fab9c31c7e17-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/llamaindex-newsletter-2024-02-27-4b9102a0f824">LlamaIndex Newsletter 2024–02–27</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-02-27</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F34ef148ef2e331372f8f0db7a8e9c9c11a76b504-1600x646.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F34ef148ef2e331372f8f0db7a8e9c9c11a76b504-1600x646.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F34ef148ef2e331372f8f0db7a8e9c9c11a76b504-1600x646.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/bridging-the-gap-in-crisis-counseling-introducing-counselor-copilot-db42e26ab4f3">Bridging the Gap in Crisis Counseling: Introducing Counselor Copilot</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-02-24</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F65e2a4a5037cc464566a13e7828fbb905fd33b38-960x863.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F65e2a4a5037cc464566a13e7828fbb905fd33b38-960x863.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F65e2a4a5037cc464566a13e7828fbb905fd33b38-960x863.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b">Introducing LlamaCloud and LlamaParse</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-02-20</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F81f41e8a6fe34f544e518f6e137dbf559e8885da-1024x1024.jpg%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F81f41e8a6fe34f544e518f6e137dbf559e8885da-1024x1024.jpg%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F81f41e8a6fe34f544e518f6e137dbf559e8885da-1024x1024.jpg%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/llamaindex-newsletter-2024-02-20-introducing-llamacloud-30511f4662f4">LlamaIndex Newsletter 2024–02–20: introducing LlamaCloud</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-02-20</p></div></li></ul></div></section></main><footer class="Footer_footer__eNA9m"><div class="Footer_navContainer__7bvx4"><div class="Footer_logoContainer__3EpzI"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" style="color:transparent" src="/llamaindex.svg"/><div class="Footer_socialContainer__GdOgk"><ul class="Socials_socials__8Y_s5"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul></div></div><div class="Footer_nav__BLEuE"><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/">LlamaIndex</a></h3><ul><li><a href="/blog"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Blog</span></a></li><li><a href="/partners"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Partners</span></a></li><li><a href="/careers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Careers</span></a></li><li><a href="/contact"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Contact</span></a></li><li><a href="/brand"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Brand</span></a></li><li><a href="https://llamaindex.statuspage.io" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Status</span></a></li><li><a href="https://app.vanta.com/runllama.ai/trust/pkcgbjf8b3ihxjpqdx17nu" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Trust Center</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/enterprise">Enterprise</a></h3><ul><li><a href="https://cloud.llamaindex.ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaCloud</span></a></li><li><a href="https://cloud.llamaindex.ai/parse" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaParse</span></a></li><li><a href="/customers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Customers</span></a></li><li><a href="/llamacloud-sharepoint-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SharePoint</span></a></li><li><a href="/llamacloud-aws-s3-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">AWS S3</span></a></li><li><a href="/llamacloud-azure-blob-storage-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure Blob Storage</span></a></li><li><a href="/llamacloud-google-drive-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Google Drive</span></a></li> </ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/framework">Framework</a></h3><ul><li><a href="https://pypi.org/project/llama-index/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python package</span></a></li><li><a href="https://docs.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python docs</span></a></li><li><a href="https://www.npmjs.com/package/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript package</span></a></li><li><a href="https://ts.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript docs</span></a></li><li><a href="https://llamahub.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaHub</span></a></li><li><a href="https://github.com/run-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">GitHub</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/community">Community</a></h3><ul><li><a href="/community#newsletter"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Newsletter</span></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Discord</span></a></li><li><a href="https://www.linkedin.com/company/91154103/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LinkedIn</span></a></li><li><a href="https://twitter.com/llama_index"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Twitter/X</span></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">YouTube</span></a></li><li><a href="https://bsky.app/profile/llamaindex.bsky.social"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">BlueSky</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e">Starter projects</h3><ul><li><a href="https://www.npmjs.com/package/create-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">create-llama</span></a></li><li><a href="https://secinsights.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SEC Insights</span></a></li><li><a href="https://github.com/run-llama/llamabot"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaBot</span></a></li><li><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/rag_cli.html"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">RAG CLI</span></a></li></ul></div></div></div><div class="Footer_copyrightContainer__mBKsT"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA">© <!-- -->2025<!-- --> LlamaIndex</p><div class="Footer_legalNav__O1yJA"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/privacy-notice.pdf">Privacy Notice</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/terms-of-service.pdf">Terms of Service</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="https://bit.ly/llamaindexdpa">Data Processing Addendum</a></p></div></div></footer></div><svg xmlns="http://www.w3.org/2000/svg" class="flt_svg" style="display:none"><defs><filter id="flt_tag"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="2"></feGaussianBlur><feColorMatrix in="blur" result="flt_tag" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="flt_tag" operator="atop"></feComposite></filter><filter id="svg_blur_large"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="8"></feGaussianBlur><feColorMatrix in="blur" result="svg_blur_large" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="svg_blur_large" operator="atop"></feComposite></filter></defs></svg></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"page":{"announcement":{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"},"post":{"_createdAt":"2024-02-22T21:47:07Z","_id":"449c511c-b4ba-46d5-91dd-85aeeae67291","_rev":"05dtDS0H5iRVsxYMarZ7DT","_type":"blogPost","_updatedAt":"2025-05-21T20:37:21Z","announcement":[{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"}],"authors":[{"_createdAt":"2024-02-22T19:51:08Z","_id":"e1ef8fc3-74dc-41a2-864d-4ae53df698e3","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"people","_updatedAt":"2024-02-24T20:08:05Z","name":"Harshad Suryawanshi","slug":{"_type":"slug","current":"harshad-suryawanshi"}}],"featured":false,"htmlContent":"\u003ch1\u003eIntroduction\u003c/h1\u003e\u003cp\u003eThe C3 Voice Assistant is my latest project aimed at making Large Language Model (LLM) and Retrieval-Augmented Generation (RAG) applications more accessible. This voice-activated assistant caters to a broad audience, including those facing typing challenges or accessibility issues.\u003c/p\u003e\u003ch1\u003eFeatures\u003c/h1\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eVoice Activation:\u003c/strong\u003e Initiated by saying “C3.” Alternatively, users can click the blue ring to activate the listening mode of the app. The wake word “C3” is configurable and you can choose any other word.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eUniversal Accessibility:\u003c/strong\u003e Ideal for users preferring voice commands or facing typing challenges.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eLLM Integration:\u003c/strong\u003e Capable of general queries and document-specific inquiries (e.g., Nvidia’s FY 2023 10K report).\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eUser-Friendly Interface:\u003c/strong\u003e The interface of the AI voice assistant is designed for simplicity and ease of use, focusing on voice chat interactions. It features a minimalistic and user-friendly React.js layout. Additionally, there is a convenient sidebar that displays the entire chat history in text format, allowing users to review and reflect on their interactions with the AI.\u003c/li\u003e\u003c/ul\u003e\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/5rqNU8akHb4?si=XhUH3_D568104cF0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen\u003e\u003c/iframe\u003e\u003ch1\u003eThe Tech Stack\u003c/h1\u003e\u003cp\u003eThe app is built on a robust and flexible tech stack that ensures a smooth, reliable, and efficient user experience. Here’s an overview:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eFrontend: \u003c/strong\u003eThe user interface is a custom application developed using React.js. It’s designed to be minimalistic yet highly functional, prioritizing ease of use and accessibility.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eBackend:\u003c/strong\u003e The server-side operations are powered by Python Flask. I’ve utilized the innovative ‘create-llama’ feature from LlamaIndex, which significantly streamlines the development process.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eHosting:\u003c/strong\u003e For a seamless performance, the frontend of the C3 Voice Assistant is hosted on Vercel. The backend, on the other hand, is deployed on Render, ensuring efficient management and operation of server-side tasks.\u003c/li\u003e\u003c/ul\u003e\u003ch1\u003eBuilding the Frontend\u003c/h1\u003e\u003cfigure\u003e\u003cimg src=\"/blog/images/1*VW4FctivpTmaQQjcAqXtzA.png\" alt=\"\" width=\"700\" height=\"505\"\u003e\u003c/figure\u003e\u003cp\u003eThe frontend, built with React.js, focuses on user interaction and accessibility. The \u003ccode class=\"cw qb qc qd qe b\"\u003eApp.js\u003c/code\u003e script incorporates features like wake word recognition, speech-to-text conversion, state management, and dynamic UI elements like speech bubbles and spinners.\u003c/p\u003e\u003ch2\u003e1. Component and State Initialization\u003c/h2\u003e\u003cp\u003eThis section sets up the React component and initializes various states, such as \u003ccode class=\"cw qb qc qd qe b\"\u003eappState\u003c/code\u003e to track the current state of the app (idle, listening, speaking), and \u003ccode class=\"cw qb qc qd qe b\"\u003etranscript\u003c/code\u003e to store the text transcribed from user speech.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"0e15\" class=\"qx nb gt qe b bf qy qz l ra rb\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eReact\u003c/span\u003e, { useState, useRef, useEffect } \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"react\"\u003c/span\u003e;\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"./App.css\"\u003c/span\u003e;\n\n\u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eApp\u003c/span\u003e = () =\u0026amp;gt; {\n  \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e [appState, setAppState] = \u003cspan class=\"hljs-title function_\"\u003euseState\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"idle\"\u003c/span\u003e);\n  \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e [transcript, setTranscript] = \u003cspan class=\"hljs-title function_\"\u003euseState\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e);\n  \u003cspan class=\"hljs-comment\"\u003e// Additional state and ref declarations...\u003c/span\u003e\n};\u003c/span\u003e\u003c/pre\u003e\u003ch2\u003e2. Speech Recognition Setup\u003c/h2\u003e\u003cp\u003eIn this useEffect hook, two speech recognition instances are initialized: one for detecting the wake word “C3” and another for the main speech recognition. This setup ensures that the app starts listening for commands when “C3” is mentioned.\u003c/p\u003e\u003cp\u003eYou can easily swap “C3” with any other wake word of your choice.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"d657\" class=\"qx nb gt qe b bf qy qz l ra rb\"\u003e  \u003cspan class=\"hljs-title function_\"\u003euseEffect\u003c/span\u003e(() =\u0026amp;gt; {\n    \u003cspan class=\"hljs-comment\"\u003e// Wake word listener setup\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eWakeWordSpeechRecognition\u003c/span\u003e =\n      \u003cspan class=\"hljs-variable language_\"\u003ewindow\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eSpeechRecognition\u003c/span\u003e || \u003cspan class=\"hljs-variable language_\"\u003ewindow\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003ewebkitSpeechRecognition\u003c/span\u003e;\n    \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e (\u003cspan class=\"hljs-title class_\"\u003eWakeWordSpeechRecognition\u003c/span\u003e \u0026amp;amp;\u0026amp;amp; !wakeWordRecognitionRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e) {\n      wakeWordRecognitionRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e = \u003cspan class=\"hljs-keyword\"\u003enew\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eWakeWordSpeechRecognition\u003c/span\u003e();\n      wakeWordRecognitionRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003econtinuous\u003c/span\u003e = \u003cspan class=\"hljs-literal\"\u003etrue\u003c/span\u003e;\n      wakeWordRecognitionRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003einterimResults\u003c/span\u003e = \u003cspan class=\"hljs-literal\"\u003efalse\u003c/span\u003e;\n\n      wakeWordRecognitionRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eonresult\u003c/span\u003e = (event) =\u0026amp;gt; {\n        \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e transcript = event.\u003cspan class=\"hljs-property\"\u003eresults\u003c/span\u003e[event.\u003cspan class=\"hljs-property\"\u003eresults\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003elength\u003c/span\u003e - \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e][\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].\u003cspan class=\"hljs-property\"\u003etranscript\u003c/span\u003e\n          .\u003cspan class=\"hljs-title function_\"\u003etrim\u003c/span\u003e()\n          .\u003cspan class=\"hljs-title function_\"\u003etoLowerCase\u003c/span\u003e();\n        \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e (transcript.\u003cspan class=\"hljs-title function_\"\u003eincludes\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"c3\"\u003c/span\u003e)) {\n          \u003cspan class=\"hljs-title function_\"\u003etoggleRecording\u003c/span\u003e(); \u003cspan class=\"hljs-comment\"\u003e// Start the main speech recognition process\u003c/span\u003e\n        }\n      };\n\n      wakeWordRecognitionRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003estart\u003c/span\u003e();\n    }\n\n    \u003cspan class=\"hljs-comment\"\u003e// Main speech recognition setup\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eSpeechRecognition\u003c/span\u003e =\n      \u003cspan class=\"hljs-variable language_\"\u003ewindow\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eSpeechRecognition\u003c/span\u003e || \u003cspan class=\"hljs-variable language_\"\u003ewindow\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003ewebkitSpeechRecognition\u003c/span\u003e;\n    \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e (\u003cspan class=\"hljs-title class_\"\u003eSpeechRecognition\u003c/span\u003e \u0026amp;amp;\u0026amp;amp; !recognitionRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e) {\n      recognitionRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e = \u003cspan class=\"hljs-keyword\"\u003enew\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eSpeechRecognition\u003c/span\u003e();\n      recognitionRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003econtinuous\u003c/span\u003e = \u003cspan class=\"hljs-literal\"\u003efalse\u003c/span\u003e;\n      recognitionRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003einterimResults\u003c/span\u003e = \u003cspan class=\"hljs-literal\"\u003efalse\u003c/span\u003e;\n\n      recognitionRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eonresult\u003c/span\u003e = (event) =\u0026amp;gt; {\n        \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e lastResultIndex = event.\u003cspan class=\"hljs-property\"\u003eresults\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003elength\u003c/span\u003e - \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e;\n        \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e transcriptResult = event.\u003cspan class=\"hljs-property\"\u003eresults\u003c/span\u003e[lastResultIndex][\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].\u003cspan class=\"hljs-property\"\u003etranscript\u003c/span\u003e;\n        \u003cspan class=\"hljs-title function_\"\u003esetTranscript\u003c/span\u003e(transcriptResult);\n        \u003cspan class=\"hljs-title function_\"\u003esetAppState\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"playing\"\u003c/span\u003e);\n        \u003cspan class=\"hljs-title function_\"\u003esetShowSpeechBubble\u003c/span\u003e(\u003cspan class=\"hljs-literal\"\u003etrue\u003c/span\u003e);\n        \u003cspan class=\"hljs-built_in\"\u003esetTimeout\u003c/span\u003e(() =\u0026amp;gt; \u003cspan class=\"hljs-title function_\"\u003esetShowSpeechBubble\u003c/span\u003e(\u003cspan class=\"hljs-literal\"\u003efalse\u003c/span\u003e), speechBubbleTimeout);\n        \u003cspan class=\"hljs-title function_\"\u003efetchResponseFromLLM\u003c/span\u003e(transcriptResult);\n      };\n\n      recognitionRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eonend\u003c/span\u003e = () =\u0026amp;gt; {\n        \u003cspan class=\"hljs-title function_\"\u003esetShowSpinner\u003c/span\u003e(\u003cspan class=\"hljs-literal\"\u003etrue\u003c/span\u003e);\n      };\n    }\n  }, []);\u003c/span\u003e\u003c/pre\u003e\u003ch2\u003e3. Handling User Speech and Response\u003c/h2\u003e\u003cp\u003e\u003ccode class=\"cw qb qc qd qe b\"\u003etoggleRecording\u003c/code\u003e controls the speech recognition process, while \u003ccode class=\"cw qb qc qd qe b\"\u003efetchResponseFromLLM\u003c/code\u003e sends the user's speech to the LLM backend and handles the response. This response is then spoken out via speech synthesis and also used to update the chat history displayed on the UI.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"79b9\" class=\"qx nb gt qe b bf qy qz l ra rb\"\u003e \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e toggleRecording = () =\u0026amp;gt; {\n    \u003cspan class=\"hljs-keyword\"\u003etry\u003c/span\u003e {\n      \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e (appState === \u003cspan class=\"hljs-string\"\u003e\"idle\"\u003c/span\u003e) {\n        recognitionRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003estart\u003c/span\u003e();\n        \u003cspan class=\"hljs-title function_\"\u003esetAppState\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"listening\"\u003c/span\u003e);\n      } \u003cspan class=\"hljs-keyword\"\u003eelse\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e (appState === \u003cspan class=\"hljs-string\"\u003e\"listening\"\u003c/span\u003e) {\n        recognitionRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003estop\u003c/span\u003e();\n      }\n    } \u003cspan class=\"hljs-keyword\"\u003ecatch\u003c/span\u003e (error) {\n    }\n  };\u003c/span\u003e\u003c/pre\u003e\u003cpre\u003e\u003cspan id=\"05ef\" class=\"qx nb gt qe b bf qy qz l ra rb\"\u003e  \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e fetchResponseFromLLM = \u003cspan class=\"hljs-keyword\"\u003easync\u003c/span\u003e (text) =\u0026amp;gt; {\n    \u003cspan class=\"hljs-keyword\"\u003etry\u003c/span\u003e {\n      \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e response = \u003cspan class=\"hljs-keyword\"\u003eawait\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003efetch\u003c/span\u003e(\n        \u003cspan class=\"hljs-string\"\u003e`https://c3-python-nostream.onrender.com/api/chat`\u003c/span\u003e,\n        {\n          \u003cspan class=\"hljs-attr\"\u003emethod\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"POST\"\u003c/span\u003e,\n          \u003cspan class=\"hljs-attr\"\u003eheaders\u003c/span\u003e: { \u003cspan class=\"hljs-string\"\u003e\"Content-Type\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"application/json\"\u003c/span\u003e },\n          \u003cspan class=\"hljs-attr\"\u003ebody\u003c/span\u003e: \u003cspan class=\"hljs-title class_\"\u003eJSON\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003estringify\u003c/span\u003e({\n            \u003cspan class=\"hljs-attr\"\u003emessages\u003c/span\u003e: [\n              {\n                \u003cspan class=\"hljs-attr\"\u003erole\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"user\"\u003c/span\u003e,\n                \u003cspan class=\"hljs-attr\"\u003econtent\u003c/span\u003e:\n                  \u003cspan class=\"hljs-string\"\u003e\"You are an AI voice assistant called C3. You can provide any general information as well as answer basic questions about the Nvidia 10k report for year ended Jan 2023\"\u003c/span\u003e +\n                  text,\n              },\n            ],\n          }),\n        }\n      );\n      \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e data = \u003cspan class=\"hljs-keyword\"\u003eawait\u003c/span\u003e response.\u003cspan class=\"hljs-title function_\"\u003ejson\u003c/span\u003e();\n\n      \u003cspan class=\"hljs-title function_\"\u003esetChatHistory\u003c/span\u003e((prevHistory) =\u0026amp;gt; [\n        ...prevHistory,\n        { \u003cspan class=\"hljs-attr\"\u003equery\u003c/span\u003e: text, \u003cspan class=\"hljs-attr\"\u003eresponse\u003c/span\u003e: data.\u003cspan class=\"hljs-property\"\u003eresult\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003econtent\u003c/span\u003e },\n      ]);\n      \u003cspan class=\"hljs-title function_\"\u003espeak\u003c/span\u003e(data.\u003cspan class=\"hljs-property\"\u003eresult\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003econtent\u003c/span\u003e);\n    } \u003cspan class=\"hljs-keyword\"\u003ecatch\u003c/span\u003e (error) {\n      \u003cspan class=\"hljs-variable language_\"\u003econsole\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eerror\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"Error communicating with LLM:\"\u003c/span\u003e, error);\n    }\n  };\u003c/span\u003e\u003c/pre\u003e\u003ch2\u003e4. Speech Synthesis\u003c/h2\u003e\u003cp\u003eThe \u003ccode class=\"cw qb qc qd qe b\"\u003espeak\u003c/code\u003e function takes the text response from the LLM and uses the SpeechSynthesis API to read it aloud, providing an interactive experience for the user.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"e336\" class=\"qx nb gt qe b bf qy qz l ra rb\"\u003e  \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e speak = (text) =\u0026amp;gt; {\n    \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e (synthRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e \u0026amp;amp;\u0026amp;amp; text) {\n      \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e utterance = \u003cspan class=\"hljs-keyword\"\u003enew\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eSpeechSynthesisUtterance\u003c/span\u003e(text);\n\n      \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e voices = \u003cspan class=\"hljs-variable language_\"\u003ewindow\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003espeechSynthesis\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003egetVoices\u003c/span\u003e();\n      \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e (voices.\u003cspan class=\"hljs-property\"\u003elength\u003c/span\u003e \u0026amp;gt; \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e) {\n        utterance.\u003cspan class=\"hljs-property\"\u003evoice\u003c/span\u003e = voices[\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e]; \u003cspan class=\"hljs-comment\"\u003e// You can change this to select different voices\u003c/span\u003e\n      }\n\n      utterance.\u003cspan class=\"hljs-property\"\u003eonstart\u003c/span\u003e = () =\u0026amp;gt; {\n        \u003cspan class=\"hljs-variable language_\"\u003econsole\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003elog\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"TTS starts speaking\"\u003c/span\u003e);\n        \u003cspan class=\"hljs-title function_\"\u003esetShowSpinner\u003c/span\u003e(\u003cspan class=\"hljs-literal\"\u003efalse\u003c/span\u003e);\n      };\n\n      utterance.\u003cspan class=\"hljs-property\"\u003eonend\u003c/span\u003e = () =\u0026amp;gt; {\n        \u003cspan class=\"hljs-title function_\"\u003esetAppState\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"idle\"\u003c/span\u003e);\n        \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e (wakeWordRecognitionRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e) {\n          wakeWordRecognitionRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003estart\u003c/span\u003e(); \u003cspan class=\"hljs-comment\"\u003e// Restart wake word listener after speaking\u003c/span\u003e\n        }\n      };\n      synthRef.\u003cspan class=\"hljs-property\"\u003ecurrent\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003espeak\u003c/span\u003e(utterance);\n    }\u003c/span\u003e\u003c/pre\u003e\u003ch2\u003e5. UI Rendering\u003c/h2\u003e\u003cp\u003eThe return statement of the \u003ccode class=\"cw qb qc qd qe b\"\u003eApp\u003c/code\u003e function contains the JSX code for rendering the app's UI. This includes buttons for starting/stopping the voice interaction, a display area for the transcript, and a chat sidebar showing the history of interactions.\u003c/p\u003e\u003cp\u003eBy combining voice recognition, LLM integration, and speech synthesis, this frontend component provides a comprehensive and accessible interface for interacting with the C3 Voice Assistant.\u003c/p\u003e\u003ch1\u003eBackend Server Setup\u003c/h1\u003e\u003col\u003e\u003cli\u003eInitialize Create-Llama: Run \u003ccode class=\"cw qb qc qd qe b\"\u003enpx create-llama@latest\u003c/code\u003e in your terminal.\u003c/li\u003e\u003cli\u003eFollow the prompts to set up a Python FastAPI backend, which we can be integrated with our frontend.\u003c/li\u003e\u003cli\u003eUse \u003ccode class=\"cw qb qc qd qe b\"\u003epoetry install\u003c/code\u003e and \u003ccode class=\"cw qb qc qd qe b\"\u003epoetry shell\u003c/code\u003e to prepare the environment.\u003c/li\u003e\u003cli\u003eCreate a \u003ccode class=\"cw qb qc qd qe b\"\u003e.env\u003c/code\u003e file with \u003ccode class=\"cw qb qc qd qe b\"\u003eOPENAI_API_KEY=\u0026lt;openai_api_key\u0026gt;\u003c/code\u003e.\u003c/li\u003e\u003cli\u003eGenerate Embeddings (optional): If a \u003ccode class=\"cw qb qc qd qe b\"\u003e./data\u003c/code\u003e directory exists, run \u003ccode class=\"cw qb qc qd qe b\"\u003epython app/engine/generate.py\u003c/code\u003e.\u003c/li\u003e\u003cli\u003eExecute \u003ccode class=\"cw qb qc qd qe b\"\u003epython main.py\u003c/code\u003eto start the server.\u003c/li\u003e\u003cli\u003eTest the API: Use \u003ccode class=\"cw qb qc qd qe b\"\u003ecurl --location 'localhost:8000/api/chat' --header 'Content-Type: application/json' --data '{ \"messages\": [{ \"role\": \"user\", \"content\": \"Hello\" }] }'\u003c/code\u003e to test.\u003c/li\u003e\u003cli\u003eModify API behavior in \u003ccode class=\"cw qb qc qd qe b\"\u003eapp/api/routers/chat.py\u003c/code\u003e. The server supports CORS for all origins, alterable with the \u003ccode class=\"cw qb qc qd qe b\"\u003eENVIRONMENT=prod\u003c/code\u003e setting.\u003c/li\u003e\u003c/ol\u003e\u003ch1\u003eIntegration\u003c/h1\u003e\u003cp\u003eOnce the backend server is set up, integrating it with the frontend is straightforward. Simply update the \u003ccode class=\"cw qb qc qd qe b\"\u003efetchResponseFromLLM\u003c/code\u003e function in your frontend's \u003ccode class=\"cw qb qc qd qe b\"\u003eApp.js\u003c/code\u003e to call the backend server URL. This change ensures that when the frontend makes a request, it communicates with your newly configured backend, thus effectively integrating the two components.\u003c/p\u003e\u003ch1\u003eFinal Thoughts\u003c/h1\u003e\u003cp\u003eWrapping up, the C3 Voice Assistant isn’t just a tech showcase; it’s a stride towards democratizing AI. It’s about making powerful AI tools, like LLMs and RAG, accessible and user-friendly. This project is more than lines of code — it’s a push to break down tech barriers and empower everyone.\u003c/p\u003e\u003cp\u003eYour thoughts and feedback are invaluable — let’s make AI more accessible together!\u003c/p\u003e\u003cp\u003eLink to Github Repo: \u003ca href=\"https://github.com/AI-ANK/C3-Voice-Assistant-UI\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eFrontend\u003c/a\u003e and \u003ca href=\"https://github.com/AI-ANK/c3-python-nostream\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBackend\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.linkedin.com/in/harshadsuryawanshi/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eConnect with Me on LinkedIn\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.linkedin.com/posts/harshadsuryawanshi_ai-llamaindex-gpt3-activity-7149796976442740736-1lXj?utm_source=share\u0026amp;utm_medium=member_desktop\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eLinkedin Post\u003c/a\u003e\u003c/p\u003e","image":{"_type":"image","asset":{"_ref":"image-cf25f1a4cbaf20cc6e025ffeefb1a3603a0c74cc-1024x1024-png","_type":"reference"}},"mainImage":"https://cdn.sanity.io/images/7m9jw85w/production/cf25f1a4cbaf20cc6e025ffeefb1a3603a0c74cc-1024x1024.png","publishedDate":"2024-01-14","relatedPosts":[{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-39a875fc787fe28f9e44db8769c6fab9c31c7e17-1024x1024-webp","_type":"reference"}},"publishedDate":"2024-02-27","slug":"llamaindex-newsletter-2024-02-27-4b9102a0f824","title":"LlamaIndex Newsletter 2024–02–27"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-34ef148ef2e331372f8f0db7a8e9c9c11a76b504-1600x646-png","_type":"reference"}},"publishedDate":"2024-02-24","slug":"bridging-the-gap-in-crisis-counseling-introducing-counselor-copilot-db42e26ab4f3","title":"Bridging the Gap in Crisis Counseling: Introducing Counselor Copilot"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-65e2a4a5037cc464566a13e7828fbb905fd33b38-960x863-png","_type":"reference"}},"publishedDate":"2024-02-20","slug":"introducing-llamacloud-and-llamaparse-af8cedf9006b","title":"Introducing LlamaCloud and LlamaParse"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-81f41e8a6fe34f544e518f6e137dbf559e8885da-1024x1024-jpg","_type":"reference"}},"publishedDate":"2024-02-20","slug":"llamaindex-newsletter-2024-02-20-introducing-llamacloud-30511f4662f4","title":"LlamaIndex Newsletter 2024–02–20: introducing LlamaCloud"}],"slug":{"_type":"slug","current":"ai-voice-assistant-enhancing-accessibility-in-ai-with-llamaindex-and-gpt3-5-f5509d296f4a"},"tags":[{"_createdAt":"2024-02-22T20:19:11Z","_id":"17d4fc95-517c-4f4a-95ce-bf753e802ac4","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"llamaindex"},"title":"Llamaindex"},{"_createdAt":"2024-02-22T20:19:12Z","_id":"7425f7b3-19b6-444d-9945-f7d75f1432ca","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:12Z","slug":{"_type":"slug","current":"voice-assistant"},"title":"Voice Assistant"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"e171aa9d-bc85-4645-8a08-eabe04c530c7","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:11Z","slug":{"_type":"slug","current":"openai"},"title":"OpenAI"},{"_createdAt":"2024-02-22T20:19:12Z","_id":"5d4cb090-64d9-43cc-ba39-aeb8838a15bd","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:12Z","slug":{"_type":"slug","current":"accessibility"},"title":"Accessibility"},{"_createdAt":"2024-02-22T20:19:12Z","_id":"4390ed61-8b8f-439a-b5d6-3366af23e592","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag","_updatedAt":"2024-02-22T20:19:12Z","slug":{"_type":"slug","current":"inclusive-ai"},"title":"Inclusive Ai"}],"title":"AI Voice Assistant: Enhancing Accessibility in AI with LlamaIndex and GPT3.5 (Deployed in Prod on Vercel and Render)"},"publishedDate":"Invalid Date"},"params":{"slug":"ai-voice-assistant-enhancing-accessibility-in-ai-with-llamaindex-and-gpt3-5-f5509d296f4a"},"draftMode":false,"token":""},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"ai-voice-assistant-enhancing-accessibility-in-ai-with-llamaindex-and-gpt3-5-f5509d296f4a"},"buildId":"C8J-EMc_4OCN1ch65l4fl","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>