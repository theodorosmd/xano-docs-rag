<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>Efficient Chunk Size Optimization for RAG Pipelines with LlamaCloud — LlamaIndex - Build Knowledge Assistants over your Enterprise Data</title><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><meta name="title" content="Efficient Chunk Size Optimization for RAG Pipelines with LlamaCloud — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta name="description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:title" content="Efficient Chunk Size Optimization for RAG Pipelines with LlamaCloud — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="og:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:image" content="https://cdn.sanity.io/images/7m9jw85w/production/bf0ee27ad4e3e17598a1e664653b59217e89dfdb-1024x1024.webp"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="Efficient Chunk Size Optimization for RAG Pipelines with LlamaCloud — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="twitter:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="twitter:image" content="https://cdn.sanity.io/images/7m9jw85w/production/bf0ee27ad4e3e17598a1e664653b59217e89dfdb-1024x1024.webp"/><link rel="alternate" type="application/rss+xml" href="https://www.llamaindex.ai/blog/feed"/><meta name="next-head-count" content="20"/><script>
            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WWRFB36R');
            </script><link rel="preload" href="/_next/static/css/41c9222e47d080c9.css" as="style"/><link rel="stylesheet" href="/_next/static/css/41c9222e47d080c9.css" data-n-g=""/><link rel="preload" href="/_next/static/css/97c33c8d95f1230e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/97c33c8d95f1230e.css" data-n-p=""/><link rel="preload" href="/_next/static/css/e009059e80bf60c5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e009059e80bf60c5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-1b629d9c8fb16f34.js" defer=""></script><script src="/_next/static/chunks/framework-df1f68dff096b68a.js" defer=""></script><script src="/_next/static/chunks/main-eca7952a704663f8.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c7c49437be49d2ad.js" defer=""></script><script src="/_next/static/chunks/d9067523-4985945b21298365.js" defer=""></script><script src="/_next/static/chunks/41155975-60c12da9ce9fa0b2.js" defer=""></script><script src="/_next/static/chunks/cb355538-cee2ea45674d9de3.js" defer=""></script><script src="/_next/static/chunks/9494-dff62cb53535dd7d.js" defer=""></script><script src="/_next/static/chunks/4063-39a391a51171ff87.js" defer=""></script><script src="/_next/static/chunks/6889-edfa85b69b88a372.js" defer=""></script><script src="/_next/static/chunks/5575-11ee0a29eaffae61.js" defer=""></script><script src="/_next/static/chunks/3444-95c636af25a42734.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-82c8e764e69afd2c.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_buildManifest.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_ssgManifest.js" defer=""></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WWRFB36R" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div class="__variable_d65c78 __variable_b1ea77 __variable_eb7534"><a class="Announcement_announcement__2ohK8" href="http://48755185.hs-sites.com/llamaindex-0">Meet LlamaIndex at the Databricks Data + AI Summit!<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M8.293 5.293a1 1 0 0 1 1.414 0l6 6a1 1 0 0 1 0 1.414l-6 6a1 1 0 0 1-1.414-1.414L13.586 12 8.293 6.707a1 1 0 0 1 0-1.414Z" clip-rule="evenodd"></path></svg></a><header class="Header_header__hO3lJ"><button class="Hamburger_hamburger__17auO Header_hamburger__lUulX"><svg width="28" height="28" viewBox="0 0 28 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.5 14H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" id="hamburger-stroke-top" class="Hamburger_hamburgerStrokeMiddle__I7VpD"></path><path d="M3.5 7H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeTop__oOhFM"></path><path d="M3.5 21H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeBottom__GIQR2"></path></svg></button><a aria-label="Homepage" href="/"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" class="Header_logo__e5KhT" style="color:transparent" src="/llamaindex.svg"/></a><nav aria-label="Main" data-orientation="horizontal" dir="ltr" style="--content-position:0px"><div style="position:relative"><ul data-orientation="horizontal" class="Nav_MenuList__PrCDJ" dir="ltr"><li><button id="radix-:R6tm:-trigger-radix-:R5mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R5mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Products</button></li><li><button id="radix-:R6tm:-trigger-radix-:R9mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R9mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Solutions</button></li><li><a class="Nav_Link__ZrzFc" href="/community" data-radix-collection-item="">Community</a></li><li><a class="Nav_Link__ZrzFc" href="/pricing" data-radix-collection-item="">Pricing</a></li><li><a class="Nav_Link__ZrzFc" href="/blog" data-radix-collection-item="">Blog</a></li><li><a class="Nav_Link__ZrzFc" href="/customers" data-radix-collection-item="">Customer stories</a></li><li><a class="Nav_Link__ZrzFc" href="/careers" data-radix-collection-item="">Careers</a></li></ul></div><div class="Nav_ViewportPosition__jmyHM"></div></nav><div class="Header_secondNav__YJvm8"><nav><a href="/contact" class="Link_link__71cl8 Link_link-variant-tertiary__BYxn_ Header_bookADemo__qCuxV">Book a demo</a></nav><a href="https://cloud.llamaindex.ai/" class="Button_button-variant-default__Oi__n Button_button__aJ0V6 Header_button__1HFhY" data-tracking-variant="default"> <!-- -->Get started</a></div><div class="MobileMenu_mobileMenu__g5Fa6"><nav class="MobileMenu_nav__EmtTw"><ul><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Products<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaparse"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.6654 1.66675V6.66675H16.6654M8.33203 10.8334L6.66536 12.5001L8.33203 14.1667M11.6654 14.1667L13.332 12.5001L11.6654 10.8334M12.082 1.66675H4.9987C4.55667 1.66675 4.13275 1.84234 3.82019 2.1549C3.50763 2.46746 3.33203 2.89139 3.33203 3.33341V16.6667C3.33203 17.1088 3.50763 17.5327 3.82019 17.8453C4.13275 18.1578 4.55667 18.3334 4.9987 18.3334H14.9987C15.4407 18.3334 15.8646 18.1578 16.1772 17.8453C16.4898 17.5327 16.6654 17.1088 16.6654 16.6667V6.25008L12.082 1.66675Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Document parsing</div><p class="MobileMenu_ListItemText__n_MHY">The first and leading GenAI-native parser over your most complex data.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaextract"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.668 1.66675V5.00008C11.668 5.44211 11.8436 5.86603 12.1561 6.17859C12.4687 6.49115 12.8926 6.66675 13.3346 6.66675H16.668M3.33464 5.83341V3.33341C3.33464 2.89139 3.51023 2.46746 3.82279 2.1549C4.13535 1.84234 4.55927 1.66675 5.0013 1.66675H12.5013L16.668 5.83341V16.6667C16.668 17.1088 16.4924 17.5327 16.1798 17.8453C15.8672 18.1578 15.4433 18.3334 15.0013 18.3334L5.05379 18.3326C4.72458 18.3755 4.39006 18.3191 4.09312 18.1706C3.79618 18.0221 3.55034 17.7884 3.38713 17.4992M4.16797 9.16675L1.66797 11.6667M1.66797 11.6667L4.16797 14.1667M1.66797 11.6667H10.0013" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Data extraction</div><p class="MobileMenu_ListItemText__n_MHY">Extract structured data from documents using a schema-driven engine.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/enterprise"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.16667 15.8333C12.8486 15.8333 15.8333 12.8486 15.8333 9.16667C15.8333 5.48477 12.8486 2.5 9.16667 2.5C5.48477 2.5 2.5 5.48477 2.5 9.16667C2.5 12.8486 5.48477 15.8333 9.16667 15.8333Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M17.5 17.5L13.875 13.875" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Knowledge Management</div><p class="MobileMenu_ListItemText__n_MHY">Connect, transform, and index your enterprise data into an agent-accessible knowledge base</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/framework"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.0013 6.66659V3.33325H6.66797M1.66797 11.6666H3.33464M16.668 11.6666H18.3346M12.5013 10.8333V12.4999M7.5013 10.8333V12.4999M5.0013 6.66659H15.0013C15.9218 6.66659 16.668 7.41278 16.668 8.33325V14.9999C16.668 15.9204 15.9218 16.6666 15.0013 16.6666H5.0013C4.08083 16.6666 3.33464 15.9204 3.33464 14.9999V8.33325C3.33464 7.41278 4.08083 6.66659 5.0013 6.66659Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Agent Framework</div><p class="MobileMenu_ListItemText__n_MHY">Orchestrate and deploy multi-agent applications over your data with the #1 agent framework.</p></a></li></ul></details></li><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Solutions<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/finance"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 6.66675H8.33073C7.8887 6.66675 7.46478 6.84234 7.15222 7.1549C6.83966 7.46746 6.66406 7.89139 6.66406 8.33342C6.66406 8.77544 6.83966 9.19937 7.15222 9.51193C7.46478 9.82449 7.8887 10.0001 8.33073 10.0001H11.6641C12.1061 10.0001 12.53 10.1757 12.8426 10.4882C13.1551 10.8008 13.3307 11.2247 13.3307 11.6667C13.3307 12.1088 13.1551 12.5327 12.8426 12.8453C12.53 13.1578 12.1061 13.3334 11.6641 13.3334H6.66406M9.9974 15.0001V5.00008M18.3307 10.0001C18.3307 14.6025 14.5998 18.3334 9.9974 18.3334C5.39502 18.3334 1.66406 14.6025 1.66406 10.0001C1.66406 5.39771 5.39502 1.66675 9.9974 1.66675C14.5998 1.66675 18.3307 5.39771 18.3307 10.0001Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Financial Analysts</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/administrative-operations"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1.66406 6.66659V15.8333C1.66406 16.2753 1.83966 16.6992 2.15222 17.0118C2.46478 17.3243 2.8887 17.4999 3.33073 17.4999H14.9974M16.6641 14.1666C17.1061 14.1666 17.53 13.991 17.8426 13.6784C18.1551 13.3659 18.3307 12.9419 18.3307 12.4999V7.49992C18.3307 7.05789 18.1551 6.63397 17.8426 6.32141C17.53 6.00885 17.1061 5.83325 16.6641 5.83325H13.4141C13.1353 5.83598 12.8604 5.76876 12.6143 5.63774C12.3683 5.50671 12.159 5.31606 12.0057 5.08325L11.3307 4.08325C11.179 3.85281 10.9724 3.66365 10.7295 3.53275C10.4866 3.40185 10.215 3.3333 9.93906 3.33325H6.66406C6.22204 3.33325 5.79811 3.50885 5.48555 3.82141C5.17299 4.13397 4.9974 4.55789 4.9974 4.99992V12.4999C4.9974 12.9419 5.17299 13.3659 5.48555 13.6784C5.79811 13.991 6.22204 14.1666 6.66406 14.1666H16.6641Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Administrative Operations</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/engineering"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 15L18.3307 10L13.3307 5M6.66406 5L1.66406 10L6.66406 15" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Engineering &amp; R&amp;D</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/customer-support"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.9974 7.50008H16.6641C17.1061 7.50008 17.53 7.67568 17.8426 7.98824C18.1551 8.3008 18.3307 8.72472 18.3307 9.16675V18.3334L14.9974 15.0001H9.9974C9.55537 15.0001 9.13145 14.8245 8.81888 14.5119C8.50632 14.1994 8.33073 13.7754 8.33073 13.3334V12.5001M11.6641 7.50008C11.6641 7.94211 11.4885 8.36603 11.1759 8.67859C10.8633 8.99115 10.4394 9.16675 9.9974 9.16675H4.9974L1.66406 12.5001V3.33341C1.66406 2.41675 2.41406 1.66675 3.33073 1.66675H9.9974C10.4394 1.66675 10.8633 1.84234 11.1759 2.1549C11.4885 2.46746 11.6641 2.89139 11.6641 3.33341V7.50008Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Customer Support</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/healthcare-pharma"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M17.0128 3.81671C16.5948 3.39719 16.098 3.06433 15.551 2.8372C15.004 2.61008 14.4176 2.49316 13.8253 2.49316C13.2331 2.49316 12.6466 2.61008 12.0996 2.8372C11.5527 3.06433 11.0559 3.39719 10.6378 3.81671L9.99617 4.46671L9.3545 3.81671C8.93643 3.39719 8.43967 3.06433 7.89268 2.8372C7.3457 2.61008 6.75926 2.49316 6.167 2.49316C5.57474 2.49316 4.9883 2.61008 4.44132 2.8372C3.89433 3.06433 3.39756 3.39719 2.9795 3.81671C1.21283 5.58338 1.1045 8.56671 3.3295 10.8334L9.99617 17.5L16.6628 10.8334C18.8878 8.56671 18.7795 5.58338 17.0128 3.81671Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M2.91406 9.99992H7.91406L8.33073 9.16659L9.9974 12.9166L11.6641 7.08325L12.9141 9.99992H17.0807" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Healthcare / Pharma</div></a></li></ul></details></li><li><a class="MobileMenu_Link__5frcx" href="/community">Community</a></li><li><a class="MobileMenu_Link__5frcx" href="/pricing">Pricing</a></li><li><a class="MobileMenu_Link__5frcx" href="/blog">Blog</a></li><li><a class="MobileMenu_Link__5frcx" href="/customers">Customer stories</a></li><li><a class="MobileMenu_Link__5frcx" href="/careers">Careers</a></li></ul></nav><a href="/contact" class="Button_button-variant-ghost__o2AbG Button_button__aJ0V6" data-tracking-variant="ghost"> <!-- -->Talk to us</a><ul class="Socials_socials__8Y_s5 Socials_socials-theme-dark__Hq8lc MobileMenu_socials__JykCO"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu MobileMenu_copyright__nKVOs">© <!-- -->2025<!-- --> LlamaIndex</p></div></header><main><section class="BlogPost_post__JHNzd"><img alt="" loading="lazy" width="800" height="512" decoding="async" data-nimg="1" class="BlogPost_featuredImage__KGxwX" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fbf0ee27ad4e3e17598a1e664653b59217e89dfdb-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fbf0ee27ad4e3e17598a1e664653b59217e89dfdb-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fbf0ee27ad4e3e17598a1e664653b59217e89dfdb-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><p class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-600__fKYth BlogPost_date__6uxQw"><a class="BlogPost_author__mesdl" href="/blog/author/llamaindex">LlamaIndex</a> <!-- -->•<!-- --> <!-- -->2024-08-21</p><h1 class="Text_text__zPO0D Text_text-size-32__koGps BlogPost_title__b2lqJ">Efficient Chunk Size Optimization for RAG Pipelines with LlamaCloud</h1><ul class="BlogPost_tags__13pBH"><li><a class="Badge_badge___1ssn" href="/blog/tag/rag"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">RAG</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/llamacloud"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">LlamaCloud</span></a></li></ul><div class="BlogPost_htmlPost__Z5oDL"><p class="Text_text__zPO0D Text_text-size-16__PkjFu">In Retrieval-Augmented Generation (RAG) systems, the choice of chunk size can significantly impact retrieval accuracy and overall system performance. However, experimenting with different chunk sizes has traditionally been a time-consuming process. This post explores the challenges associated with chunk size optimization and introduces LlamaCloud&#x27;s features that facilitate this process.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Challenges in Chunk Size Experimentation</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">A lot of developers have figured out ways to experiment with retrieval parameters and prompts in a RAG pipeline - adjusting top-k and the QA prompts are relatively straightforward endeavors and of-course have an impact on performance.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Experimenting with parameters during the indexing stage, such as chunking is equally as important, but harder to do. Indexing experimentation presents several technical challenges:</p><ol><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>Reindexing Overhead</strong>: Changing chunk sizes typically necessitates reindexing the entire dataset, which can be computationally expensive and time-consuming, especially for large datasets.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>Storage Inefficiency</strong>: Maintaining multiple versions of indexed data with different chunk sizes can lead to significant storage overhead.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>Limited Visibility</strong>: Without proper tooling, it&#x27;s difficult to visualize how documents are being chunked and how this affects retrieval quality.</li></ol><p class="Text_text__zPO0D Text_text-size-16__PkjFu">These factors make it annoying to experiment with chunking, especially in an ad-hoc pipeline setup in a Jupyter notebook. Most experimentation and observability tools primarily focus on query-time traces and not on data observability. As a result we’ve noticed a certain reluctance from developers to experiment with chunking despite the impact on final performance.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">LlamaCloud&#x27;s Approach to Chunk Size Optimization</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaCloud is an enterprise-ready platform that lets developers easily setup and iterate on RAG pipelines over unstructured data. It provides a set of features designed to streamline the process of chunk size experimentation:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>Index Cloning</strong>: Enables quick creation of index copies with different chunking configurations.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>Chunk Visualization</strong>: Allows direct inspection of how documents are chunked and how it impacts retrieval.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>Efficient Iteration</strong>: Facilitates testing different chunk sizes without the need for manual data store management or complex reindexing processes.</li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The following sections outline a workflow for utilizing these features to optimize chunk sizes in a RAG pipeline.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Workflow: Optimizing Chunk Sizes with LlamaCloud</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Below we detail an example use case where we’re able to make use of LlamaCloud’s setup and experimentation features to find a chunking configuration that better answers a question in an ad-hoc fashion. This is reflective of user behaviors where the user wants to sanity-check their RAG pipeline on some questions that they know the full-answer to, before running more systematic evaluation.</p><h3 class="Text_text__zPO0D Text_text-size-40__fIyvA">Initial RAG Pipeline Setup</h3><p class="Text_text__zPO0D Text_text-size-16__PkjFu">First, create an initial index in LlamaCloud. Create a new LlamaCloud Index via the UI and upload your document set (e.g., three ICLR 2024 research papers). In the &quot;Transform Settings&quot;, select &quot;Auto&quot; and set a chunk size of 512 tokens as a baseline.</p><h3 class="Text_text__zPO0D Text_text-size-40__fIyvA">Define “Golden” Question-Answer Pair</h3><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Find an example question that you want to test over this data. In this example, the question we want to try asking is: &quot;Describe the core features of SWE-bench&quot;.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">You should have the golden context in mind. Here the answer is directly found in Section 2.3 of the SWE-bench paper which directly describes the Features of SWE-bench.</p><figure><img alt="" loading="lazy" width="1037" height="673" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F30fe1c5dd009729a01457dea69a2fe32894c29d6-2074x1346.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1080&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F30fe1c5dd009729a01457dea69a2fe32894c29d6-2074x1346.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=3840&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F30fe1c5dd009729a01457dea69a2fe32894c29d6-2074x1346.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=3840&amp;q=75"/></figure><h3 class="Text_text__zPO0D Text_text-size-40__fIyvA">Baseline Configuration Testing through Playground</h3><p class="Text_text__zPO0D Text_text-size-16__PkjFu">You can now use LlamaCloud playground to evaluate the initial setup. Navigate to the &quot;Playground&quot; section of your index page and click on the “Chat” tab. This gives you a full chat UI over your index with intermediate step + response streaming and citations.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Enter the question above. You’ll get back a response that seems reasonable at first glance! The response describes SWE-Bench as being representative of real-world software engineering tasks, being continuously updatable, and more.</p><figure><img alt="" loading="lazy" width="1495" height="881" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fbf023f7cf3707b52b03ebc2dacd078ec1b60ae23-2990x1762.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fbf023f7cf3707b52b03ebc2dacd078ec1b60ae23-2990x1762.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=3840&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fbf023f7cf3707b52b03ebc2dacd078ec1b60ae23-2990x1762.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=3840&amp;q=75"/></figure><p class="Text_text__zPO0D Text_text-size-16__PkjFu">But you’ll notice that the last two sections are missing - “cross-context code editing” and “wide scope for possible solutions”.</p><h3 class="Text_text__zPO0D Text_text-size-40__fIyvA">3. Chunk Inspection</h3><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Since the answer is partially correct, we might hypothesize that the chunking is causing the relevant context to be broken up. Access the retrieval UI to view retrieved chunks and their sources. Use the &quot;View in File&quot; feature to examine how the source document is parsed and chunked. You may observe that relevant information is split across multiple chunks, potentially affecting retrieval quality.</p><figure><img alt="" loading="lazy" width="1690" height="948" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F32f6e26fa1bb1b0bba943ad446d311374e31000c-3380x1896.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F32f6e26fa1bb1b0bba943ad446d311374e31000c-3380x1896.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=3840&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F32f6e26fa1bb1b0bba943ad446d311374e31000c-3380x1896.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=3840&amp;q=75"/></figure><h3 class="Text_text__zPO0D Text_text-size-40__fIyvA">4. Chunk Size Iteration</h3><p class="Text_text__zPO0D Text_text-size-16__PkjFu">To test an alternative chunking strategy, use the &quot;Copy&quot; button on the Index page to duplicate your index. In the new index, select &quot;Edit&quot; to modify chunking parameters. Switch to &quot;Manual&quot; mode, set &quot;Segmentation Configuration&quot; to &quot;Page&quot;, and set &quot;Chunking Configuration&quot; mode to &quot;None&quot;. Apply these changes to initiate a new indexing run with updated settings.</p><figure><img alt="" loading="lazy" width="962" height="490" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F86f09b433fc9c7cf10066bc7058bbf8cb263641c-1924x980.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1080&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F86f09b433fc9c7cf10066bc7058bbf8cb263641c-1924x980.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=2048&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F86f09b433fc9c7cf10066bc7058bbf8cb263641c-1924x980.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=2048&amp;q=75"/></figure><h3 class="Text_text__zPO0D Text_text-size-40__fIyvA">5. Result Comparison</h3><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Execute the same query on the new index and compare the results. You should observe a more comprehensive response that better captures the full context of SWE-bench&#x27;s features.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Next Steps</h2><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu">If you haven’t done so already, signup for a LlamaCloud account: <a href="https://cloud.llamaindex.ai/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">https://cloud.llamaindex.ai/</a>. We’re actively letting people off the waitlist!</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Check out the <a href="https://github.com/run-llama/llamacloud-demo/blob/main/examples/experimentation/chunk_size_adhoc.ipynb" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">full notebook</a>.</li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu">While the ad-hoc experimentation process described in this post provides a quick way to iterate on chunk sizes, it&#x27;s important to recognize that this is just the beginning of optimizing your RAG pipeline. Here are some suggested next steps to further refine your system:</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>1. Systematic Evaluation</strong>: Develop a more structured evaluation framework. This could involve creating a test set of queries with known correct answers, and systematically comparing the performance of different chunk sizes across various metrics such as relevance, coherence, and factual accuracy. We have a fantastic set of <a href="https://docs.llamaindex.ai/en/stable/module_guides/observability/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">observability and evaluation partners</a> to help you get started, including <a href="https://llamatrace.com/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">LlamaTrace</a> (by Arize), <a href="https://traceloop.com/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Traceloop</a>, and <a href="https://langfuse.com/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Langfuse</a>.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>2. Automated Testing</strong>: Implement automated tests that can run through your evaluation framework each time you make changes to your chunking strategy. This can help you quickly identify if new configurations are improving or degrading performance.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>3. Fine-tuning Retrieval Parameters</strong>: Once you&#x27;ve found a chunking strategy that works well, experiment with other retrieval parameters such as the number of retrieved chunks, reranking strategies, or hybrid search methods.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>4. Domain-Specific Optimization</strong>: Consider how the nature of your specific documents and use case might influence optimal chunk sizes. Technical documentation, narrative text, and structured data might all benefit from different chunking strategies.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>5. Monitoring and Continuous Improvement</strong>: Set up monitoring for your production RAG system to track key performance indicators over time. Use this data to inform ongoing optimization efforts.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">By combining the rapid iteration capabilities of LlamaCloud with these more systematic approaches, you can create a robust, high-performing RAG pipeline tailored to your specific needs.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">If you’re interested in chatting about our LlamaCloud plans to solve your enterprise RAG needs, <a href="https://www.llamaindex.ai/contact" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">get in touch.</a></p></div><div class="BlogPost_relatedPosts__0z6SN"><h2 class="Text_text__zPO0D Text_text-align-center__HhKqo Text_text-size-16__PkjFu Text_text-weight-400__5ENkK Text_text-family-spaceGrotesk__E4zcE BlogPost_relatedPostsTitle___JIrW">Related articles</h2><ul class="BlogPost_relatedPostsList__uOKzB"><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F89380b5946452462d6c4a91f8109f705dc044c82-1080x1080.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F89380b5946452462d6c4a91f8109f705dc044c82-1080x1080.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F89380b5946452462d6c4a91f8109f705dc044c82-1080x1080.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/introducing-the-spreadsheet-agent-in-private-preview">Introducing the Spreadsheet Agent, in private preview</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2025-06-05</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9fdb15bafdf8c0921f36c6cd8cdac43c8ca87e27-2232x1562.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9fdb15bafdf8c0921f36c6cd8cdac43c8ca87e27-2232x1562.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9fdb15bafdf8c0921f36c6cd8cdac43c8ca87e27-2232x1562.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/rag-is-dead-long-live-agentic-retrieval">RAG is dead, long live agentic retrieval</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2025-05-29</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F63188044661ee9b8d5406238dba50804df90e7bf-1468x758.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F63188044661ee9b8d5406238dba50804df90e7bf-1468x758.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F63188044661ee9b8d5406238dba50804df90e7bf-1468x758.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/get-citations-and-reasoning-for-extracted-data-in-llamaextract">Get Citations and Reasoning for Extracted Data in LlamaExtract</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2025-05-07</p></div></li><li><div class="CardBlog_card__mm0Zw CardBlog_featuredCard__5FPeD"><div class="CardBlog_grid__5PeSv"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F13ef1e27c4ec6c9a72d2ce1fae36f5acac0062ba-1263x631.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F13ef1e27c4ec6c9a72d2ce1fae36f5acac0062ba-1263x631.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F13ef1e27c4ec6c9a72d2ce1fae36f5acac0062ba-1263x631.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><div class="CardBlog_thumbnailGradient__x5CbY"><p class="Text_text__zPO0D Text_text-size-36__cH7Hj Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/beyond-chatbots-adopting-agentic-document-workflows-for-enterprises">Beyond chatbots: adopting Agentic Document Workflows for enterprises</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu CardBlog_date__E1rJK">2025-04-23</p></div></div></div></li></ul></div></section></main><footer class="Footer_footer__eNA9m"><div class="Footer_navContainer__7bvx4"><div class="Footer_logoContainer__3EpzI"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" style="color:transparent" src="/llamaindex.svg"/><div class="Footer_socialContainer__GdOgk"><ul class="Socials_socials__8Y_s5"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul></div></div><div class="Footer_nav__BLEuE"><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/">LlamaIndex</a></h3><ul><li><a href="/blog"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Blog</span></a></li><li><a href="/partners"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Partners</span></a></li><li><a href="/careers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Careers</span></a></li><li><a href="/contact"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Contact</span></a></li><li><a href="/brand"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Brand</span></a></li><li><a href="https://llamaindex.statuspage.io" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Status</span></a></li><li><a href="https://app.vanta.com/runllama.ai/trust/pkcgbjf8b3ihxjpqdx17nu" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Trust Center</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/enterprise">Enterprise</a></h3><ul><li><a href="https://cloud.llamaindex.ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaCloud</span></a></li><li><a href="https://cloud.llamaindex.ai/parse" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaParse</span></a></li><li><a href="/customers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Customers</span></a></li><li><a href="/llamacloud-sharepoint-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SharePoint</span></a></li><li><a href="/llamacloud-aws-s3-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">AWS S3</span></a></li><li><a href="/llamacloud-azure-blob-storage-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure Blob Storage</span></a></li><li><a href="/llamacloud-google-drive-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Google Drive</span></a></li> </ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/framework">Framework</a></h3><ul><li><a href="https://pypi.org/project/llama-index/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python package</span></a></li><li><a href="https://docs.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python docs</span></a></li><li><a href="https://www.npmjs.com/package/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript package</span></a></li><li><a href="https://ts.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript docs</span></a></li><li><a href="https://llamahub.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaHub</span></a></li><li><a href="https://github.com/run-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">GitHub</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/community">Community</a></h3><ul><li><a href="/community#newsletter"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Newsletter</span></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Discord</span></a></li><li><a href="https://www.linkedin.com/company/91154103/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LinkedIn</span></a></li><li><a href="https://twitter.com/llama_index"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Twitter/X</span></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">YouTube</span></a></li><li><a href="https://bsky.app/profile/llamaindex.bsky.social"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">BlueSky</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e">Starter projects</h3><ul><li><a href="https://www.npmjs.com/package/create-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">create-llama</span></a></li><li><a href="https://secinsights.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SEC Insights</span></a></li><li><a href="https://github.com/run-llama/llamabot"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaBot</span></a></li><li><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/rag_cli.html"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">RAG CLI</span></a></li></ul></div></div></div><div class="Footer_copyrightContainer__mBKsT"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA">© <!-- -->2025<!-- --> LlamaIndex</p><div class="Footer_legalNav__O1yJA"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/privacy-notice.pdf">Privacy Notice</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/terms-of-service.pdf">Terms of Service</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="https://bit.ly/llamaindexdpa">Data Processing Addendum</a></p></div></div></footer></div><svg xmlns="http://www.w3.org/2000/svg" class="flt_svg" style="display:none"><defs><filter id="flt_tag"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="2"></feGaussianBlur><feColorMatrix in="blur" result="flt_tag" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="flt_tag" operator="atop"></feComposite></filter><filter id="svg_blur_large"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="8"></feGaussianBlur><feColorMatrix in="blur" result="svg_blur_large" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="svg_blur_large" operator="atop"></feComposite></filter></defs></svg></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"page":{"announcement":{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"},"post":{"_createdAt":"2024-08-21T19:21:53Z","_id":"2d43d9ed-bff9-4fc7-89a2-1272d68e5f26","_rev":"Ys5IzmCaJ2UnW2RAX7U7e4","_type":"blogPost","_updatedAt":"2025-05-21T20:37:01Z","announcement":[{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"}],"authors":[{"_createdAt":"2024-02-20T20:23:12Z","_id":"363ec4e9-0b8f-48d2-ba6a-567a9c527c3d","_rev":"rGZ2nN6K5mjOGJOoWaUhNb","_type":"people","_updatedAt":"2024-02-25T00:45:24Z","image":{"_type":"image","asset":{"_ref":"image-89523511cf20d73e3f10077add50128d077ed520-176x176-png","_type":"reference"}},"name":"LlamaIndex","slug":{"_type":"slug","current":"llamaindex"}}],"featured":false,"image":{"_type":"image","asset":{"_ref":"image-bf0ee27ad4e3e17598a1e664653b59217e89dfdb-1024x1024-webp","_type":"reference"}},"mainImage":"https://cdn.sanity.io/images/7m9jw85w/production/bf0ee27ad4e3e17598a1e664653b59217e89dfdb-1024x1024.webp","publishedDate":"2024-08-21","relatedPosts":[{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-89380b5946452462d6c4a91f8109f705dc044c82-1080x1080-png","_type":"reference"}},"publishedDate":"2025-06-05","slug":"introducing-the-spreadsheet-agent-in-private-preview","title":"Introducing the Spreadsheet Agent, in private preview"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-9fdb15bafdf8c0921f36c6cd8cdac43c8ca87e27-2232x1562-png","_type":"reference"}},"publishedDate":"2025-05-29","slug":"rag-is-dead-long-live-agentic-retrieval","title":"RAG is dead, long live agentic retrieval"},{"featured":false,"image":{"_type":"image","asset":{"_ref":"image-63188044661ee9b8d5406238dba50804df90e7bf-1468x758-png","_type":"reference"}},"publishedDate":"2025-05-07","slug":"get-citations-and-reasoning-for-extracted-data-in-llamaextract","title":"Get Citations and Reasoning for Extracted Data in LlamaExtract"},{"featured":true,"image":{"_type":"image","asset":{"_ref":"image-13ef1e27c4ec6c9a72d2ce1fae36f5acac0062ba-1263x631-png","_type":"reference"}},"publishedDate":"2025-04-23","slug":"beyond-chatbots-adopting-agentic-document-workflows-for-enterprises","title":"Beyond chatbots: adopting Agentic Document Workflows for enterprises"}],"slug":{"_type":"slug","current":"efficient-chunk-size-optimization-for-rag-pipelines-with-llamacloud"},"tags":[{"_createdAt":"2024-02-22T20:19:11Z","_id":"893258fa-46ae-4ae2-b1a3-acb12849ab60","_rev":"RDEDF5eNko8cW03GEH0cXj","_type":"blogTag","_updatedAt":"2024-08-21T19:17:20Z","slug":{"_type":"slug","current":"rag"},"title":"RAG"},{"_createdAt":"2024-02-22T20:19:11Z","_id":"3b10fb60-ef85-40c3-a872-da635f552781","_rev":"RDEDF5eNko8cW03GEH0hfd","_type":"blogTag","_updatedAt":"2024-08-21T19:17:46Z","slug":{"_type":"slug","current":"llamacloud"},"title":"LlamaCloud"}],"text":[{"_key":"b37bff6a0485","_type":"block","children":[{"_key":"dc7659877daa0","_type":"span","marks":[],"text":"In Retrieval-Augmented Generation (RAG) systems, the choice of chunk size can significantly impact retrieval accuracy and overall system performance. However, experimenting with different chunk sizes has traditionally been a time-consuming process. This post explores the challenges associated with chunk size optimization and introduces LlamaCloud's features that facilitate this process."}],"markDefs":[],"style":"normal"},{"_key":"e7c7e15360e4","_type":"block","children":[{"_key":"173d56c0fe3f0","_type":"span","marks":[],"text":"Challenges in Chunk Size Experimentation"}],"markDefs":[],"style":"h2"},{"_key":"477e3b191011","_type":"block","children":[{"_key":"bafba7e7c3be0","_type":"span","marks":[],"text":"A lot of developers have figured out ways to experiment with retrieval parameters and prompts in a RAG pipeline - adjusting top-k and the QA prompts are relatively straightforward endeavors and of-course have an impact on performance."}],"markDefs":[],"style":"normal"},{"_key":"bf762dc14721","_type":"block","children":[{"_key":"575e8e2d7f7c0","_type":"span","marks":[],"text":"Experimenting with parameters during the indexing stage, such as chunking is equally as important, but harder to do. Indexing experimentation presents several technical challenges:"}],"markDefs":[],"style":"normal"},{"_key":"07b326d324e1","_type":"block","children":[{"_key":"7a67d3d19aa10","_type":"span","marks":["strong"],"text":"Reindexing Overhead"},{"_key":"7a67d3d19aa11","_type":"span","marks":[],"text":": Changing chunk sizes typically necessitates reindexing the entire dataset, which can be computationally expensive and time-consuming, especially for large datasets."}],"level":1,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"69d0b51a88be","_type":"block","children":[{"_key":"da560d7a738c0","_type":"span","marks":["strong"],"text":"Storage Inefficiency"},{"_key":"da560d7a738c1","_type":"span","marks":[],"text":": Maintaining multiple versions of indexed data with different chunk sizes can lead to significant storage overhead."}],"level":1,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"e228eb7d90b8","_type":"block","children":[{"_key":"1f59875eb21b0","_type":"span","marks":["strong"],"text":"Limited Visibility"},{"_key":"1f59875eb21b1","_type":"span","marks":[],"text":": Without proper tooling, it's difficult to visualize how documents are being chunked and how this affects retrieval quality."}],"level":1,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"bdeb7b66509a","_type":"block","children":[{"_key":"c9e0e18ef8760","_type":"span","marks":[],"text":"These factors make it annoying to experiment with chunking, especially in an ad-hoc pipeline setup in a Jupyter notebook. Most experimentation and observability tools primarily focus on query-time traces and not on data observability. As a result we’ve noticed a certain reluctance from developers to experiment with chunking despite the impact on final performance."}],"markDefs":[],"style":"normal"},{"_key":"24f9d0d920f6","_type":"block","children":[{"_key":"30775505a9970","_type":"span","marks":[],"text":"LlamaCloud's Approach to Chunk Size Optimization"}],"markDefs":[],"style":"h2"},{"_key":"5e064d166b0e","_type":"block","children":[{"_key":"98be5c3d50820","_type":"span","marks":[],"text":"LlamaCloud is an enterprise-ready platform that lets developers easily setup and iterate on RAG pipelines over unstructured data. It provides a set of features designed to streamline the process of chunk size experimentation:"}],"markDefs":[],"style":"normal"},{"_key":"103e48a685d8","_type":"block","children":[{"_key":"9179cb0a43c10","_type":"span","marks":["strong"],"text":"Index Cloning"},{"_key":"9179cb0a43c11","_type":"span","marks":[],"text":": Enables quick creation of index copies with different chunking configurations."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"5341f1aaf5f2","_type":"block","children":[{"_key":"4c232d2cfd2a0","_type":"span","marks":["strong"],"text":"Chunk Visualization"},{"_key":"4c232d2cfd2a1","_type":"span","marks":[],"text":": Allows direct inspection of how documents are chunked and how it impacts retrieval."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"6bab4b3391b4","_type":"block","children":[{"_key":"e9b2ed8a24bb0","_type":"span","marks":["strong"],"text":"Efficient Iteration"},{"_key":"e9b2ed8a24bb1","_type":"span","marks":[],"text":": Facilitates testing different chunk sizes without the need for manual data store management or complex reindexing processes."}],"level":1,"listItem":"bullet","markDefs":[],"style":"normal"},{"_key":"04f7417ed899","_type":"block","children":[{"_key":"a74dc35200320","_type":"span","marks":[],"text":"The following sections outline a workflow for utilizing these features to optimize chunk sizes in a RAG pipeline."}],"markDefs":[],"style":"normal"},{"_key":"040787a5f576","_type":"block","children":[{"_key":"f875d7c1a8510","_type":"span","marks":[],"text":"Workflow: Optimizing Chunk Sizes with LlamaCloud"}],"markDefs":[],"style":"h2"},{"_key":"38f990bf69af","_type":"block","children":[{"_key":"108912f4db8a0","_type":"span","marks":[],"text":"Below we detail an example use case where we’re able to make use of LlamaCloud’s setup and experimentation features to find a chunking configuration that better answers a question in an ad-hoc fashion. This is reflective of user behaviors where the user wants to sanity-check their RAG pipeline on some questions that they know the full-answer to, before running more systematic evaluation."}],"markDefs":[],"style":"normal"},{"_key":"c7f3a024bd81","_type":"block","children":[{"_key":"78073b25d2380","_type":"span","marks":[],"text":"Initial RAG Pipeline Setup"}],"markDefs":[],"style":"h3"},{"_key":"4925941781d3","_type":"block","children":[{"_key":"44ca3bf0887c0","_type":"span","marks":[],"text":"First, create an initial index in LlamaCloud. Create a new LlamaCloud Index via the UI and upload your document set (e.g., three ICLR 2024 research papers). In the \"Transform Settings\", select \"Auto\" and set a chunk size of 512 tokens as a baseline."}],"markDefs":[],"style":"normal"},{"_key":"bd569764d0f5","_type":"block","children":[{"_key":"99b7477247a50","_type":"span","marks":[],"text":"Define “Golden” Question-Answer Pair"}],"markDefs":[],"style":"h3"},{"_key":"3a127d188049","_type":"block","children":[{"_key":"3429f74e9e410","_type":"span","marks":[],"text":"Find an example question that you want to test over this data. In this example, the question we want to try asking is: \"Describe the core features of SWE-bench\"."}],"markDefs":[],"style":"normal"},{"_key":"0adb44ff9f92","_type":"block","children":[{"_key":"03bcd2738efe0","_type":"span","marks":[],"text":"You should have the golden context in mind. Here the answer is directly found in Section 2.3 of the SWE-bench paper which directly describes the Features of SWE-bench."}],"markDefs":[],"style":"normal"},{"_key":"59d759513eda","_type":"image","asset":{"_ref":"image-30fe1c5dd009729a01457dea69a2fe32894c29d6-2074x1346-png","_type":"reference"}},{"_key":"e7b0c3db523d","_type":"block","children":[{"_key":"93303e880faf0","_type":"span","marks":[],"text":"Baseline Configuration Testing through Playground"}],"markDefs":[],"style":"h3"},{"_key":"fdb60df33d8c","_type":"block","children":[{"_key":"08f080efea530","_type":"span","marks":[],"text":"You can now use LlamaCloud playground to evaluate the initial setup. Navigate to the \"Playground\" section of your index page and click on the “Chat” tab. This gives you a full chat UI over your index with intermediate step + response streaming and citations."}],"markDefs":[],"style":"normal"},{"_key":"2f99920812f5","_type":"block","children":[{"_key":"20354bfbc5300","_type":"span","marks":[],"text":"Enter the question above. You’ll get back a response that seems reasonable at first glance! The response describes SWE-Bench as being representative of real-world software engineering tasks, being continuously updatable, and more."}],"markDefs":[],"style":"normal"},{"_key":"3919d33c7a74","_type":"image","asset":{"_ref":"image-bf023f7cf3707b52b03ebc2dacd078ec1b60ae23-2990x1762-png","_type":"reference"}},{"_key":"a88d5cdb0fb5","_type":"block","children":[{"_key":"151792a448d70","_type":"span","marks":[],"text":"But you’ll notice that the last two sections are missing - “cross-context code editing” and “wide scope for possible solutions”."}],"markDefs":[],"style":"normal"},{"_key":"b13b00d57805","_type":"block","children":[{"_key":"c875eec5dc6c0","_type":"span","marks":[],"text":"3. Chunk Inspection"}],"markDefs":[],"style":"h3"},{"_key":"4e185f45dbc8","_type":"block","children":[{"_key":"ba1dae70d67a0","_type":"span","marks":[],"text":"Since the answer is partially correct, we might hypothesize that the chunking is causing the relevant context to be broken up. Access the retrieval UI to view retrieved chunks and their sources. Use the \"View in File\" feature to examine how the source document is parsed and chunked. You may observe that relevant information is split across multiple chunks, potentially affecting retrieval quality."}],"markDefs":[],"style":"normal"},{"_key":"d7040bc07f98","_type":"image","asset":{"_ref":"image-32f6e26fa1bb1b0bba943ad446d311374e31000c-3380x1896-png","_type":"reference"}},{"_key":"1c76e574091f","_type":"block","children":[{"_key":"59f66b276a2c0","_type":"span","marks":[],"text":"4. Chunk Size Iteration"}],"markDefs":[],"style":"h3"},{"_key":"f5b6e07b13e8","_type":"block","children":[{"_key":"904ed87119d00","_type":"span","marks":[],"text":"To test an alternative chunking strategy, use the \"Copy\" button on the Index page to duplicate your index. In the new index, select \"Edit\" to modify chunking parameters. Switch to \"Manual\" mode, set \"Segmentation Configuration\" to \"Page\", and set \"Chunking Configuration\" mode to \"None\". Apply these changes to initiate a new indexing run with updated settings."}],"markDefs":[],"style":"normal"},{"_key":"0fe6c937d37c","_type":"image","asset":{"_ref":"image-86f09b433fc9c7cf10066bc7058bbf8cb263641c-1924x980-png","_type":"reference"}},{"_key":"9128af3ec2ff","_type":"block","children":[{"_key":"684b8fe4ca730","_type":"span","marks":[],"text":"5. Result Comparison"}],"markDefs":[],"style":"h3"},{"_key":"46e2bf495b2e","_type":"block","children":[{"_key":"287187422f200","_type":"span","marks":[],"text":"Execute the same query on the new index and compare the results. You should observe a more comprehensive response that better captures the full context of SWE-bench's features."}],"markDefs":[],"style":"normal"},{"_key":"7b77ac6c5166","_type":"block","children":[{"_key":"baf99958919e0","_type":"span","marks":[],"text":"Next Steps"}],"markDefs":[],"style":"h2"},{"_key":"92a66436ace1","_type":"block","children":[{"_key":"16f90f68e6a00","_type":"span","marks":[],"text":"If you haven’t done so already, signup for a LlamaCloud account: "},{"_key":"16f90f68e6a01","_type":"span","marks":["6944c0a1533d"],"text":"https://cloud.llamaindex.ai/"},{"_key":"16f90f68e6a02","_type":"span","marks":[],"text":". We’re actively letting people off the waitlist!"}],"level":1,"listItem":"bullet","markDefs":[{"_key":"6944c0a1533d","_type":"link","href":"https://cloud.llamaindex.ai/"}],"style":"normal"},{"_key":"0c883793d5ef","_type":"block","children":[{"_key":"ceb469fc15ab0","_type":"span","marks":[],"text":"Check out the "},{"_key":"aee0c8424912","_type":"span","marks":["7bd6efecd853"],"text":"full notebook"},{"_key":"857cb77492cc","_type":"span","marks":[],"text":"."}],"level":1,"listItem":"bullet","markDefs":[{"_key":"7bd6efecd853","_type":"link","href":"https://github.com/run-llama/llamacloud-demo/blob/main/examples/experimentation/chunk_size_adhoc.ipynb"}],"style":"normal"},{"_key":"9a6b554a1948","_type":"block","children":[{"_key":"e8c9b9fc021d0","_type":"span","marks":[],"text":"While the ad-hoc experimentation process described in this post provides a quick way to iterate on chunk sizes, it's important to recognize that this is just the beginning of optimizing your RAG pipeline. Here are some suggested next steps to further refine your system:"}],"markDefs":[{"_key":"dbfd22de2746","_type":"link","href":"https://docs.llamaindex.ai/en/stable/module_guides/observability/"},{"_key":"8e0c8fe6a4a2","_type":"link","href":"https://llamatrace.com/"},{"_key":"0da579742153","_type":"link","href":"https://traceloop.com/"},{"_key":"14383a0a6d0d","_type":"link","href":"https://langfuse.com/"}],"style":"normal"},{"_key":"2cf9b43d25a5","_type":"block","children":[{"_key":"80d62c706d27","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"52672d012bc3","_type":"block","children":[{"_key":"970870403dcb0","_type":"span","marks":["strong"],"text":"1. Systematic Evaluation"},{"_key":"970870403dcb1","_type":"span","marks":[],"text":": Develop a more structured evaluation framework. This could involve creating a test set of queries with known correct answers, and systematically comparing the performance of different chunk sizes across various metrics such as relevance, coherence, and factual accuracy. We have a fantastic set of "},{"_key":"970870403dcb2","_type":"span","marks":["dbfd22de2746"],"text":"observability and evaluation partners"},{"_key":"970870403dcb3","_type":"span","marks":[],"text":" to help you get started, including "},{"_key":"970870403dcb4","_type":"span","marks":["8e0c8fe6a4a2"],"text":"LlamaTrace"},{"_key":"970870403dcb5","_type":"span","marks":[],"text":" (by Arize), "},{"_key":"970870403dcb6","_type":"span","marks":["0da579742153"],"text":"Traceloop"},{"_key":"970870403dcb7","_type":"span","marks":[],"text":", and "},{"_key":"970870403dcb8","_type":"span","marks":["14383a0a6d0d"],"text":"Langfuse"},{"_key":"970870403dcb9","_type":"span","marks":[],"text":"."}],"markDefs":[{"_key":"dbfd22de2746","_type":"link","href":"https://docs.llamaindex.ai/en/stable/module_guides/observability/"},{"_key":"8e0c8fe6a4a2","_type":"link","href":"https://llamatrace.com/"},{"_key":"0da579742153","_type":"link","href":"https://traceloop.com/"},{"_key":"14383a0a6d0d","_type":"link","href":"https://langfuse.com/"}],"style":"normal"},{"_key":"d38991d316e1","_type":"block","children":[{"_key":"6d33471a800d0","_type":"span","marks":["strong"],"text":"2. Automated Testing"},{"_key":"6d33471a800d1","_type":"span","marks":[],"text":": Implement automated tests that can run through your evaluation framework each time you make changes to your chunking strategy. This can help you quickly identify if new configurations are improving or degrading performance."}],"markDefs":[],"style":"normal"},{"_key":"808d07025b5b","_type":"block","children":[{"_key":"be505fedf84a0","_type":"span","marks":["strong"],"text":"3. Fine-tuning Retrieval Parameters"},{"_key":"be505fedf84a1","_type":"span","marks":[],"text":": Once you've found a chunking strategy that works well, experiment with other retrieval parameters such as the number of retrieved chunks, reranking strategies, or hybrid search methods."}],"markDefs":[],"style":"normal"},{"_key":"440fee6c1366","_type":"block","children":[{"_key":"e8cba001dd3f0","_type":"span","marks":["strong"],"text":"4. Domain-Specific Optimization"},{"_key":"e8cba001dd3f1","_type":"span","marks":[],"text":": Consider how the nature of your specific documents and use case might influence optimal chunk sizes. Technical documentation, narrative text, and structured data might all benefit from different chunking strategies."}],"markDefs":[],"style":"normal"},{"_key":"1a8b25861188","_type":"block","children":[{"_key":"829371c004900","_type":"span","marks":["strong"],"text":"5. Monitoring and Continuous Improvement"},{"_key":"829371c004901","_type":"span","marks":[],"text":": Set up monitoring for your production RAG system to track key performance indicators over time. Use this data to inform ongoing optimization efforts."}],"markDefs":[],"style":"normal"},{"_key":"f2b0b97c14cb","_type":"block","children":[{"_key":"a8878addc1330","_type":"span","marks":[],"text":"By combining the rapid iteration capabilities of LlamaCloud with these more systematic approaches, you can create a robust, high-performing RAG pipeline tailored to your specific needs."}],"markDefs":[],"style":"normal"},{"_key":"40cbeb32844e","_type":"block","children":[{"_key":"57e9ed5242e50","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"0f3f90af7e7c","_type":"block","children":[{"_key":"5c4e90e72346","_type":"span","marks":[],"text":"If you’re interested in chatting about our LlamaCloud plans to solve your enterprise RAG needs, "},{"_key":"57e9ed5242e51","_type":"span","marks":["318721d97529"],"text":"get in touch."}],"markDefs":[{"_key":"318721d97529","_type":"link","href":"https://www.llamaindex.ai/contact"}],"style":"normal"}],"title":"Efficient Chunk Size Optimization for RAG Pipelines with LlamaCloud"},"publishedDate":"Invalid Date"},"params":{"slug":"efficient-chunk-size-optimization-for-rag-pipelines-with-llamacloud"},"draftMode":false,"token":""},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"efficient-chunk-size-optimization-for-rag-pipelines-with-llamacloud"},"buildId":"C8J-EMc_4OCN1ch65l4fl","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>