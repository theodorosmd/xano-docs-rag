<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>Batch inference with MyMagic AI and LlamaIndex — LlamaIndex - Build Knowledge Assistants over your Enterprise Data</title><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><meta name="title" content="Batch inference with MyMagic AI and LlamaIndex — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta name="description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:title" content="Batch inference with MyMagic AI and LlamaIndex — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="og:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="og:image" content="https://cdn.sanity.io/images/7m9jw85w/production/9deefa59f3a0c792677dd519ba014574a85a538c-1024x1024.webp"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="Batch inference with MyMagic AI and LlamaIndex — LlamaIndex - Build Knowledge Assistants over your Enterprise Data"/><meta property="twitter:description" content="LlamaIndex is a simple, flexible framework for building knowledge assistants using LLMs connected to your enterprise data."/><meta property="twitter:image" content="https://cdn.sanity.io/images/7m9jw85w/production/9deefa59f3a0c792677dd519ba014574a85a538c-1024x1024.webp"/><link rel="alternate" type="application/rss+xml" href="https://www.llamaindex.ai/blog/feed"/><meta name="next-head-count" content="20"/><script>
            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WWRFB36R');
            </script><link rel="preload" href="/_next/static/css/41c9222e47d080c9.css" as="style"/><link rel="stylesheet" href="/_next/static/css/41c9222e47d080c9.css" data-n-g=""/><link rel="preload" href="/_next/static/css/97c33c8d95f1230e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/97c33c8d95f1230e.css" data-n-p=""/><link rel="preload" href="/_next/static/css/e009059e80bf60c5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e009059e80bf60c5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-1b629d9c8fb16f34.js" defer=""></script><script src="/_next/static/chunks/framework-df1f68dff096b68a.js" defer=""></script><script src="/_next/static/chunks/main-eca7952a704663f8.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c7c49437be49d2ad.js" defer=""></script><script src="/_next/static/chunks/d9067523-4985945b21298365.js" defer=""></script><script src="/_next/static/chunks/41155975-60c12da9ce9fa0b2.js" defer=""></script><script src="/_next/static/chunks/cb355538-cee2ea45674d9de3.js" defer=""></script><script src="/_next/static/chunks/9494-dff62cb53535dd7d.js" defer=""></script><script src="/_next/static/chunks/4063-39a391a51171ff87.js" defer=""></script><script src="/_next/static/chunks/6889-edfa85b69b88a372.js" defer=""></script><script src="/_next/static/chunks/5575-11ee0a29eaffae61.js" defer=""></script><script src="/_next/static/chunks/3444-95c636af25a42734.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-82c8e764e69afd2c.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_buildManifest.js" defer=""></script><script src="/_next/static/C8J-EMc_4OCN1ch65l4fl/_ssgManifest.js" defer=""></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WWRFB36R" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div class="__variable_d65c78 __variable_b1ea77 __variable_eb7534"><a class="Announcement_announcement__2ohK8" href="http://48755185.hs-sites.com/llamaindex-0">Meet LlamaIndex at the Databricks Data + AI Summit!<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M8.293 5.293a1 1 0 0 1 1.414 0l6 6a1 1 0 0 1 0 1.414l-6 6a1 1 0 0 1-1.414-1.414L13.586 12 8.293 6.707a1 1 0 0 1 0-1.414Z" clip-rule="evenodd"></path></svg></a><header class="Header_header__hO3lJ"><button class="Hamburger_hamburger__17auO Header_hamburger__lUulX"><svg width="28" height="28" viewBox="0 0 28 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.5 14H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" id="hamburger-stroke-top" class="Hamburger_hamburgerStrokeMiddle__I7VpD"></path><path d="M3.5 7H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeTop__oOhFM"></path><path d="M3.5 21H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeBottom__GIQR2"></path></svg></button><a aria-label="Homepage" href="/"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" class="Header_logo__e5KhT" style="color:transparent" src="/llamaindex.svg"/></a><nav aria-label="Main" data-orientation="horizontal" dir="ltr" style="--content-position:0px"><div style="position:relative"><ul data-orientation="horizontal" class="Nav_MenuList__PrCDJ" dir="ltr"><li><button id="radix-:R6tm:-trigger-radix-:R5mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R5mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Products</button></li><li><button id="radix-:R6tm:-trigger-radix-:R9mtm:" data-state="closed" aria-expanded="false" aria-controls="radix-:R6tm:-content-radix-:R9mtm:" class="Nav_Trigger__ws43x" data-radix-collection-item="">Solutions</button></li><li><a class="Nav_Link__ZrzFc" href="/community" data-radix-collection-item="">Community</a></li><li><a class="Nav_Link__ZrzFc" href="/pricing" data-radix-collection-item="">Pricing</a></li><li><a class="Nav_Link__ZrzFc" href="/blog" data-radix-collection-item="">Blog</a></li><li><a class="Nav_Link__ZrzFc" href="/customers" data-radix-collection-item="">Customer stories</a></li><li><a class="Nav_Link__ZrzFc" href="/careers" data-radix-collection-item="">Careers</a></li></ul></div><div class="Nav_ViewportPosition__jmyHM"></div></nav><div class="Header_secondNav__YJvm8"><nav><a href="/contact" class="Link_link__71cl8 Link_link-variant-tertiary__BYxn_ Header_bookADemo__qCuxV">Book a demo</a></nav><a href="https://cloud.llamaindex.ai/" class="Button_button-variant-default__Oi__n Button_button__aJ0V6 Header_button__1HFhY" data-tracking-variant="default"> <!-- -->Get started</a></div><div class="MobileMenu_mobileMenu__g5Fa6"><nav class="MobileMenu_nav__EmtTw"><ul><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Products<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaparse"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.6654 1.66675V6.66675H16.6654M8.33203 10.8334L6.66536 12.5001L8.33203 14.1667M11.6654 14.1667L13.332 12.5001L11.6654 10.8334M12.082 1.66675H4.9987C4.55667 1.66675 4.13275 1.84234 3.82019 2.1549C3.50763 2.46746 3.33203 2.89139 3.33203 3.33341V16.6667C3.33203 17.1088 3.50763 17.5327 3.82019 17.8453C4.13275 18.1578 4.55667 18.3334 4.9987 18.3334H14.9987C15.4407 18.3334 15.8646 18.1578 16.1772 17.8453C16.4898 17.5327 16.6654 17.1088 16.6654 16.6667V6.25008L12.082 1.66675Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Document parsing</div><p class="MobileMenu_ListItemText__n_MHY">The first and leading GenAI-native parser over your most complex data.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/llamaextract"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.668 1.66675V5.00008C11.668 5.44211 11.8436 5.86603 12.1561 6.17859C12.4687 6.49115 12.8926 6.66675 13.3346 6.66675H16.668M3.33464 5.83341V3.33341C3.33464 2.89139 3.51023 2.46746 3.82279 2.1549C4.13535 1.84234 4.55927 1.66675 5.0013 1.66675H12.5013L16.668 5.83341V16.6667C16.668 17.1088 16.4924 17.5327 16.1798 17.8453C15.8672 18.1578 15.4433 18.3334 15.0013 18.3334L5.05379 18.3326C4.72458 18.3755 4.39006 18.3191 4.09312 18.1706C3.79618 18.0221 3.55034 17.7884 3.38713 17.4992M4.16797 9.16675L1.66797 11.6667M1.66797 11.6667L4.16797 14.1667M1.66797 11.6667H10.0013" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Data extraction</div><p class="MobileMenu_ListItemText__n_MHY">Extract structured data from documents using a schema-driven engine.</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/enterprise"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9.16667 15.8333C12.8486 15.8333 15.8333 12.8486 15.8333 9.16667C15.8333 5.48477 12.8486 2.5 9.16667 2.5C5.48477 2.5 2.5 5.48477 2.5 9.16667C2.5 12.8486 5.48477 15.8333 9.16667 15.8333Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M17.5 17.5L13.875 13.875" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Knowledge Management</div><p class="MobileMenu_ListItemText__n_MHY">Connect, transform, and index your enterprise data into an agent-accessible knowledge base</p></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/framework"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.0013 6.66659V3.33325H6.66797M1.66797 11.6666H3.33464M16.668 11.6666H18.3346M12.5013 10.8333V12.4999M7.5013 10.8333V12.4999M5.0013 6.66659H15.0013C15.9218 6.66659 16.668 7.41278 16.668 8.33325V14.9999C16.668 15.9204 15.9218 16.6666 15.0013 16.6666H5.0013C4.08083 16.6666 3.33464 15.9204 3.33464 14.9999V8.33325C3.33464 7.41278 4.08083 6.66659 5.0013 6.66659Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Agent Framework</div><p class="MobileMenu_ListItemText__n_MHY">Orchestrate and deploy multi-agent applications over your data with the #1 agent framework.</p></a></li></ul></details></li><li><details class="MobileMenu_ListItem__yMtVi"><summary class="MobileMenu_ListItemHeading___yPC6">Solutions<!-- --> <span class="MobileMenu_icon__6gmaF"><svg width="11" height="6" viewBox="0 0 11 6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10 1L5.5 5L1 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></summary><ul class="MobileMenu_List__XjJr0"><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/finance"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 6.66675H8.33073C7.8887 6.66675 7.46478 6.84234 7.15222 7.1549C6.83966 7.46746 6.66406 7.89139 6.66406 8.33342C6.66406 8.77544 6.83966 9.19937 7.15222 9.51193C7.46478 9.82449 7.8887 10.0001 8.33073 10.0001H11.6641C12.1061 10.0001 12.53 10.1757 12.8426 10.4882C13.1551 10.8008 13.3307 11.2247 13.3307 11.6667C13.3307 12.1088 13.1551 12.5327 12.8426 12.8453C12.53 13.1578 12.1061 13.3334 11.6641 13.3334H6.66406M9.9974 15.0001V5.00008M18.3307 10.0001C18.3307 14.6025 14.5998 18.3334 9.9974 18.3334C5.39502 18.3334 1.66406 14.6025 1.66406 10.0001C1.66406 5.39771 5.39502 1.66675 9.9974 1.66675C14.5998 1.66675 18.3307 5.39771 18.3307 10.0001Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Financial Analysts</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/administrative-operations"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1.66406 6.66659V15.8333C1.66406 16.2753 1.83966 16.6992 2.15222 17.0118C2.46478 17.3243 2.8887 17.4999 3.33073 17.4999H14.9974M16.6641 14.1666C17.1061 14.1666 17.53 13.991 17.8426 13.6784C18.1551 13.3659 18.3307 12.9419 18.3307 12.4999V7.49992C18.3307 7.05789 18.1551 6.63397 17.8426 6.32141C17.53 6.00885 17.1061 5.83325 16.6641 5.83325H13.4141C13.1353 5.83598 12.8604 5.76876 12.6143 5.63774C12.3683 5.50671 12.159 5.31606 12.0057 5.08325L11.3307 4.08325C11.179 3.85281 10.9724 3.66365 10.7295 3.53275C10.4866 3.40185 10.215 3.3333 9.93906 3.33325H6.66406C6.22204 3.33325 5.79811 3.50885 5.48555 3.82141C5.17299 4.13397 4.9974 4.55789 4.9974 4.99992V12.4999C4.9974 12.9419 5.17299 13.3659 5.48555 13.6784C5.79811 13.991 6.22204 14.1666 6.66406 14.1666H16.6641Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Administrative Operations</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/engineering"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.3307 15L18.3307 10L13.3307 5M6.66406 5L1.66406 10L6.66406 15" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Engineering &amp; R&amp;D</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/customer-support"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.9974 7.50008H16.6641C17.1061 7.50008 17.53 7.67568 17.8426 7.98824C18.1551 8.3008 18.3307 8.72472 18.3307 9.16675V18.3334L14.9974 15.0001H9.9974C9.55537 15.0001 9.13145 14.8245 8.81888 14.5119C8.50632 14.1994 8.33073 13.7754 8.33073 13.3334V12.5001M11.6641 7.50008C11.6641 7.94211 11.4885 8.36603 11.1759 8.67859C10.8633 8.99115 10.4394 9.16675 9.9974 9.16675H4.9974L1.66406 12.5001V3.33341C1.66406 2.41675 2.41406 1.66675 3.33073 1.66675H9.9974C10.4394 1.66675 10.8633 1.84234 11.1759 2.1549C11.4885 2.46746 11.6641 2.89139 11.6641 3.33341V7.50008Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Customer Support</div></a></li><li><a class="MobileMenu_ListItemLink__dnvmV" href="/solutions/healthcare-pharma"><div class="MobileMenu_ListItemHeading___yPC6"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M17.0128 3.81671C16.5948 3.39719 16.098 3.06433 15.551 2.8372C15.004 2.61008 14.4176 2.49316 13.8253 2.49316C13.2331 2.49316 12.6466 2.61008 12.0996 2.8372C11.5527 3.06433 11.0559 3.39719 10.6378 3.81671L9.99617 4.46671L9.3545 3.81671C8.93643 3.39719 8.43967 3.06433 7.89268 2.8372C7.3457 2.61008 6.75926 2.49316 6.167 2.49316C5.57474 2.49316 4.9883 2.61008 4.44132 2.8372C3.89433 3.06433 3.39756 3.39719 2.9795 3.81671C1.21283 5.58338 1.1045 8.56671 3.3295 10.8334L9.99617 17.5L16.6628 10.8334C18.8878 8.56671 18.7795 5.58338 17.0128 3.81671Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M2.91406 9.99992H7.91406L8.33073 9.16659L9.9974 12.9166L11.6641 7.08325L12.9141 9.99992H17.0807" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg>Healthcare / Pharma</div></a></li></ul></details></li><li><a class="MobileMenu_Link__5frcx" href="/community">Community</a></li><li><a class="MobileMenu_Link__5frcx" href="/pricing">Pricing</a></li><li><a class="MobileMenu_Link__5frcx" href="/blog">Blog</a></li><li><a class="MobileMenu_Link__5frcx" href="/customers">Customer stories</a></li><li><a class="MobileMenu_Link__5frcx" href="/careers">Careers</a></li></ul></nav><a href="/contact" class="Button_button-variant-ghost__o2AbG Button_button__aJ0V6" data-tracking-variant="ghost"> <!-- -->Talk to us</a><ul class="Socials_socials__8Y_s5 Socials_socials-theme-dark__Hq8lc MobileMenu_socials__JykCO"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu MobileMenu_copyright__nKVOs">© <!-- -->2025<!-- --> LlamaIndex</p></div></header><main><section class="BlogPost_post__JHNzd"><img alt="" loading="lazy" width="800" height="512" decoding="async" data-nimg="1" class="BlogPost_featuredImage__KGxwX" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9deefa59f3a0c792677dd519ba014574a85a538c-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9deefa59f3a0c792677dd519ba014574a85a538c-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F9deefa59f3a0c792677dd519ba014574a85a538c-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><p class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-600__fKYth BlogPost_date__6uxQw"><a class="BlogPost_author__mesdl" href="/blog/author/mymagic-ai">MyMagic AI</a> <!-- -->•<!-- --> <!-- -->2024-05-22</p><h1 class="Text_text__zPO0D Text_text-size-32__koGps BlogPost_title__b2lqJ">Batch inference with MyMagic AI and LlamaIndex</h1><ul class="BlogPost_tags__13pBH"><li><a class="Badge_badge___1ssn" href="/blog/tag/mymagic-ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">MyMagic AI</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/batch-inference"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Batch inference</span></a></li></ul><div class="BlogPost_htmlPost__Z5oDL"><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><em>This is a guest post from MyMagic AI.</em></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><a href="https://mymagic.ai/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">MyMagic AI</a> allows processing and analyzing large datasets with AI. MyMagic AI offers a powerful API for <em>batch</em> inference (also known as <em>offline</em> or <em>delayed</em> inference) that brings various open-source Large Language Models (LLMs) such as Llama 70B, Mistral 7B, Mixtral 8x7B, CodeLlama70b, and advanced Embedding models to its users. Our framework is designed to perform data extraction, summarization, categorization, sentiment analysis, training data generation, and embedding, to name a few. And now it&#x27;s integrated directly into LlamaIndex!</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Part 1: batch inference</h2><h3 class="Text_text__zPO0D Text_text-size-40__fIyvA">How It Works:</h3><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>1. Setup</strong>:</p><ol><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Organize Your Data in an AWS S3 or GCS Bucket:<ol><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Create a folder using your user ID assigned to you upon registration.</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Inside that folder, create another folder (called a &quot;session&quot;) to store all the files you need for your tasks.</li></ol></li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Purpose of the &#x27;Session&#x27; Folder:<ol><li class="Text_text__zPO0D Text_text-size-16__PkjFu">This &quot;Session&quot; folder keeps your files separate from others, making sure that your tasks run on the right set of files. You can name your session subfolder anything you like.</li></ol></li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Granting Access to MyMagic AI:<ol><li class="Text_text__zPO0D Text_text-size-16__PkjFu">To allow MyMagic AI to securely access your files in the cloud, follow the setup instructions provided in the <a href="https://docs.mymagic.ai/" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">MyMagic AI documentation</a>.</li></ol></li></ol><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>2. Install</strong>: Install both MyMagic AI’s API integration and LlamaIndex library:</p><pre><code>pip install llama-index
pip install llama-index-llms-mymagic</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><strong>3. API Request:</strong> The llamaIndex library is a wrapper around MyMagic AI’s API. What it does under the hood is simple: it sends a POST request to the MyMagic AI API while specifying the model, storage provider, bucket name, session name, and other necessary details.</p><pre><code><span class="hljs-keyword">import</span> asyncio
<span class="hljs-keyword">from</span> llama_index.llms.mymagic <span class="hljs-keyword">import</span> MyMagicAI

llm = MyMagicAI(
    api_key=<span class="hljs-string">&quot;user_...&quot;</span>, <span class="hljs-comment"># provided by MyMagic AI upon sign-up</span>
    storage_provider=<span class="hljs-string">&quot;s3&quot;</span>,
    bucket_name=<span class="hljs-string">&quot;batch-bucket&quot;</span>, <span class="hljs-comment"># you may name anything</span>
    session=<span class="hljs-string">&quot;my-session&quot;</span>,
    role_arn=<span class="hljs-string">&quot;arn:aws:iam::&lt;your account id&gt;:role/mymagic-role&quot;</span>,
    system_prompt=<span class="hljs-string">&quot;You are an AI assistant that helps to summarize the documents without essential loss of information&quot;</span>, <span class="hljs-comment"># default prompt at https://docs.mymagic.ai/api-reference/endpoint/create</span>
    region=<span class="hljs-string">&quot;eu-west-2&quot;</span>,
)</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We have designed the integration to allow the user to set up the bucket and data together with the system prompt when instantiating the llm object. Other inputs, e.g. question (i.e. your prompt), model and max_tokens are dynamic requirements when submitting complete and acomplete requests.</p><pre><code>resp = llm.complete(
    question=<span class="hljs-string">&quot;Summarise this in one sentence.&quot;</span>,
    model=<span class="hljs-string">&quot;mixtral8x7&quot;</span>, 
    max_tokens=<span class="hljs-number">20</span>,  <span class="hljs-comment"># default is 10</span>
)
<span class="hljs-built_in">print</span>(resp)
<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():
    aresp = <span class="hljs-keyword">await</span> llm.acomplete(
        question=<span class="hljs-string">&quot;Summarize this in one sentence.&quot;</span>,
        model=<span class="hljs-string">&quot;llama7b&quot;</span>,
        max_tokens=<span class="hljs-number">20</span>,
    )
    <span class="hljs-built_in">print</span>(aresp)

asyncio.run(main())</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">This dynamic entry allows developers to experiment with different prompts and models in their workflow while also controlling for model output to cap their spending limit. MyMagic AI’s backend supports both synchronous requests (complete) and asynchronous requests (acomplete). It is advisable, however, to use our async endpoints as much as possible as batch jobs are inherently asynchronous with potentially long processing times (depending on the size of your data).</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Currently, we do not support chat or achat methods as our API is not designed for real-time interactive experience. However, we are planning to add those methods in the future that will function in a “batch way”. The user queries will be aggregated and appended as one prompt (to give the chat context) and sent to all files at once.</p><h3 class="Text_text__zPO0D Text_text-size-40__fIyvA">Use Cases</h3><p class="Text_text__zPO0D Text_text-size-16__PkjFu">While there are myriads of use cases, here we provide a few to help motivate our users. Feel free to embed our API in your workflows that are good fit for batch processing.</p><h4 class="Text_text__zPO0D Text_text-size-32__koGps">1. Extraction</h4><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Imagine needing to extract specific information from millions of files stored in a bucket. Information from all files will be extracted with one API call instead of a million sequential ones.</p><h4 class="Text_text__zPO0D Text_text-size-32__koGps">2. Classification</h4><p class="Text_text__zPO0D Text_text-size-16__PkjFu">For businesses looking to classify customer reviews such as positive, neutral, and negative. With one request you can start processing the requests over the weekend and get them ready by Monday morning.</p><h4 class="Text_text__zPO0D Text_text-size-32__koGps">3. Embedding</h4><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Embedding text files for further machine learning applications is another powerful use case of MyMagic AI&#x27;s API. You will be ready for your vector db in a matter of days not weeks.</p><h4 class="Text_text__zPO0D Text_text-size-32__koGps">4. Training (Fine-tuning) Data Generation</h4><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Imagine generating thousands of synthetic data for your fine-tuning tasks. With MyMagic AI’s API, you can reduce the generation time by a factor of 5-10x compared to GPT-3.5.</p><h4 class="Text_text__zPO0D Text_text-size-32__koGps">5. Transcription</h4><p class="Text_text__zPO0D Text_text-size-16__PkjFu">MyMagic AI’s API supports different types of files, so it is also easy to batch transcribe many mp3 or mp4 files in your bucket.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Part 2: Integration with LlamaIndex’s RAG Pipeline</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The output from batch inference processes, often voluminous, can seamlessly integrate into LlamaIndex&#x27;s RAG pipeline for effective data storage and retrieval.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">This section demonstrates how to use the Llama3 model from the Ollama library coupled with BGE embedding to manage information storage and execute queries. Please ensure the following prerequisites are installed and Llama3 model is pulled:</p><pre><code>pip install llama-index-embeddings-huggingface
curl -fsSL https://ollama.com/install.sh | sh
ollama pull llama3</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">For this demo, we have run a batch summarization job on 5 Amazon reviews (but this might be millions in some real scenarios) and saved the results as reviews_1_5.json:</p><pre><code>{
  &quot;id_review1&quot;: {
    &quot;query&quot;: &quot;Summarize the document!&quot;,
    &quot;output&quot;: &quot;The document describes a family with a young boy who believes there is a zombie in his closet, while his parents are constantly fighting. The movie is criticized for its inconsistent genre, described as a slow-paced drama with occasional thriller elements. The review praises the well-playing parents and the decent dialogs but criticizes the lack of a boogeyman-like horror element. The overall rating is 3 out of 10.&quot;
  },
  &quot;id_review2&quot;: {
    &quot;query&quot;: &quot;Summarize the document!&quot;,
    &quot;output&quot;: &quot;The document is a positive review of a light-hearted Woody Allen comedy. The reviewer praises the witty dialogue, likable characters, and Woody Allen&#x27;s control over his signature style. The film is noted for making the reviewer laugh more than any recent Woody Allen comedy and praises Scarlett Johansson&#x27;s performance. It concludes by calling the film a great comedy to watch with friends.&quot;
  },
  &quot;id_review3&quot;: {
    &quot;query&quot;: &quot;Summarize the document!&quot;,
    &quot;output&quot;: &quot;The document describes a well-made film about one of the great masters of comedy, filmed in an old-time BBC fashion that adds realism. The actors, including Michael Sheen, are well-chosen and convincing. The production is masterful, showcasing realistic details like the fantasy of the guard and the meticulously crafted sets of Orton and Halliwell&#x27;s flat. Overall, it is a terrific and well-written piece.&quot;
  },
  &quot;id_review4&quot;: {
    &quot;query&quot;: &quot;Summarize the document!&quot;,
    &quot;output&quot;: &quot;Petter Mattei&#x27;s &#x27;Love in the Time of Money&#x27; is a visually appealing film set in New York, exploring human relations in the context of money, power, and success. The characters, played by a talented cast including Steve Buscemi and Rosario Dawson, are connected in various ways but often unaware of their shared links. The film showcases the different stages of loneliness experienced by individuals in a big city. Mattei successfully portrays the world of these characters, creating a luxurious and sophisticated look. The film is a modern adaptation of Arthur Schnitzler&#x27;s play on the same theme. Mattei&#x27;s work is appreciated, and viewers look forward to his future projects.&quot;
  },
  &quot;id_review5&quot;: {
    &quot;query&quot;: &quot;Summarize the document!&quot;,
    &quot;output&quot;: &quot;The document describes the TV show &#x27;Oz&#x27;, set in the Oswald Maximum Security State Penitentiary. Known for its brutality, violence, and lack of privacy, it features an experimental section of the prison called Em City, where all the cells have glass fronts and face inwards. The show goes where others wouldn&#x27;t dare, featuring graphic violence, injustice, and the harsh realities of prison life. The viewer may become comfortable with uncomfortable viewing if they can embrace their darker side.&quot;
  },
  &quot;token_count&quot;: 3391
}
</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Now let’s embed and store this document and ask questions using LlamaIndex’s query engine. Bring in our dependencies:</p><pre><code><span class="hljs-keyword">import</span> os

<span class="hljs-keyword">from</span> llama_index.embeddings.huggingface <span class="hljs-keyword">import</span> HuggingFaceEmbedding
<span class="hljs-keyword">from</span> llama_index.core.indices.vector_store <span class="hljs-keyword">import</span> VectorStoreIndex
<span class="hljs-keyword">from</span> llama_index.core.settings <span class="hljs-keyword">import</span> Settings
<span class="hljs-keyword">from</span> llama_index.core.readers <span class="hljs-keyword">import</span> SimpleDirectoryReader
<span class="hljs-keyword">from</span> llama_index.llms.ollama <span class="hljs-keyword">import</span> Ollama</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Configure the embedding model and Llama3 model</p><pre><code>embed_model = HuggingFaceEmbedding(model_name=<span class="hljs-string">&quot;BAAI/bge-base-en-v1.5&quot;</span>)
llm = Ollama(model=<span class="hljs-string">&quot;llama3&quot;</span>, request_timeout=<span class="hljs-number">300.0</span>)</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Update settings for the indexing pipeline:</p><pre><code>Settings.llm = llm
Settings.embed_model = embed_model
Settings.chunk_size = <span class="hljs-number">512</span> <span class="hljs-comment"># This parameter defines the size of text chunks for embedding</span>

documents = SimpleDirectoryReader(<span class="hljs-string">&quot;reviews_1_5.json&quot;</span>).load_data() <span class="hljs-comment">#Modify path for your case</span></code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Now create our index, our query engine and run a query:</p><pre><code>index = VectorStoreIndex.from_documents(documents, show_progress=<span class="hljs-literal">True</span>)

query_engine = index.as_query_engine(similarity_top_k=<span class="hljs-number">3</span>)

response = query_engine.query(<span class="hljs-string">&quot;What is the least favourite movie?&quot;</span>)
<span class="hljs-built_in">print</span>(response)</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Output:</p><pre><code>Based on query results, the least favourite movie is: review 1 with a rating of 3 out of 10.</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Now we know that the review 1 is the least favorite movie among these reviews.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Next Steps</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">This shows how batch inference combined with real-time inference can be a powerful tool for analyzing, storing and retrieving information from massive amounts of data. <a href="https://vivacious-river-18.authkit.app/sign-up?redirect_uri=https://api.mymagic.ai/workspace" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Get started with MyMagic AI’s API</a> today!</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><br/></p></div></section></main><footer class="Footer_footer__eNA9m"><div class="Footer_navContainer__7bvx4"><div class="Footer_logoContainer__3EpzI"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" style="color:transparent" src="/llamaindex.svg"/><div class="Footer_socialContainer__GdOgk"><ul class="Socials_socials__8Y_s5"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul></div></div><div class="Footer_nav__BLEuE"><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/">LlamaIndex</a></h3><ul><li><a href="/blog"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Blog</span></a></li><li><a href="/partners"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Partners</span></a></li><li><a href="/careers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Careers</span></a></li><li><a href="/contact"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Contact</span></a></li><li><a href="/brand"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Brand</span></a></li><li><a href="https://llamaindex.statuspage.io" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Status</span></a></li><li><a href="https://app.vanta.com/runllama.ai/trust/pkcgbjf8b3ihxjpqdx17nu" target="_blank"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Trust Center</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/enterprise">Enterprise</a></h3><ul><li><a href="https://cloud.llamaindex.ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaCloud</span></a></li><li><a href="https://cloud.llamaindex.ai/parse" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaParse</span></a></li><li><a href="/customers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Customers</span></a></li><li><a href="/llamacloud-sharepoint-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SharePoint</span></a></li><li><a href="/llamacloud-aws-s3-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">AWS S3</span></a></li><li><a href="/llamacloud-azure-blob-storage-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Azure Blob Storage</span></a></li><li><a href="/llamacloud-google-drive-data-loading-for-generative-ai" data-tracking-variant="link" data-tracking-section="footer"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Google Drive</span></a></li> </ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/framework">Framework</a></h3><ul><li><a href="https://pypi.org/project/llama-index/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python package</span></a></li><li><a href="https://docs.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python docs</span></a></li><li><a href="https://www.npmjs.com/package/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript package</span></a></li><li><a href="https://ts.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript docs</span></a></li><li><a href="https://llamahub.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaHub</span></a></li><li><a href="https://github.com/run-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">GitHub</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/community">Community</a></h3><ul><li><a href="/community#newsletter"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Newsletter</span></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Discord</span></a></li><li><a href="https://www.linkedin.com/company/91154103/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LinkedIn</span></a></li><li><a href="https://twitter.com/llama_index"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Twitter/X</span></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">YouTube</span></a></li><li><a href="https://bsky.app/profile/llamaindex.bsky.social"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">BlueSky</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e">Starter projects</h3><ul><li><a href="https://www.npmjs.com/package/create-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">create-llama</span></a></li><li><a href="https://secinsights.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SEC Insights</span></a></li><li><a href="https://github.com/run-llama/llamabot"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaBot</span></a></li><li><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/rag_cli.html"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">RAG CLI</span></a></li></ul></div></div></div><div class="Footer_copyrightContainer__mBKsT"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA">© <!-- -->2025<!-- --> LlamaIndex</p><div class="Footer_legalNav__O1yJA"><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/privacy-notice.pdf">Privacy Notice</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="/files/terms-of-service.pdf">Terms of Service</a></p><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA"><a href="https://bit.ly/llamaindexdpa">Data Processing Addendum</a></p></div></div></footer></div><svg xmlns="http://www.w3.org/2000/svg" class="flt_svg" style="display:none"><defs><filter id="flt_tag"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="2"></feGaussianBlur><feColorMatrix in="blur" result="flt_tag" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="flt_tag" operator="atop"></feComposite></filter><filter id="svg_blur_large"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="8"></feGaussianBlur><feColorMatrix in="blur" result="svg_blur_large" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="svg_blur_large" operator="atop"></feComposite></filter></defs></svg></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"page":{"announcement":{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"},"post":{"_createdAt":"2024-05-22T20:44:58Z","_id":"ef48392a-90ba-471a-ac50-45bfb8ee62c3","_rev":"05dtDS0H5iRVsxYMarZpVs","_type":"blogPost","_updatedAt":"2025-05-21T20:40:26Z","announcement":[{"_createdAt":"2024-12-15T02:26:13Z","_id":"announcement","_rev":"bDjEm7gsnDBrRrmjaaG2yK","_type":"announcement","_updatedAt":"2025-05-19T19:20:19Z","title":"Meet LlamaIndex at the Databricks Data + AI Summit!","url":"http://48755185.hs-sites.com/llamaindex-0"}],"authors":[{"_createdAt":"2024-05-22T20:32:37Z","_id":"b6bd9472-a268-4df5-b88f-6bac3c5de877","_rev":"R46RXOZp1WXhG9qNKi39kC","_type":"people","_updatedAt":"2024-05-22T20:32:37Z","name":"MyMagic AI","slug":{"_type":"slug","current":"mymagic-ai"}}],"featured":false,"image":{"_type":"image","asset":{"_ref":"image-9deefa59f3a0c792677dd519ba014574a85a538c-1024x1024-webp","_type":"reference"}},"mainImage":"https://cdn.sanity.io/images/7m9jw85w/production/9deefa59f3a0c792677dd519ba014574a85a538c-1024x1024.webp","publishedDate":"2024-05-22","relatedPosts":[],"slug":{"_type":"slug","current":"batch-inference-with-mymagic-ai-and-llamaindex"},"tags":[{"_createdAt":"2024-05-22T20:32:56Z","_id":"832378db-9666-49bb-8e87-c8304aa0f794","_rev":"R46RXOZp1WXhG9qNKi3AGm","_type":"blogTag","_updatedAt":"2024-05-22T20:32:56Z","slug":{"_type":"slug","current":"mymagic-ai"},"title":"MyMagic AI"},{"_createdAt":"2024-05-22T20:33:11Z","_id":"cada807b-622e-46ef-b599-e9e44e63cd10","_rev":"R46RXOZp1WXhG9qNKi3CA4","_type":"blogTag","_updatedAt":"2024-05-22T20:33:11Z","slug":{"_type":"slug","current":"batch-inference"},"title":"Batch inference"}],"text":[{"_key":"a552b38c3477","_type":"block","children":[{"_key":"5fa9b020014e0","_type":"span","marks":["em"],"text":"This is a guest post from MyMagic AI."}],"markDefs":[],"style":"normal"},{"_key":"18b7318cfd4e","_type":"block","children":[{"_key":"f0fb52f85b62","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"973d4cfe39de","_type":"block","children":[{"_key":"7262a024767e","_type":"span","marks":["184bafab5a70"],"text":"MyMagic AI"},{"_key":"5fa9b020014e1","_type":"span","marks":[],"text":" allows processing and analyzing large datasets with AI. MyMagic AI offers a powerful API for "},{"_key":"5fa9b020014e2","_type":"span","marks":["em"],"text":"batch"},{"_key":"5fa9b020014e3","_type":"span","marks":[],"text":" inference (also known as "},{"_key":"5fa9b020014e4","_type":"span","marks":["em"],"text":"offline"},{"_key":"5fa9b020014e5","_type":"span","marks":[],"text":" or "},{"_key":"5fa9b020014e6","_type":"span","marks":["em"],"text":"delayed"},{"_key":"5fa9b020014e7","_type":"span","marks":[],"text":" inference) that brings various open-source Large Language Models (LLMs) such as Llama 70B, Mistral 7B, Mixtral 8x7B, CodeLlama70b, and advanced Embedding models to its users. Our framework is designed to perform data extraction, summarization, categorization, sentiment analysis, training data generation, and embedding, to name a few. And now it's integrated directly into LlamaIndex!"}],"markDefs":[{"_key":"184bafab5a70","_type":"link","href":"https://mymagic.ai/"}],"style":"normal"},{"_key":"b3fa05c49c68","_type":"block","children":[{"_key":"f4986b4fc3b4","_type":"span","marks":[],"text":"Part 1: batch inference"}],"markDefs":[],"style":"h2"},{"_key":"1dae9b176353","_type":"block","children":[{"_key":"5d333cf8b2fd0","_type":"span","marks":[],"text":"How It Works:"}],"markDefs":[],"style":"h3"},{"_key":"a04e9631dac9","_type":"block","children":[{"_key":"4740bdea4e74","_type":"span","marks":["strong"],"text":"1. Setup"},{"_key":"1cd70839e8021","_type":"span","marks":[],"text":":"}],"markDefs":[],"style":"normal"},{"_key":"6c6845d25069","_type":"block","children":[{"_key":"9b46398395cd0","_type":"span","marks":[],"text":"Organize Your Data in an AWS S3 or GCS Bucket:"}],"level":2,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"fc1b1e7ab6a6","_type":"block","children":[{"_key":"814ab5e7ebdb0","_type":"span","marks":[],"text":"Create a folder using your user ID assigned to you upon registration."}],"level":3,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"dfd937c77081","_type":"block","children":[{"_key":"f216fcbfb1740","_type":"span","marks":[],"text":"Inside that folder, create another folder (called a \"session\") to store all the files you need for your tasks."}],"level":3,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"ec58fb871b62","_type":"block","children":[{"_key":"9381862fef590","_type":"span","marks":[],"text":"Purpose of the 'Session' Folder:"}],"level":2,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"9614bc2ac2c3","_type":"block","children":[{"_key":"d61acdec8d450","_type":"span","marks":[],"text":"This \"Session\" folder keeps your files separate from others, making sure that your tasks run on the right set of files. You can name your session subfolder anything you like."}],"level":3,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"a4a4d19c1d8b","_type":"block","children":[{"_key":"acdb962e85120","_type":"span","marks":[],"text":"Granting Access to MyMagic AI:"}],"level":2,"listItem":"number","markDefs":[],"style":"normal"},{"_key":"b823fb12f0f3","_type":"block","children":[{"_key":"19a659ec707e0","_type":"span","marks":[],"text":"To allow MyMagic AI to securely access your files in the cloud, follow the setup instructions provided in the "},{"_key":"19a659ec707e1","_type":"span","marks":["4660f48681bc"],"text":"MyMagic AI documentation"},{"_key":"19a659ec707e2","_type":"span","marks":[],"text":"."}],"level":3,"listItem":"number","markDefs":[{"_key":"4660f48681bc","_type":"link","href":"https://docs.mymagic.ai/"}],"style":"normal"},{"_key":"e16d9891f323","_type":"block","children":[{"_key":"bd6f6113bb830","_type":"span","marks":["strong"],"text":"2. Install"},{"_key":"bd6f6113bb831","_type":"span","marks":[],"text":": Install both MyMagic AI’s API integration and LlamaIndex library:"}],"markDefs":[],"style":"normal"},{"_key":"828b04ccacfa","_type":"codeBlock","code":"pip install llama-index\npip install llama-index-llms-mymagic","language":"sh"},{"_key":"594f0bf92e1e","_type":"block","children":[{"_key":"60d947bf5ab8","_type":"span","marks":["strong"],"text":"3. API Request:"},{"_key":"42266f2f7e8e","_type":"span","marks":[],"text":" The llamaIndex library is a wrapper around MyMagic AI’s API. What it does under the hood is simple: it sends a POST request to the MyMagic AI API while specifying the model, storage provider, bucket name, session name, and other necessary details."}],"markDefs":[],"style":"normal"},{"_key":"30c994c35167","_type":"codeBlock","code":"import asyncio\nfrom llama_index.llms.mymagic import MyMagicAI\n\nllm = MyMagicAI(\n    api_key=\"user_...\", # provided by MyMagic AI upon sign-up\n    storage_provider=\"s3\",\n    bucket_name=\"batch-bucket\", # you may name anything\n    session=\"my-session\",\n    role_arn=\"arn:aws:iam::\u003cyour account id\u003e:role/mymagic-role\",\n    system_prompt=\"You are an AI assistant that helps to summarize the documents without essential loss of information\", # default prompt at https://docs.mymagic.ai/api-reference/endpoint/create\n    region=\"eu-west-2\",\n)","language":"python"},{"_key":"1a0238d27487","_type":"block","children":[{"_key":"83b4ecbbf0140","_type":"span","marks":[],"text":"We have designed the integration to allow the user to set up the bucket and data together with the system prompt when instantiating the llm object. Other inputs, e.g. question (i.e. your prompt), model and max_tokens are dynamic requirements when submitting complete and acomplete requests."}],"markDefs":[],"style":"normal"},{"_key":"c8832cd118ae","_type":"codeBlock","code":"resp = llm.complete(\n    question=\"Summarise this in one sentence.\",\n    model=\"mixtral8x7\", \n    max_tokens=20,  # default is 10\n)\nprint(resp)\nasync def main():\n    aresp = await llm.acomplete(\n        question=\"Summarize this in one sentence.\",\n        model=\"llama7b\",\n        max_tokens=20,\n    )\n    print(aresp)\n\nasyncio.run(main())","language":"python"},{"_key":"0cf8c0fb0c65","_type":"block","children":[{"_key":"6727ee09aa910","_type":"span","marks":[],"text":"This dynamic entry allows developers to experiment with different prompts and models in their workflow while also controlling for model output to cap their spending limit. MyMagic AI’s backend supports both synchronous requests (complete) and asynchronous requests (acomplete). It is advisable, however, to use our async endpoints as much as possible as batch jobs are inherently asynchronous with potentially long processing times (depending on the size of your data)."}],"markDefs":[],"style":"normal"},{"_key":"dde081e24faa","_type":"block","children":[{"_key":"912cf0914e730","_type":"span","marks":[],"text":"Currently, we do not support chat or achat methods as our API is not designed for real-time interactive experience. However, we are planning to add those methods in the future that will function in a “batch way”. The user queries will be aggregated and appended as one prompt (to give the chat context) and sent to all files at once."}],"markDefs":[],"style":"normal"},{"_key":"36b796ce090f","_type":"block","children":[{"_key":"35ebb491cb7a0","_type":"span","marks":[],"text":"Use Cases"}],"markDefs":[],"style":"h3"},{"_key":"222189924bb6","_type":"block","children":[{"_key":"147057ac5ee50","_type":"span","marks":[],"text":"While there are myriads of use cases, here we provide a few to help motivate our users. Feel free to embed our API in your workflows that are good fit for batch processing."}],"markDefs":[],"style":"normal"},{"_key":"58d005152a6f","_type":"block","children":[{"_key":"dbfa7f0818090","_type":"span","marks":[],"text":"1. Extraction"}],"markDefs":[],"style":"h4"},{"_key":"0beaf62fa679","_type":"block","children":[{"_key":"3da04ccf61c50","_type":"span","marks":[],"text":"Imagine needing to extract specific information from millions of files stored in a bucket. Information from all files will be extracted with one API call instead of a million sequential ones."}],"markDefs":[],"style":"normal"},{"_key":"f01cce1b3d1c","_type":"block","children":[{"_key":"0025841a45bb0","_type":"span","marks":[],"text":"2. Classification"}],"markDefs":[],"style":"h4"},{"_key":"9e921ee55f7f","_type":"block","children":[{"_key":"2e1dd75e0c670","_type":"span","marks":[],"text":"For businesses looking to classify customer reviews such as positive, neutral, and negative. With one request you can start processing the requests over the weekend and get them ready by Monday morning."}],"markDefs":[],"style":"normal"},{"_key":"c510660ec77c","_type":"block","children":[{"_key":"82f729caf5c40","_type":"span","marks":[],"text":"3. Embedding"}],"markDefs":[],"style":"h4"},{"_key":"2c908da0344a","_type":"block","children":[{"_key":"6c99f6ca035d0","_type":"span","marks":[],"text":"Embedding text files for further machine learning applications is another powerful use case of MyMagic AI's API. You will be ready for your vector db in a matter of days not weeks."}],"markDefs":[],"style":"normal"},{"_key":"81e9f0addddc","_type":"block","children":[{"_key":"ddc61b4f7c880","_type":"span","marks":[],"text":"4. Training (Fine-tuning) Data Generation"}],"markDefs":[],"style":"h4"},{"_key":"abebd966f501","_type":"block","children":[{"_key":"d94c9dea62dc0","_type":"span","marks":[],"text":"Imagine generating thousands of synthetic data for your fine-tuning tasks. With MyMagic AI’s API, you can reduce the generation time by a factor of 5-10x compared to GPT-3.5."}],"markDefs":[],"style":"normal"},{"_key":"1b85b17d9b44","_type":"block","children":[{"_key":"29f77ffee0c00","_type":"span","marks":[],"text":"5. Transcription"}],"markDefs":[],"style":"h4"},{"_key":"1d334e658167","_type":"block","children":[{"_key":"89ffdf8ee2a70","_type":"span","marks":[],"text":"MyMagic AI’s API supports different types of files, so it is also easy to batch transcribe many mp3 or mp4 files in your bucket."}],"markDefs":[],"style":"normal"},{"_key":"2c885a79cc88","_type":"block","children":[{"_key":"70caaf30ce790","_type":"span","marks":[],"text":"Part 2: Integration with LlamaIndex’s RAG Pipeline"}],"markDefs":[],"style":"h2"},{"_key":"63b72994a204","_type":"block","children":[{"_key":"7493a9ba05ef0","_type":"span","marks":[],"text":"The output from batch inference processes, often voluminous, can seamlessly integrate into LlamaIndex's RAG pipeline for effective data storage and retrieval."}],"markDefs":[],"style":"normal"},{"_key":"dfa306e1020c","_type":"block","children":[{"_key":"ba1eafcfbcee0","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"44960f3bf29b","_type":"block","children":[{"_key":"67d7fa0497ef0","_type":"span","marks":[],"text":"This section demonstrates how to use the Llama3 model from the Ollama library coupled with BGE embedding to manage information storage and execute queries. Please ensure the following prerequisites are installed and Llama3 model is pulled:"}],"markDefs":[],"style":"normal"},{"_key":"6bacc65b50f8","_type":"codeBlock","code":"pip install llama-index-embeddings-huggingface\ncurl -fsSL https://ollama.com/install.sh | sh\nollama pull llama3","language":"sh"},{"_key":"fce925ad228c","_type":"block","children":[{"_key":"c4e5c578dc4f0","_type":"span","marks":[],"text":"For this demo, we have run a batch summarization job on 5 Amazon reviews (but this might be millions in some real scenarios) and saved the results as reviews_1_5.json:"}],"markDefs":[],"style":"normal"},{"_key":"07cf83819a25","_type":"codeBlock","code":"{\n  \"id_review1\": {\n    \"query\": \"Summarize the document!\",\n    \"output\": \"The document describes a family with a young boy who believes there is a zombie in his closet, while his parents are constantly fighting. The movie is criticized for its inconsistent genre, described as a slow-paced drama with occasional thriller elements. The review praises the well-playing parents and the decent dialogs but criticizes the lack of a boogeyman-like horror element. The overall rating is 3 out of 10.\"\n  },\n  \"id_review2\": {\n    \"query\": \"Summarize the document!\",\n    \"output\": \"The document is a positive review of a light-hearted Woody Allen comedy. The reviewer praises the witty dialogue, likable characters, and Woody Allen's control over his signature style. The film is noted for making the reviewer laugh more than any recent Woody Allen comedy and praises Scarlett Johansson's performance. It concludes by calling the film a great comedy to watch with friends.\"\n  },\n  \"id_review3\": {\n    \"query\": \"Summarize the document!\",\n    \"output\": \"The document describes a well-made film about one of the great masters of comedy, filmed in an old-time BBC fashion that adds realism. The actors, including Michael Sheen, are well-chosen and convincing. The production is masterful, showcasing realistic details like the fantasy of the guard and the meticulously crafted sets of Orton and Halliwell's flat. Overall, it is a terrific and well-written piece.\"\n  },\n  \"id_review4\": {\n    \"query\": \"Summarize the document!\",\n    \"output\": \"Petter Mattei's 'Love in the Time of Money' is a visually appealing film set in New York, exploring human relations in the context of money, power, and success. The characters, played by a talented cast including Steve Buscemi and Rosario Dawson, are connected in various ways but often unaware of their shared links. The film showcases the different stages of loneliness experienced by individuals in a big city. Mattei successfully portrays the world of these characters, creating a luxurious and sophisticated look. The film is a modern adaptation of Arthur Schnitzler's play on the same theme. Mattei's work is appreciated, and viewers look forward to his future projects.\"\n  },\n  \"id_review5\": {\n    \"query\": \"Summarize the document!\",\n    \"output\": \"The document describes the TV show 'Oz', set in the Oswald Maximum Security State Penitentiary. Known for its brutality, violence, and lack of privacy, it features an experimental section of the prison called Em City, where all the cells have glass fronts and face inwards. The show goes where others wouldn't dare, featuring graphic violence, injustice, and the harsh realities of prison life. The viewer may become comfortable with uncomfortable viewing if they can embrace their darker side.\"\n  },\n  \"token_count\": 3391\n}\n","language":"text"},{"_key":"1028b9100f40","_type":"block","children":[{"_key":"007bf9994f0c0","_type":"span","marks":[],"text":"Now let’s embed and store this document and ask questions using LlamaIndex’s query engine. Bring in our dependencies:"}],"markDefs":[],"style":"normal"},{"_key":"7b826b1eb476","_type":"codeBlock","code":"import os\n\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom llama_index.core.indices.vector_store import VectorStoreIndex\nfrom llama_index.core.settings import Settings\nfrom llama_index.core.readers import SimpleDirectoryReader\nfrom llama_index.llms.ollama import Ollama","language":"python"},{"_key":"f6fea6e9c9b4","_type":"block","children":[{"_key":"7666c8d345690","_type":"span","marks":[],"text":"Configure the embedding model and Llama3 model"}],"markDefs":[],"style":"normal"},{"_key":"9f44a5b95ff8","_type":"codeBlock","code":"embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\nllm = Ollama(model=\"llama3\", request_timeout=300.0)","language":"python"},{"_key":"abfd2d3eddd7","_type":"block","children":[{"_key":"20019792252a","_type":"span","marks":[],"text":"Update settings for the indexing pipeline:"}],"markDefs":[],"style":"normal"},{"_key":"8be951b11741","_type":"codeBlock","code":"Settings.llm = llm\nSettings.embed_model = embed_model\nSettings.chunk_size = 512 # This parameter defines the size of text chunks for embedding\n\ndocuments = SimpleDirectoryReader(\"reviews_1_5.json\").load_data() #Modify path for your case","language":"python"},{"_key":"d5f5c376af92","_type":"block","children":[{"_key":"d2c86c7a5ab5","_type":"span","marks":[],"text":"Now create our index, our query engine and run a query:"}],"markDefs":[],"style":"normal"},{"_key":"c8b8a38fc8fd","_type":"codeBlock","code":"index = VectorStoreIndex.from_documents(documents, show_progress=True)\n\nquery_engine = index.as_query_engine(similarity_top_k=3)\n\nresponse = query_engine.query(\"What is the least favourite movie?\")\nprint(response)","language":"python"},{"_key":"666f732c36ce","_type":"block","children":[{"_key":"c1692dfde2cf","_type":"span","marks":[],"text":"Output:"}],"markDefs":[],"style":"normal"},{"_key":"b5979497af23","_type":"codeBlock","code":"Based on query results, the least favourite movie is: review 1 with a rating of 3 out of 10.","language":"text"},{"_key":"1fe4b40bb5c9","_type":"block","children":[{"_key":"d0f7da3d7c070","_type":"span","marks":[],"text":"Now we know that the review 1 is the least favorite movie among these reviews."}],"markDefs":[],"style":"normal"},{"_key":"6d4558a804ae","_type":"block","children":[{"_key":"40ed2a3322bd","_type":"span","marks":[],"text":"Next Steps"}],"markDefs":[],"style":"h2"},{"_key":"cc53b6146212","_type":"block","children":[{"_key":"9144af4fb2d70","_type":"span","marks":[],"text":"This shows how batch inference combined with real-time inference can be a powerful tool for analyzing, storing and retrieving information from massive amounts of data. "},{"_key":"880148e675440","_type":"span","marks":["798c8eafe7fc"],"text":"Get started with MyMagic AI’s API"},{"_key":"ddd9a6b2b3bf","_type":"span","marks":[],"text":" today!"}],"markDefs":[{"_key":"798c8eafe7fc","_type":"link","href":"https://vivacious-river-18.authkit.app/sign-up?redirect_uri=https://api.mymagic.ai/workspace"}],"style":"normal"},{"_key":"a1935305e4e3","_type":"block","children":[{"_key":"184ddbda75520","_type":"span","marks":[],"text":"\n"}],"markDefs":[],"style":"normal"}],"title":"Batch inference with MyMagic AI and LlamaIndex"},"publishedDate":"Invalid Date"},"params":{"slug":"batch-inference-with-mymagic-ai-and-llamaindex"},"draftMode":false,"token":""},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"batch-inference-with-mymagic-ai-and-llamaindex"},"buildId":"C8J-EMc_4OCN1ch65l4fl","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>